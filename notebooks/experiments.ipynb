{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm import generate_response\n",
    "from src.experiments import run_experiment, evaluate_experiment, generate_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generate_fn = lambda t: [generate_response(\"meta-llama/Llama-3-70b-chat-hf\", t.input, i * 0.4) for i in range(3)]\n",
    "\n",
    "config = {\n",
    "    \"name\":\"temperature_sampling_test\",\n",
    "    \"dataset\": \"dataset.+schema.originating_dfs.header_description.after_variable_cell.maxp6000.maxp_no_prefix-1.maxctxcell-1.schema_only.json\",\n",
    "    \"dataset_src\": \"existing_tasks\"\n",
    "}\n",
    "\n",
    "run_experiment(generate_fn, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_experiment(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments import generate_additional_metrics\n",
    "\n",
    "config = {\n",
    "    \"name\":\"temperature_sampling_test\",\n",
    "    \"dataset\": \"dataset.+schema.originating_dfs.header_description.after_variable_cell.maxp6000.maxp_no_prefix-1.maxctxcell-1.schema_only.json\",\n",
    "    \"dataset_src\": \"existing_tasks\"\n",
    "}\n",
    "\n",
    "generate_additional_metrics(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "config = {\n",
    "    \"name\":\"temperature_sampling_test\",\n",
    "    \"dataset\": \"dataset.+schema.originating_dfs.header_description.after_variable_cell.maxp6000.maxp_no_prefix-1.maxctxcell-1.schema_only.json\",\n",
    "    \"dataset_src\": \"existing_tasks\"\n",
    "}\n",
    "\n",
    "EXPERIMENTS_ROOT = \"experiments\"\n",
    "DATASETS_ROOT = \"arcade_nl2code/annotated_dataset/dataset\"\n",
    "\n",
    "def generate_results_df(config):\n",
    "    current_dir = os.getcwd()\n",
    "    folder_path = os.path.join(current_dir, EXPERIMENTS_ROOT, config['name'])\n",
    "    predictions_path = os.path.join(folder_path, \"predictions.json\")\n",
    "    metadata_path = os.path.join(current_dir, \"metadata\", config[\"dataset_src\"], \"tasks.csv\")\n",
    "    output_path = os.path.join(folder_path, \"results.csv\")\n",
    "\n",
    "    with open(predictions_path, \"r\") as f:\n",
    "        predictions = json.loads(f.read())\n",
    "\n",
    "    tasks = []\n",
    "\n",
    "    for notebook in predictions:\n",
    "        for i, turn in enumerate(notebook[\"turns\"]):\n",
    "            task = {}\n",
    "\n",
    "            preds = turn[\"predictions\"]\n",
    "            ref = turn[\"metadata\"][\"example\"][\"turn\"][\"code\"][\"value\"]\n",
    "            codebleu_scores = [calc_codebleu([ref], [p], lang=\"python\") for p in preds]\n",
    "            \n",
    "            task[\"notebook_name\"] = notebook[\"metadata\"][\"notebook_name\"]\n",
    "            task[\"turn_index\"] = i\n",
    "            task[\"predictions\"] = turn[\"predictions\"]\n",
    "            task[\"reference\"] = turn[\"metadata\"][\"example\"][\"turn\"][\"code\"][\"value\"]\n",
    "            task[\"results\"] = [e | s for e, s in zip(turn[\"eval_results\"], codebleu_scores)]\n",
    "            tasks.append(task)\n",
    "    \n",
    "    df_tasks = pd.DataFrame(tasks)\n",
    "    df_metadata = pd.read_csv(metadata_path)\n",
    "    df = df_tasks.merge(df_metadata, on=['notebook_name', 'turn_index'])\n",
    "    df.to_csv(output_path, encoding='utf-8', index=False)\n",
    "\n",
    "generate_results_df(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = {\n",
    "    name: \"basic_test_experiment\",\n",
    "    dataset_name: \n",
    "    model_name: \"llama70b\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"vanilla_default\": {\n",
    "        \"dataset_name\": \"vanilla_default\",\n",
    "        \"add_exemplars\": False,\n",
    "        \"max_prompt_size\": 900,\n",
    "        \"max_notebook_context_length\": 1200,\n",
    "        \"prompt_style\": \"vanilla\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM(Enum):\n",
    "    LLAMA_8B\n",
    "    LLAMA_70B\n",
    "    DEEPSEEK_33B\n",
    "    GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm import generate_response\n",
    "from src.experiments import run_experiment\n",
    "\n",
    "temperatures = [0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "def generate_fn(model, task):\n",
    "    return [generate_response(model, task.input, t) for t in temperatures]\n",
    "\n",
    "config = { \n",
    "    \"name\":\"vanilla_baseline\",\n",
    "    \"generate_fn\": generate_fn,\n",
    "    \"models\": [\"LLAMA3_INSTRUCT_8B\", \"LLAMA3_INSTRUCT_70B\"],\n",
    "    \"dataset\": {\n",
    "        \"dataset_name\": \"vanilla_default\",\n",
    "        \"add_exemplars\": False,\n",
    "        \"max_prompt_size\": 900,\n",
    "        \"max_notebook_context_length\": 1200,\n",
    "        \"prompt_style\": \"vanilla\"\n",
    "    },\n",
    "    \"metadata\":{\n",
    "        \"temperatures\": temperatures\n",
    "    }\n",
    "}\n",
    "\n",
    "run_experiment(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm import generate_response\n",
    "from src.experiments import run_experiment\n",
    "\n",
    "config = {\n",
    "    \"name\":\"vanilla_baseline\",\n",
    "    \"dataset\": {\n",
    "        \"dataset_name\": \"vanilla_default\",\n",
    "        \"add_exemplars\": False,\n",
    "        \"max_prompt_size\": 900,\n",
    "        \"max_notebook_context_length\": 1200,\n",
    "        \"prompt_style\": \"vanilla\"\n",
    "    },\n",
    "    \"models\": [\"llama3-70b\"]\n",
    "}\n",
    "\n",
    "run_experiment(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments import generate_dataset\n",
    "\n",
    "config = { \n",
    "    \"name\":\"vanilla_exemplars\",\n",
    "    # \"generate_fn\": generate_fn,\n",
    "    \"models\": [\"LLAMA3_INSTRUCT_8B\", \"LLAMA3_INSTRUCT_70B\", \"DEEPSEEK_CODER_33B\"],\n",
    "    \"dataset\": {\n",
    "        \"dataset_name\": \"vanilla_exemplars\",\n",
    "        \"add_exemplars\": True,\n",
    "        \"max_prompt_size\": 2100,\n",
    "        \"max_notebook_context_length\": 1200,\n",
    "        \"prompt_style\": \"vanilla\"\n",
    "    },\n",
    "    \"metadata\":{\n",
    "        # \"temperatures\": temperatures\n",
    "    }\n",
    "}\n",
    "\n",
    "generate_dataset(**config[\"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments import run_experiment\n",
    "\n",
    "config = { \n",
    "    \"name\":\"vanilla_baseline_no_max_token\",\n",
    "    \"models\": [\"LLAMA3_INSTRUCT_8B\", \"LLAMA3_INSTRUCT_70B\"],\n",
    "    \"dataset\": {\n",
    "        \"dataset_name\": \"vanilla_default\"\n",
    "    }\n",
    "}\n",
    "\n",
    "run_experiment(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm import generate_response\n",
    "generate_response(\"LLAMA3_INSTRUCT_70B\", \"hello there\", 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "def generate_fn(model):\n",
    "    return [(generate_response, model, \"hello there\", 0.2) for i in range(25)]\n",
    "\n",
    "\n",
    "with futures.ThreadPoolExecutor(10) as executor:\n",
    "    fs = [executor.submit(*args) for args in generate_fn(\"LLAMA3_INSTRUCT_70B\")]\n",
    "    code_strs = [f.result() for f in futures.as_completed(fs)]\n",
    "    print(code_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
