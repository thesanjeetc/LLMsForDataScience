{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "DATASETS_ROOT = \"arcade_nl2code/annotated_dataset/dataset\"\n",
    "\n",
    "dataset_src = \"existing_tasks\"\n",
    "trunccate_path = \"dataset.schema.originating_dfs.header_description.after_variable_cell.maxp900.maxp_no_prefix-1.maxctxcell-1.truncate_metadata.json\"\n",
    "max_prompt = 4000\n",
    "schema_repr = \"originating_dfs.header_description.after_variable_cell\"\n",
    "\n",
    "dataset_path = os.path.join(DATASETS_ROOT, dataset_src, \"dataset.json\")\n",
    "folder_path = os.path.join(DATASETS_ROOT, dataset_src, \"derived_datasets/\")\n",
    "artifacts_path = os.path.join(DATASETS_ROOT, dataset_src, \"artifacts/\")\n",
    "truncate_metadata_path = os.path.join(folder_path, trunccate_path)\n",
    "\n",
    "command = [\n",
    "    \"faketime\", \"2022-12-10 12:00:00\",\n",
    "    \"python\", \"-m\",\n",
    "    \"arcade_nl2code.annotated_dataset.generate_schema_augmented_prompts\",\n",
    "    \"--dataset\", dataset_path,\n",
    "    \"--output_folder\", folder_path,\n",
    "    \"--runtime_artifacts_root\", artifacts_path,\n",
    "    \"--schema_representation_method\", schema_repr,\n",
    "    \"--max_prompt_size\", str(max_prompt),\n",
    "    \"--truncate_metadata_path\", truncate_metadata_path,\n",
    "    \"--ignore_errors\"\n",
    "]\n",
    "\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def generate_dataset(\n",
    "    dataset_name,\n",
    "    dataset_src, \n",
    "    add_exemplars=False\n",
    "    max_prompt_size = 4000\n",
    "    max_notebook_context_length = 3000,\n",
    "    prompt_style=\"vanilla\"\n",
    "):    \n",
    "    DATASETS_ROOT = \"arcade_nl2code/annotated_dataset/dataset\"\n",
    "    schema_repr_method = \"originating_dfs.header_description.after_variable_cell\"\n",
    "\n",
    "    dataset_path = os.path.join(DATASETS_ROOT, dataset_src, \"dataset.json\")\n",
    "    folder_path = os.path.join(\"datasets\", dataset_src, \"derived_datasets/\")\n",
    "    artifacts_path = os.path.join(DATASETS_ROOT, dataset_src, \"artifacts/\")\n",
    "\n",
    "    prompt_styles = {\n",
    "        \"vanilla\": \"short_code_no_preamble\", \n",
    "        \"step_by_step\": \"step_only_no_preamble\", \n",
    "        \"step_by_step+preamble\": \"step_only\", \n",
    "        \"step_by_step+preamble+explanation\": \"step+explanation\"\n",
    "    }\n",
    "\n",
    "    file_name_prefix=f\"dataset.{dataset_name}\"\n",
    "\n",
    "    dataset_file_name=f\"{file_name_prefix}.{prompt_style}.json\"\n",
    "    cmd = [\n",
    "        \"faketime\", \"2022-12-10 12:00:00\", \n",
    "        \"python\", \"-m\",\n",
    "        \"arcade_nl2code.annotated_dataset.generate_schema_augmented_prompts\",\n",
    "        \"--dataset\", dataset_path,\n",
    "        \"--output_folder\", folder_path,\n",
    "        \"--output_dataset_name\", dataset_file_name,\n",
    "        \"--runtime_artifacts_root\", artifacts_path,\n",
    "        \"--schema_representation_method\", schema_repr_method,\n",
    "        \"--max_prompt_size\", str(max_prompt_size),\n",
    "    ]\n",
    "\n",
    "    if add_exemplars:\n",
    "        cmd.extend([\n",
    "            \"--max_notebook_context_len\", str(max_notebook_context_length),\n",
    "            \"--add_exemplars\",\n",
    "            \"--exemplar_notebook\", \"arcade_nl2code/annotated_dataset/resources/prompt_exemplar_templates.ipynb\",\n",
    "            \"--format_configs\", prompt_styles[prompt_style],\n",
    "            \"--exemplar_index\", \"0,1,2,3,4,5\"\n",
    "        ])\n",
    "        \n",
    "\n",
    "    subprocess.run(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset(\"existing_tasks\", add_exemplars=True, prompt_style=\"step_by_step+preamble+explanation\", exemplar_index_str=\"0,1,4,5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_ROOT = \"arcade_nl2code/annotated_dataset/dataset\"\n",
    "\n",
    "dataset_src = \"existing_tasks\"\n",
    "max_prompt_size = 6000\n",
    "schema_repr_method = \"originating_dfs.header_description.after_variable_cell\"\n",
    "\n",
    "dataset_path = os.path.join(DATASETS_ROOT, dataset_src, \"dataset.json\")\n",
    "folder_path = os.path.join(\"datasets\", dataset_src, \"derived_datasets/\")\n",
    "artifacts_path = os.path.join(DATASETS_ROOT, dataset_src, \"artifacts/\")\n",
    "truncate_metadata_path = os.path.join(folder_path, trunccate_path)\n",
    "\n",
    "\n",
    "for exemplar_index in [\"1,2,3,5\", \"1,3,4,5\", \"0,1,4,5\"]:\n",
    "    exemplar_index_string = exemplar_index.replace(\",\", \"_\")\n",
    "\n",
    "    config_names = [\"short_code_no_preamble\", \"step_only_no_preamble\", \"step_only\", \"step+explanation\"]\n",
    "    prompt_styles = [\"vanilla_prompting\", \"step_by_step\", \"step_by_step+preamble\", \"step_by_step+preamble+explanation\"]\n",
    "\n",
    "    for i in range(len(config_names)):\n",
    "        config_name = config_names[i]\n",
    "        prompt_style = prompt_styles[i]\n",
    "\n",
    "        subprocess.run([\n",
    "            \"faketime\", \"2022-12-10 12:00:00\", \"python\", \"-m\",\n",
    "            \"arcade_nl2code.annotated_dataset.generate_schema_augmented_prompts\",\n",
    "            \"--dataset\", dataset_path,\n",
    "            \"--output_folder\", folder_path,\n",
    "            \"--runtime_artifacts_root\", artifacts_path,\n",
    "            \"--schema_representation_method\", schema_repr_method,\n",
    "            \"--max_prompt_size\", str(max_prompt_size),\n",
    "            \"--add_exemplars\",\n",
    "            \"--exemplar_notebook\", \"arcade_nl2code/annotated_dataset/resources/prompt_exemplar_templates.ipynb\",\n",
    "            \"--format_configs\", config_name,\n",
    "            \"--exemplar_index\", exemplar_index,\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments import generate_dataset\n",
    "\n",
    "# generate_dataset(\"vanilla_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"name\":\"vanilla_default_llama\",\n",
    "    \"dataset\": {\n",
    "        \"dataset_name\": \"vanilla_default\",\n",
    "        \"add_exemplars\": False,\n",
    "        \"max_prompt_size\": 900,\n",
    "        \"max_notebook_context_length\": 1200,\n",
    "        \"prompt_style\": \"vanilla\"\n",
    "    },\n",
    "    \"models\": [\"llama3-70b\"]\n",
    "}\n",
    "\n",
    "generate_dataset(**config[\"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -r arcade_nl2code/annotated_dataset/dataset/existing_tasks/artifacts/ artifacts/\n",
    "cp -r arcade_nl2code/annotated_dataset/dataset/new_tasks/artifacts/ artifacts/\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "DATASETS_DIR = \"arcade_nl2code/annotated_dataset/dataset/\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for dataset_src in [\"existing_tasks\", \"new_tasks\"]:\n",
    "    temp_dataset_path = os.path.join(DATASETS_DIR, dataset_src, \"dataset.json\")\n",
    "    with open(temp_dataset_path, \"r\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    dataset.extend(list(map(lambda n: n | {\"dataset_src\": dataset_src}, data)))\n",
    "\n",
    "    with open(os.path.join(\"datasets\", \"dataset.json\"), \"w\") as f:\n",
    "        f.write(json.dumps(dataset, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "DATASETS_DIR = \"../datasets/arcade\"\n",
    "\n",
    "for d in [\".arcade.few_shot.cot.explanations.json\", \".arcade.few_shot.cot.json\", \".arcade.few_shot.vanilla.json\"]:\n",
    "    dataset = []\n",
    "    for dataset_src in [\"existing_tasks\", \"new_tasks\"]:\n",
    "        dp = f\"dataset.{dataset_src}{d}\"\n",
    "        temp_dataset_path = os.path.join(DATASETS_DIR, dp)\n",
    "        with open(temp_dataset_path, \"r\") as f:\n",
    "            data = json.loads(f.read())\n",
    "        dataset.extend(list(map(lambda n: n | {\"dataset_src\": dataset_src}, data)))\n",
    "\n",
    "    with open(os.path.join(\"../datasets\", f\"dataset{d}\"), \"w\") as f:\n",
    "        f.write(json.dumps(dataset, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
