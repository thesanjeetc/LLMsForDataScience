
        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> air-condition-dataac/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert columns with numeric values to numeric data types</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>air.power_consumption = air.power_consumption.str.extract('(\d+)').astype(float)
air.refrigerant = air.refrigerant.str.extract('(\d+)').astype(float)
air.noise_level = air.noise_level.str.extract('(\d+)').astype(float)
air.price = air.price.str.extract('(\d+)').astype(float)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>air.power_consumption = air.power_consumption.str.extract('(\d+)').astype(float)
air.refrigerant = air.refrigerant.str.extract('(\d+)').astype(float)
air.noise_level = air.noise_level.str.extract('(\d+)').astype(float)
air.price = air.price.str.extract('(\d+)').astype(float)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>air.power_consumption = air.power_consumption.str.extract('(\\d+)').astype(
    float)
air.refrigerant = air.refrigerant.str.extract('(\\d+)').astype(float)
air.noise_level = air.noise_level.str.extract('(\\d+)').astype(float)
__output__ = air.price = air.price.str.extract('(\\d+)').astype(float)
</code></pre>
        <p><span onclick="$('#var_output_e6ac92f4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e6ac92f4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>27294.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>38999.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28490.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>32999.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>27490.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>42990.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>35990.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>269</th>
      <td>37490.0</td>
    </tr>
    <tr>
      <th>270</th>
      <td>32999.0</td>
    </tr>
    <tr>
      <th>271</th>
      <td>34890.0</td>
    </tr>
    <tr>
      <th>272</th>
      <td>49500.0</td>
    </tr>
    <tr>
      <th>273</th>
      <td>32999.0</td>
    </tr>
    <tr>
      <th>274</th>
      <td>38990.0</td>
    </tr>
    <tr>
      <th>275</th>
      <td>38559.0</td>
    </tr>
  </tbody>
</table>
<p>276 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> air, __output__ </p>
    
          <p>air (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>brand_name</th>
      <th>ton</th>
      <th>condenser_coil</th>
      <th>power_consumption</th>
      <th>refrigerant</th>
      <th>noise_level</th>
      <th>star</th>
      <th>ratings</th>
      <th>price</th>
      <th>image_url</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Haier</td>
      <td>1</td>
      <td>Copper</td>
      <td>704.0</td>
      <td>32.0</td>
      <td>26.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>27294.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l1ch4sw0/air-conditioner-new/0/j/f/-original-imagcxh3d6ezzqhp.jpeg?q=70</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Daikin</td>
      <td>1.5</td>
      <td>Alloy</td>
      <td>1304.0</td>
      <td>32.0</td>
      <td>42.0</td>
      <td>4.2</td>
      <td>0</td>
      <td>38999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l2krs7k0/air-conditioner-new/v/x/g/-original-imagdwym4y6wb4vu.jpeg?q=70</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Croma</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1570.0</td>
      <td>32.0</td>
      <td>49.0</td>
      <td>3.8</td>
      <td>75</td>
      <td>28490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l1pc3gw0/air-conditioner-new/y/e/h/-original-imagd7qhxffd2ksw.jpeg?q=70</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Panasonic</td>
      <td>1</td>
      <td>Copper</td>
      <td>1095.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0sgyvk0/air-conditioner-new/4/8/i/-original-imagchbyyxgnsztk.jpeg?q=70</td>
    </tr>
    <tr>
      <th>4</th>
      <td>MarQ</td>
      <td>By</td>
      <td>Copper</td>
      <td>712.0</td>
      <td>32.0</td>
      <td>40.0</td>
      <td>4.0</td>
      <td>642</td>
      <td>27490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzfvzww0/air-conditioner-new/j/p/s/-original-imagbgbzyx7vkpvj.jpeg?q=70</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Panasonic</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>840.0</td>
      <td>32.0</td>
      <td>46.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>42990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0r1j0w0/air-conditioner-new/n/i/w/-original-imagcgg5ktjp2p3j.jpeg?q=70</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Panasonic</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1056.0</td>
      <td>32.0</td>
      <td>48.0</td>
      <td>4.2</td>
      <td>1125</td>
      <td>35990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kltryq80/air-conditioner-new/l/l/y/cs-ru18xkytw-cu-ru18xkytw-split-panasonic-inverter-original-imagyugnrnv2djmk.jpeg?q=70</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>269</th>
      <td>LG</td>
      <td>Convertible</td>
      <td>Copper</td>
      <td>571.0</td>
      <td>32.0</td>
      <td>21.0</td>
      <td>4.3</td>
      <td>9470</td>
      <td>37490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/klfhk7k0/air-conditioner-new/s/8/c/ms-q18ynza-split-lg-dual-inverter-original-imagyk3ergg9fveh.jpeg?q=70</td>
    </tr>
    <tr>
      <th>270</th>
      <td>Panasonic</td>
      <td>1</td>
      <td>Copper</td>
      <td>1095.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0sgyvk0/air-conditioner-new/4/8/i/-original-imagchbyyxgnsztk.jpeg?q=70</td>
    </tr>
    <tr>
      <th>271</th>
      <td>Lloyd</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1440.0</td>
      <td>32.0</td>
      <td>57.0</td>
      <td>4.1</td>
      <td>0</td>
      <td>34890.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kmuxevk0/air-conditioner-new/9/w/1/gls18i36wsel-split-lloyd-inverter-original-imagfnav3j88g9hd.jpeg?q=70</td>
    </tr>
    <tr>
      <th>272</th>
      <td>Hitachi</td>
      <td>2</td>
      <td>Copper</td>
      <td>2350.0</td>
      <td>410.0</td>
      <td>37.0</td>
      <td>4.2</td>
      <td>2029</td>
      <td>49500.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kd4uj680/air-conditioner-new/y/8/p/rmi-emi-cmi-324hbea-mps-2-split-hitachi-inverter-original-imafu44ge2gsrsvt.jpeg?q=70</td>
    </tr>
    <tr>
      <th>273</th>
      <td>CARRIER</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1550.0</td>
      <td>32.0</td>
      <td>58.0</td>
      <td>4.2</td>
      <td>810</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/klphn680/air-conditioner-new/o/7/2/caw18sn5r39f0-window-carrier-fixed-speed-original-imagys52wsawg9cn.jpeg?q=70</td>
    </tr>
    <tr>
      <th>274</th>
      <td>LIVPURE</td>
      <td>1</td>
      <td>Copper</td>
      <td>1080.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.2</td>
      <td>2586</td>
      <td>38990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kn7sdjk0/air-conditioner-new/g/g/u/hks-in12k3s19a-split-livpure-inverter-original-imagfxxzhx7wnwjz.jpeg?q=70</td>
    </tr>
    <tr>
      <th>275</th>
      <td>SAMSUNG</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1490.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>38559.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0r1j0w0/air-conditioner-new/l/k/k/-original-imagcgzz4hjpdpga.jpeg?q=70</td>
    </tr>
  </tbody>
</table>
<p>276 rows × 10 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>27294.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>38999.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28490.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>32999.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>27490.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>42990.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>35990.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>269</th>
      <td>37490.0</td>
    </tr>
    <tr>
      <th>270</th>
      <td>32999.0</td>
    </tr>
    <tr>
      <th>271</th>
      <td>34890.0</td>
    </tr>
    <tr>
      <th>272</th>
      <td>49500.0</td>
    </tr>
    <tr>
      <th>273</th>
      <td>32999.0</td>
    </tr>
    <tr>
      <th>274</th>
      <td>38990.0</td>
    </tr>
    <tr>
      <th>275</th>
      <td>38559.0</td>
    </tr>
  </tbody>
</table>
<p>276 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> air-condition-dataac/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average prices wihin brands that produce AC units with Alloy and Copper condenser coils?  Show brand names as an index and condenser coil materials as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>air.groupby(['brand_name','condenser_coil']).price.mean().unstack().dropna(subset=['Alloy','Copper'])[['Alloy','Copper']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>air.groupby(['brand_name','condenser_coil']).price.mean().unstack().dropna(subset=['Alloy','Copper'])[['Alloy','Copper']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = air.groupby(['brand_name', 'condenser_coil']).price.mean(
    ).unstack().dropna(subset=['Alloy', 'Copper'])[['Alloy', 'Copper']]
</code></pre>
        <p><span onclick="$('#var_output_a1f74660').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a1f74660" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>condenser_coil</th>
      <th>Alloy</th>
      <th>Copper</th>
    </tr>
    <tr>
      <th>brand_name</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Daikin</th>
      <td>38999.0</td>
      <td>40881.47619</td>
    </tr>
    <tr>
      <th>SAMSUNG</th>
      <td>43500.0</td>
      <td>37332.62500</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>condenser_coil</th>
      <th>Alloy</th>
      <th>Copper</th>
    </tr>
    <tr>
      <th>brand_name</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Daikin</th>
      <td>38999.0</td>
      <td>40881.47619</td>
    </tr>
    <tr>
      <th>SAMSUNG</th>
      <td>43500.0</td>
      <td>37332.62500</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> air-condition-dataac/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which brand produces the highest number of units having less than forty decibels? Return the name of the brand and number of units.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = air.groupby([air.noise_level<40,'brand_name',]).size().unstack(0)
df.columns = ['noise<40','noise>=40']
df = df['noise>=40'].agg(['idxmax','max'])
df.index = ['brand_name','units']
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = air.groupby([air.noise_level<40,'brand_name',]).size().unstack(0)
df.columns = ['noise<40','noise>=40']
df = df['noise>=40'].agg(['idxmax','max'])
df.index = ['brand_name','units']
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = air.groupby([air.noise_level < 40, 'brand_name']).size().unstack(0)
df.columns = ['noise<40', 'noise>=40']
df = df['noise>=40'].agg(['idxmax', 'max'])
df.index = ['brand_name', 'units']
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_9e44394d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9e44394d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>brand_name    Daikin
units           13.0
Name: noise>=40, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (Series):</p>
          <pre><code>brand_name    Daikin
units           13.0
Name: noise>=40, dtype: object</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>brand_name    Daikin
units           13.0
Name: noise>=40, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> air-condition-dataac/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent change in average price of AC units for every one star increase in customer feedback?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>air.groupby((air.star).astype(int)).price.mean().pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>air.groupby((air.star).astype(int)).price.mean().pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = air.groupby(air.star.astype(int)).price.mean().pct_change()
</code></pre>
        <p><span onclick="$('#var_output_bbff728b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bbff728b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>star
0         NaN
2    0.066630
3   -0.182656
4    0.059657
5   -0.117327
Name: price, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>star
0         NaN
2    0.066630
3   -0.182656
4    0.059657
5   -0.117327
Name: price, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> air-condition-dataac/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new column 'power_consumption_group' that maps the AC units' power consumption into bins of 500.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>bounds = (round(air.power_consumption / 500) *500).agg(['min','max'])
air['power_consumption_group'] = pd.cut(air.power_consumption,
                                        bins = np.arange(bounds['min'],bounds['max'],500))
air</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>bounds = (round(air.power_consumption / 500) *500).agg(['min','max'])
air['power_consumption_group'] = pd.cut(air.power_consumption,
                                        bins = np.arange(bounds['min'],bounds['max'],500))
air</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>bounds = (round(air.power_consumption / 500) * 500).agg(['min', 'max'])
air['power_consumption_group'] = pd.cut(air.power_consumption, bins=np.
    arange(bounds['min'], bounds['max'], 500))
__output__ = air
</code></pre>
        <p><span onclick="$('#var_output_3f290735').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3f290735" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>brand_name</th>
      <th>ton</th>
      <th>condenser_coil</th>
      <th>power_consumption</th>
      <th>refrigerant</th>
      <th>noise_level</th>
      <th>star</th>
      <th>ratings</th>
      <th>price</th>
      <th>image_url</th>
      <th>power_consumption_group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Haier</td>
      <td>1</td>
      <td>Copper</td>
      <td>704.0</td>
      <td>32.0</td>
      <td>26.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>27294.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l1ch4sw0/air-conditioner-new/0/j/f/-original-imagcxh3d6ezzqhp.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Daikin</td>
      <td>1.5</td>
      <td>Alloy</td>
      <td>1304.0</td>
      <td>32.0</td>
      <td>42.0</td>
      <td>4.2</td>
      <td>0</td>
      <td>38999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l2krs7k0/air-conditioner-new/v/x/g/-original-imagdwym4y6wb4vu.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Croma</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1570.0</td>
      <td>32.0</td>
      <td>49.0</td>
      <td>3.8</td>
      <td>75</td>
      <td>28490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l1pc3gw0/air-conditioner-new/y/e/h/-original-imagd7qhxffd2ksw.jpeg?q=70</td>
      <td>(1500.0, 2000.0]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Panasonic</td>
      <td>1</td>
      <td>Copper</td>
      <td>1095.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0sgyvk0/air-conditioner-new/4/8/i/-original-imagchbyyxgnsztk.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>MarQ</td>
      <td>By</td>
      <td>Copper</td>
      <td>712.0</td>
      <td>32.0</td>
      <td>40.0</td>
      <td>4.0</td>
      <td>642</td>
      <td>27490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzfvzww0/air-conditioner-new/j/p/s/-original-imagbgbzyx7vkpvj.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Panasonic</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>840.0</td>
      <td>32.0</td>
      <td>46.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>42990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0r1j0w0/air-conditioner-new/n/i/w/-original-imagcgg5ktjp2p3j.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Panasonic</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1056.0</td>
      <td>32.0</td>
      <td>48.0</td>
      <td>4.2</td>
      <td>1125</td>
      <td>35990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kltryq80/air-conditioner-new/l/l/y/cs-ru18xkytw-cu-ru18xkytw-split-panasonic-inverter-original-imagyugnrnv2djmk.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>269</th>
      <td>LG</td>
      <td>Convertible</td>
      <td>Copper</td>
      <td>571.0</td>
      <td>32.0</td>
      <td>21.0</td>
      <td>4.3</td>
      <td>9470</td>
      <td>37490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/klfhk7k0/air-conditioner-new/s/8/c/ms-q18ynza-split-lg-dual-inverter-original-imagyk3ergg9fveh.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>270</th>
      <td>Panasonic</td>
      <td>1</td>
      <td>Copper</td>
      <td>1095.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0sgyvk0/air-conditioner-new/4/8/i/-original-imagchbyyxgnsztk.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>271</th>
      <td>Lloyd</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1440.0</td>
      <td>32.0</td>
      <td>57.0</td>
      <td>4.1</td>
      <td>0</td>
      <td>34890.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kmuxevk0/air-conditioner-new/9/w/1/gls18i36wsel-split-lloyd-inverter-original-imagfnav3j88g9hd.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>272</th>
      <td>Hitachi</td>
      <td>2</td>
      <td>Copper</td>
      <td>2350.0</td>
      <td>410.0</td>
      <td>37.0</td>
      <td>4.2</td>
      <td>2029</td>
      <td>49500.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kd4uj680/air-conditioner-new/y/8/p/rmi-emi-cmi-324hbea-mps-2-split-hitachi-inverter-original-imafu44ge2gsrsvt.jpeg?q=70</td>
      <td>(2000.0, 2500.0]</td>
    </tr>
    <tr>
      <th>273</th>
      <td>CARRIER</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1550.0</td>
      <td>32.0</td>
      <td>58.0</td>
      <td>4.2</td>
      <td>810</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/klphn680/air-conditioner-new/o/7/2/caw18sn5r39f0-window-carrier-fixed-speed-original-imagys52wsawg9cn.jpeg?q=70</td>
      <td>(1500.0, 2000.0]</td>
    </tr>
    <tr>
      <th>274</th>
      <td>LIVPURE</td>
      <td>1</td>
      <td>Copper</td>
      <td>1080.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.2</td>
      <td>2586</td>
      <td>38990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kn7sdjk0/air-conditioner-new/g/g/u/hks-in12k3s19a-split-livpure-inverter-original-imagfxxzhx7wnwjz.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>275</th>
      <td>SAMSUNG</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1490.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>38559.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0r1j0w0/air-conditioner-new/l/k/k/-original-imagcgzz4hjpdpga.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
  </tbody>
</table>
<p>276 rows × 11 columns</p>
      
        <p><strong>Hyp output variables:</strong> air, bounds, __output__ </p>
    
          <p>air (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>brand_name</th>
      <th>ton</th>
      <th>condenser_coil</th>
      <th>power_consumption</th>
      <th>refrigerant</th>
      <th>noise_level</th>
      <th>star</th>
      <th>ratings</th>
      <th>price</th>
      <th>image_url</th>
      <th>power_consumption_group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Haier</td>
      <td>1</td>
      <td>Copper</td>
      <td>704.0</td>
      <td>32.0</td>
      <td>26.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>27294.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l1ch4sw0/air-conditioner-new/0/j/f/-original-imagcxh3d6ezzqhp.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Daikin</td>
      <td>1.5</td>
      <td>Alloy</td>
      <td>1304.0</td>
      <td>32.0</td>
      <td>42.0</td>
      <td>4.2</td>
      <td>0</td>
      <td>38999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l2krs7k0/air-conditioner-new/v/x/g/-original-imagdwym4y6wb4vu.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Croma</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1570.0</td>
      <td>32.0</td>
      <td>49.0</td>
      <td>3.8</td>
      <td>75</td>
      <td>28490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l1pc3gw0/air-conditioner-new/y/e/h/-original-imagd7qhxffd2ksw.jpeg?q=70</td>
      <td>(1500.0, 2000.0]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Panasonic</td>
      <td>1</td>
      <td>Copper</td>
      <td>1095.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0sgyvk0/air-conditioner-new/4/8/i/-original-imagchbyyxgnsztk.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>MarQ</td>
      <td>By</td>
      <td>Copper</td>
      <td>712.0</td>
      <td>32.0</td>
      <td>40.0</td>
      <td>4.0</td>
      <td>642</td>
      <td>27490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzfvzww0/air-conditioner-new/j/p/s/-original-imagbgbzyx7vkpvj.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Panasonic</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>840.0</td>
      <td>32.0</td>
      <td>46.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>42990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0r1j0w0/air-conditioner-new/n/i/w/-original-imagcgg5ktjp2p3j.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Panasonic</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1056.0</td>
      <td>32.0</td>
      <td>48.0</td>
      <td>4.2</td>
      <td>1125</td>
      <td>35990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kltryq80/air-conditioner-new/l/l/y/cs-ru18xkytw-cu-ru18xkytw-split-panasonic-inverter-original-imagyugnrnv2djmk.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>269</th>
      <td>LG</td>
      <td>Convertible</td>
      <td>Copper</td>
      <td>571.0</td>
      <td>32.0</td>
      <td>21.0</td>
      <td>4.3</td>
      <td>9470</td>
      <td>37490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/klfhk7k0/air-conditioner-new/s/8/c/ms-q18ynza-split-lg-dual-inverter-original-imagyk3ergg9fveh.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>270</th>
      <td>Panasonic</td>
      <td>1</td>
      <td>Copper</td>
      <td>1095.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0sgyvk0/air-conditioner-new/4/8/i/-original-imagchbyyxgnsztk.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>271</th>
      <td>Lloyd</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1440.0</td>
      <td>32.0</td>
      <td>57.0</td>
      <td>4.1</td>
      <td>0</td>
      <td>34890.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kmuxevk0/air-conditioner-new/9/w/1/gls18i36wsel-split-lloyd-inverter-original-imagfnav3j88g9hd.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>272</th>
      <td>Hitachi</td>
      <td>2</td>
      <td>Copper</td>
      <td>2350.0</td>
      <td>410.0</td>
      <td>37.0</td>
      <td>4.2</td>
      <td>2029</td>
      <td>49500.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kd4uj680/air-conditioner-new/y/8/p/rmi-emi-cmi-324hbea-mps-2-split-hitachi-inverter-original-imafu44ge2gsrsvt.jpeg?q=70</td>
      <td>(2000.0, 2500.0]</td>
    </tr>
    <tr>
      <th>273</th>
      <td>CARRIER</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1550.0</td>
      <td>32.0</td>
      <td>58.0</td>
      <td>4.2</td>
      <td>810</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/klphn680/air-conditioner-new/o/7/2/caw18sn5r39f0-window-carrier-fixed-speed-original-imagys52wsawg9cn.jpeg?q=70</td>
      <td>(1500.0, 2000.0]</td>
    </tr>
    <tr>
      <th>274</th>
      <td>LIVPURE</td>
      <td>1</td>
      <td>Copper</td>
      <td>1080.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.2</td>
      <td>2586</td>
      <td>38990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kn7sdjk0/air-conditioner-new/g/g/u/hks-in12k3s19a-split-livpure-inverter-original-imagfxxzhx7wnwjz.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>275</th>
      <td>SAMSUNG</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1490.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>38559.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0r1j0w0/air-conditioner-new/l/k/k/-original-imagcgzz4hjpdpga.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
  </tbody>
</table>
<p>276 rows × 11 columns</p>
      
          <p>bounds (Series):</p>
          <pre><code>min       0.0
max    6000.0
Name: power_consumption, dtype: float64</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>brand_name</th>
      <th>ton</th>
      <th>condenser_coil</th>
      <th>power_consumption</th>
      <th>refrigerant</th>
      <th>noise_level</th>
      <th>star</th>
      <th>ratings</th>
      <th>price</th>
      <th>image_url</th>
      <th>power_consumption_group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Haier</td>
      <td>1</td>
      <td>Copper</td>
      <td>704.0</td>
      <td>32.0</td>
      <td>26.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>27294.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l1ch4sw0/air-conditioner-new/0/j/f/-original-imagcxh3d6ezzqhp.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Daikin</td>
      <td>1.5</td>
      <td>Alloy</td>
      <td>1304.0</td>
      <td>32.0</td>
      <td>42.0</td>
      <td>4.2</td>
      <td>0</td>
      <td>38999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l2krs7k0/air-conditioner-new/v/x/g/-original-imagdwym4y6wb4vu.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Croma</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1570.0</td>
      <td>32.0</td>
      <td>49.0</td>
      <td>3.8</td>
      <td>75</td>
      <td>28490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l1pc3gw0/air-conditioner-new/y/e/h/-original-imagd7qhxffd2ksw.jpeg?q=70</td>
      <td>(1500.0, 2000.0]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Panasonic</td>
      <td>1</td>
      <td>Copper</td>
      <td>1095.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0sgyvk0/air-conditioner-new/4/8/i/-original-imagchbyyxgnsztk.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>MarQ</td>
      <td>By</td>
      <td>Copper</td>
      <td>712.0</td>
      <td>32.0</td>
      <td>40.0</td>
      <td>4.0</td>
      <td>642</td>
      <td>27490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzfvzww0/air-conditioner-new/j/p/s/-original-imagbgbzyx7vkpvj.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Panasonic</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>840.0</td>
      <td>32.0</td>
      <td>46.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>42990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0r1j0w0/air-conditioner-new/n/i/w/-original-imagcgg5ktjp2p3j.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Panasonic</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1056.0</td>
      <td>32.0</td>
      <td>48.0</td>
      <td>4.2</td>
      <td>1125</td>
      <td>35990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kltryq80/air-conditioner-new/l/l/y/cs-ru18xkytw-cu-ru18xkytw-split-panasonic-inverter-original-imagyugnrnv2djmk.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>269</th>
      <td>LG</td>
      <td>Convertible</td>
      <td>Copper</td>
      <td>571.0</td>
      <td>32.0</td>
      <td>21.0</td>
      <td>4.3</td>
      <td>9470</td>
      <td>37490.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/klfhk7k0/air-conditioner-new/s/8/c/ms-q18ynza-split-lg-dual-inverter-original-imagyk3ergg9fveh.jpeg?q=70</td>
      <td>(500.0, 1000.0]</td>
    </tr>
    <tr>
      <th>270</th>
      <td>Panasonic</td>
      <td>1</td>
      <td>Copper</td>
      <td>1095.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.3</td>
      <td>10156</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0sgyvk0/air-conditioner-new/4/8/i/-original-imagchbyyxgnsztk.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>271</th>
      <td>Lloyd</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1440.0</td>
      <td>32.0</td>
      <td>57.0</td>
      <td>4.1</td>
      <td>0</td>
      <td>34890.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kmuxevk0/air-conditioner-new/9/w/1/gls18i36wsel-split-lloyd-inverter-original-imagfnav3j88g9hd.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>272</th>
      <td>Hitachi</td>
      <td>2</td>
      <td>Copper</td>
      <td>2350.0</td>
      <td>410.0</td>
      <td>37.0</td>
      <td>4.2</td>
      <td>2029</td>
      <td>49500.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kd4uj680/air-conditioner-new/y/8/p/rmi-emi-cmi-324hbea-mps-2-split-hitachi-inverter-original-imafu44ge2gsrsvt.jpeg?q=70</td>
      <td>(2000.0, 2500.0]</td>
    </tr>
    <tr>
      <th>273</th>
      <td>CARRIER</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1550.0</td>
      <td>32.0</td>
      <td>58.0</td>
      <td>4.2</td>
      <td>810</td>
      <td>32999.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/klphn680/air-conditioner-new/o/7/2/caw18sn5r39f0-window-carrier-fixed-speed-original-imagys52wsawg9cn.jpeg?q=70</td>
      <td>(1500.0, 2000.0]</td>
    </tr>
    <tr>
      <th>274</th>
      <td>LIVPURE</td>
      <td>1</td>
      <td>Copper</td>
      <td>1080.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>4.2</td>
      <td>2586</td>
      <td>38990.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kn7sdjk0/air-conditioner-new/g/g/u/hks-in12k3s19a-split-livpure-inverter-original-imagfxxzhx7wnwjz.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
    <tr>
      <th>275</th>
      <td>SAMSUNG</td>
      <td>1.5</td>
      <td>Copper</td>
      <td>1490.0</td>
      <td>32.0</td>
      <td>45.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>38559.0</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0r1j0w0/air-conditioner-new/l/k/k/-original-imagcgzz4hjpdpga.jpeg?q=70</td>
      <td>(1000.0, 1500.0]</td>
    </tr>
  </tbody>
</table>
<p>276 rows × 11 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> air-condition-dataac/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which brand has the highest ratings within each power consumption group?  Show power connumption group as an index and brand name and ratings as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = air.groupby(['brand_name','power_consumption_group']).ratings.mean().unstack().agg(['idxmax','max']).T
df.columns = ['brand_name','ratings']
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = air.groupby(['brand_name','power_consumption_group']).ratings.mean().unstack().agg(['idxmax','max']).T
df.columns = ['brand_name','ratings']
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = air.groupby(['brand_name', 'power_consumption_group']).ratings.mean(
    ).unstack().agg(['idxmax', 'max']).T
df.columns = ['brand_name', 'ratings']
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_0031c3ba').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0031c3ba" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>brand_name</th>
      <th>ratings</th>
    </tr>
    <tr>
      <th>power_consumption_group</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(0.0, 500.0]</th>
      <td>Lloyd</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>(500.0, 1000.0]</th>
      <td>Panasonic</td>
      <td>8522.903226</td>
    </tr>
    <tr>
      <th>(1000.0, 1500.0]</th>
      <td>SAMSUNG</td>
      <td>14032.0</td>
    </tr>
    <tr>
      <th>(1500.0, 2000.0]</th>
      <td>Panasonic</td>
      <td>7343.333333</td>
    </tr>
    <tr>
      <th>(2000.0, 2500.0]</th>
      <td>Hitachi</td>
      <td>2029.0</td>
    </tr>
    <tr>
      <th>(2500.0, 3000.0]</th>
      <td>IFB</td>
      <td>676.0</td>
    </tr>
    <tr>
      <th>(3000.0, 3500.0]</th>
      <td>LG</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>(3500.0, 4000.0]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(4000.0, 4500.0]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(4500.0, 5000.0]</th>
      <td>LG</td>
      <td>1136.5</td>
    </tr>
    <tr>
      <th>(5000.0, 5500.0]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>brand_name</th>
      <th>ratings</th>
    </tr>
    <tr>
      <th>power_consumption_group</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(0.0, 500.0]</th>
      <td>Lloyd</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>(500.0, 1000.0]</th>
      <td>Panasonic</td>
      <td>8522.903226</td>
    </tr>
    <tr>
      <th>(1000.0, 1500.0]</th>
      <td>SAMSUNG</td>
      <td>14032.0</td>
    </tr>
    <tr>
      <th>(1500.0, 2000.0]</th>
      <td>Panasonic</td>
      <td>7343.333333</td>
    </tr>
    <tr>
      <th>(2000.0, 2500.0]</th>
      <td>Hitachi</td>
      <td>2029.0</td>
    </tr>
    <tr>
      <th>(2500.0, 3000.0]</th>
      <td>IFB</td>
      <td>676.0</td>
    </tr>
    <tr>
      <th>(3000.0, 3500.0]</th>
      <td>LG</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>(3500.0, 4000.0]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(4000.0, 4500.0]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(4500.0, 5000.0]</th>
      <td>LG</td>
      <td>1136.5</td>
    </tr>
    <tr>
      <th>(5000.0, 5500.0]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>brand_name</th>
      <th>ratings</th>
    </tr>
    <tr>
      <th>power_consumption_group</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(0.0, 500.0]</th>
      <td>Lloyd</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>(500.0, 1000.0]</th>
      <td>Panasonic</td>
      <td>8522.903226</td>
    </tr>
    <tr>
      <th>(1000.0, 1500.0]</th>
      <td>SAMSUNG</td>
      <td>14032.0</td>
    </tr>
    <tr>
      <th>(1500.0, 2000.0]</th>
      <td>Panasonic</td>
      <td>7343.333333</td>
    </tr>
    <tr>
      <th>(2000.0, 2500.0]</th>
      <td>Hitachi</td>
      <td>2029.0</td>
    </tr>
    <tr>
      <th>(2500.0, 3000.0]</th>
      <td>IFB</td>
      <td>676.0</td>
    </tr>
    <tr>
      <th>(3000.0, 3500.0]</th>
      <td>LG</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>(3500.0, 4000.0]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(4000.0, 4500.0]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(4500.0, 5000.0]</th>
      <td>LG</td>
      <td>1136.5</td>
    </tr>
    <tr>
      <th>(5000.0, 5500.0]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> air-condition-dataac/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the highest and lowest bounds of refrigerants and noise levels for each power consumption group?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>air.groupby(['power_consumption_group'])['refrigerant','noise_level'].agg(['min','max'])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>air.groupby(['power_consumption_group'])['refrigerant','noise_level'].agg(['min','max'])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = air.groupby(['power_consumption_group'])['refrigerant',
    'noise_level'].agg(['min', 'max'])
</code></pre>
        <p><span onclick="$('#var_output_80e0e671').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_80e0e671" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">refrigerant</th>
      <th colspan="2" halign="left">noise_level</th>
    </tr>
    <tr>
      <th></th>
      <th>min</th>
      <th>max</th>
      <th>min</th>
      <th>max</th>
    </tr>
    <tr>
      <th>power_consumption_group</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(0.0, 500.0]</th>
      <td>10.0</td>
      <td>10.0</td>
      <td>52.0</td>
      <td>52.0</td>
    </tr>
    <tr>
      <th>(500.0, 1000.0]</th>
      <td>22.0</td>
      <td>410.0</td>
      <td>21.0</td>
      <td>63.0</td>
    </tr>
    <tr>
      <th>(1000.0, 1500.0]</th>
      <td>32.0</td>
      <td>34.0</td>
      <td>21.0</td>
      <td>62.0</td>
    </tr>
    <tr>
      <th>(1500.0, 2000.0]</th>
      <td>22.0</td>
      <td>410.0</td>
      <td>22.0</td>
      <td>410.0</td>
    </tr>
    <tr>
      <th>(2000.0, 2500.0]</th>
      <td>32.0</td>
      <td>410.0</td>
      <td>32.0</td>
      <td>56.0</td>
    </tr>
    <tr>
      <th>(2500.0, 3000.0]</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>39.0</td>
      <td>39.0</td>
    </tr>
    <tr>
      <th>(3000.0, 3500.0]</th>
      <td>32.0</td>
      <td>32.0</td>
      <td>20.0</td>
      <td>45.0</td>
    </tr>
    <tr>
      <th>(3500.0, 4000.0]</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(4000.0, 4500.0]</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(4500.0, 5000.0]</th>
      <td>32.0</td>
      <td>32.0</td>
      <td>26.0</td>
      <td>44.0</td>
    </tr>
    <tr>
      <th>(5000.0, 5500.0]</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 4 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">refrigerant</th>
      <th colspan="2" halign="left">noise_level</th>
    </tr>
    <tr>
      <th></th>
      <th>min</th>
      <th>max</th>
      <th>min</th>
      <th>max</th>
    </tr>
    <tr>
      <th>power_consumption_group</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(0.0, 500.0]</th>
      <td>10.0</td>
      <td>10.0</td>
      <td>52.0</td>
      <td>52.0</td>
    </tr>
    <tr>
      <th>(500.0, 1000.0]</th>
      <td>22.0</td>
      <td>410.0</td>
      <td>21.0</td>
      <td>63.0</td>
    </tr>
    <tr>
      <th>(1000.0, 1500.0]</th>
      <td>32.0</td>
      <td>34.0</td>
      <td>21.0</td>
      <td>62.0</td>
    </tr>
    <tr>
      <th>(1500.0, 2000.0]</th>
      <td>22.0</td>
      <td>410.0</td>
      <td>22.0</td>
      <td>410.0</td>
    </tr>
    <tr>
      <th>(2000.0, 2500.0]</th>
      <td>32.0</td>
      <td>410.0</td>
      <td>32.0</td>
      <td>56.0</td>
    </tr>
    <tr>
      <th>(2500.0, 3000.0]</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>39.0</td>
      <td>39.0</td>
    </tr>
    <tr>
      <th>(3000.0, 3500.0]</th>
      <td>32.0</td>
      <td>32.0</td>
      <td>20.0</td>
      <td>45.0</td>
    </tr>
    <tr>
      <th>(3500.0, 4000.0]</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(4000.0, 4500.0]</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(4500.0, 5000.0]</th>
      <td>32.0</td>
      <td>32.0</td>
      <td>26.0</td>
      <td>44.0</td>
    </tr>
    <tr>
      <th>(5000.0, 5500.0]</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 4 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> air-condition-dataac/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the highest correlated feature, in absolute value, with the price of AC units?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = air.corr().price.drop(index='price')
df.reindex(df.abs().sort_values(ascending=False).index).head(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = air.corr().price.drop(index='price')
df.reindex(df.abs().sort_values(ascending=False).index).head(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = air.corr().price.drop(index='price')
__output__ = df.reindex(df.abs().sort_values(ascending=False).index).head(1)
</code></pre>
        <p><span onclick="$('#var_output_715841a4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_715841a4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>star   -0.153936
Name: price, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (Series):</p>
          <pre><code>power_consumption    0.085548
refrigerant          0.136401
noise_level         -0.032556
star                -0.153936
ratings              0.048106
Name: price, dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>star   -0.153936
Name: price, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> air-condition-dataac/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the share of AC units produced for each brand?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>air.groupby('brand_name').size() / air.groupby('brand_name').size().sum() *100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>air.groupby('brand_name').size() / air.groupby('brand_name').size().sum() *100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = air.groupby('brand_name').size() / air.groupby('brand_name').size(
    ).sum() * 100
</code></pre>
        <p><span onclick="$('#var_output_51dbe9c2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_51dbe9c2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>brand_name
 4-in-1 Convertible 1 Ton 4 Star Split Inverter     0.362319
Blue                                                5.072464
CARRIER                                             5.797101
Croma                                               5.797101
Daikin                                              7.971014
                                                      ...   
SAMSUNG                                             9.420290
Thomson                                             0.362319
Voltas                                              8.333333
Whirlpool                                           4.347826
iFFALCON                                            0.362319
Length: 27, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>brand_name
 4-in-1 Convertible 1 Ton 4 Star Split Inverter     0.362319
Blue                                                5.072464
CARRIER                                             5.797101
Croma                                               5.797101
Daikin                                              7.971014
                                                      ...   
SAMSUNG                                             9.420290
Thomson                                             0.362319
Voltas                                              8.333333
Whirlpool                                           4.347826
iFFALCON                                            0.362319
Length: 27, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> air-condition-dataac/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average ratings received for every combination of brand name and power consumption group?  Show the brand name as an index and power consumption group as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>air.groupby(['brand_name','power_consumption_group']).ratings.mean().unstack().fillna(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>air.groupby(['brand_name','power_consumption_group']).ratings.mean().unstack().fillna(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = air.groupby(['brand_name', 'power_consumption_group']
    ).ratings.mean().unstack().fillna(0)
</code></pre>
        <p><span onclick="$('#var_output_412257a0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_412257a0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>power_consumption_group</th>
      <th>(0.0, 500.0]</th>
      <th>(500.0, 1000.0]</th>
      <th>(1000.0, 1500.0]</th>
      <th>(1500.0, 2000.0]</th>
      <th>(2000.0, 2500.0]</th>
      <th>(2500.0, 3000.0]</th>
      <th>(3000.0, 3500.0]</th>
      <th>(3500.0, 4000.0]</th>
      <th>(4000.0, 4500.0]</th>
      <th>(4500.0, 5000.0]</th>
      <th>(5000.0, 5500.0]</th>
    </tr>
    <tr>
      <th>brand_name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4-in-1 Convertible 1 Ton 4 Star Split Inverter</th>
      <td>0.0</td>
      <td>1449.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Blue</th>
      <td>0.0</td>
      <td>2285.666667</td>
      <td>846.600000</td>
      <td>86.666667</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>CARRIER</th>
      <td>0.0</td>
      <td>1938.400000</td>
      <td>6461.333333</td>
      <td>231.428571</td>
      <td>685.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Croma</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>75.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Daikin</th>
      <td>0.0</td>
      <td>941.800000</td>
      <td>316.727273</td>
      <td>411.333333</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Godrej</th>
      <td>0.0</td>
      <td>158.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Haier</th>
      <td>0.0</td>
      <td>50.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>ONIDA</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2599.500000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Panasonic</th>
      <td>0.0</td>
      <td>8522.903226</td>
      <td>4090.923077</td>
      <td>7343.333333</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>SAMSUNG</th>
      <td>0.0</td>
      <td>45.400000</td>
      <td>14032.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Thomson</th>
      <td>0.0</td>
      <td>211.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Voltas</th>
      <td>0.0</td>
      <td>2061.000000</td>
      <td>904.400000</td>
      <td>2641.333333</td>
      <td>79.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Whirlpool</th>
      <td>0.0</td>
      <td>2749.666667</td>
      <td>7877.500000</td>
      <td>7188.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>iFFALCON</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>27 rows × 11 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>power_consumption_group</th>
      <th>(0.0, 500.0]</th>
      <th>(500.0, 1000.0]</th>
      <th>(1000.0, 1500.0]</th>
      <th>(1500.0, 2000.0]</th>
      <th>(2000.0, 2500.0]</th>
      <th>(2500.0, 3000.0]</th>
      <th>(3000.0, 3500.0]</th>
      <th>(3500.0, 4000.0]</th>
      <th>(4000.0, 4500.0]</th>
      <th>(4500.0, 5000.0]</th>
      <th>(5000.0, 5500.0]</th>
    </tr>
    <tr>
      <th>brand_name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4-in-1 Convertible 1 Ton 4 Star Split Inverter</th>
      <td>0.0</td>
      <td>1449.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Blue</th>
      <td>0.0</td>
      <td>2285.666667</td>
      <td>846.600000</td>
      <td>86.666667</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>CARRIER</th>
      <td>0.0</td>
      <td>1938.400000</td>
      <td>6461.333333</td>
      <td>231.428571</td>
      <td>685.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Croma</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>75.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Daikin</th>
      <td>0.0</td>
      <td>941.800000</td>
      <td>316.727273</td>
      <td>411.333333</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Godrej</th>
      <td>0.0</td>
      <td>158.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Haier</th>
      <td>0.0</td>
      <td>50.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>ONIDA</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2599.500000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Panasonic</th>
      <td>0.0</td>
      <td>8522.903226</td>
      <td>4090.923077</td>
      <td>7343.333333</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>SAMSUNG</th>
      <td>0.0</td>
      <td>45.400000</td>
      <td>14032.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Thomson</th>
      <td>0.0</td>
      <td>211.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Voltas</th>
      <td>0.0</td>
      <td>2061.000000</td>
      <td>904.400000</td>
      <td>2641.333333</td>
      <td>79.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Whirlpool</th>
      <td>0.0</td>
      <td>2749.666667</td>
      <td>7877.500000</td>
      <td>7188.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>iFFALCON</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>27 rows × 11 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> boeing-historical-airplane-orders-deliveries/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the data types of columns with numeric values to numeric data types.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>orders['Delivery Year '] = pd.to_numeric(orders['Delivery Year '], errors='coerce')
orders['Order Year'] = pd.to_numeric(orders['Order Year'], errors='coerce')
orders['Order Total'] = pd.to_numeric(orders['Order Total'], errors='coerce')
orders['Delivery Total'] = pd.to_numeric(orders['Delivery Total'], errors='coerce')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>orders['Delivery Year '] = pd.to_numeric(orders['Delivery Year '], errors='coerce')
orders['Order Year'] = pd.to_numeric(orders['Order Year'], errors='coerce')
orders['Order Total'] = pd.to_numeric(orders['Order Total'], errors='coerce')
orders['Delivery Total'] = pd.to_numeric(orders['Delivery Total'], errors='coerce')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>orders['Delivery Year '] = pd.to_numeric(orders['Delivery Year '], errors=
    'coerce')
orders['Order Year'] = pd.to_numeric(orders['Order Year'], errors='coerce')
orders['Order Total'] = pd.to_numeric(orders['Order Total'], errors='coerce')
__output__ = orders['Delivery Total'] = pd.to_numeric(orders[
    'Delivery Total'], errors='coerce')
</code></pre>
        <p><span onclick="$('#var_output_d2c15ba8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d2c15ba8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0       1.0
1       1.0
2       1.0
3       0.0
4       1.0
       ... 
9068    2.0
9069    1.0
9070    1.0
9071    1.0
9072    NaN
Name: Delivery Total, Length: 9073, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> orders, __output__ </p>
    
          <p>orders (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Customer Name</th>
      <th>Delivery Year</th>
      <th>Engine</th>
      <th>Model Series</th>
      <th>Order Month</th>
      <th>Order Year</th>
      <th>Region</th>
      <th>Delivery Total</th>
      <th>Order Total</th>
      <th>Unfilled Orders</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>Ariana Afghan Airlines</td>
      <td>1968.0</td>
      <td>PW</td>
      <td>727</td>
      <td>Mar</td>
      <td>1968.0</td>
      <td>Central Asia</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Afghanistan</td>
      <td>Ariana Afghan Airlines</td>
      <td>1970.0</td>
      <td>PW</td>
      <td>727</td>
      <td>Apr</td>
      <td>1969.0</td>
      <td>Central Asia</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Afghanistan</td>
      <td>Ariana Afghan Airlines</td>
      <td>1979.0</td>
      <td>GE</td>
      <td>DC-10</td>
      <td>Sep</td>
      <td>1978.0</td>
      <td>Central Asia</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Afghanistan</td>
      <td>Ariana Afghan Airlines</td>
      <td>NaN</td>
      <td>CF</td>
      <td>737-700</td>
      <td>Nov</td>
      <td>2005.0</td>
      <td>Central Asia</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Algeria</td>
      <td>Air Algerie</td>
      <td>1974.0</td>
      <td>PW</td>
      <td>727</td>
      <td>Jan</td>
      <td>1974.0</td>
      <td>Africa</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Algeria</td>
      <td>Air Algerie</td>
      <td>1974.0</td>
      <td>PW</td>
      <td>737-200</td>
      <td>Jan</td>
      <td>1974.0</td>
      <td>Africa</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Algeria</td>
      <td>Air Algerie</td>
      <td>1975.0</td>
      <td>PW</td>
      <td>727</td>
      <td>Jan</td>
      <td>1974.0</td>
      <td>Africa</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9066</th>
      <td>Zambia</td>
      <td>Zambia Airways</td>
      <td>1976.0</td>
      <td>PW</td>
      <td>737-200</td>
      <td>Jun</td>
      <td>1975.0</td>
      <td>Africa</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>9067</th>
      <td>Zambia</td>
      <td>Zambia Airways</td>
      <td>1984.0</td>
      <td>GE</td>
      <td>DC-10</td>
      <td>Nov</td>
      <td>1983.0</td>
      <td>Africa</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>9068</th>
      <td>Zimbabwe</td>
      <td>Air Zimbabwe</td>
      <td>1987.0</td>
      <td>PW</td>
      <td>737-200</td>
      <td>Jan</td>
      <td>1987.0</td>
      <td>Africa</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>9069</th>
      <td>Zimbabwe</td>
      <td>Air Zimbabwe</td>
      <td>1990.0</td>
      <td>PW</td>
      <td>767-200ER</td>
      <td>Mar</td>
      <td>1989.0</td>
      <td>Africa</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>9070</th>
      <td>Zimbabwe</td>
      <td>Air Zimbabwe</td>
      <td>1989.0</td>
      <td>PW</td>
      <td>767-200ER</td>
      <td>Jul</td>
      <td>1988.0</td>
      <td>Africa</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>9071</th>
      <td>Zimbabwe</td>
      <td>Air Zimbabwe</td>
      <td>1986.0</td>
      <td>PW</td>
      <td>737-200</td>
      <td>Dec</td>
      <td>1986.0</td>
      <td>Africa</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>9072</th>
      <td>All</td>
      <td>All</td>
      <td>NaN</td>
      <td>All</td>
      <td>All</td>
      <td>All</td>
      <td>NaN</td>
      <td>All</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5,163</td>
    </tr>
  </tbody>
</table>
<p>9073 rows × 11 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0       1.0
1       1.0
2       1.0
3       0.0
4       1.0
       ... 
9068    2.0
9069    1.0
9070    1.0
9071    1.0
9072    NaN
Name: Delivery Total, Length: 9073, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> boeing-historical-airplane-orders-deliveries/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total cumulative annual plane orders for every region?  Show the years as an index and the regions as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>orders.groupby(['Region','Order Year'])['Order Total'].sum().unstack(0).cumsum().ffill().fillna(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>orders.groupby(['Region','Order Year'])['Order Total'].sum().unstack(0).cumsum().ffill().fillna(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = orders.groupby(['Region', 'Order Year'])['Order Total'].sum(
    ).unstack(0).cumsum().ffill().fillna(0)
</code></pre>
        <p><span onclick="$('#var_output_77c23d1e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_77c23d1e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Region</th>
      <th>Africa</th>
      <th>Caribbean</th>
      <th>Central America and Mexico</th>
      <th>Central Asia</th>
      <th>East Asia</th>
      <th>Europe</th>
      <th>Middle East</th>
      <th>North America</th>
      <th>Oceania</th>
      <th>South America</th>
      <th>South Asia</th>
      <th>Southeast Asia</th>
      <th>Unidentified</th>
    </tr>
    <tr>
      <th>Order Year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1955.0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>28.0</td>
      <td>3.0</td>
      <td>110.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1956.0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>56.0</td>
      <td>3.0</td>
      <td>161.0</td>
      <td>7.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1957.0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>64.0</td>
      <td>3.0</td>
      <td>186.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1958.0</th>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>68.0</td>
      <td>3.0</td>
      <td>219.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1959.0</th>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>80.0</td>
      <td>3.0</td>
      <td>242.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1960.0</th>
      <td>5.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>95.0</td>
      <td>5.0</td>
      <td>361.0</td>
      <td>10.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1961.0</th>
      <td>5.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>6.0</td>
      <td>123.0</td>
      <td>18.0</td>
      <td>447.0</td>
      <td>11.0</td>
      <td>6.0</td>
      <td>9.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2016.0</th>
      <td>711.0</td>
      <td>29.0</td>
      <td>369.0</td>
      <td>88.0</td>
      <td>3357.0</td>
      <td>6538.0</td>
      <td>1497.0</td>
      <td>12862.0</td>
      <td>708.0</td>
      <td>702.0</td>
      <td>555.0</td>
      <td>1748.0</td>
      <td>681.0</td>
    </tr>
    <tr>
      <th>2017.0</th>
      <td>722.0</td>
      <td>29.0</td>
      <td>369.0</td>
      <td>89.0</td>
      <td>3490.0</td>
      <td>6700.0</td>
      <td>1700.0</td>
      <td>13021.0</td>
      <td>717.0</td>
      <td>703.0</td>
      <td>559.0</td>
      <td>1883.0</td>
      <td>916.0</td>
    </tr>
    <tr>
      <th>2018.0</th>
      <td>733.0</td>
      <td>49.0</td>
      <td>369.0</td>
      <td>94.0</td>
      <td>3538.0</td>
      <td>6829.0</td>
      <td>1710.0</td>
      <td>13426.0</td>
      <td>723.0</td>
      <td>718.0</td>
      <td>715.0</td>
      <td>2056.0</td>
      <td>1028.0</td>
    </tr>
    <tr>
      <th>2019.0</th>
      <td>733.0</td>
      <td>49.0</td>
      <td>369.0</td>
      <td>95.0</td>
      <td>3558.0</td>
      <td>6894.0</td>
      <td>1745.0</td>
      <td>13479.0</td>
      <td>731.0</td>
      <td>718.0</td>
      <td>717.0</td>
      <td>2074.0</td>
      <td>1072.0</td>
    </tr>
    <tr>
      <th>2020.0</th>
      <td>733.0</td>
      <td>49.0</td>
      <td>369.0</td>
      <td>95.0</td>
      <td>3590.0</td>
      <td>6971.0</td>
      <td>1749.0</td>
      <td>13503.0</td>
      <td>760.0</td>
      <td>718.0</td>
      <td>717.0</td>
      <td>2077.0</td>
      <td>1087.0</td>
    </tr>
    <tr>
      <th>2021.0</th>
      <td>737.0</td>
      <td>54.0</td>
      <td>369.0</td>
      <td>100.0</td>
      <td>3591.0</td>
      <td>6995.0</td>
      <td>1767.0</td>
      <td>14175.0</td>
      <td>762.0</td>
      <td>727.0</td>
      <td>789.0</td>
      <td>2088.0</td>
      <td>1173.0</td>
    </tr>
    <tr>
      <th>2022.0</th>
      <td>737.0</td>
      <td>74.0</td>
      <td>369.0</td>
      <td>100.0</td>
      <td>3591.0</td>
      <td>7001.0</td>
      <td>1783.0</td>
      <td>14277.0</td>
      <td>762.0</td>
      <td>727.0</td>
      <td>789.0</td>
      <td>2092.0</td>
      <td>1238.0</td>
    </tr>
  </tbody>
</table>
<p>68 rows × 13 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Region</th>
      <th>Africa</th>
      <th>Caribbean</th>
      <th>Central America and Mexico</th>
      <th>Central Asia</th>
      <th>East Asia</th>
      <th>Europe</th>
      <th>Middle East</th>
      <th>North America</th>
      <th>Oceania</th>
      <th>South America</th>
      <th>South Asia</th>
      <th>Southeast Asia</th>
      <th>Unidentified</th>
    </tr>
    <tr>
      <th>Order Year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1955.0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>28.0</td>
      <td>3.0</td>
      <td>110.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1956.0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>56.0</td>
      <td>3.0</td>
      <td>161.0</td>
      <td>7.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1957.0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>64.0</td>
      <td>3.0</td>
      <td>186.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1958.0</th>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>68.0</td>
      <td>3.0</td>
      <td>219.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1959.0</th>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>80.0</td>
      <td>3.0</td>
      <td>242.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1960.0</th>
      <td>5.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>95.0</td>
      <td>5.0</td>
      <td>361.0</td>
      <td>10.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1961.0</th>
      <td>5.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>6.0</td>
      <td>123.0</td>
      <td>18.0</td>
      <td>447.0</td>
      <td>11.0</td>
      <td>6.0</td>
      <td>9.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2016.0</th>
      <td>711.0</td>
      <td>29.0</td>
      <td>369.0</td>
      <td>88.0</td>
      <td>3357.0</td>
      <td>6538.0</td>
      <td>1497.0</td>
      <td>12862.0</td>
      <td>708.0</td>
      <td>702.0</td>
      <td>555.0</td>
      <td>1748.0</td>
      <td>681.0</td>
    </tr>
    <tr>
      <th>2017.0</th>
      <td>722.0</td>
      <td>29.0</td>
      <td>369.0</td>
      <td>89.0</td>
      <td>3490.0</td>
      <td>6700.0</td>
      <td>1700.0</td>
      <td>13021.0</td>
      <td>717.0</td>
      <td>703.0</td>
      <td>559.0</td>
      <td>1883.0</td>
      <td>916.0</td>
    </tr>
    <tr>
      <th>2018.0</th>
      <td>733.0</td>
      <td>49.0</td>
      <td>369.0</td>
      <td>94.0</td>
      <td>3538.0</td>
      <td>6829.0</td>
      <td>1710.0</td>
      <td>13426.0</td>
      <td>723.0</td>
      <td>718.0</td>
      <td>715.0</td>
      <td>2056.0</td>
      <td>1028.0</td>
    </tr>
    <tr>
      <th>2019.0</th>
      <td>733.0</td>
      <td>49.0</td>
      <td>369.0</td>
      <td>95.0</td>
      <td>3558.0</td>
      <td>6894.0</td>
      <td>1745.0</td>
      <td>13479.0</td>
      <td>731.0</td>
      <td>718.0</td>
      <td>717.0</td>
      <td>2074.0</td>
      <td>1072.0</td>
    </tr>
    <tr>
      <th>2020.0</th>
      <td>733.0</td>
      <td>49.0</td>
      <td>369.0</td>
      <td>95.0</td>
      <td>3590.0</td>
      <td>6971.0</td>
      <td>1749.0</td>
      <td>13503.0</td>
      <td>760.0</td>
      <td>718.0</td>
      <td>717.0</td>
      <td>2077.0</td>
      <td>1087.0</td>
    </tr>
    <tr>
      <th>2021.0</th>
      <td>737.0</td>
      <td>54.0</td>
      <td>369.0</td>
      <td>100.0</td>
      <td>3591.0</td>
      <td>6995.0</td>
      <td>1767.0</td>
      <td>14175.0</td>
      <td>762.0</td>
      <td>727.0</td>
      <td>789.0</td>
      <td>2088.0</td>
      <td>1173.0</td>
    </tr>
    <tr>
      <th>2022.0</th>
      <td>737.0</td>
      <td>74.0</td>
      <td>369.0</td>
      <td>100.0</td>
      <td>3591.0</td>
      <td>7001.0</td>
      <td>1783.0</td>
      <td>14277.0</td>
      <td>762.0</td>
      <td>727.0</td>
      <td>789.0</td>
      <td>2092.0</td>
      <td>1238.0</td>
    </tr>
  </tbody>
</table>
<p>68 rows × 13 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> boeing-historical-airplane-orders-deliveries/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent change in total annual plane orders placed by customers in China over the past twenty years?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>orders[(orders.Country=='China') & (orders['Order Year']>=dt.datetime.now().year-20)].groupby('Order Year')['Order Total'].sum().pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>orders[(orders.Country=='China') & (orders['Order Year']>=dt.datetime.now().year-20)].groupby('Order Year')['Order Total'].sum().pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = orders[(orders.Country == 'China') & (orders['Order Year'] >= 
    dt.datetime.now().year - 20)].groupby('Order Year')['Order Total'].sum(
    ).pct_change()
</code></pre>
        <p><span onclick="$('#var_output_d75dfe5e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d75dfe5e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Order Year
2002.0          NaN
2003.0    11.666667
2004.0    -0.552632
2005.0     6.764706
2006.0    -0.037879
            ...    
2015.0     0.418919
2016.0    -0.642857
2017.0    -0.613333
2020.0    -0.827586
2021.0    -0.800000
Name: Order Total, Length: 18, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Order Year
2002.0          NaN
2003.0    11.666667
2004.0    -0.552632
2005.0     6.764706
2006.0    -0.037879
            ...    
2015.0     0.418919
2016.0    -0.642857
2017.0    -0.613333
2020.0    -0.827586
2021.0    -0.800000
Name: Order Total, Length: 18, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> boeing-historical-airplane-orders-deliveries/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which customer ordered the highest number of planes in each country over the past ten years?  Return the Country, customer name and total planes ordered.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = orders[(orders['Order Year']>=dt.datetime.now().year-10)].groupby(['Country','Customer Name'])['Order Total'].sum().unstack(0).agg(['idxmax','max']).T
df.columns = ['customer_name','total_orders']
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = orders[(orders['Order Year']>=dt.datetime.now().year-10)].groupby(['Country','Customer Name'])['Order Total'].sum().unstack(0).agg(['idxmax','max']).T
df.columns = ['customer_name','total_orders']
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = orders[orders['Order Year'] >= dt.datetime.now().year - 10].groupby([
    'Country', 'Customer Name'])['Order Total'].sum().unstack(0).agg([
    'idxmax', 'max']).T
df.columns = ['customer_name', 'total_orders']
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_0162233b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0162233b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customer_name</th>
      <th>total_orders</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Algeria</th>
      <td>Air Algerie</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Angola</th>
      <td>TAAG Angola Airlines</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Argentina</th>
      <td>Aerolineas Argentinas</td>
      <td>31.0</td>
    </tr>
    <tr>
      <th>Australia</th>
      <td>Virgin Australia Airlines</td>
      <td>76.0</td>
    </tr>
    <tr>
      <th>Azerbaijan</th>
      <td>Silk Way Airlines</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>Bangladesh</th>
      <td>Biman Bangladesh Airlines</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>Belarus</th>
      <td>Belavia Belarusian Airlines</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>USA</th>
      <td>United Airlines</td>
      <td>614.0</td>
    </tr>
    <tr>
      <th>Ukraine</th>
      <td>SkyUp Airlines</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>Unidentified</th>
      <td>Unidentified Customer(s)</td>
      <td>1150.0</td>
    </tr>
    <tr>
      <th>United Arab Emirates</th>
      <td>flydubai</td>
      <td>262.0</td>
    </tr>
    <tr>
      <th>United Kingdom</th>
      <td>TUI Travel PLC</td>
      <td>80.0</td>
    </tr>
    <tr>
      <th>Uzbekistan</th>
      <td>Uzbekistan Airways</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>Vietnam</th>
      <td>VietJet Air</td>
      <td>200.0</td>
    </tr>
  </tbody>
</table>
<p>67 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customer_name</th>
      <th>total_orders</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Algeria</th>
      <td>Air Algerie</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Angola</th>
      <td>TAAG Angola Airlines</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Argentina</th>
      <td>Aerolineas Argentinas</td>
      <td>31.0</td>
    </tr>
    <tr>
      <th>Australia</th>
      <td>Virgin Australia Airlines</td>
      <td>76.0</td>
    </tr>
    <tr>
      <th>Azerbaijan</th>
      <td>Silk Way Airlines</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>Bangladesh</th>
      <td>Biman Bangladesh Airlines</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>Belarus</th>
      <td>Belavia Belarusian Airlines</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>USA</th>
      <td>United Airlines</td>
      <td>614.0</td>
    </tr>
    <tr>
      <th>Ukraine</th>
      <td>SkyUp Airlines</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>Unidentified</th>
      <td>Unidentified Customer(s)</td>
      <td>1150.0</td>
    </tr>
    <tr>
      <th>United Arab Emirates</th>
      <td>flydubai</td>
      <td>262.0</td>
    </tr>
    <tr>
      <th>United Kingdom</th>
      <td>TUI Travel PLC</td>
      <td>80.0</td>
    </tr>
    <tr>
      <th>Uzbekistan</th>
      <td>Uzbekistan Airways</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>Vietnam</th>
      <td>VietJet Air</td>
      <td>200.0</td>
    </tr>
  </tbody>
</table>
<p>67 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customer_name</th>
      <th>total_orders</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Algeria</th>
      <td>Air Algerie</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Angola</th>
      <td>TAAG Angola Airlines</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Argentina</th>
      <td>Aerolineas Argentinas</td>
      <td>31.0</td>
    </tr>
    <tr>
      <th>Australia</th>
      <td>Virgin Australia Airlines</td>
      <td>76.0</td>
    </tr>
    <tr>
      <th>Azerbaijan</th>
      <td>Silk Way Airlines</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>Bangladesh</th>
      <td>Biman Bangladesh Airlines</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>Belarus</th>
      <td>Belavia Belarusian Airlines</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>USA</th>
      <td>United Airlines</td>
      <td>614.0</td>
    </tr>
    <tr>
      <th>Ukraine</th>
      <td>SkyUp Airlines</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>Unidentified</th>
      <td>Unidentified Customer(s)</td>
      <td>1150.0</td>
    </tr>
    <tr>
      <th>United Arab Emirates</th>
      <td>flydubai</td>
      <td>262.0</td>
    </tr>
    <tr>
      <th>United Kingdom</th>
      <td>TUI Travel PLC</td>
      <td>80.0</td>
    </tr>
    <tr>
      <th>Uzbekistan</th>
      <td>Uzbekistan Airways</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>Vietnam</th>
      <td>VietJet Air</td>
      <td>200.0</td>
    </tr>
  </tbody>
</table>
<p>67 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> boeing-historical-airplane-orders-deliveries/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many customers in each region ordered at least one hundered planes in total?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = orders.groupby(['Region','Customer Name'])['Order Total'].sum()
df[df>=100].reset_index().groupby('Region')['Customer Name'].count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = orders.groupby(['Region','Customer Name'])['Order Total'].sum()
df[df>=100].reset_index().groupby('Region')['Customer Name'].count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = orders.groupby(['Region', 'Customer Name'])['Order Total'].sum()
__output__ = df[df >= 100].reset_index().groupby('Region')['Customer Name'
    ].count()
</code></pre>
        <p><span onclick="$('#var_output_e5edd6eb').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e5edd6eb" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Region
Central America and Mexico     2
East Asia                     10
Europe                        17
Middle East                    6
North America                 28
Oceania                        2
South America                  2
South Asia                     3
Southeast Asia                 6
Unidentified                   1
Name: Customer Name, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (Series):</p>
          <pre><code>Region          Customer Name                 
Africa          AMC Airlines                         2.0
                Air Afrique                          9.0
                Air Algerie                         63.0
                Air Austral                          7.0
                Air Gabon                            2.0
                                                   ...  
Southeast Asia  Transportation Partners Pte Lt       5.0
                UNI Airways                         10.0
                VietJet Air                        200.0
                Vietnam Airlines                    12.0
Unidentified    Unidentified Customer(s)          1238.0
Name: Order Total, Length: 568, dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Region
Central America and Mexico     2
East Asia                     10
Europe                        17
Middle East                    6
North America                 28
Oceania                        2
South America                  2
South Asia                     3
Southeast Asia                 6
Unidentified                   1
Name: Customer Name, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> boeing-historical-airplane-orders-deliveries/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which Region had the highest total number of deliveries in a single year? Return the Region and the year that had the highest numeber of total deliveries.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>region = orders.groupby(['Region','Delivery Year '])['Delivery Total'].sum().idxmax()
region = pd.DataFrame(region, index=['region','year']).T
region</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>region = orders.groupby(['Region','Delivery Year '])['Delivery Total'].sum().idxmax()
region = pd.DataFrame(region, index=['region','year']).T
region</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>region = orders.groupby(['Region', 'Delivery Year '])['Delivery Total'].sum(
    ).idxmax()
region = pd.DataFrame(region, index=['region', 'year']).T
__output__ = region
</code></pre>
        <p><span onclick="$('#var_output_5e03b6d4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5e03b6d4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>region</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>North America</td>
      <td>1968.0</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> region, __output__ </p>
    
          <p>region (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>region</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>North America</td>
      <td>1968.0</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>region</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>North America</td>
      <td>1968.0</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> boeing-historical-airplane-orders-deliveries/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which country in that region had the highest share of deliveries during that year?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>orders[(orders.Region == region['region'].item()) & (orders['Delivery Year '] == region['year'].item())].groupby('Country')['Delivery Total'].sum().idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>orders[(orders.Region == region['region'].item()) & (orders['Delivery Year '] == region['year'].item())].groupby('Country')['Delivery Total'].sum().idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = orders[(orders.Region == region['region'].item()) & (orders[
    'Delivery Year '] == region['year'].item())].groupby('Country')[
    'Delivery Total'].sum().idxmax()
</code></pre>
        <p><span onclick="$('#var_output_fdcc2261').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_fdcc2261" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>USA</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>USA</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> boeing-historical-airplane-orders-deliveries/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the cumulative sum of orders placed by Emirates Airlines?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>orders[orders['Customer Name'].str.contains('emirates',case=False)].groupby('Order Year')['Order Total'].sum().cumsum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>orders[orders['Customer Name'].str.contains('emirates',case=False)].groupby('Order Year')['Order Total'].sum().cumsum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = orders[orders['Customer Name'].str.contains('emirates', case=
    False)].groupby('Order Year')['Order Total'].sum().cumsum()
</code></pre>
        <p><span onclick="$('#var_output_e45b0962').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e45b0962" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Order Year
1992.0      7.0
1997.0      9.0
2004.0     13.0
2005.0     47.0
2007.0     59.0
2010.0     89.0
2011.0    139.0
2014.0    289.0
2019.0    319.0
2021.0    321.0
Name: Order Total, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Order Year
1992.0      7.0
1997.0      9.0
2004.0     13.0
2005.0     47.0
2007.0     59.0
2010.0     89.0
2011.0    139.0
2014.0    289.0
2019.0    319.0
2021.0    321.0
Name: Order Total, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> boeing-historical-airplane-orders-deliveries/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which customer in each region ordered the largest variety of plane models?  Return the region, customer name and unique fleet models</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = orders.groupby(['Region','Customer Name'])['Model Series'].nunique().unstack(0).agg(['idxmax','max']).T
df.columns = ['Customer Name','Unique Fleet Models']
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = orders.groupby(['Region','Customer Name'])['Model Series'].nunique().unstack(0).agg(['idxmax','max']).T
df.columns = ['Customer Name','Unique Fleet Models']
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = orders.groupby(['Region', 'Customer Name'])['Model Series'].nunique(
    ).unstack(0).agg(['idxmax', 'max']).T
df.columns = ['Customer Name', 'Unique Fleet Models']
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_5848cba5').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5848cba5" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Customer Name</th>
      <th>Unique Fleet Models</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Africa</th>
      <td>Ethiopian Airlines Group</td>
      <td>13.0</td>
    </tr>
    <tr>
      <th>All</th>
      <td>All</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Caribbean</th>
      <td>BWIA</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Central America and Mexico</th>
      <td>Aeromexico</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>Central Asia</th>
      <td>Turkmenhowayollary Agency</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>East Asia</th>
      <td>Korean Air</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>Europe</th>
      <td>KLM Royal Dutch Airlines</td>
      <td>16.0</td>
    </tr>
    <tr>
      <th>Middle East</th>
      <td>EL AL Israel Airlines</td>
      <td>13.0</td>
    </tr>
    <tr>
      <th>North America</th>
      <td>United Airlines</td>
      <td>28.0</td>
    </tr>
    <tr>
      <th>Oceania</th>
      <td>Air New Zealand</td>
      <td>12.0</td>
    </tr>
    <tr>
      <th>South America</th>
      <td>Varig Airlines</td>
      <td>14.0</td>
    </tr>
    <tr>
      <th>South Asia</th>
      <td>Air India</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Southeast Asia</th>
      <td>China Airlines</td>
      <td>13.0</td>
    </tr>
    <tr>
      <th>Unidentified</th>
      <td>Unidentified Customer(s)</td>
      <td>18.0</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Customer Name</th>
      <th>Unique Fleet Models</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Africa</th>
      <td>Ethiopian Airlines Group</td>
      <td>13.0</td>
    </tr>
    <tr>
      <th>All</th>
      <td>All</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Caribbean</th>
      <td>BWIA</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Central America and Mexico</th>
      <td>Aeromexico</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>Central Asia</th>
      <td>Turkmenhowayollary Agency</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>East Asia</th>
      <td>Korean Air</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>Europe</th>
      <td>KLM Royal Dutch Airlines</td>
      <td>16.0</td>
    </tr>
    <tr>
      <th>Middle East</th>
      <td>EL AL Israel Airlines</td>
      <td>13.0</td>
    </tr>
    <tr>
      <th>North America</th>
      <td>United Airlines</td>
      <td>28.0</td>
    </tr>
    <tr>
      <th>Oceania</th>
      <td>Air New Zealand</td>
      <td>12.0</td>
    </tr>
    <tr>
      <th>South America</th>
      <td>Varig Airlines</td>
      <td>14.0</td>
    </tr>
    <tr>
      <th>South Asia</th>
      <td>Air India</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Southeast Asia</th>
      <td>China Airlines</td>
      <td>13.0</td>
    </tr>
    <tr>
      <th>Unidentified</th>
      <td>Unidentified Customer(s)</td>
      <td>18.0</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Customer Name</th>
      <th>Unique Fleet Models</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Africa</th>
      <td>Ethiopian Airlines Group</td>
      <td>13.0</td>
    </tr>
    <tr>
      <th>All</th>
      <td>All</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Caribbean</th>
      <td>BWIA</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Central America and Mexico</th>
      <td>Aeromexico</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>Central Asia</th>
      <td>Turkmenhowayollary Agency</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>East Asia</th>
      <td>Korean Air</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>Europe</th>
      <td>KLM Royal Dutch Airlines</td>
      <td>16.0</td>
    </tr>
    <tr>
      <th>Middle East</th>
      <td>EL AL Israel Airlines</td>
      <td>13.0</td>
    </tr>
    <tr>
      <th>North America</th>
      <td>United Airlines</td>
      <td>28.0</td>
    </tr>
    <tr>
      <th>Oceania</th>
      <td>Air New Zealand</td>
      <td>12.0</td>
    </tr>
    <tr>
      <th>South America</th>
      <td>Varig Airlines</td>
      <td>14.0</td>
    </tr>
    <tr>
      <th>South Asia</th>
      <td>Air India</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Southeast Asia</th>
      <td>China Airlines</td>
      <td>13.0</td>
    </tr>
    <tr>
      <th>Unidentified</th>
      <td>Unidentified Customer(s)</td>
      <td>18.0</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> boeing-historical-airplane-orders-deliveries/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the global order share of each country for the total orders placed in the last ten years?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = orders[(orders['Order Year']>=dt.datetime.now().year-10)].groupby('Country')['Order Total'].sum()
df/df.sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = orders[(orders['Order Year']>=dt.datetime.now().year-10)].groupby('Country')['Order Total'].sum()
df/df.sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = orders[orders['Order Year'] >= dt.datetime.now().year - 10].groupby(
    'Country')['Order Total'].sum()
__output__ = df / df.sum()
</code></pre>
        <p><span onclick="$('#var_output_f40d8125').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f40d8125" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Country
Algeria                 0.001321
Angola                  0.000305
Argentina               0.003150
Australia               0.010365
Azerbaijan              0.001118
                          ...   
Unidentified            0.116858
United Arab Emirates    0.052840
United Kingdom          0.020018
Uzbekistan              0.000508
Vietnam                 0.021339
Name: Order Total, Length: 67, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (Series):</p>
          <pre><code>Country
Algeria                   13.0
Angola                     3.0
Argentina                 31.0
Australia                102.0
Azerbaijan                11.0
                         ...  
Unidentified            1150.0
United Arab Emirates     520.0
United Kingdom           197.0
Uzbekistan                 5.0
Vietnam                  210.0
Name: Order Total, Length: 67, dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Country
Algeria                 0.001321
Angola                  0.000305
Argentina               0.003150
Australia               0.010365
Azerbaijan              0.001118
                          ...   
Unidentified            0.116858
United Arab Emirates    0.052840
United Kingdom          0.020018
Uzbekistan              0.000508
Vietnam                 0.021339
Name: Order Total, Length: 67, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> boeing-historical-airplane-orders-deliveries/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which month in each of the past fifteen years had the highest number of total orders?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>orders[(orders['Order Year']>=dt.datetime.now().year-15)].groupby(['Order Year','Order Month'])['Order Total'].sum().unstack(0).idxmax().T</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>orders[(orders['Order Year']>=dt.datetime.now().year-15)].groupby(['Order Year','Order Month'])['Order Total'].sum().unstack(0).idxmax().T</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = orders[orders['Order Year'] >= dt.datetime.now().year - 15
    ].groupby(['Order Year', 'Order Month'])['Order Total'].sum().unstack(0
    ).idxmax().T
</code></pre>
        <p><span onclick="$('#var_output_73d76cb6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_73d76cb6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Order Year
2007.0    Dec
2008.0    Feb
2009.0    Dec
2010.0    Jul
2011.0    Dec
         ... 
2018.0    Jun
2019.0    Nov
2020.0    Dec
2021.0    Jun
2022.0    Jan
Length: 16, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Order Year
2007.0    Dec
2008.0    Feb
2009.0    Dec
2010.0    Jul
2011.0    Dec
         ... 
2018.0    Jun
2019.0    Nov
2020.0    Dec
2021.0    Jun
2022.0    Jan
Length: 16, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-attorney-cases-prosecuted/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new column 'num_charges' representing the number of filed charges for each case.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>district['num_charges'] = district.list_of_filed_charges.str.split(', ', expand=True).count(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>district['num_charges'] = district.list_of_filed_charges.str.split(', ', expand=True).count(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = district['num_charges'
    ] = district.list_of_filed_charges.str.split(', ', expand=True).count(1)
</code></pre>
        <p><span onclick="$('#var_output_a96af09c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a96af09c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0        2
1        6
2        1
3        3
4        3
        ..
93292    0
93293    0
93294    0
93295    2
93296    0
Length: 93297, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> district, __output__ </p>
    
          <p>district (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>incident_number</th>
      <th>court_number</th>
      <th>arrest_date</th>
      <th>list_of_filed_charges</th>
      <th>filed_case_type</th>
      <th>crime_type</th>
      <th>dv_case</th>
      <th>da_action_taken</th>
      <th>case_status</th>
      <th>data_as_of</th>
      <th>data_loaded_at</th>
      <th>num_charges</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>110011337</td>
      <td>11000408</td>
      <td>2014-01-08</td>
      <td>11352A/F/0, 11359/F/0</td>
      <td>MTR</td>
      <td>Narcotics</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>Filed Motion to Revoke</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>110038109</td>
      <td>11001244</td>
      <td>2014-01-16</td>
      <td>594B1/F/0, 136.1C1/F/0, 245A4/F/0, 245A1/F/0, 422/F/0, 236/F/0</td>
      <td>MTR</td>
      <td>Assault</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>Filed Motion to Revoke</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>110062318</td>
      <td>11002136</td>
      <td>2014-01-21</td>
      <td>11352A/F/0</td>
      <td>MTR</td>
      <td>Narcotics</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>Filed Motion to Revoke</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>110086948</td>
      <td>11002870</td>
      <td>2014-01-23</td>
      <td>211/F/0, 496A/F/0, 32/F/0</td>
      <td>MTR</td>
      <td>Robbery</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>Filed Motion to Revoke</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>110088900</td>
      <td>11002931</td>
      <td>2014-01-15</td>
      <td>12021C/F/0, 12031A2S/F/0, 12025A2B/F/0</td>
      <td>MTR</td>
      <td>NaN</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>Filed Motion to Revoke</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>3</td>
    </tr>
    <tr>
      <th>5</th>
      <td>110096765</td>
      <td>11003213</td>
      <td>2014-01-10</td>
      <td>11352A/F/0, 11350B/F/0</td>
      <td>MTR</td>
      <td>Narcotics</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>Filed Motion to Revoke</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>110100689</td>
      <td>11003402</td>
      <td>2014-01-06</td>
      <td>653FD/M/0, 11350A/F/0</td>
      <td>MTR</td>
      <td>Narcotics</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>Filed Motion to Revoke</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>93290</th>
      <td>220498758</td>
      <td>22007860</td>
      <td>2022-07-27</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>Pending</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>0</td>
    </tr>
    <tr>
      <th>93291</th>
      <td>220559639</td>
      <td>22009248</td>
      <td>2022-08-20</td>
      <td>32310C/M/0</td>
      <td>Misdemeanor</td>
      <td>NaN</td>
      <td>Yes</td>
      <td>New charges filed</td>
      <td>NaN</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>1</td>
    </tr>
    <tr>
      <th>93292</th>
      <td>200588448</td>
      <td>22009070</td>
      <td>2022-08-17</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Yes</td>
      <td>New charges filed</td>
      <td>Pending</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>0</td>
    </tr>
    <tr>
      <th>93293</th>
      <td>220562808</td>
      <td>22009317</td>
      <td>2022-08-21</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>Conviction</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>0</td>
    </tr>
    <tr>
      <th>93294</th>
      <td>Z20220725-22500044</td>
      <td>22500044</td>
      <td>2022-08-25</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>NaN</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>0</td>
    </tr>
    <tr>
      <th>93295</th>
      <td>220593364</td>
      <td>22010021</td>
      <td>2022-09-01</td>
      <td>664/459/F/0, 664/459/F/0</td>
      <td>Felony</td>
      <td>NaN</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>Dismissal</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>2</td>
    </tr>
    <tr>
      <th>93296</th>
      <td>220647115</td>
      <td>22011048</td>
      <td>2022-09-22</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>No</td>
      <td>New charges filed</td>
      <td>Pending</td>
      <td>2022-09-26</td>
      <td>2022-10-14 22:00:53</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>93297 rows × 12 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0        2
1        6
2        1
3        3
4        3
        ..
93292    0
93293    0
93294    0
93295    2
93296    0
Length: 93297, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-attorney-cases-prosecuted/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many cases had more than three filled charges each month over the past twelve months?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>district[(district.num_charges>3) & 
         (district.arrest_date>=(dt.datetime.today() + dt.timedelta(days=-(12*30))))].groupby(pd.Grouper(key='arrest_date',
                                                                                                         freq='M')).incident_number.nunique()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>district[(district.num_charges>3) & 
         (district.arrest_date>=(dt.datetime.today() + dt.timedelta(days=-(12*30))))].groupby(pd.Grouper(key='arrest_date',
                                                                                                         freq='M')).incident_number.nunique()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = district[(district.num_charges > 3) & (district.arrest_date >=
    dt.datetime.today() + dt.timedelta(days=-(12 * 30)))].groupby(pd.
    Grouper(key='arrest_date', freq='M')).incident_number.nunique()
</code></pre>
        <p><span onclick="$('#var_output_6429424f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6429424f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>arrest_date
2021-12-31     69
2022-01-31    152
2022-02-28    128
2022-03-31    140
2022-04-30    108
2022-05-31    140
2022-06-30    132
2022-07-31    150
2022-08-31    167
2022-09-30    108
Freq: M, Name: incident_number, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>arrest_date
2021-12-31     69
2022-01-31    152
2022-02-28    128
2022-03-31    140
2022-04-30    108
2022-05-31    140
2022-06-30    132
2022-07-31    150
2022-08-31    167
2022-09-30    108
Freq: M, Name: incident_number, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-attorney-cases-prosecuted/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common crime type each year?  Show the year as an index and crime type and count as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = district.groupby([pd.Grouper(key='arrest_date',freq='Y'),'crime_type']).size().unstack(0).agg(['idxmax','max']).T
df.index = df.index.year
df.columns = ['crime_type','crime_count']
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = district.groupby([pd.Grouper(key='arrest_date',freq='Y'),'crime_type']).size().unstack(0).agg(['idxmax','max']).T
df.index = df.index.year
df.columns = ['crime_type','crime_count']
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = district.groupby([pd.Grouper(key='arrest_date', freq='Y'), 'crime_type']
    ).size().unstack(0).agg(['idxmax', 'max']).T
df.index = df.index.year
df.columns = ['crime_type', 'crime_count']
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_a5845499').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a5845499" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>crime_type</th>
      <th>crime_count</th>
    </tr>
    <tr>
      <th>arrest_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2011</th>
      <td>Narcotics</td>
      <td>1963.0</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>DUI</td>
      <td>1647.0</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>DUI</td>
      <td>1259.0</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>Burglary</td>
      <td>1143.0</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>Burglary</td>
      <td>1120.0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>Burglary</td>
      <td>1348.0</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>Burglary</td>
      <td>1323.0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>Burglary</td>
      <td>1413.0</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>Burglary</td>
      <td>1313.0</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>Burglary</td>
      <td>920.0</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>Burglary</td>
      <td>752.0</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>Assault</td>
      <td>543.0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>crime_type</th>
      <th>crime_count</th>
    </tr>
    <tr>
      <th>arrest_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2011</th>
      <td>Narcotics</td>
      <td>1963.0</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>DUI</td>
      <td>1647.0</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>DUI</td>
      <td>1259.0</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>Burglary</td>
      <td>1143.0</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>Burglary</td>
      <td>1120.0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>Burglary</td>
      <td>1348.0</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>Burglary</td>
      <td>1323.0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>Burglary</td>
      <td>1413.0</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>Burglary</td>
      <td>1313.0</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>Burglary</td>
      <td>920.0</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>Burglary</td>
      <td>752.0</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>Assault</td>
      <td>543.0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>crime_type</th>
      <th>crime_count</th>
    </tr>
    <tr>
      <th>arrest_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2011</th>
      <td>Narcotics</td>
      <td>1963.0</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>DUI</td>
      <td>1647.0</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>DUI</td>
      <td>1259.0</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>Burglary</td>
      <td>1143.0</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>Burglary</td>
      <td>1120.0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>Burglary</td>
      <td>1348.0</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>Burglary</td>
      <td>1323.0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>Burglary</td>
      <td>1413.0</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>Burglary</td>
      <td>1313.0</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>Burglary</td>
      <td>920.0</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>Burglary</td>
      <td>752.0</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>Assault</td>
      <td>543.0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-attorney-cases-prosecuted/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent change of total cases of each crime type each year.  Show the year as an index and crime types as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = district.groupby([pd.Grouper(key='arrest_date',freq='Y'),'crime_type']).size().unstack().pct_change()
df.index = df.index.year
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = district.groupby([pd.Grouper(key='arrest_date',freq='Y'),'crime_type']).size().unstack().pct_change()
df.index = df.index.year
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = district.groupby([pd.Grouper(key='arrest_date', freq='Y'), 'crime_type']
    ).size().unstack().pct_change()
df.index = df.index.year
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_2c5797cd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2c5797cd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>crime_type</th>
      <th>Annoy/Molest Children</th>
      <th>Arson</th>
      <th>Assault</th>
      <th>Assault and Battery</th>
      <th>Bookmaking</th>
      <th>Burglary</th>
      <th>Contributing Delinquency of Minor</th>
      <th>...</th>
      <th>Theft</th>
      <th>Trespassing</th>
      <th>Unlawful Sexual Intercourse</th>
      <th>Vandalism</th>
      <th>Weapons</th>
      <th>Willful Homicide</th>
      <th>Willful Homicide (Att.)</th>
    </tr>
    <tr>
      <th>arrest_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2011</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>0.00</td>
      <td>1.214286</td>
      <td>-0.038270</td>
      <td>-0.132756</td>
      <td>0.0</td>
      <td>0.251689</td>
      <td>NaN</td>
      <td>...</td>
      <td>-0.154639</td>
      <td>0.100000</td>
      <td>0.000000</td>
      <td>-0.469512</td>
      <td>0.011952</td>
      <td>0.428571</td>
      <td>-0.482759</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>1.00</td>
      <td>-0.032258</td>
      <td>0.024221</td>
      <td>0.039933</td>
      <td>0.0</td>
      <td>0.008097</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.394309</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.942529</td>
      <td>0.153543</td>
      <td>-0.250000</td>
      <td>0.400000</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>0.00</td>
      <td>0.133333</td>
      <td>0.478041</td>
      <td>0.094400</td>
      <td>0.0</td>
      <td>0.530120</td>
      <td>-0.5</td>
      <td>...</td>
      <td>-0.014577</td>
      <td>-0.340909</td>
      <td>2.000000</td>
      <td>-0.065089</td>
      <td>0.341297</td>
      <td>0.333333</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.00</td>
      <td>0.647059</td>
      <td>-0.003429</td>
      <td>0.111111</td>
      <td>0.0</td>
      <td>-0.020122</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.150888</td>
      <td>0.344828</td>
      <td>-0.666667</td>
      <td>0.215190</td>
      <td>0.089059</td>
      <td>-0.150000</td>
      <td>0.392857</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>1.00</td>
      <td>0.357143</td>
      <td>0.092890</td>
      <td>0.151316</td>
      <td>0.0</td>
      <td>0.203571</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.080139</td>
      <td>0.230769</td>
      <td>0.000000</td>
      <td>0.031250</td>
      <td>0.084112</td>
      <td>0.411765</td>
      <td>-0.230769</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>-0.50</td>
      <td>-0.078947</td>
      <td>0.047219</td>
      <td>-0.139429</td>
      <td>0.0</td>
      <td>-0.018546</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.096774</td>
      <td>0.645833</td>
      <td>1.000000</td>
      <td>0.060606</td>
      <td>-0.157328</td>
      <td>-0.291667</td>
      <td>0.200000</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>-0.50</td>
      <td>0.271429</td>
      <td>0.121242</td>
      <td>0.159363</td>
      <td>0.0</td>
      <td>0.068027</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.196429</td>
      <td>-0.050633</td>
      <td>0.500000</td>
      <td>0.000000</td>
      <td>0.148338</td>
      <td>0.000000</td>
      <td>-0.166667</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>3.00</td>
      <td>-0.044944</td>
      <td>-0.074173</td>
      <td>-0.132875</td>
      <td>0.0</td>
      <td>-0.070771</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.014925</td>
      <td>-0.346667</td>
      <td>0.000000</td>
      <td>-0.328571</td>
      <td>-0.122494</td>
      <td>-0.264706</td>
      <td>0.200000</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>0.00</td>
      <td>0.011765</td>
      <td>-0.485521</td>
      <td>-0.425363</td>
      <td>0.0</td>
      <td>-0.299315</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.487879</td>
      <td>-0.591837</td>
      <td>-0.666667</td>
      <td>-0.035461</td>
      <td>-0.401015</td>
      <td>0.200000</td>
      <td>-0.194444</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>-0.75</td>
      <td>-0.302326</td>
      <td>0.120075</td>
      <td>0.298851</td>
      <td>0.0</td>
      <td>-0.182609</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.295858</td>
      <td>1.350000</td>
      <td>0.000000</td>
      <td>0.272059</td>
      <td>0.211864</td>
      <td>0.000000</td>
      <td>-0.068966</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>0.00</td>
      <td>-0.333333</td>
      <td>-0.090452</td>
      <td>-0.148673</td>
      <td>0.0</td>
      <td>-0.373670</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.016807</td>
      <td>-0.234043</td>
      <td>0.000000</td>
      <td>-0.034682</td>
      <td>-0.181818</td>
      <td>-0.633333</td>
      <td>-0.518519</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 44 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>crime_type</th>
      <th>Annoy/Molest Children</th>
      <th>Arson</th>
      <th>Assault</th>
      <th>Assault and Battery</th>
      <th>Bookmaking</th>
      <th>Burglary</th>
      <th>Contributing Delinquency of Minor</th>
      <th>...</th>
      <th>Theft</th>
      <th>Trespassing</th>
      <th>Unlawful Sexual Intercourse</th>
      <th>Vandalism</th>
      <th>Weapons</th>
      <th>Willful Homicide</th>
      <th>Willful Homicide (Att.)</th>
    </tr>
    <tr>
      <th>arrest_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2011</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>0.00</td>
      <td>1.214286</td>
      <td>-0.038270</td>
      <td>-0.132756</td>
      <td>0.0</td>
      <td>0.251689</td>
      <td>NaN</td>
      <td>...</td>
      <td>-0.154639</td>
      <td>0.100000</td>
      <td>0.000000</td>
      <td>-0.469512</td>
      <td>0.011952</td>
      <td>0.428571</td>
      <td>-0.482759</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>1.00</td>
      <td>-0.032258</td>
      <td>0.024221</td>
      <td>0.039933</td>
      <td>0.0</td>
      <td>0.008097</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.394309</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.942529</td>
      <td>0.153543</td>
      <td>-0.250000</td>
      <td>0.400000</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>0.00</td>
      <td>0.133333</td>
      <td>0.478041</td>
      <td>0.094400</td>
      <td>0.0</td>
      <td>0.530120</td>
      <td>-0.5</td>
      <td>...</td>
      <td>-0.014577</td>
      <td>-0.340909</td>
      <td>2.000000</td>
      <td>-0.065089</td>
      <td>0.341297</td>
      <td>0.333333</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.00</td>
      <td>0.647059</td>
      <td>-0.003429</td>
      <td>0.111111</td>
      <td>0.0</td>
      <td>-0.020122</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.150888</td>
      <td>0.344828</td>
      <td>-0.666667</td>
      <td>0.215190</td>
      <td>0.089059</td>
      <td>-0.150000</td>
      <td>0.392857</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>1.00</td>
      <td>0.357143</td>
      <td>0.092890</td>
      <td>0.151316</td>
      <td>0.0</td>
      <td>0.203571</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.080139</td>
      <td>0.230769</td>
      <td>0.000000</td>
      <td>0.031250</td>
      <td>0.084112</td>
      <td>0.411765</td>
      <td>-0.230769</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>-0.50</td>
      <td>-0.078947</td>
      <td>0.047219</td>
      <td>-0.139429</td>
      <td>0.0</td>
      <td>-0.018546</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.096774</td>
      <td>0.645833</td>
      <td>1.000000</td>
      <td>0.060606</td>
      <td>-0.157328</td>
      <td>-0.291667</td>
      <td>0.200000</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>-0.50</td>
      <td>0.271429</td>
      <td>0.121242</td>
      <td>0.159363</td>
      <td>0.0</td>
      <td>0.068027</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.196429</td>
      <td>-0.050633</td>
      <td>0.500000</td>
      <td>0.000000</td>
      <td>0.148338</td>
      <td>0.000000</td>
      <td>-0.166667</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>3.00</td>
      <td>-0.044944</td>
      <td>-0.074173</td>
      <td>-0.132875</td>
      <td>0.0</td>
      <td>-0.070771</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.014925</td>
      <td>-0.346667</td>
      <td>0.000000</td>
      <td>-0.328571</td>
      <td>-0.122494</td>
      <td>-0.264706</td>
      <td>0.200000</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>0.00</td>
      <td>0.011765</td>
      <td>-0.485521</td>
      <td>-0.425363</td>
      <td>0.0</td>
      <td>-0.299315</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.487879</td>
      <td>-0.591837</td>
      <td>-0.666667</td>
      <td>-0.035461</td>
      <td>-0.401015</td>
      <td>0.200000</td>
      <td>-0.194444</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>-0.75</td>
      <td>-0.302326</td>
      <td>0.120075</td>
      <td>0.298851</td>
      <td>0.0</td>
      <td>-0.182609</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.295858</td>
      <td>1.350000</td>
      <td>0.000000</td>
      <td>0.272059</td>
      <td>0.211864</td>
      <td>0.000000</td>
      <td>-0.068966</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>0.00</td>
      <td>-0.333333</td>
      <td>-0.090452</td>
      <td>-0.148673</td>
      <td>0.0</td>
      <td>-0.373670</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.016807</td>
      <td>-0.234043</td>
      <td>0.000000</td>
      <td>-0.034682</td>
      <td>-0.181818</td>
      <td>-0.633333</td>
      <td>-0.518519</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 44 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>crime_type</th>
      <th>Annoy/Molest Children</th>
      <th>Arson</th>
      <th>Assault</th>
      <th>Assault and Battery</th>
      <th>Bookmaking</th>
      <th>Burglary</th>
      <th>Contributing Delinquency of Minor</th>
      <th>...</th>
      <th>Theft</th>
      <th>Trespassing</th>
      <th>Unlawful Sexual Intercourse</th>
      <th>Vandalism</th>
      <th>Weapons</th>
      <th>Willful Homicide</th>
      <th>Willful Homicide (Att.)</th>
    </tr>
    <tr>
      <th>arrest_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2011</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>0.00</td>
      <td>1.214286</td>
      <td>-0.038270</td>
      <td>-0.132756</td>
      <td>0.0</td>
      <td>0.251689</td>
      <td>NaN</td>
      <td>...</td>
      <td>-0.154639</td>
      <td>0.100000</td>
      <td>0.000000</td>
      <td>-0.469512</td>
      <td>0.011952</td>
      <td>0.428571</td>
      <td>-0.482759</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>1.00</td>
      <td>-0.032258</td>
      <td>0.024221</td>
      <td>0.039933</td>
      <td>0.0</td>
      <td>0.008097</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.394309</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.942529</td>
      <td>0.153543</td>
      <td>-0.250000</td>
      <td>0.400000</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>0.00</td>
      <td>0.133333</td>
      <td>0.478041</td>
      <td>0.094400</td>
      <td>0.0</td>
      <td>0.530120</td>
      <td>-0.5</td>
      <td>...</td>
      <td>-0.014577</td>
      <td>-0.340909</td>
      <td>2.000000</td>
      <td>-0.065089</td>
      <td>0.341297</td>
      <td>0.333333</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.00</td>
      <td>0.647059</td>
      <td>-0.003429</td>
      <td>0.111111</td>
      <td>0.0</td>
      <td>-0.020122</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.150888</td>
      <td>0.344828</td>
      <td>-0.666667</td>
      <td>0.215190</td>
      <td>0.089059</td>
      <td>-0.150000</td>
      <td>0.392857</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>1.00</td>
      <td>0.357143</td>
      <td>0.092890</td>
      <td>0.151316</td>
      <td>0.0</td>
      <td>0.203571</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.080139</td>
      <td>0.230769</td>
      <td>0.000000</td>
      <td>0.031250</td>
      <td>0.084112</td>
      <td>0.411765</td>
      <td>-0.230769</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>-0.50</td>
      <td>-0.078947</td>
      <td>0.047219</td>
      <td>-0.139429</td>
      <td>0.0</td>
      <td>-0.018546</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.096774</td>
      <td>0.645833</td>
      <td>1.000000</td>
      <td>0.060606</td>
      <td>-0.157328</td>
      <td>-0.291667</td>
      <td>0.200000</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>-0.50</td>
      <td>0.271429</td>
      <td>0.121242</td>
      <td>0.159363</td>
      <td>0.0</td>
      <td>0.068027</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.196429</td>
      <td>-0.050633</td>
      <td>0.500000</td>
      <td>0.000000</td>
      <td>0.148338</td>
      <td>0.000000</td>
      <td>-0.166667</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>3.00</td>
      <td>-0.044944</td>
      <td>-0.074173</td>
      <td>-0.132875</td>
      <td>0.0</td>
      <td>-0.070771</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.014925</td>
      <td>-0.346667</td>
      <td>0.000000</td>
      <td>-0.328571</td>
      <td>-0.122494</td>
      <td>-0.264706</td>
      <td>0.200000</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>0.00</td>
      <td>0.011765</td>
      <td>-0.485521</td>
      <td>-0.425363</td>
      <td>0.0</td>
      <td>-0.299315</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.487879</td>
      <td>-0.591837</td>
      <td>-0.666667</td>
      <td>-0.035461</td>
      <td>-0.401015</td>
      <td>0.200000</td>
      <td>-0.194444</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>-0.75</td>
      <td>-0.302326</td>
      <td>0.120075</td>
      <td>0.298851</td>
      <td>0.0</td>
      <td>-0.182609</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.295858</td>
      <td>1.350000</td>
      <td>0.000000</td>
      <td>0.272059</td>
      <td>0.211864</td>
      <td>0.000000</td>
      <td>-0.068966</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>0.00</td>
      <td>-0.333333</td>
      <td>-0.090452</td>
      <td>-0.148673</td>
      <td>0.0</td>
      <td>-0.373670</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.016807</td>
      <td>-0.234043</td>
      <td>0.000000</td>
      <td>-0.034682</td>
      <td>-0.181818</td>
      <td>-0.633333</td>
      <td>-0.518519</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 44 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-attorney-cases-prosecuted/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which crime type had the highest number of filled charges over the past five years?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>district[district.arrest_date.dt.year >= dt.datetime.now().year-5].groupby('crime_type').num_charges.sum().idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>district[district.arrest_date.dt.year >= dt.datetime.now().year-5].groupby('crime_type').num_charges.sum().idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = district[district.arrest_date.dt.year >= dt.datetime.now().
    year - 5].groupby('crime_type').num_charges.sum().idxmax()
</code></pre>
        <p><span onclick="$('#var_output_15e3801f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_15e3801f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Burglary</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Burglary</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-attorney-cases-prosecuted/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of dismissed cases each year?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = district.groupby([pd.Grouper(key='arrest_date',freq='Y'),'case_status']).size().unstack()
df = df['Dismissal'] / df.sum(1) *100
df.index = df.index.year
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = district.groupby([pd.Grouper(key='arrest_date',freq='Y'),'case_status']).size().unstack()
df = df['Dismissal'] / df.sum(1) *100
df.index = df.index.year
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = district.groupby([pd.Grouper(key='arrest_date', freq='Y'), 'case_status']
    ).size().unstack()
df = df['Dismissal'] / df.sum(1) * 100
df.index = df.index.year
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_d68d747f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d68d747f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>arrest_date
2011    13.627950
2012     9.920424
2013    11.769581
2014    12.170054
2015    12.680675
2016    13.620357
2017    14.842434
2018    13.106848
2019    11.107302
2020    10.433477
2021     9.608746
2022     4.258098
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (Series):</p>
          <pre><code>arrest_date
2011    13.627950
2012     9.920424
2013    11.769581
2014    12.170054
2015    12.680675
2016    13.620357
2017    14.842434
2018    13.106848
2019    11.107302
2020    10.433477
2021     9.608746
2022     4.258098
dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>arrest_date
2011    13.627950
2012     9.920424
2013    11.769581
2014    12.170054
2015    12.680675
2016    13.620357
2017    14.842434
2018    13.106848
2019    11.107302
2020    10.433477
2021     9.608746
2022     4.258098
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-attorney-cases-prosecuted/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average interval, in days, between consecutive robberies reported over the past twelve months?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = district[(district.arrest_date>=(dt.datetime.today() + dt.timedelta(days=-(12*30)))) & (district.crime_type=='Robbery')][['crime_type','arrest_date']]
df.sort_values(by='arrest_date',inplace=True)
df['next_arrest_after'] = df.arrest_date - df.arrest_date.shift(1)
df.next_arrest_after.dt.days.mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = district[(district.arrest_date>=(dt.datetime.today() + dt.timedelta(days=-(12*30)))) & (district.crime_type=='Robbery')][['crime_type','arrest_date']]
df.sort_values(by='arrest_date',inplace=True)
df['next_arrest_after'] = df.arrest_date - df.arrest_date.shift(1)
df.next_arrest_after.dt.days.mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = district[(district.arrest_date >= dt.datetime.today() + dt.timedelta(
    days=-(12 * 30))) & (district.crime_type == 'Robbery')][['crime_type',
    'arrest_date']]
__tmp_1 = df.sort_values(by='arrest_date', inplace=True)
df['next_arrest_after'] = df.arrest_date - df.arrest_date.shift(1)
__output__ = df.next_arrest_after.dt.days.mean()
</code></pre>
        <p><span onclick="$('#var_output_e889fbea').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e889fbea" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>1.541899441340782</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>crime_type</th>
      <th>arrest_date</th>
      <th>next_arrest_after</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15931</th>
      <td>Robbery</td>
      <td>2021-12-19</td>
      <td>NaT</td>
    </tr>
    <tr>
      <th>10480</th>
      <td>Robbery</td>
      <td>2021-12-20</td>
      <td>1 days</td>
    </tr>
    <tr>
      <th>10502</th>
      <td>Robbery</td>
      <td>2021-12-21</td>
      <td>1 days</td>
    </tr>
    <tr>
      <th>15937</th>
      <td>Robbery</td>
      <td>2021-12-21</td>
      <td>0 days</td>
    </tr>
    <tr>
      <th>15922</th>
      <td>Robbery</td>
      <td>2021-12-24</td>
      <td>3 days</td>
    </tr>
    <tr>
      <th>15939</th>
      <td>Robbery</td>
      <td>2021-12-29</td>
      <td>5 days</td>
    </tr>
    <tr>
      <th>15938</th>
      <td>Robbery</td>
      <td>2021-12-29</td>
      <td>0 days</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>16085</th>
      <td>Robbery</td>
      <td>2022-09-12</td>
      <td>3 days</td>
    </tr>
    <tr>
      <th>16086</th>
      <td>Robbery</td>
      <td>2022-09-13</td>
      <td>1 days</td>
    </tr>
    <tr>
      <th>16087</th>
      <td>Robbery</td>
      <td>2022-09-13</td>
      <td>0 days</td>
    </tr>
    <tr>
      <th>16088</th>
      <td>Robbery</td>
      <td>2022-09-15</td>
      <td>2 days</td>
    </tr>
    <tr>
      <th>16089</th>
      <td>Robbery</td>
      <td>2022-09-16</td>
      <td>1 days</td>
    </tr>
    <tr>
      <th>16090</th>
      <td>Robbery</td>
      <td>2022-09-18</td>
      <td>2 days</td>
    </tr>
    <tr>
      <th>16091</th>
      <td>Robbery</td>
      <td>2022-09-21</td>
      <td>3 days</td>
    </tr>
  </tbody>
</table>
<p>180 rows × 3 columns</p>
      
          <p>__output__ (float64):</p>
          <pre><code>1.541899441340782</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-attorney-cases-prosecuted/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average number of filed charges for drug related cases?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>int(district[district.crime_type.str.contains('narcotic',case=False, na=False)].num_charges.mean())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>int(district[district.crime_type.str.contains('narcotic',case=False, na=False)].num_charges.mean())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = int(district[district.crime_type.str.contains('narcotic', case
    =False, na=False)].num_charges.mean())
</code></pre>
        <p><span onclick="$('#var_output_d38702de').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d38702de" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>3</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>3</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-attorney-cases-prosecuted/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which crime is associated with the highest total number of filled charges each year?  Show the year as an index and crime type and total filled charges as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = district.groupby([pd.Grouper(key='arrest_date',freq='Y'),'crime_type']).num_charges.sum().unstack(0).agg(['idxmax','max']).T
df.index = df.index.year
df.columns = ['crime_type','num_charges']
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = district.groupby([pd.Grouper(key='arrest_date',freq='Y'),'crime_type']).num_charges.sum().unstack(0).agg(['idxmax','max']).T
df.index = df.index.year
df.columns = ['crime_type','num_charges']
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = district.groupby([pd.Grouper(key='arrest_date', freq='Y'), 'crime_type']
    ).num_charges.sum().unstack(0).agg(['idxmax', 'max']).T
df.index = df.index.year
df.columns = ['crime_type', 'num_charges']
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_daee139d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_daee139d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>crime_type</th>
      <th>num_charges</th>
    </tr>
    <tr>
      <th>arrest_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2011</th>
      <td>Narcotics</td>
      <td>4577.0</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>DUI</td>
      <td>4414.0</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>DUI</td>
      <td>3902.0</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>Assault</td>
      <td>4475.0</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>Assault</td>
      <td>4388.0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>Assault</td>
      <td>5616.0</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>Burglary</td>
      <td>5320.0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>Assault</td>
      <td>5836.0</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>Burglary</td>
      <td>5446.0</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>Burglary</td>
      <td>3321.0</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>Assault</td>
      <td>3035.0</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>Assault</td>
      <td>2607.0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>crime_type</th>
      <th>num_charges</th>
    </tr>
    <tr>
      <th>arrest_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2011</th>
      <td>Narcotics</td>
      <td>4577.0</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>DUI</td>
      <td>4414.0</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>DUI</td>
      <td>3902.0</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>Assault</td>
      <td>4475.0</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>Assault</td>
      <td>4388.0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>Assault</td>
      <td>5616.0</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>Burglary</td>
      <td>5320.0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>Assault</td>
      <td>5836.0</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>Burglary</td>
      <td>5446.0</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>Burglary</td>
      <td>3321.0</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>Assault</td>
      <td>3035.0</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>Assault</td>
      <td>2607.0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>crime_type</th>
      <th>num_charges</th>
    </tr>
    <tr>
      <th>arrest_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2011</th>
      <td>Narcotics</td>
      <td>4577.0</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>DUI</td>
      <td>4414.0</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>DUI</td>
      <td>3902.0</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>Assault</td>
      <td>4475.0</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>Assault</td>
      <td>4388.0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>Assault</td>
      <td>5616.0</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>Burglary</td>
      <td>5320.0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>Assault</td>
      <td>5836.0</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>Burglary</td>
      <td>5446.0</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>Burglary</td>
      <td>3321.0</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>Assault</td>
      <td>3035.0</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>Assault</td>
      <td>2607.0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-attorney-cases-prosecuted/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the month-over-month percent change in reported burglary cases over the past twelve months?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>district[(district.arrest_date>=(dt.datetime.today() + dt.timedelta(days=-(12*30)))) & 
         (district.crime_type=='Burglary')].groupby(pd.Grouper(key='arrest_date',freq='M')).size().pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>district[(district.arrest_date>=(dt.datetime.today() + dt.timedelta(days=-(12*30)))) & 
         (district.crime_type=='Burglary')].groupby(pd.Grouper(key='arrest_date',freq='M')).size().pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = district[(district.arrest_date >= dt.datetime.today() + dt.
    timedelta(days=-(12 * 30))) & (district.crime_type == 'Burglary')].groupby(
    pd.Grouper(key='arrest_date', freq='M')).size().pct_change()
</code></pre>
        <p><span onclick="$('#var_output_546eebca').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_546eebca" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>arrest_date
2021-12-31         NaN
2022-01-31    1.750000
2022-02-28   -0.163636
2022-03-31    0.130435
2022-04-30    0.057692
2022-05-31   -0.072727
2022-06-30    0.039216
2022-07-31    0.188679
2022-08-31   -0.015873
2022-09-30   -0.451613
Freq: M, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>arrest_date
2021-12-31         NaN
2022-01-31    1.750000
2022-02-28   -0.163636
2022-03-31    0.130435
2022-04-30    0.057692
2022-05-31   -0.072727
2022-06-30    0.039216
2022-07-31    0.188679
2022-08-31   -0.015873
2022-09-30   -0.451613
Freq: M, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> victoria-bc-city-tree-species-data/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average diameter of trees within every category planted in each area?  Show the Area as rows and categories as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>trees.groupby(['Area','TreeCategory']).DiameterAtBreastHeight.mean().unstack()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>trees.groupby(['Area','TreeCategory']).DiameterAtBreastHeight.mean().unstack()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = trees.groupby(['Area', 'TreeCategory']
    ).DiameterAtBreastHeight.mean().unstack()
</code></pre>
        <p><span onclick="$('#var_output_16ebb754').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_16ebb754" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>TreeCategory</th>
      <th>Boulevard Tree</th>
      <th>Co-owned Trees</th>
      <th>Hardscape Trees</th>
      <th>Median Trees</th>
      <th>Memorial Tree</th>
      <th>Park Frontage Trees</th>
      <th>Park Trees</th>
      <th>Private Tree</th>
      <th>Setback Trees</th>
      <th>Stewardship Food Tree PARK</th>
    </tr>
    <tr>
      <th>Area</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Burnside</th>
      <td>28.045662</td>
      <td>40.818182</td>
      <td>24.439815</td>
      <td>32.727273</td>
      <td>NaN</td>
      <td>25.884615</td>
      <td>27.904602</td>
      <td>NaN</td>
      <td>33.063779</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Downtown</th>
      <td>24.000000</td>
      <td>NaN</td>
      <td>23.032429</td>
      <td>50.214286</td>
      <td>NaN</td>
      <td>27.375000</td>
      <td>45.822581</td>
      <td>NaN</td>
      <td>19.406250</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Fairfield</th>
      <td>36.417996</td>
      <td>40.918919</td>
      <td>28.489362</td>
      <td>48.500000</td>
      <td>NaN</td>
      <td>42.150579</td>
      <td>43.241570</td>
      <td>NaN</td>
      <td>33.855670</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Fernwood</th>
      <td>32.403621</td>
      <td>46.851852</td>
      <td>37.612903</td>
      <td>46.333333</td>
      <td>NaN</td>
      <td>43.928571</td>
      <td>37.724274</td>
      <td>45.0</td>
      <td>38.301568</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Gonzales</th>
      <td>31.416413</td>
      <td>54.232558</td>
      <td>24.055556</td>
      <td>34.818182</td>
      <td>NaN</td>
      <td>42.612903</td>
      <td>43.640199</td>
      <td>NaN</td>
      <td>37.978286</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Harris Green</th>
      <td>36.564417</td>
      <td>NaN</td>
      <td>28.074866</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>43.177778</td>
      <td>NaN</td>
      <td>15.666667</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Hillside/Quadra</th>
      <td>33.168350</td>
      <td>62.518519</td>
      <td>21.760870</td>
      <td>20.693548</td>
      <td>NaN</td>
      <td>37.911765</td>
      <td>33.024970</td>
      <td>1.0</td>
      <td>34.237994</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>James Bay</th>
      <td>36.607600</td>
      <td>38.870130</td>
      <td>23.086957</td>
      <td>72.500000</td>
      <td>6.0</td>
      <td>46.785185</td>
      <td>35.633930</td>
      <td>NaN</td>
      <td>33.158683</td>
      <td>1.8</td>
    </tr>
    <tr>
      <th>North Jubilee</th>
      <td>45.894180</td>
      <td>49.027027</td>
      <td>49.800000</td>
      <td>53.666667</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>33.923077</td>
      <td>NaN</td>
      <td>35.641447</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>North Park</th>
      <td>25.366013</td>
      <td>50.111111</td>
      <td>22.185185</td>
      <td>35.866667</td>
      <td>NaN</td>
      <td>61.500000</td>
      <td>58.304348</td>
      <td>NaN</td>
      <td>25.895288</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Oaklands</th>
      <td>30.906040</td>
      <td>42.872340</td>
      <td>36.466667</td>
      <td>33.000000</td>
      <td>NaN</td>
      <td>43.745098</td>
      <td>40.277397</td>
      <td>66.0</td>
      <td>38.054201</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Rockland</th>
      <td>34.618911</td>
      <td>56.852459</td>
      <td>76.000000</td>
      <td>49.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>47.071429</td>
      <td>85.0</td>
      <td>37.433460</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>South Jubilee</th>
      <td>26.359551</td>
      <td>90.000000</td>
      <td>16.000000</td>
      <td>73.750000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>33.148148</td>
      <td>NaN</td>
      <td>37.326923</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Victoria West</th>
      <td>25.072368</td>
      <td>44.707692</td>
      <td>18.250000</td>
      <td>13.829268</td>
      <td>NaN</td>
      <td>26.628205</td>
      <td>33.208573</td>
      <td>NaN</td>
      <td>28.571101</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 10 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>TreeCategory</th>
      <th>Boulevard Tree</th>
      <th>Co-owned Trees</th>
      <th>Hardscape Trees</th>
      <th>Median Trees</th>
      <th>Memorial Tree</th>
      <th>Park Frontage Trees</th>
      <th>Park Trees</th>
      <th>Private Tree</th>
      <th>Setback Trees</th>
      <th>Stewardship Food Tree PARK</th>
    </tr>
    <tr>
      <th>Area</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Burnside</th>
      <td>28.045662</td>
      <td>40.818182</td>
      <td>24.439815</td>
      <td>32.727273</td>
      <td>NaN</td>
      <td>25.884615</td>
      <td>27.904602</td>
      <td>NaN</td>
      <td>33.063779</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Downtown</th>
      <td>24.000000</td>
      <td>NaN</td>
      <td>23.032429</td>
      <td>50.214286</td>
      <td>NaN</td>
      <td>27.375000</td>
      <td>45.822581</td>
      <td>NaN</td>
      <td>19.406250</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Fairfield</th>
      <td>36.417996</td>
      <td>40.918919</td>
      <td>28.489362</td>
      <td>48.500000</td>
      <td>NaN</td>
      <td>42.150579</td>
      <td>43.241570</td>
      <td>NaN</td>
      <td>33.855670</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Fernwood</th>
      <td>32.403621</td>
      <td>46.851852</td>
      <td>37.612903</td>
      <td>46.333333</td>
      <td>NaN</td>
      <td>43.928571</td>
      <td>37.724274</td>
      <td>45.0</td>
      <td>38.301568</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Gonzales</th>
      <td>31.416413</td>
      <td>54.232558</td>
      <td>24.055556</td>
      <td>34.818182</td>
      <td>NaN</td>
      <td>42.612903</td>
      <td>43.640199</td>
      <td>NaN</td>
      <td>37.978286</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Harris Green</th>
      <td>36.564417</td>
      <td>NaN</td>
      <td>28.074866</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>43.177778</td>
      <td>NaN</td>
      <td>15.666667</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Hillside/Quadra</th>
      <td>33.168350</td>
      <td>62.518519</td>
      <td>21.760870</td>
      <td>20.693548</td>
      <td>NaN</td>
      <td>37.911765</td>
      <td>33.024970</td>
      <td>1.0</td>
      <td>34.237994</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>James Bay</th>
      <td>36.607600</td>
      <td>38.870130</td>
      <td>23.086957</td>
      <td>72.500000</td>
      <td>6.0</td>
      <td>46.785185</td>
      <td>35.633930</td>
      <td>NaN</td>
      <td>33.158683</td>
      <td>1.8</td>
    </tr>
    <tr>
      <th>North Jubilee</th>
      <td>45.894180</td>
      <td>49.027027</td>
      <td>49.800000</td>
      <td>53.666667</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>33.923077</td>
      <td>NaN</td>
      <td>35.641447</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>North Park</th>
      <td>25.366013</td>
      <td>50.111111</td>
      <td>22.185185</td>
      <td>35.866667</td>
      <td>NaN</td>
      <td>61.500000</td>
      <td>58.304348</td>
      <td>NaN</td>
      <td>25.895288</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Oaklands</th>
      <td>30.906040</td>
      <td>42.872340</td>
      <td>36.466667</td>
      <td>33.000000</td>
      <td>NaN</td>
      <td>43.745098</td>
      <td>40.277397</td>
      <td>66.0</td>
      <td>38.054201</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Rockland</th>
      <td>34.618911</td>
      <td>56.852459</td>
      <td>76.000000</td>
      <td>49.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>47.071429</td>
      <td>85.0</td>
      <td>37.433460</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>South Jubilee</th>
      <td>26.359551</td>
      <td>90.000000</td>
      <td>16.000000</td>
      <td>73.750000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>33.148148</td>
      <td>NaN</td>
      <td>37.326923</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Victoria West</th>
      <td>25.072368</td>
      <td>44.707692</td>
      <td>18.250000</td>
      <td>13.829268</td>
      <td>NaN</td>
      <td>26.628205</td>
      <td>33.208573</td>
      <td>NaN</td>
      <td>28.571101</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 10 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> victoria-bc-city-tree-species-data/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # In which parks were the tallest trees planted for every category? Return the park name and height of the tallest tree.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = trees.groupby(['Parks','TreeCategory']).Height.max().unstack().agg(['idxmax','max']).T
df.columns = ['Park Name','Height']
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = trees.groupby(['Parks','TreeCategory']).Height.max().unstack().agg(['idxmax','max']).T
df.columns = ['Park Name','Height']
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = trees.groupby(['Parks', 'TreeCategory']).Height.max().unstack().agg([
    'idxmax', 'max']).T
df.columns = ['Park Name', 'Height']
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_138421c5').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_138421c5" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Park Name</th>
      <th>Height</th>
    </tr>
    <tr>
      <th>TreeCategory</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Boulevard Tree</th>
      <td>LAW COURTS GREEN</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>Co-owned Trees</th>
      <td>Z ADD 01</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Hardscape Trees</th>
      <td>BASTION SQUARE</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>Median Trees</th>
      <td>JOHNSON STREET GREEN</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Memorial Tree</th>
      <td>BEACON HILL PARK</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>Park Frontage Trees</th>
      <td>PIONEER SQUARE</td>
      <td>32.0</td>
    </tr>
    <tr>
      <th>Park Trees</th>
      <td>BEACON HILL PARK</td>
      <td>44.0</td>
    </tr>
    <tr>
      <th>Private Tree</th>
      <td>FERNWOOD ALLOTMENT GARDEN</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Setback Trees</th>
      <td>JOHNSON STREET GREEN</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Stewardship Food Tree PARK</th>
      <td>CHARLES REDFERN PARK</td>
      <td>12.0</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Park Name</th>
      <th>Height</th>
    </tr>
    <tr>
      <th>TreeCategory</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Boulevard Tree</th>
      <td>LAW COURTS GREEN</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>Co-owned Trees</th>
      <td>Z ADD 01</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Hardscape Trees</th>
      <td>BASTION SQUARE</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>Median Trees</th>
      <td>JOHNSON STREET GREEN</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Memorial Tree</th>
      <td>BEACON HILL PARK</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>Park Frontage Trees</th>
      <td>PIONEER SQUARE</td>
      <td>32.0</td>
    </tr>
    <tr>
      <th>Park Trees</th>
      <td>BEACON HILL PARK</td>
      <td>44.0</td>
    </tr>
    <tr>
      <th>Private Tree</th>
      <td>FERNWOOD ALLOTMENT GARDEN</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Setback Trees</th>
      <td>JOHNSON STREET GREEN</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Stewardship Food Tree PARK</th>
      <td>CHARLES REDFERN PARK</td>
      <td>12.0</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Park Name</th>
      <th>Height</th>
    </tr>
    <tr>
      <th>TreeCategory</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Boulevard Tree</th>
      <td>LAW COURTS GREEN</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>Co-owned Trees</th>
      <td>Z ADD 01</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Hardscape Trees</th>
      <td>BASTION SQUARE</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>Median Trees</th>
      <td>JOHNSON STREET GREEN</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Memorial Tree</th>
      <td>BEACON HILL PARK</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>Park Frontage Trees</th>
      <td>PIONEER SQUARE</td>
      <td>32.0</td>
    </tr>
    <tr>
      <th>Park Trees</th>
      <td>BEACON HILL PARK</td>
      <td>44.0</td>
    </tr>
    <tr>
      <th>Private Tree</th>
      <td>FERNWOOD ALLOTMENT GARDEN</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Setback Trees</th>
      <td>JOHNSON STREET GREEN</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Stewardship Food Tree PARK</th>
      <td>CHARLES REDFERN PARK</td>
      <td>12.0</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> victoria-bc-city-tree-species-data/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common space of growth for 'Hawthorn' trees?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>trees[trees.CommonName == 'Hawthorn'].GrowSpace.value_counts().idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>trees[trees.CommonName == 'Hawthorn'].GrowSpace.value_counts().idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = trees[trees.CommonName == 'Hawthorn'].GrowSpace.value_counts(
    ).idxmax()
</code></pre>
        <p><span onclick="$('#var_output_80025f0e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_80025f0e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Turf</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Turf</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> victoria-bc-city-tree-species-data/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the name of the park that has the highest variety of trees planted?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>park = trees.groupby('Parks').CommonName.nunique().idxmax()
park</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>park = trees.groupby('Parks').CommonName.nunique().idxmax()
park</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>park = trees.groupby('Parks').CommonName.nunique().idxmax()
__output__ = park
</code></pre>
        <p><span onclick="$('#var_output_81c1e73e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_81c1e73e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>BEACON HILL PARK</code></pre>
      
        <p><strong>Hyp output variables:</strong> park, __output__ </p>
    
          <p>park (str):</p>
          <pre><code>BEACON HILL PARK</code></pre>
      
          <p>__output__ (str):</p>
          <pre><code>BEACON HILL PARK</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> victoria-bc-city-tree-species-data/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many front and left facing trees were planted in that park?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>trees[(trees.Parks==park) & (trees.SideOfParcel.str.contains('front|left',case=False))].groupby('SideOfParcel').size()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>trees[(trees.Parks==park) & (trees.SideOfParcel.str.contains('front|left',case=False))].groupby('SideOfParcel').size()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = trees[(trees.Parks == park) & trees.SideOfParcel.str.contains(
    'front|left', case=False)].groupby('SideOfParcel').size()
</code></pre>
        <p><span onclick="$('#var_output_cefc1633').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_cefc1633" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>SideOfParcel
Front    45
Left     80
dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>SideOfParcel
Front    45
Left     80
dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> victoria-bc-city-tree-species-data/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many trees having a diameter of more than and less than ten were planted in each area?  Show the areas as rows and 'Diameter >10' and 'Diameter <= 10' as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = trees.groupby(['Area',trees.DiameterAtBreastHeight>10]).size().unstack()
df.columns = ['Diameter > 10', 'Diameter <= 10']
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = trees.groupby(['Area',trees.DiameterAtBreastHeight>10]).size().unstack()
df.columns = ['Diameter > 10', 'Diameter <= 10']
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = trees.groupby(['Area', trees.DiameterAtBreastHeight > 10]).size().unstack(
    )
df.columns = ['Diameter > 10', 'Diameter <= 10']
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_e25985b5').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e25985b5" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Diameter &gt; 10</th>
      <th>Diameter &lt;= 10</th>
    </tr>
    <tr>
      <th>Area</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Burnside</th>
      <td>514</td>
      <td>2286</td>
    </tr>
    <tr>
      <th>Downtown</th>
      <td>203</td>
      <td>805</td>
    </tr>
    <tr>
      <th>Fairfield</th>
      <td>1015</td>
      <td>6008</td>
    </tr>
    <tr>
      <th>Fernwood</th>
      <td>511</td>
      <td>1790</td>
    </tr>
    <tr>
      <th>Gonzales</th>
      <td>433</td>
      <td>1606</td>
    </tr>
    <tr>
      <th>Harris Green</th>
      <td>83</td>
      <td>316</td>
    </tr>
    <tr>
      <th>Hillside/Quadra</th>
      <td>519</td>
      <td>3242</td>
    </tr>
    <tr>
      <th>James Bay</th>
      <td>764</td>
      <td>5759</td>
    </tr>
    <tr>
      <th>North Jubilee</th>
      <td>98</td>
      <td>485</td>
    </tr>
    <tr>
      <th>North Park</th>
      <td>190</td>
      <td>572</td>
    </tr>
    <tr>
      <th>Oaklands</th>
      <td>373</td>
      <td>1594</td>
    </tr>
    <tr>
      <th>Rockland</th>
      <td>200</td>
      <td>757</td>
    </tr>
    <tr>
      <th>South Jubilee</th>
      <td>100</td>
      <td>358</td>
    </tr>
    <tr>
      <th>Victoria West</th>
      <td>741</td>
      <td>2424</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Diameter &gt; 10</th>
      <th>Diameter &lt;= 10</th>
    </tr>
    <tr>
      <th>Area</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Burnside</th>
      <td>514</td>
      <td>2286</td>
    </tr>
    <tr>
      <th>Downtown</th>
      <td>203</td>
      <td>805</td>
    </tr>
    <tr>
      <th>Fairfield</th>
      <td>1015</td>
      <td>6008</td>
    </tr>
    <tr>
      <th>Fernwood</th>
      <td>511</td>
      <td>1790</td>
    </tr>
    <tr>
      <th>Gonzales</th>
      <td>433</td>
      <td>1606</td>
    </tr>
    <tr>
      <th>Harris Green</th>
      <td>83</td>
      <td>316</td>
    </tr>
    <tr>
      <th>Hillside/Quadra</th>
      <td>519</td>
      <td>3242</td>
    </tr>
    <tr>
      <th>James Bay</th>
      <td>764</td>
      <td>5759</td>
    </tr>
    <tr>
      <th>North Jubilee</th>
      <td>98</td>
      <td>485</td>
    </tr>
    <tr>
      <th>North Park</th>
      <td>190</td>
      <td>572</td>
    </tr>
    <tr>
      <th>Oaklands</th>
      <td>373</td>
      <td>1594</td>
    </tr>
    <tr>
      <th>Rockland</th>
      <td>200</td>
      <td>757</td>
    </tr>
    <tr>
      <th>South Jubilee</th>
      <td>100</td>
      <td>358</td>
    </tr>
    <tr>
      <th>Victoria West</th>
      <td>741</td>
      <td>2424</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Diameter &gt; 10</th>
      <th>Diameter &lt;= 10</th>
    </tr>
    <tr>
      <th>Area</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Burnside</th>
      <td>514</td>
      <td>2286</td>
    </tr>
    <tr>
      <th>Downtown</th>
      <td>203</td>
      <td>805</td>
    </tr>
    <tr>
      <th>Fairfield</th>
      <td>1015</td>
      <td>6008</td>
    </tr>
    <tr>
      <th>Fernwood</th>
      <td>511</td>
      <td>1790</td>
    </tr>
    <tr>
      <th>Gonzales</th>
      <td>433</td>
      <td>1606</td>
    </tr>
    <tr>
      <th>Harris Green</th>
      <td>83</td>
      <td>316</td>
    </tr>
    <tr>
      <th>Hillside/Quadra</th>
      <td>519</td>
      <td>3242</td>
    </tr>
    <tr>
      <th>James Bay</th>
      <td>764</td>
      <td>5759</td>
    </tr>
    <tr>
      <th>North Jubilee</th>
      <td>98</td>
      <td>485</td>
    </tr>
    <tr>
      <th>North Park</th>
      <td>190</td>
      <td>572</td>
    </tr>
    <tr>
      <th>Oaklands</th>
      <td>373</td>
      <td>1594</td>
    </tr>
    <tr>
      <th>Rockland</th>
      <td>200</td>
      <td>757</td>
    </tr>
    <tr>
      <th>South Jubilee</th>
      <td>100</td>
      <td>358</td>
    </tr>
    <tr>
      <th>Victoria West</th>
      <td>741</td>
      <td>2424</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> victoria-bc-city-tree-species-data/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which park had the highest variety of planted trees in each area? Return the park name and count of unique planted trees.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = trees.groupby(['Area','Parks']).CommonName.nunique().unstack(0).agg(['idxmax','max']).T
df.columns = ['park_name','unique_trees']
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = trees.groupby(['Area','Parks']).CommonName.nunique().unstack(0).agg(['idxmax','max']).T
df.columns = ['park_name','unique_trees']
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = trees.groupby(['Area', 'Parks']).CommonName.nunique().unstack(0).agg([
    'idxmax', 'max']).T
df.columns = ['park_name', 'unique_trees']
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_11e358bb').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_11e358bb" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>park_name</th>
      <th>unique_trees</th>
    </tr>
    <tr>
      <th>Area</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Burnside</th>
      <td>CECELIA RAVINE PARK</td>
      <td>32.0</td>
    </tr>
    <tr>
      <th>Downtown</th>
      <td>CENTENNIAL SQUARE</td>
      <td>17.0</td>
    </tr>
    <tr>
      <th>Fairfield</th>
      <td>BEACON HILL PARK</td>
      <td>131.0</td>
    </tr>
    <tr>
      <th>Fernwood</th>
      <td>STADACONA PARK</td>
      <td>47.0</td>
    </tr>
    <tr>
      <th>Gonzales</th>
      <td>HOLLYWOOD PARK</td>
      <td>48.0</td>
    </tr>
    <tr>
      <th>Harris Green</th>
      <td>PANDORA GREEN</td>
      <td>17.0</td>
    </tr>
    <tr>
      <th>Hillside/Quadra</th>
      <td>TOPAZ PARK</td>
      <td>37.0</td>
    </tr>
    <tr>
      <th>James Bay</th>
      <td>BEACON HILL PARK</td>
      <td>123.0</td>
    </tr>
    <tr>
      <th>North Jubilee</th>
      <td>BEGBIE PARKWAY</td>
      <td>12.0</td>
    </tr>
    <tr>
      <th>North Park</th>
      <td>CENTRAL PARK</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Oaklands</th>
      <td>OSWALD STREET PLAYGROUND</td>
      <td>21.0</td>
    </tr>
    <tr>
      <th>Rockland</th>
      <td>Z ADD 01</td>
      <td>21.0</td>
    </tr>
    <tr>
      <th>South Jubilee</th>
      <td>REDFERN PARK</td>
      <td>18.0</td>
    </tr>
    <tr>
      <th>Victoria West</th>
      <td>BANFIELD PARK</td>
      <td>51.0</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>park_name</th>
      <th>unique_trees</th>
    </tr>
    <tr>
      <th>Area</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Burnside</th>
      <td>CECELIA RAVINE PARK</td>
      <td>32.0</td>
    </tr>
    <tr>
      <th>Downtown</th>
      <td>CENTENNIAL SQUARE</td>
      <td>17.0</td>
    </tr>
    <tr>
      <th>Fairfield</th>
      <td>BEACON HILL PARK</td>
      <td>131.0</td>
    </tr>
    <tr>
      <th>Fernwood</th>
      <td>STADACONA PARK</td>
      <td>47.0</td>
    </tr>
    <tr>
      <th>Gonzales</th>
      <td>HOLLYWOOD PARK</td>
      <td>48.0</td>
    </tr>
    <tr>
      <th>Harris Green</th>
      <td>PANDORA GREEN</td>
      <td>17.0</td>
    </tr>
    <tr>
      <th>Hillside/Quadra</th>
      <td>TOPAZ PARK</td>
      <td>37.0</td>
    </tr>
    <tr>
      <th>James Bay</th>
      <td>BEACON HILL PARK</td>
      <td>123.0</td>
    </tr>
    <tr>
      <th>North Jubilee</th>
      <td>BEGBIE PARKWAY</td>
      <td>12.0</td>
    </tr>
    <tr>
      <th>North Park</th>
      <td>CENTRAL PARK</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Oaklands</th>
      <td>OSWALD STREET PLAYGROUND</td>
      <td>21.0</td>
    </tr>
    <tr>
      <th>Rockland</th>
      <td>Z ADD 01</td>
      <td>21.0</td>
    </tr>
    <tr>
      <th>South Jubilee</th>
      <td>REDFERN PARK</td>
      <td>18.0</td>
    </tr>
    <tr>
      <th>Victoria West</th>
      <td>BANFIELD PARK</td>
      <td>51.0</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>park_name</th>
      <th>unique_trees</th>
    </tr>
    <tr>
      <th>Area</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Burnside</th>
      <td>CECELIA RAVINE PARK</td>
      <td>32.0</td>
    </tr>
    <tr>
      <th>Downtown</th>
      <td>CENTENNIAL SQUARE</td>
      <td>17.0</td>
    </tr>
    <tr>
      <th>Fairfield</th>
      <td>BEACON HILL PARK</td>
      <td>131.0</td>
    </tr>
    <tr>
      <th>Fernwood</th>
      <td>STADACONA PARK</td>
      <td>47.0</td>
    </tr>
    <tr>
      <th>Gonzales</th>
      <td>HOLLYWOOD PARK</td>
      <td>48.0</td>
    </tr>
    <tr>
      <th>Harris Green</th>
      <td>PANDORA GREEN</td>
      <td>17.0</td>
    </tr>
    <tr>
      <th>Hillside/Quadra</th>
      <td>TOPAZ PARK</td>
      <td>37.0</td>
    </tr>
    <tr>
      <th>James Bay</th>
      <td>BEACON HILL PARK</td>
      <td>123.0</td>
    </tr>
    <tr>
      <th>North Jubilee</th>
      <td>BEGBIE PARKWAY</td>
      <td>12.0</td>
    </tr>
    <tr>
      <th>North Park</th>
      <td>CENTRAL PARK</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>Oaklands</th>
      <td>OSWALD STREET PLAYGROUND</td>
      <td>21.0</td>
    </tr>
    <tr>
      <th>Rockland</th>
      <td>Z ADD 01</td>
      <td>21.0</td>
    </tr>
    <tr>
      <th>South Jubilee</th>
      <td>REDFERN PARK</td>
      <td>18.0</td>
    </tr>
    <tr>
      <th>Victoria West</th>
      <td>BANFIELD PARK</td>
      <td>51.0</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> victoria-bc-city-tree-species-data/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common species planted in each street?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>trees.groupby(['Street','Species']).size().unstack().idxmax().T</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>trees.groupby(['Street','Species']).size().unstack().idxmax().T</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = trees.groupby(['Street', 'Species']).size().unstack().idxmax().T
</code></pre>
        <p><span onclick="$('#var_output_0a08794a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0a08794a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Species
Abies amabilis                  FAIRFIELD RD
Abies concolor                  FAIRFIELD RD
Abies grandis                      DALLAS RD
Abies koreana                      DALLAS RD
Abies pinsapo                   FAIRFIELD RD
                                    ...     
Wildlife snag                      DALLAS RD
Zelkova serrata                 BLANSHARD ST
Zelkova serrata 'Green Vase'        OLIVE ST
Zelkova serrata villag green         DOCK ST
x Cupressocyparis leylandii        DALLAS RD
Length: 454, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Species
Abies amabilis                  FAIRFIELD RD
Abies concolor                  FAIRFIELD RD
Abies grandis                      DALLAS RD
Abies koreana                      DALLAS RD
Abies pinsapo                   FAIRFIELD RD
                                    ...     
Wildlife snag                      DALLAS RD
Zelkova serrata                 BLANSHARD ST
Zelkova serrata 'Green Vase'        OLIVE ST
Zelkova serrata villag green         DOCK ST
x Cupressocyparis leylandii        DALLAS RD
Length: 454, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> victoria-bc-city-tree-species-data/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average height of trees planted in each direction for every space of growth?  Show the grow space as rows and direction as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>trees.groupby(['GrowSpace','SideOfParcel']).Height.mean().unstack()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>trees.groupby(['GrowSpace','SideOfParcel']).Height.mean().unstack()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = trees.groupby(['GrowSpace', 'SideOfParcel']).Height.mean(
    ).unstack()
</code></pre>
        <p><span onclick="$('#var_output_94916874').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_94916874" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>SideOfParcel</th>
      <th>Front</th>
      <th>Left</th>
      <th>Median</th>
      <th>Rear</th>
      <th>Right</th>
      <th>Side</th>
    </tr>
    <tr>
      <th>GrowSpace</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Natural Areas</th>
      <td>10.875000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>None</th>
      <td>6.150000</td>
      <td>15.000000</td>
      <td>NaN</td>
      <td>4.500000</td>
      <td>6.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Raised planter</th>
      <td>5.527778</td>
      <td>6.375000</td>
      <td>18.000000</td>
      <td>3.666667</td>
      <td>5.083333</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Shrub bed</th>
      <td>8.811702</td>
      <td>8.445055</td>
      <td>7.050000</td>
      <td>8.276316</td>
      <td>8.246753</td>
      <td>17.0</td>
    </tr>
    <tr>
      <th>Soil Cells</th>
      <td>3.363636</td>
      <td>NaN</td>
      <td>3.000000</td>
      <td>NaN</td>
      <td>3.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Tree well</th>
      <td>8.123513</td>
      <td>8.370787</td>
      <td>5.538462</td>
      <td>8.867925</td>
      <td>8.444444</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Turf</th>
      <td>8.576518</td>
      <td>8.883527</td>
      <td>9.618421</td>
      <td>9.208560</td>
      <td>8.730448</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Unmaintained area</th>
      <td>9.906667</td>
      <td>8.703704</td>
      <td>NaN</td>
      <td>13.319672</td>
      <td>8.241935</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 6 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>SideOfParcel</th>
      <th>Front</th>
      <th>Left</th>
      <th>Median</th>
      <th>Rear</th>
      <th>Right</th>
      <th>Side</th>
    </tr>
    <tr>
      <th>GrowSpace</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Natural Areas</th>
      <td>10.875000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>None</th>
      <td>6.150000</td>
      <td>15.000000</td>
      <td>NaN</td>
      <td>4.500000</td>
      <td>6.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Raised planter</th>
      <td>5.527778</td>
      <td>6.375000</td>
      <td>18.000000</td>
      <td>3.666667</td>
      <td>5.083333</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Shrub bed</th>
      <td>8.811702</td>
      <td>8.445055</td>
      <td>7.050000</td>
      <td>8.276316</td>
      <td>8.246753</td>
      <td>17.0</td>
    </tr>
    <tr>
      <th>Soil Cells</th>
      <td>3.363636</td>
      <td>NaN</td>
      <td>3.000000</td>
      <td>NaN</td>
      <td>3.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Tree well</th>
      <td>8.123513</td>
      <td>8.370787</td>
      <td>5.538462</td>
      <td>8.867925</td>
      <td>8.444444</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Turf</th>
      <td>8.576518</td>
      <td>8.883527</td>
      <td>9.618421</td>
      <td>9.208560</td>
      <td>8.730448</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Unmaintained area</th>
      <td>9.906667</td>
      <td>8.703704</td>
      <td>NaN</td>
      <td>13.319672</td>
      <td>8.241935</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 6 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> victoria-bc-city-tree-species-data/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many more unique tree species are planted in Oaklands compared to Downtown?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = trees[trees.Area.fillna('').str.contains('Oaklands|Downtown')].groupby('Area').CommonName.nunique()
df['Oaklands'] - df['Downtown']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = trees[trees.Area.fillna('').str.contains('Oaklands|Downtown')].groupby('Area').CommonName.nunique()
df['Oaklands'] - df['Downtown']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = trees[trees.Area.fillna('').str.contains('Oaklands|Downtown')].groupby(
    'Area').CommonName.nunique()
__output__ = df['Oaklands'] - df['Downtown']
</code></pre>
        <p><span onclick="$('#var_output_a520fd8b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a520fd8b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>44</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (Series):</p>
          <pre><code>Area
Downtown     68
Oaklands    112
Name: CommonName, dtype: int64</code></pre>
      
          <p>__output__ (int64):</p>
          <pre><code>44</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Replace the missing data points in the columns "Short description", "Gender", "Occupation" and "Manner of death" with the word "Unknown".</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>values = {"Short description": 'Unknown', "Gender": 'Unknown', "Occupation": 'Unknown', "Manner of death": 'Unknown'}
age.fillna(value=values, inplace=True)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>values = {"Short description": 'Unknown', "Gender": 'Unknown', "Occupation": 'Unknown', "Manner of death": 'Unknown'}
age.fillna(value=values, inplace=True)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>values = {'Short description': 'Unknown', 'Gender': 'Unknown', 'Occupation':
    'Unknown', 'Manner of death': 'Unknown'}
__output__ = age.fillna(value=values, inplace=True)
</code></pre>
        <p><span onclick="$('#var_output_2e6da423').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2e6da423" style="display: none;">
          
        <p><strong>Ref output variables:</strong> age </p>
    
          <p>age (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Name</th>
      <th>Short description</th>
      <th>Gender</th>
      <th>Country</th>
      <th>Occupation</th>
      <th>Birth year</th>
      <th>Death year</th>
      <th>Manner of death</th>
      <th>Age of death</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Q23</td>
      <td>George Washington</td>
      <td>1st president of the United States (1732–1799)</td>
      <td>Male</td>
      <td>United States of America; Kingdom of Great Britain</td>
      <td>Politician</td>
      <td>1732</td>
      <td>1799.0</td>
      <td>natural causes</td>
      <td>67.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Q42</td>
      <td>Douglas Adams</td>
      <td>English writer and humorist</td>
      <td>Male</td>
      <td>United Kingdom</td>
      <td>Artist</td>
      <td>1952</td>
      <td>2001.0</td>
      <td>natural causes</td>
      <td>49.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Q91</td>
      <td>Abraham Lincoln</td>
      <td>16th president of the United States (1809-1865)</td>
      <td>Male</td>
      <td>United States of America</td>
      <td>Politician</td>
      <td>1809</td>
      <td>1865.0</td>
      <td>homicide</td>
      <td>56.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Q254</td>
      <td>Wolfgang Amadeus Mozart</td>
      <td>Austrian composer of the Classical period</td>
      <td>Male</td>
      <td>Archduchy of Austria; Archbishopric of Salzburg</td>
      <td>Artist</td>
      <td>1756</td>
      <td>1791.0</td>
      <td>Unknown</td>
      <td>35.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Q255</td>
      <td>Ludwig van Beethoven</td>
      <td>German classical and romantic composer</td>
      <td>Male</td>
      <td>Holy Roman Empire; Austrian Empire</td>
      <td>Artist</td>
      <td>1770</td>
      <td>1827.0</td>
      <td>Unknown</td>
      <td>57.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Q260</td>
      <td>Jean-François Champollion</td>
      <td>French classical scholar</td>
      <td>Male</td>
      <td>Kingdom of France; First French Empire</td>
      <td>Egyptologist</td>
      <td>1790</td>
      <td>1832.0</td>
      <td>natural causes</td>
      <td>42.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Q272</td>
      <td>Paul Morand</td>
      <td>French writer</td>
      <td>Male</td>
      <td>France</td>
      <td>Artist</td>
      <td>1888</td>
      <td>1976.0</td>
      <td>Unknown</td>
      <td>88.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>Q76833750</td>
      <td>Thomas Edie Hill</td>
      <td>(1832-1915) author of Hill's Manual (Q76833256) and Hill's Album</td>
      <td>Unknown</td>
      <td>NaN</td>
      <td>Artist</td>
      <td>1832</td>
      <td>1915.0</td>
      <td>Unknown</td>
      <td>83.0</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>Q76837507</td>
      <td>Arthur Erskine Owen Humphreys-Owen</td>
      <td>soldier</td>
      <td>Male</td>
      <td>NaN</td>
      <td>Military personnel</td>
      <td>1876</td>
      <td>1928.0</td>
      <td>Unknown</td>
      <td>52.0</td>
    </tr>
    <tr>
      <th>100005</th>
      <td>Q76844515</td>
      <td>Leopold Ornstein</td>
      <td>advocaat uit Tsjecho-Slowakije (1913-2005)</td>
      <td>Male</td>
      <td>United States of America; Czechoslovakia</td>
      <td>Military personnel</td>
      <td>1913</td>
      <td>2005.0</td>
      <td>Unknown</td>
      <td>92.0</td>
    </tr>
    <tr>
      <th>100006</th>
      <td>Q76995470</td>
      <td>David Hillhouse Buel</td>
      <td>Union Army officer</td>
      <td>Male</td>
      <td>United States of America</td>
      <td>Military personnel</td>
      <td>1839</td>
      <td>1870.0</td>
      <td>homicide</td>
      <td>31.0</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>Q77024421</td>
      <td>Ruth Adams</td>
      <td>Australian sculptor</td>
      <td>Female</td>
      <td>Australia</td>
      <td>Puppeteer</td>
      <td>1918</td>
      <td>2006.0</td>
      <td>Unknown</td>
      <td>88.0</td>
    </tr>
    <tr>
      <th>100008</th>
      <td>Q77085334</td>
      <td>R. Victor Jones</td>
      <td>American physicist</td>
      <td>Unknown</td>
      <td>United States of America</td>
      <td>Researcher</td>
      <td>1929</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>90.0</td>
    </tr>
    <tr>
      <th>100009</th>
      <td>Q77249504</td>
      <td>Ron Thorsen</td>
      <td>xugador de baloncestu canadianu (1948–2004)</td>
      <td>Unknown</td>
      <td>Canada; United States of America</td>
      <td>Athlete</td>
      <td>1948</td>
      <td>2004.0</td>
      <td>Unknown</td>
      <td>56.0</td>
    </tr>
  </tbody>
</table>
<p>100010 rows × 10 columns</p>
      
        <p><strong>Hyp output variables:</strong> age </p>
    
          <p>age (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Name</th>
      <th>Short description</th>
      <th>Gender</th>
      <th>Country</th>
      <th>Occupation</th>
      <th>Birth year</th>
      <th>Death year</th>
      <th>Manner of death</th>
      <th>Age of death</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Q23</td>
      <td>George Washington</td>
      <td>1st president of the United States (1732–1799)</td>
      <td>Male</td>
      <td>United States of America; Kingdom of Great Britain</td>
      <td>Politician</td>
      <td>1732</td>
      <td>1799.0</td>
      <td>natural causes</td>
      <td>67.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Q42</td>
      <td>Douglas Adams</td>
      <td>English writer and humorist</td>
      <td>Male</td>
      <td>United Kingdom</td>
      <td>Artist</td>
      <td>1952</td>
      <td>2001.0</td>
      <td>natural causes</td>
      <td>49.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Q91</td>
      <td>Abraham Lincoln</td>
      <td>16th president of the United States (1809-1865)</td>
      <td>Male</td>
      <td>United States of America</td>
      <td>Politician</td>
      <td>1809</td>
      <td>1865.0</td>
      <td>homicide</td>
      <td>56.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Q254</td>
      <td>Wolfgang Amadeus Mozart</td>
      <td>Austrian composer of the Classical period</td>
      <td>Male</td>
      <td>Archduchy of Austria; Archbishopric of Salzburg</td>
      <td>Artist</td>
      <td>1756</td>
      <td>1791.0</td>
      <td>Unknown</td>
      <td>35.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Q255</td>
      <td>Ludwig van Beethoven</td>
      <td>German classical and romantic composer</td>
      <td>Male</td>
      <td>Holy Roman Empire; Austrian Empire</td>
      <td>Artist</td>
      <td>1770</td>
      <td>1827.0</td>
      <td>Unknown</td>
      <td>57.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Q260</td>
      <td>Jean-François Champollion</td>
      <td>French classical scholar</td>
      <td>Male</td>
      <td>Kingdom of France; First French Empire</td>
      <td>Egyptologist</td>
      <td>1790</td>
      <td>1832.0</td>
      <td>natural causes</td>
      <td>42.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Q272</td>
      <td>Paul Morand</td>
      <td>French writer</td>
      <td>Male</td>
      <td>France</td>
      <td>Artist</td>
      <td>1888</td>
      <td>1976.0</td>
      <td>Unknown</td>
      <td>88.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>Q76833750</td>
      <td>Thomas Edie Hill</td>
      <td>(1832-1915) author of Hill's Manual (Q76833256) and Hill's Album</td>
      <td>Unknown</td>
      <td>NaN</td>
      <td>Artist</td>
      <td>1832</td>
      <td>1915.0</td>
      <td>Unknown</td>
      <td>83.0</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>Q76837507</td>
      <td>Arthur Erskine Owen Humphreys-Owen</td>
      <td>soldier</td>
      <td>Male</td>
      <td>NaN</td>
      <td>Military personnel</td>
      <td>1876</td>
      <td>1928.0</td>
      <td>Unknown</td>
      <td>52.0</td>
    </tr>
    <tr>
      <th>100005</th>
      <td>Q76844515</td>
      <td>Leopold Ornstein</td>
      <td>advocaat uit Tsjecho-Slowakije (1913-2005)</td>
      <td>Male</td>
      <td>United States of America; Czechoslovakia</td>
      <td>Military personnel</td>
      <td>1913</td>
      <td>2005.0</td>
      <td>Unknown</td>
      <td>92.0</td>
    </tr>
    <tr>
      <th>100006</th>
      <td>Q76995470</td>
      <td>David Hillhouse Buel</td>
      <td>Union Army officer</td>
      <td>Male</td>
      <td>United States of America</td>
      <td>Military personnel</td>
      <td>1839</td>
      <td>1870.0</td>
      <td>homicide</td>
      <td>31.0</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>Q77024421</td>
      <td>Ruth Adams</td>
      <td>Australian sculptor</td>
      <td>Female</td>
      <td>Australia</td>
      <td>Puppeteer</td>
      <td>1918</td>
      <td>2006.0</td>
      <td>Unknown</td>
      <td>88.0</td>
    </tr>
    <tr>
      <th>100008</th>
      <td>Q77085334</td>
      <td>R. Victor Jones</td>
      <td>American physicist</td>
      <td>Unknown</td>
      <td>United States of America</td>
      <td>Researcher</td>
      <td>1929</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>90.0</td>
    </tr>
    <tr>
      <th>100009</th>
      <td>Q77249504</td>
      <td>Ron Thorsen</td>
      <td>xugador de baloncestu canadianu (1948–2004)</td>
      <td>Unknown</td>
      <td>Canada; United States of America</td>
      <td>Athlete</td>
      <td>1948</td>
      <td>2004.0</td>
      <td>Unknown</td>
      <td>56.0</td>
    </tr>
  </tbody>
</table>
<p>100010 rows × 10 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('age', 'age', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a column named 'First Country' that identifies the first mentioned country for each person.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>age['First Country'] = age.Country.str.split('; ', expand=True)[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>age['First Country'] = age.Country.str.split('; ', expand=True)[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = age['First Country'] = age.Country.str.split('; ', expand=True)[0]
</code></pre>
        <p><span onclick="$('#var_output_10cb23a3').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_10cb23a3" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0         United States of America
1                   United Kingdom
2         United States of America
3             Archduchy of Austria
4                Holy Roman Empire
                    ...           
100005    United States of America
100006    United States of America
100007                   Australia
100008    United States of America
100009                      Canada
Name: 0, Length: 100010, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> age, __output__ </p>
    
          <p>age (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Name</th>
      <th>Short description</th>
      <th>Gender</th>
      <th>Country</th>
      <th>Occupation</th>
      <th>Birth year</th>
      <th>Death year</th>
      <th>Manner of death</th>
      <th>Age of death</th>
      <th>First Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Q23</td>
      <td>George Washington</td>
      <td>1st president of the United States (1732–1799)</td>
      <td>Male</td>
      <td>United States of America; Kingdom of Great Britain</td>
      <td>Politician</td>
      <td>1732</td>
      <td>1799.0</td>
      <td>natural causes</td>
      <td>67.0</td>
      <td>United States of America</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Q42</td>
      <td>Douglas Adams</td>
      <td>English writer and humorist</td>
      <td>Male</td>
      <td>United Kingdom</td>
      <td>Artist</td>
      <td>1952</td>
      <td>2001.0</td>
      <td>natural causes</td>
      <td>49.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Q91</td>
      <td>Abraham Lincoln</td>
      <td>16th president of the United States (1809-1865)</td>
      <td>Male</td>
      <td>United States of America</td>
      <td>Politician</td>
      <td>1809</td>
      <td>1865.0</td>
      <td>homicide</td>
      <td>56.0</td>
      <td>United States of America</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Q254</td>
      <td>Wolfgang Amadeus Mozart</td>
      <td>Austrian composer of the Classical period</td>
      <td>Male</td>
      <td>Archduchy of Austria; Archbishopric of Salzburg</td>
      <td>Artist</td>
      <td>1756</td>
      <td>1791.0</td>
      <td>Unknown</td>
      <td>35.0</td>
      <td>Archduchy of Austria</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Q255</td>
      <td>Ludwig van Beethoven</td>
      <td>German classical and romantic composer</td>
      <td>Male</td>
      <td>Holy Roman Empire; Austrian Empire</td>
      <td>Artist</td>
      <td>1770</td>
      <td>1827.0</td>
      <td>Unknown</td>
      <td>57.0</td>
      <td>Holy Roman Empire</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Q260</td>
      <td>Jean-François Champollion</td>
      <td>French classical scholar</td>
      <td>Male</td>
      <td>Kingdom of France; First French Empire</td>
      <td>Egyptologist</td>
      <td>1790</td>
      <td>1832.0</td>
      <td>natural causes</td>
      <td>42.0</td>
      <td>Kingdom of France</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Q272</td>
      <td>Paul Morand</td>
      <td>French writer</td>
      <td>Male</td>
      <td>France</td>
      <td>Artist</td>
      <td>1888</td>
      <td>1976.0</td>
      <td>Unknown</td>
      <td>88.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>Q76833750</td>
      <td>Thomas Edie Hill</td>
      <td>(1832-1915) author of Hill's Manual (Q76833256) and Hill's Album</td>
      <td>Unknown</td>
      <td>NaN</td>
      <td>Artist</td>
      <td>1832</td>
      <td>1915.0</td>
      <td>Unknown</td>
      <td>83.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>Q76837507</td>
      <td>Arthur Erskine Owen Humphreys-Owen</td>
      <td>soldier</td>
      <td>Male</td>
      <td>NaN</td>
      <td>Military personnel</td>
      <td>1876</td>
      <td>1928.0</td>
      <td>Unknown</td>
      <td>52.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>100005</th>
      <td>Q76844515</td>
      <td>Leopold Ornstein</td>
      <td>advocaat uit Tsjecho-Slowakije (1913-2005)</td>
      <td>Male</td>
      <td>United States of America; Czechoslovakia</td>
      <td>Military personnel</td>
      <td>1913</td>
      <td>2005.0</td>
      <td>Unknown</td>
      <td>92.0</td>
      <td>United States of America</td>
    </tr>
    <tr>
      <th>100006</th>
      <td>Q76995470</td>
      <td>David Hillhouse Buel</td>
      <td>Union Army officer</td>
      <td>Male</td>
      <td>United States of America</td>
      <td>Military personnel</td>
      <td>1839</td>
      <td>1870.0</td>
      <td>homicide</td>
      <td>31.0</td>
      <td>United States of America</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>Q77024421</td>
      <td>Ruth Adams</td>
      <td>Australian sculptor</td>
      <td>Female</td>
      <td>Australia</td>
      <td>Puppeteer</td>
      <td>1918</td>
      <td>2006.0</td>
      <td>Unknown</td>
      <td>88.0</td>
      <td>Australia</td>
    </tr>
    <tr>
      <th>100008</th>
      <td>Q77085334</td>
      <td>R. Victor Jones</td>
      <td>American physicist</td>
      <td>Unknown</td>
      <td>United States of America</td>
      <td>Researcher</td>
      <td>1929</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>90.0</td>
      <td>United States of America</td>
    </tr>
    <tr>
      <th>100009</th>
      <td>Q77249504</td>
      <td>Ron Thorsen</td>
      <td>xugador de baloncestu canadianu (1948–2004)</td>
      <td>Unknown</td>
      <td>Canada; United States of America</td>
      <td>Athlete</td>
      <td>1948</td>
      <td>2004.0</td>
      <td>Unknown</td>
      <td>56.0</td>
      <td>Canada</td>
    </tr>
  </tbody>
</table>
<p>100010 rows × 11 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0         United States of America
1                   United Kingdom
2         United States of America
3             Archduchy of Austria
4                Holy Roman Empire
                    ...           
100005    United States of America
100006    United States of America
100007                   Australia
100008    United States of America
100009                      Canada
Name: 0, Length: 100010, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a dataset for the list of countries mentioned for each person.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>countries = age.Country.str.split('; ', expand=True).iloc[:,:3]
countries.columns = ['country_1','country_2','country_3']
pd.concat([age.Name, countries], axis=1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>countries = age.Country.str.split('; ', expand=True).iloc[:,:3]
countries.columns = ['country_1','country_2','country_3']
pd.concat([age.Name, countries], axis=1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>countries = age.Country.str.split('; ', expand=True).iloc[:, :3]
countries.columns = ['country_1', 'country_2', 'country_3']
__output__ = pd.concat([age.Name, countries], axis=1)
</code></pre>
        <p><span onclick="$('#var_output_67153040').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_67153040" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>country_1</th>
      <th>country_2</th>
      <th>country_3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>George Washington</td>
      <td>United States of America</td>
      <td>Kingdom of Great Britain</td>
      <td>None</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Douglas Adams</td>
      <td>United Kingdom</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Abraham Lincoln</td>
      <td>United States of America</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Wolfgang Amadeus Mozart</td>
      <td>Archduchy of Austria</td>
      <td>Archbishopric of Salzburg</td>
      <td>None</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Ludwig van Beethoven</td>
      <td>Holy Roman Empire</td>
      <td>Austrian Empire</td>
      <td>None</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Jean-François Champollion</td>
      <td>Kingdom of France</td>
      <td>First French Empire</td>
      <td>None</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Paul Morand</td>
      <td>France</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>Thomas Edie Hill</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>Arthur Erskine Owen Humphreys-Owen</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>100005</th>
      <td>Leopold Ornstein</td>
      <td>United States of America</td>
      <td>Czechoslovakia</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100006</th>
      <td>David Hillhouse Buel</td>
      <td>United States of America</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>Ruth Adams</td>
      <td>Australia</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100008</th>
      <td>R. Victor Jones</td>
      <td>United States of America</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100009</th>
      <td>Ron Thorsen</td>
      <td>Canada</td>
      <td>United States of America</td>
      <td>None</td>
    </tr>
  </tbody>
</table>
<p>100010 rows × 4 columns</p>
      
        <p><strong>Hyp output variables:</strong> countries, __output__ </p>
    
          <p>countries (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_1</th>
      <th>country_2</th>
      <th>country_3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>United States of America</td>
      <td>Kingdom of Great Britain</td>
      <td>None</td>
    </tr>
    <tr>
      <th>1</th>
      <td>United Kingdom</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>United States of America</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Archduchy of Austria</td>
      <td>Archbishopric of Salzburg</td>
      <td>None</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Holy Roman Empire</td>
      <td>Austrian Empire</td>
      <td>None</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Kingdom of France</td>
      <td>First French Empire</td>
      <td>None</td>
    </tr>
    <tr>
      <th>6</th>
      <td>France</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>100005</th>
      <td>United States of America</td>
      <td>Czechoslovakia</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100006</th>
      <td>United States of America</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>Australia</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100008</th>
      <td>United States of America</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100009</th>
      <td>Canada</td>
      <td>United States of America</td>
      <td>None</td>
    </tr>
  </tbody>
</table>
<p>100010 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>country_1</th>
      <th>country_2</th>
      <th>country_3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>George Washington</td>
      <td>United States of America</td>
      <td>Kingdom of Great Britain</td>
      <td>None</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Douglas Adams</td>
      <td>United Kingdom</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Abraham Lincoln</td>
      <td>United States of America</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Wolfgang Amadeus Mozart</td>
      <td>Archduchy of Austria</td>
      <td>Archbishopric of Salzburg</td>
      <td>None</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Ludwig van Beethoven</td>
      <td>Holy Roman Empire</td>
      <td>Austrian Empire</td>
      <td>None</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Jean-François Champollion</td>
      <td>Kingdom of France</td>
      <td>First French Empire</td>
      <td>None</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Paul Morand</td>
      <td>France</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>Thomas Edie Hill</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>Arthur Erskine Owen Humphreys-Owen</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>100005</th>
      <td>Leopold Ornstein</td>
      <td>United States of America</td>
      <td>Czechoslovakia</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100006</th>
      <td>David Hillhouse Buel</td>
      <td>United States of America</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>Ruth Adams</td>
      <td>Australia</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100008</th>
      <td>R. Victor Jones</td>
      <td>United States of America</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>100009</th>
      <td>Ron Thorsen</td>
      <td>Canada</td>
      <td>United States of America</td>
      <td>None</td>
    </tr>
  </tbody>
</table>
<p>100010 rows × 4 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the gender distribution for the top ten common occupations? Return a dataframe in wide format listing occupations as rows and genders as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>common_occupations = age['Occupation'].value_counts().head(10)
age[age['Occupation'].isin(common_occupations.index)].pivot_table(index='Occupation',columns='Gender',values='Id', aggfunc='count').fillna(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>common_occupations = age['Occupation'].value_counts().head(10)
age[age['Occupation'].isin(common_occupations.index)].pivot_table(index='Occupation',columns='Gender',values='Id', aggfunc='count').fillna(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>common_occupations = age['Occupation'].value_counts().head(10)
__output__ = age[age['Occupation'].isin(common_occupations.index)].pivot_table(
    index='Occupation', columns='Gender', values='Id', aggfunc='count').fillna(
    0)
</code></pre>
        <p><span onclick="$('#var_output_45ccd12a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_45ccd12a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Gender</th>
      <th>Eunuch; Male</th>
      <th>Female</th>
      <th>Female; Male</th>
      <th>Male</th>
      <th>Transgender Female</th>
      <th>Transgender Female; Male</th>
      <th>Transgender Male</th>
      <th>Unknown</th>
    </tr>
    <tr>
      <th>Occupation</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Architect</th>
      <td>0.0</td>
      <td>44.0</td>
      <td>0.0</td>
      <td>1247.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>179.0</td>
    </tr>
    <tr>
      <th>Artist</th>
      <td>0.0</td>
      <td>3576.0</td>
      <td>0.0</td>
      <td>17082.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2403.0</td>
    </tr>
    <tr>
      <th>Athlete</th>
      <td>0.0</td>
      <td>292.0</td>
      <td>0.0</td>
      <td>8443.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>385.0</td>
    </tr>
    <tr>
      <th>Businessperson</th>
      <td>0.0</td>
      <td>61.0</td>
      <td>0.0</td>
      <td>1343.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>201.0</td>
    </tr>
    <tr>
      <th>Journalist</th>
      <td>0.0</td>
      <td>162.0</td>
      <td>0.0</td>
      <td>1004.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>189.0</td>
    </tr>
    <tr>
      <th>Military personnel</th>
      <td>1.0</td>
      <td>67.0</td>
      <td>0.0</td>
      <td>3731.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>419.0</td>
    </tr>
    <tr>
      <th>Politician</th>
      <td>0.0</td>
      <td>610.0</td>
      <td>1.0</td>
      <td>13874.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1502.0</td>
    </tr>
    <tr>
      <th>Religious figure</th>
      <td>0.0</td>
      <td>69.0</td>
      <td>0.0</td>
      <td>2737.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>263.0</td>
    </tr>
    <tr>
      <th>Researcher</th>
      <td>0.0</td>
      <td>544.0</td>
      <td>0.0</td>
      <td>6101.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>731.0</td>
    </tr>
    <tr>
      <th>Unknown</th>
      <td>0.0</td>
      <td>1574.0</td>
      <td>0.0</td>
      <td>12099.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>3252.0</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 8 columns</p>
      
        <p><strong>Hyp output variables:</strong> common_occupations, __output__ </p>
    
          <p>common_occupations (Series):</p>
          <pre><code>Artist                23065
Unknown               16928
Politician            15988
Athlete                9121
Researcher             7376
Military personnel     4219
Religious figure       3069
Businessperson         1605
Architect              1470
Journalist             1355
Name: Occupation, dtype: int64</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Gender</th>
      <th>Eunuch; Male</th>
      <th>Female</th>
      <th>Female; Male</th>
      <th>Male</th>
      <th>Transgender Female</th>
      <th>Transgender Female; Male</th>
      <th>Transgender Male</th>
      <th>Unknown</th>
    </tr>
    <tr>
      <th>Occupation</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Architect</th>
      <td>0.0</td>
      <td>44.0</td>
      <td>0.0</td>
      <td>1247.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>179.0</td>
    </tr>
    <tr>
      <th>Artist</th>
      <td>0.0</td>
      <td>3576.0</td>
      <td>0.0</td>
      <td>17082.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2403.0</td>
    </tr>
    <tr>
      <th>Athlete</th>
      <td>0.0</td>
      <td>292.0</td>
      <td>0.0</td>
      <td>8443.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>385.0</td>
    </tr>
    <tr>
      <th>Businessperson</th>
      <td>0.0</td>
      <td>61.0</td>
      <td>0.0</td>
      <td>1343.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>201.0</td>
    </tr>
    <tr>
      <th>Journalist</th>
      <td>0.0</td>
      <td>162.0</td>
      <td>0.0</td>
      <td>1004.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>189.0</td>
    </tr>
    <tr>
      <th>Military personnel</th>
      <td>1.0</td>
      <td>67.0</td>
      <td>0.0</td>
      <td>3731.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>419.0</td>
    </tr>
    <tr>
      <th>Politician</th>
      <td>0.0</td>
      <td>610.0</td>
      <td>1.0</td>
      <td>13874.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1502.0</td>
    </tr>
    <tr>
      <th>Religious figure</th>
      <td>0.0</td>
      <td>69.0</td>
      <td>0.0</td>
      <td>2737.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>263.0</td>
    </tr>
    <tr>
      <th>Researcher</th>
      <td>0.0</td>
      <td>544.0</td>
      <td>0.0</td>
      <td>6101.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>731.0</td>
    </tr>
    <tr>
      <th>Unknown</th>
      <td>0.0</td>
      <td>1574.0</td>
      <td>0.0</td>
      <td>12099.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>3252.0</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 8 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the three most common occupations and death counts for those who suicided?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>age[age['Manner of death']=='suicide']['Occupation'].value_counts().head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>age[age['Manner of death']=='suicide']['Occupation'].value_counts().head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = age[age['Manner of death'] == 'suicide']['Occupation'
    ].value_counts().head(3)
</code></pre>
        <p><span onclick="$('#var_output_36500c14').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_36500c14" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Artist        175
Politician     70
Athlete        42
Name: Occupation, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Artist        175
Politician     70
Athlete        42
Name: Occupation, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the five most common causes of death for females?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>age[age['Gender'].str.match('Female')].groupby(['Manner of death'], as_index=False).Id.size().sort_values('size',ascending=False).head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>age[age['Gender'].str.match('Female')].groupby(['Manner of death'], as_index=False).Id.size().sort_values('size',ascending=False).head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = age[age['Gender'].str.match('Female')].groupby([
    'Manner of death'], as_index=False).Id.size().sort_values('size',
    ascending=False).head(5)
</code></pre>
        <p><span onclick="$('#var_output_5992d6c1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5992d6c1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Manner of death</th>
      <th>size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Unknown</td>
      <td>8078</td>
    </tr>
    <tr>
      <th>6</th>
      <td>natural causes</td>
      <td>476</td>
    </tr>
    <tr>
      <th>9</th>
      <td>suicide</td>
      <td>56</td>
    </tr>
    <tr>
      <th>2</th>
      <td>accident</td>
      <td>50</td>
    </tr>
    <tr>
      <th>4</th>
      <td>homicide</td>
      <td>45</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Manner of death</th>
      <th>size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Unknown</td>
      <td>8078</td>
    </tr>
    <tr>
      <th>6</th>
      <td>natural causes</td>
      <td>476</td>
    </tr>
    <tr>
      <th>9</th>
      <td>suicide</td>
      <td>56</td>
    </tr>
    <tr>
      <th>2</th>
      <td>accident</td>
      <td>50</td>
    </tr>
    <tr>
      <th>4</th>
      <td>homicide</td>
      <td>45</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common cause of death in each country? Return a dataframe with the counts and most common death cause.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>deaths_by_country = age[age['Manner of death']!='Unknown'].groupby(['First Country','Manner of death'])['Id'].size()
deaths_by_country.max(level=0).reset_index().merge(deaths_by_country.reset_index()).rename(columns={'Id':'Death Count'})</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>deaths_by_country = age[age['Manner of death']!='Unknown'].groupby(['First Country','Manner of death'])['Id'].size()
deaths_by_country.max(level=0).reset_index().merge(deaths_by_country.reset_index()).rename(columns={'Id':'Death Count'})</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>deaths_by_country = age[age['Manner of death'] != 'Unknown'].groupby([
    'First Country', 'Manner of death'])['Id'].size()
__output__ = deaths_by_country.max(level=0).reset_index().merge(
    deaths_by_country.reset_index()).rename(columns={'Id': 'Death Count'})
</code></pre>
        <p><span onclick="$('#var_output_521a5ea0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_521a5ea0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>First Country</th>
      <th>Death Count</th>
      <th>Manner of death</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>2</td>
      <td>homicide</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Albania</td>
      <td>2</td>
      <td>natural causes</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Algeria</td>
      <td>1</td>
      <td>homicide</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Angola</td>
      <td>1</td>
      <td>natural causes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Antigua and Barbuda</td>
      <td>1</td>
      <td>accident</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Argentina</td>
      <td>23</td>
      <td>natural causes</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Armenia</td>
      <td>1</td>
      <td>homicide</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>260</th>
      <td>Yuan dynasty</td>
      <td>1</td>
      <td>capital punishment</td>
    </tr>
    <tr>
      <th>261</th>
      <td>Yuan dynasty</td>
      <td>1</td>
      <td>homicide</td>
    </tr>
    <tr>
      <th>262</th>
      <td>Yugoslavia</td>
      <td>1</td>
      <td>homicide</td>
    </tr>
    <tr>
      <th>263</th>
      <td>Yugoslavia</td>
      <td>1</td>
      <td>suicide</td>
    </tr>
    <tr>
      <th>264</th>
      <td>Zambia</td>
      <td>1</td>
      <td>accident</td>
    </tr>
    <tr>
      <th>265</th>
      <td>Zambia</td>
      <td>1</td>
      <td>natural causes</td>
    </tr>
    <tr>
      <th>266</th>
      <td>ancient Rome</td>
      <td>1</td>
      <td>homicide</td>
    </tr>
  </tbody>
</table>
<p>267 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> deaths_by_country, __output__ </p>
    
          <p>deaths_by_country (Series):</p>
          <pre><code>First Country        Manner of death
Afghanistan          homicide           2
Albania              natural causes     2
Algeria              homicide           1
Angola               natural causes     1
Antigua and Barbuda  accident           1
                                       ..
Yugoslavia           homicide           1
                     suicide            1
Zambia               accident           1
                     natural causes     1
ancient Rome         homicide           1
Name: Id, Length: 517, dtype: int64</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>First Country</th>
      <th>Death Count</th>
      <th>Manner of death</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>2</td>
      <td>homicide</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Albania</td>
      <td>2</td>
      <td>natural causes</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Algeria</td>
      <td>1</td>
      <td>homicide</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Angola</td>
      <td>1</td>
      <td>natural causes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Antigua and Barbuda</td>
      <td>1</td>
      <td>accident</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Argentina</td>
      <td>23</td>
      <td>natural causes</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Armenia</td>
      <td>1</td>
      <td>homicide</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>260</th>
      <td>Yuan dynasty</td>
      <td>1</td>
      <td>capital punishment</td>
    </tr>
    <tr>
      <th>261</th>
      <td>Yuan dynasty</td>
      <td>1</td>
      <td>homicide</td>
    </tr>
    <tr>
      <th>262</th>
      <td>Yugoslavia</td>
      <td>1</td>
      <td>homicide</td>
    </tr>
    <tr>
      <th>263</th>
      <td>Yugoslavia</td>
      <td>1</td>
      <td>suicide</td>
    </tr>
    <tr>
      <th>264</th>
      <td>Zambia</td>
      <td>1</td>
      <td>accident</td>
    </tr>
    <tr>
      <th>265</th>
      <td>Zambia</td>
      <td>1</td>
      <td>natural causes</td>
    </tr>
    <tr>
      <th>266</th>
      <td>ancient Rome</td>
      <td>1</td>
      <td>homicide</td>
    </tr>
  </tbody>
</table>
<p>267 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average age at death for those who were born during the 1950s?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>age[(age['Birth year'].between(1950,1960, inclusive='left'))].groupby('Birth year')['Age of death'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>age[(age['Birth year'].between(1950,1960, inclusive='left'))].groupby('Birth year')['Age of death'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = age[age['Birth year'].between(1950, 1960, inclusive='left')
    ].groupby('Birth year')['Age of death'].mean()
</code></pre>
        <p><span onclick="$('#var_output_b3349f81').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b3349f81" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Birth year
1950    57.075697
1951    58.275701
1952    55.958904
1953    55.304124
1954    54.648352
1955    53.427746
1956    53.875706
1957    50.878378
1958    51.178295
1959    48.817391
Name: Age of death, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Birth year
1950    57.075697
1951    58.275701
1952    55.958904
1953    55.304124
1954    54.648352
1955    53.427746
1956    53.875706
1957    50.878378
1958    51.178295
1959    48.817391
Name: Age of death, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the number of deaths by accident as a percentage of total deaths in the last ten years?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>import datetime as dt

last_ten_years = age[(age['Death year']>=dt.datetime.today().year-10)]
total_deaths = last_ten_years.groupby('Death year').size()
deaths_by_accident = last_ten_years[last_ten_years['Manner of death'].str.contains('accident')].groupby('Death year').size() 

deaths_by_accident / total_deaths * 100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>import datetime as dt

last_ten_years = age[(age['Death year']>=dt.datetime.today().year-10)]
total_deaths = last_ten_years.groupby('Death year').size()
deaths_by_accident = last_ten_years[last_ten_years['Manner of death'].str.contains('accident')].groupby('Death year').size() 

deaths_by_accident / total_deaths * 100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>import datetime as dt
last_ten_years = age[age['Death year'] >= dt.datetime.today().year - 10]
total_deaths = last_ten_years.groupby('Death year').size()
deaths_by_accident = last_ten_years[last_ten_years['Manner of death'].str.
    contains('accident')].groupby('Death year').size()
__output__ = deaths_by_accident / total_deaths * 100
</code></pre>
        <p><span onclick="$('#var_output_951f021f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_951f021f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Death year
2012.0    0.675676
2013.0    0.446429
2014.0    1.067616
2015.0    0.691443
2016.0    0.529568
2017.0    0.179533
2018.0    0.288739
2019.0    0.631579
2020.0         NaN
2021.0         NaN
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> last_ten_years, total_deaths, deaths_by_accident, __output__ </p>
    
          <p>last_ten_years (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Name</th>
      <th>Short description</th>
      <th>Gender</th>
      <th>Country</th>
      <th>Occupation</th>
      <th>Birth year</th>
      <th>Death year</th>
      <th>Manner of death</th>
      <th>Age of death</th>
      <th>First Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>19</th>
      <td>Q1254</td>
      <td>Kofi Annan</td>
      <td>7th Secretary-General of the United Nations (1938-2018)</td>
      <td>Male</td>
      <td>Ghana</td>
      <td>Politician</td>
      <td>1938</td>
      <td>2018.0</td>
      <td>natural causes</td>
      <td>80.0</td>
      <td>Ghana</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Q2571</td>
      <td>Walter Scheel</td>
      <td>President of West Germany (1974-1979)</td>
      <td>Male</td>
      <td>Germany</td>
      <td>Politician</td>
      <td>1919</td>
      <td>2016.0</td>
      <td>natural causes</td>
      <td>97.0</td>
      <td>Germany</td>
    </tr>
    <tr>
      <th>57</th>
      <td>Q7440</td>
      <td>Ruth R. Benerito</td>
      <td>American scientist and inventor</td>
      <td>Female</td>
      <td>United States of America</td>
      <td>Researcher</td>
      <td>1916</td>
      <td>2013.0</td>
      <td>Unknown</td>
      <td>97.0</td>
      <td>United States of America</td>
    </tr>
    <tr>
      <th>73</th>
      <td>Q9513</td>
      <td>A. P. J. Abdul Kalam</td>
      <td>11th President of India, scientist and science administrator (1931-2015)</td>
      <td>Male</td>
      <td>India; British Raj</td>
      <td>Researcher</td>
      <td>1931</td>
      <td>2015.0</td>
      <td>natural causes</td>
      <td>84.0</td>
      <td>India</td>
    </tr>
    <tr>
      <th>79</th>
      <td>Q10411</td>
      <td>Odd Børretzen</td>
      <td>Norwegian author, illustrator, translator and singer-songwriter (1926-2012)</td>
      <td>Male</td>
      <td>Norway</td>
      <td>Artist</td>
      <td>1926</td>
      <td>2012.0</td>
      <td>natural causes</td>
      <td>86.0</td>
      <td>Norway</td>
    </tr>
    <tr>
      <th>96</th>
      <td>Q13001</td>
      <td>Paul Van Grembergen</td>
      <td>Flemish former minister (1937-2016)</td>
      <td>Male</td>
      <td>Belgium</td>
      <td>Politician</td>
      <td>1937</td>
      <td>2016.0</td>
      <td>Unknown</td>
      <td>79.0</td>
      <td>Belgium</td>
    </tr>
    <tr>
      <th>99</th>
      <td>Q14239</td>
      <td>Kaisa Sere</td>
      <td>Finnish computer scientist</td>
      <td>Female</td>
      <td>Finland</td>
      <td>Researcher</td>
      <td>1954</td>
      <td>2012.0</td>
      <td>Unknown</td>
      <td>58.0</td>
      <td>Finland</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99936</th>
      <td>Q76299109</td>
      <td>Giuseppe Setaro</td>
      <td>muzikant uit Koninkrijk Italië (1934-2014)</td>
      <td>Male</td>
      <td>Italy; Kingdom of Italy</td>
      <td>Artist</td>
      <td>1934</td>
      <td>2014.0</td>
      <td>Unknown</td>
      <td>80.0</td>
      <td>Italy</td>
    </tr>
    <tr>
      <th>99942</th>
      <td>Q76313398</td>
      <td>Edward Anthony Watson Bullock</td>
      <td>1926-2015</td>
      <td>Male</td>
      <td>NaN</td>
      <td>Unknown</td>
      <td>1926</td>
      <td>2015.0</td>
      <td>Unknown</td>
      <td>89.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>99974</th>
      <td>Q76364704</td>
      <td>Dorothy Arnold</td>
      <td>(1924-2016)</td>
      <td>Unknown</td>
      <td>NaN</td>
      <td>Unknown</td>
      <td>1924</td>
      <td>2016.0</td>
      <td>Unknown</td>
      <td>92.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>99984</th>
      <td>Q76428497</td>
      <td>John W. Schrader</td>
      <td>immunologist</td>
      <td>Unknown</td>
      <td>NaN</td>
      <td>Unknown</td>
      <td>1947</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>72.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>99986</th>
      <td>Q76440787</td>
      <td>Rosa Salazar</td>
      <td>landarbeidster uit Ecuador (-2019)</td>
      <td>Unknown</td>
      <td>Ecuador</td>
      <td>Peasant</td>
      <td>1960</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>59.0</td>
      <td>Ecuador</td>
    </tr>
    <tr>
      <th>100001</th>
      <td>Q76809469</td>
      <td>Алексеев Андрей Николаевич</td>
      <td>Russisch zoöloog (1930-2015)</td>
      <td>Unknown</td>
      <td>Russia; Soviet Union</td>
      <td>Unknown</td>
      <td>1930</td>
      <td>2015.0</td>
      <td>Unknown</td>
      <td>85.0</td>
      <td>Russia</td>
    </tr>
    <tr>
      <th>100008</th>
      <td>Q77085334</td>
      <td>R. Victor Jones</td>
      <td>American physicist</td>
      <td>Unknown</td>
      <td>United States of America</td>
      <td>Researcher</td>
      <td>1929</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>90.0</td>
      <td>United States of America</td>
    </tr>
  </tbody>
</table>
<p>9784 rows × 11 columns</p>
      
          <p>total_deaths (Series):</p>
          <pre><code>Death year
2012.0    1036
2013.0    1120
2014.0    1124
2015.0    1157
2016.0    1133
2017.0    1114
2018.0    1039
2019.0     950
2020.0     944
2021.0     167
dtype: int64</code></pre>
      
          <p>deaths_by_accident (Series):</p>
          <pre><code>Death year
2012.0     7
2013.0     5
2014.0    12
2015.0     8
2016.0     6
2017.0     2
2018.0     3
2019.0     6
dtype: int64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Death year
2012.0    0.675676
2013.0    0.446429
2014.0    1.067616
2015.0    0.691443
2016.0    0.529568
2017.0    0.179533
2018.0    0.288739
2019.0    0.631579
2020.0         NaN
2021.0         NaN
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the five most common nationalities of artists who died after the year 2000 and were born in the 1950s.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>artists = age[age['Occupation'].str.contains('Artist', case=False)]
artists[(artists['Death year']>=2000) & (artists['Birth year'].between(1950,1960,inclusive='left'))]['Country'].value_counts().head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>artists = age[age['Occupation'].str.contains('Artist', case=False)]
artists[(artists['Death year']>=2000) & (artists['Birth year'].between(1950,1960,inclusive='left'))]['Country'].value_counts().head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>artists = age[age['Occupation'].str.contains('Artist', case=False)]
__output__ = artists[(artists['Death year'] >= 2000) & artists['Birth year'
    ].between(1950, 1960, inclusive='left')]['Country'].value_counts().head(5)
</code></pre>
        <p><span onclick="$('#var_output_862b9c88').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_862b9c88" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>United States of America    90
Germany                     24
United Kingdom              23
Poland                      21
France                      17
Name: Country, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> artists, __output__ </p>
    
          <p>artists (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Name</th>
      <th>Short description</th>
      <th>Gender</th>
      <th>Country</th>
      <th>Occupation</th>
      <th>Birth year</th>
      <th>Death year</th>
      <th>Manner of death</th>
      <th>Age of death</th>
      <th>First Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Q42</td>
      <td>Douglas Adams</td>
      <td>English writer and humorist</td>
      <td>Male</td>
      <td>United Kingdom</td>
      <td>Artist</td>
      <td>1952</td>
      <td>2001.0</td>
      <td>natural causes</td>
      <td>49.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Q254</td>
      <td>Wolfgang Amadeus Mozart</td>
      <td>Austrian composer of the Classical period</td>
      <td>Male</td>
      <td>Archduchy of Austria; Archbishopric of Salzburg</td>
      <td>Artist</td>
      <td>1756</td>
      <td>1791.0</td>
      <td>Unknown</td>
      <td>35.0</td>
      <td>Archduchy of Austria</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Q255</td>
      <td>Ludwig van Beethoven</td>
      <td>German classical and romantic composer</td>
      <td>Male</td>
      <td>Holy Roman Empire; Austrian Empire</td>
      <td>Artist</td>
      <td>1770</td>
      <td>1827.0</td>
      <td>Unknown</td>
      <td>57.0</td>
      <td>Holy Roman Empire</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Q272</td>
      <td>Paul Morand</td>
      <td>French writer</td>
      <td>Male</td>
      <td>France</td>
      <td>Artist</td>
      <td>1888</td>
      <td>1976.0</td>
      <td>Unknown</td>
      <td>88.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Q296</td>
      <td>Claude Monet</td>
      <td>French impressionist painter (1840-1926)</td>
      <td>Male</td>
      <td>France</td>
      <td>Artist</td>
      <td>1840</td>
      <td>1926.0</td>
      <td>natural causes</td>
      <td>86.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Q297</td>
      <td>Diego Velázquez</td>
      <td>Spanish painter (1599-1660)</td>
      <td>Male</td>
      <td>Spain</td>
      <td>Artist</td>
      <td>1599</td>
      <td>1660.0</td>
      <td>Unknown</td>
      <td>61.0</td>
      <td>Spain</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Q301</td>
      <td>El Greco</td>
      <td>Greek painter, sculptor and architect</td>
      <td>Male</td>
      <td>Spain; Republic of Venice</td>
      <td>Artist</td>
      <td>1541</td>
      <td>1614.0</td>
      <td>Unknown</td>
      <td>73.0</td>
      <td>Spain</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99971</th>
      <td>Q76362891</td>
      <td>Hans Solis</td>
      <td>Died before 26 December 1616. German, Painter, illustrator.</td>
      <td>Male</td>
      <td>Germany</td>
      <td>Artist</td>
      <td>1554</td>
      <td>1608.0</td>
      <td>Unknown</td>
      <td>54.0</td>
      <td>Germany</td>
    </tr>
    <tr>
      <th>99980</th>
      <td>Q76384425</td>
      <td>Mercedes Rossy</td>
      <td>Spanish jazz pianist</td>
      <td>Female</td>
      <td>Spain</td>
      <td>Artist</td>
      <td>1961</td>
      <td>1995.0</td>
      <td>Unknown</td>
      <td>34.0</td>
      <td>Spain</td>
    </tr>
    <tr>
      <th>99983</th>
      <td>Q76416961</td>
      <td>Herbert Mathew Hale</td>
      <td>Australian zoologist, entomologist, museum curator</td>
      <td>Male</td>
      <td>Australia</td>
      <td>Artist</td>
      <td>1895</td>
      <td>1963.0</td>
      <td>Unknown</td>
      <td>68.0</td>
      <td>Australia</td>
    </tr>
    <tr>
      <th>99988</th>
      <td>Q76460068</td>
      <td>Jaroslav Kučera</td>
      <td>Czechoslovak painter</td>
      <td>Male</td>
      <td>NaN</td>
      <td>Artist</td>
      <td>1885</td>
      <td>1950.0</td>
      <td>Unknown</td>
      <td>65.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>99996</th>
      <td>Q76668971</td>
      <td>Luis Nieto Miranda</td>
      <td>Peruvian poet</td>
      <td>Male</td>
      <td>Peru</td>
      <td>Artist</td>
      <td>1910</td>
      <td>1997.0</td>
      <td>Unknown</td>
      <td>87.0</td>
      <td>Peru</td>
    </tr>
    <tr>
      <th>100002</th>
      <td>Q76823117</td>
      <td>Víctor Núñez Izquierdo</td>
      <td>Spaans kunstschilder (1918-1984)</td>
      <td>Male</td>
      <td>Spain</td>
      <td>Artist</td>
      <td>1918</td>
      <td>1984.0</td>
      <td>Unknown</td>
      <td>66.0</td>
      <td>Spain</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>Q76833750</td>
      <td>Thomas Edie Hill</td>
      <td>(1832-1915) author of Hill's Manual (Q76833256) and Hill's Album</td>
      <td>Unknown</td>
      <td>NaN</td>
      <td>Artist</td>
      <td>1832</td>
      <td>1915.0</td>
      <td>Unknown</td>
      <td>83.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>23065 rows × 11 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>United States of America    90
Germany                     24
United Kingdom              23
Poland                      21
France                      17
Name: Country, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Retrieve the records of the doctors who died in the last three years.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>presidents = age[(age['Short description'].str.contains('doctor',case=False)) & 
                 (age['Death year']>=dt.datetime.today().year - 3)]
presidents</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>presidents = age[(age['Short description'].str.contains('doctor',case=False)) & 
                 (age['Death year']>=dt.datetime.today().year - 3)]
presidents</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>presidents = age[age['Short description'].str.contains('doctor', case=False
    ) & (age['Death year'] >= dt.datetime.today().year - 3)]
__output__ = presidents
</code></pre>
        <p><span onclick="$('#var_output_7f684d34').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7f684d34" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Name</th>
      <th>Short description</th>
      <th>Gender</th>
      <th>Country</th>
      <th>Occupation</th>
      <th>Birth year</th>
      <th>Death year</th>
      <th>Manner of death</th>
      <th>Age of death</th>
      <th>First Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>39696</th>
      <td>Q5585563</td>
      <td>Gordon McVie</td>
      <td>British doctor</td>
      <td>Male</td>
      <td>United Kingdom</td>
      <td>Unknown</td>
      <td>1945</td>
      <td>2021.0</td>
      <td>Unknown</td>
      <td>76.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>53685</th>
      <td>Q9155052</td>
      <td>Anna Borkiewicz-Celińska</td>
      <td>Polish historian, doctor of humanities , decorated and imprisoned platoon officer of the Home Army</td>
      <td>Female</td>
      <td>Poland</td>
      <td>Researcher</td>
      <td>1921</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>98.0</td>
      <td>Poland</td>
    </tr>
    <tr>
      <th>58798</th>
      <td>Q11986008</td>
      <td>Václav Špičák</td>
      <td>Czech doctor</td>
      <td>Male</td>
      <td>NaN</td>
      <td>Physician</td>
      <td>1929</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>90.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>59137</th>
      <td>Q12043321</td>
      <td>Otto Trefný</td>
      <td>Czech politician and doctor</td>
      <td>Male</td>
      <td>Czechoslovakia</td>
      <td>Politician</td>
      <td>1932</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>87.0</td>
      <td>Czechoslovakia</td>
    </tr>
    <tr>
      <th>94749</th>
      <td>Q57985154</td>
      <td>Charles Daniel Marivate</td>
      <td>Medical Doctor and son of first Xitsonga novelist, Daniel Cornel Marivate</td>
      <td>Male</td>
      <td>South Africa</td>
      <td>Physician</td>
      <td>1924</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>95.0</td>
      <td>South Africa</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 11 columns</p>
      
        <p><strong>Hyp output variables:</strong> presidents, __output__ </p>
    
          <p>presidents (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Name</th>
      <th>Short description</th>
      <th>Gender</th>
      <th>Country</th>
      <th>Occupation</th>
      <th>Birth year</th>
      <th>Death year</th>
      <th>Manner of death</th>
      <th>Age of death</th>
      <th>First Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>39696</th>
      <td>Q5585563</td>
      <td>Gordon McVie</td>
      <td>British doctor</td>
      <td>Male</td>
      <td>United Kingdom</td>
      <td>Unknown</td>
      <td>1945</td>
      <td>2021.0</td>
      <td>Unknown</td>
      <td>76.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>53685</th>
      <td>Q9155052</td>
      <td>Anna Borkiewicz-Celińska</td>
      <td>Polish historian, doctor of humanities , decorated and imprisoned platoon officer of the Home Army</td>
      <td>Female</td>
      <td>Poland</td>
      <td>Researcher</td>
      <td>1921</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>98.0</td>
      <td>Poland</td>
    </tr>
    <tr>
      <th>58798</th>
      <td>Q11986008</td>
      <td>Václav Špičák</td>
      <td>Czech doctor</td>
      <td>Male</td>
      <td>NaN</td>
      <td>Physician</td>
      <td>1929</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>90.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>59137</th>
      <td>Q12043321</td>
      <td>Otto Trefný</td>
      <td>Czech politician and doctor</td>
      <td>Male</td>
      <td>Czechoslovakia</td>
      <td>Politician</td>
      <td>1932</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>87.0</td>
      <td>Czechoslovakia</td>
    </tr>
    <tr>
      <th>94749</th>
      <td>Q57985154</td>
      <td>Charles Daniel Marivate</td>
      <td>Medical Doctor and son of first Xitsonga novelist, Daniel Cornel Marivate</td>
      <td>Male</td>
      <td>South Africa</td>
      <td>Physician</td>
      <td>1924</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>95.0</td>
      <td>South Africa</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 11 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Name</th>
      <th>Short description</th>
      <th>Gender</th>
      <th>Country</th>
      <th>Occupation</th>
      <th>Birth year</th>
      <th>Death year</th>
      <th>Manner of death</th>
      <th>Age of death</th>
      <th>First Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>39696</th>
      <td>Q5585563</td>
      <td>Gordon McVie</td>
      <td>British doctor</td>
      <td>Male</td>
      <td>United Kingdom</td>
      <td>Unknown</td>
      <td>1945</td>
      <td>2021.0</td>
      <td>Unknown</td>
      <td>76.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>53685</th>
      <td>Q9155052</td>
      <td>Anna Borkiewicz-Celińska</td>
      <td>Polish historian, doctor of humanities , decorated and imprisoned platoon officer of the Home Army</td>
      <td>Female</td>
      <td>Poland</td>
      <td>Researcher</td>
      <td>1921</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>98.0</td>
      <td>Poland</td>
    </tr>
    <tr>
      <th>58798</th>
      <td>Q11986008</td>
      <td>Václav Špičák</td>
      <td>Czech doctor</td>
      <td>Male</td>
      <td>NaN</td>
      <td>Physician</td>
      <td>1929</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>90.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>59137</th>
      <td>Q12043321</td>
      <td>Otto Trefný</td>
      <td>Czech politician and doctor</td>
      <td>Male</td>
      <td>Czechoslovakia</td>
      <td>Politician</td>
      <td>1932</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>87.0</td>
      <td>Czechoslovakia</td>
    </tr>
    <tr>
      <th>94749</th>
      <td>Q57985154</td>
      <td>Charles Daniel Marivate</td>
      <td>Medical Doctor and son of first Xitsonga novelist, Daniel Cornel Marivate</td>
      <td>Male</td>
      <td>South Africa</td>
      <td>Physician</td>
      <td>1924</td>
      <td>2019.0</td>
      <td>Unknown</td>
      <td>95.0</td>
      <td>South Africa</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 11 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> age-dataset/notebook_1.ipynb|||turn_11 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the cause of death and median death age of individuals associated with world wars?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>age[age['Short description'].str.contains('world war', case=False)].groupby('Manner of death')['Age of death'].median()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>age[age['Short description'].str.contains('world war', case=False)].groupby('Manner of death')['Age of death'].median()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = age[age['Short description'].str.contains('world war', case=False)
    ].groupby('Manner of death')['Age of death'].median()
</code></pre>
        <p><span onclick="$('#var_output_a39fde47').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a39fde47" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Manner of death
Unknown               72.0
accident              27.0
capital punishment    47.0
homicide              27.0
natural causes        68.0
suicide               35.0
Name: Age of death, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Manner of death
Unknown               72.0
accident              27.0
capital punishment    47.0
homicide              27.0
natural causes        68.0
suicide               35.0
Name: Age of death, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> netflix-tv-shows-and-movies/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a dataset containing all the title details and the credits for each title.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>listings = titles.merge(credits, how='left', left_on='id', right_on='id')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>listings = titles.merge(credits, how='left', left_on='id', right_on='id')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = listings = titles.merge(credits, how='left', left_on='id',
    right_on='id')
</code></pre>
        <p><span onclick="$('#var_output_59144d3d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_59144d3d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>title</th>
      <th>type</th>
      <th>description</th>
      <th>release_year</th>
      <th>age_certification</th>
      <th>runtime</th>
      <th>...</th>
      <th>imdb_votes</th>
      <th>tmdb_popularity</th>
      <th>tmdb_score</th>
      <th>person_id</th>
      <th>name</th>
      <th>character</th>
      <th>role</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ts300399</td>
      <td>Five Came Back: The Reference Films</td>
      <td>SHOW</td>
      <td>This collection includes 12 World War II-era propaganda films — many of which are graphic and offensive — discussed in the docuseries "Five Came Back."</td>
      <td>1945</td>
      <td>TV-MA</td>
      <td>48</td>
      <td>...</td>
      <td>NaN</td>
      <td>0.600</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>3748.0</td>
      <td>Robert De Niro</td>
      <td>Travis Bickle</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>2</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>14658.0</td>
      <td>Jodie Foster</td>
      <td>Iris Steensma</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>3</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>7064.0</td>
      <td>Albert Brooks</td>
      <td>Tom</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>4</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>3739.0</td>
      <td>Harvey Keitel</td>
      <td>Matthew 'Sport' Higgins</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>5</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>48933.0</td>
      <td>Cybill Shepherd</td>
      <td>Betsy</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>6</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>32267.0</td>
      <td>Peter Boyle</td>
      <td>Wizard</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>77578</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>2050257.0</td>
      <td>Pa Jimi Solanke</td>
      <td>Akanji's Father</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77579</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>1347054.0</td>
      <td>Nnenna Rachael Okonkwo</td>
      <td>Afinni</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77580</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>157590.0</td>
      <td>Lucien Morgan</td>
      <td>Dr. Ian Stones</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77581</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>129059.0</td>
      <td>Magdalena Korpas</td>
      <td>Jane</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77582</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>2050199.0</td>
      <td>Mistura Olusanya</td>
      <td>Nurse Titi</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77583</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>2050423.0</td>
      <td>Yemi Amodu</td>
      <td>NaN</td>
      <td>DIRECTOR</td>
    </tr>
    <tr>
      <th>77584</th>
      <td>ts271048</td>
      <td>Mighty Little Bheem: Kite Festival</td>
      <td>SHOW</td>
      <td>With winter behind them, Bheem and his townspeople usher in a sunny new season in all their favorite ways during the Makar Sankranti festival.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>16.0</td>
      <td>0.979</td>
      <td>10.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>77585 rows × 19 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__, listings </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>title</th>
      <th>type</th>
      <th>description</th>
      <th>release_year</th>
      <th>age_certification</th>
      <th>runtime</th>
      <th>...</th>
      <th>imdb_votes</th>
      <th>tmdb_popularity</th>
      <th>tmdb_score</th>
      <th>person_id</th>
      <th>name</th>
      <th>character</th>
      <th>role</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ts300399</td>
      <td>Five Came Back: The Reference Films</td>
      <td>SHOW</td>
      <td>This collection includes 12 World War II-era propaganda films — many of which are graphic and offensive — discussed in the docuseries "Five Came Back."</td>
      <td>1945</td>
      <td>TV-MA</td>
      <td>48</td>
      <td>...</td>
      <td>NaN</td>
      <td>0.600</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>3748.0</td>
      <td>Robert De Niro</td>
      <td>Travis Bickle</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>2</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>14658.0</td>
      <td>Jodie Foster</td>
      <td>Iris Steensma</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>3</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>7064.0</td>
      <td>Albert Brooks</td>
      <td>Tom</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>4</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>3739.0</td>
      <td>Harvey Keitel</td>
      <td>Matthew 'Sport' Higgins</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>5</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>48933.0</td>
      <td>Cybill Shepherd</td>
      <td>Betsy</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>6</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>32267.0</td>
      <td>Peter Boyle</td>
      <td>Wizard</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>77578</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>2050257.0</td>
      <td>Pa Jimi Solanke</td>
      <td>Akanji's Father</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77579</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>1347054.0</td>
      <td>Nnenna Rachael Okonkwo</td>
      <td>Afinni</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77580</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>157590.0</td>
      <td>Lucien Morgan</td>
      <td>Dr. Ian Stones</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77581</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>129059.0</td>
      <td>Magdalena Korpas</td>
      <td>Jane</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77582</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>2050199.0</td>
      <td>Mistura Olusanya</td>
      <td>Nurse Titi</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77583</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>2050423.0</td>
      <td>Yemi Amodu</td>
      <td>NaN</td>
      <td>DIRECTOR</td>
    </tr>
    <tr>
      <th>77584</th>
      <td>ts271048</td>
      <td>Mighty Little Bheem: Kite Festival</td>
      <td>SHOW</td>
      <td>With winter behind them, Bheem and his townspeople usher in a sunny new season in all their favorite ways during the Makar Sankranti festival.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>16.0</td>
      <td>0.979</td>
      <td>10.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>77585 rows × 19 columns</p>
      
          <p>listings (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>title</th>
      <th>type</th>
      <th>description</th>
      <th>release_year</th>
      <th>age_certification</th>
      <th>runtime</th>
      <th>...</th>
      <th>imdb_votes</th>
      <th>tmdb_popularity</th>
      <th>tmdb_score</th>
      <th>person_id</th>
      <th>name</th>
      <th>character</th>
      <th>role</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ts300399</td>
      <td>Five Came Back: The Reference Films</td>
      <td>SHOW</td>
      <td>This collection includes 12 World War II-era propaganda films — many of which are graphic and offensive — discussed in the docuseries "Five Came Back."</td>
      <td>1945</td>
      <td>TV-MA</td>
      <td>48</td>
      <td>...</td>
      <td>NaN</td>
      <td>0.600</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>3748.0</td>
      <td>Robert De Niro</td>
      <td>Travis Bickle</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>2</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>14658.0</td>
      <td>Jodie Foster</td>
      <td>Iris Steensma</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>3</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>7064.0</td>
      <td>Albert Brooks</td>
      <td>Tom</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>4</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>3739.0</td>
      <td>Harvey Keitel</td>
      <td>Matthew 'Sport' Higgins</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>5</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>48933.0</td>
      <td>Cybill Shepherd</td>
      <td>Betsy</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>6</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>...</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
      <td>32267.0</td>
      <td>Peter Boyle</td>
      <td>Wizard</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>77578</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>2050257.0</td>
      <td>Pa Jimi Solanke</td>
      <td>Akanji's Father</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77579</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>1347054.0</td>
      <td>Nnenna Rachael Okonkwo</td>
      <td>Afinni</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77580</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>157590.0</td>
      <td>Lucien Morgan</td>
      <td>Dr. Ian Stones</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77581</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>129059.0</td>
      <td>Magdalena Korpas</td>
      <td>Jane</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77582</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>2050199.0</td>
      <td>Mistura Olusanya</td>
      <td>Nurse Titi</td>
      <td>ACTOR</td>
    </tr>
    <tr>
      <th>77583</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>...</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
      <td>2050423.0</td>
      <td>Yemi Amodu</td>
      <td>NaN</td>
      <td>DIRECTOR</td>
    </tr>
    <tr>
      <th>77584</th>
      <td>ts271048</td>
      <td>Mighty Little Bheem: Kite Festival</td>
      <td>SHOW</td>
      <td>With winter behind them, Bheem and his townspeople usher in a sunny new season in all their favorite ways during the Makar Sankranti festival.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>16.0</td>
      <td>0.979</td>
      <td>10.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>77585 rows × 19 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> netflix-tv-shows-and-movies/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the average IMDB and TMDB scores for movies and shows?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>titles.groupby('type')[['imdb_score','tmdb_score']].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>titles.groupby('type')[['imdb_score','tmdb_score']].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = titles.groupby('type')[['imdb_score', 'tmdb_score']].mean()
</code></pre>
        <p><span onclick="$('#var_output_a63d812b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a63d812b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>imdb_score</th>
      <th>tmdb_score</th>
    </tr>
    <tr>
      <th>type</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MOVIE</th>
      <td>6.266980</td>
      <td>6.450098</td>
    </tr>
    <tr>
      <th>SHOW</th>
      <td>7.017377</td>
      <td>7.504543</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>imdb_score</th>
      <th>tmdb_score</th>
    </tr>
    <tr>
      <th>type</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MOVIE</th>
      <td>6.266980</td>
      <td>6.450098</td>
    </tr>
    <tr>
      <th>SHOW</th>
      <td>7.017377</td>
      <td>7.504543</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> netflix-tv-shows-and-movies/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which actor and director has the highest average IMDB score?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>average_scores = listings.groupby(['role','name']).imdb_score.mean()
average_scores.groupby('role').agg({'idxmax','max'})</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>average_scores = listings.groupby(['role','name']).imdb_score.mean()
average_scores.groupby('role').agg({'idxmax','max'})</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>average_scores = listings.groupby(['role', 'name']).imdb_score.mean()
__output__ = average_scores.groupby('role').agg({'idxmax', 'max'})
</code></pre>
        <p><span onclick="$('#var_output_3582241e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3582241e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>max</th>
      <th>idxmax</th>
    </tr>
    <tr>
      <th>role</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ACTOR</th>
      <td>9.5</td>
      <td>(ACTOR, Anna Gunn)</td>
    </tr>
    <tr>
      <th>DIRECTOR</th>
      <td>9.1</td>
      <td>(DIRECTOR, Jason Hehir)</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> average_scores, __output__ </p>
    
          <p>average_scores (Series):</p>
          <pre><code>role      name               
ACTOR      Michael Hayden        6.9
          'Jeeva' Ravi           7.7
          'Weird Al' Yankovic    6.5
          21 Savage              4.3
          2Mex                   6.3
                                ... 
DIRECTOR  이혜주                    7.9
          장성                     NaN
          주둥닝                    8.0
          지뢰                     7.4
          허윤무                    8.6
Name: imdb_score, Length: 54140, dtype: float64</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>max</th>
      <th>idxmax</th>
    </tr>
    <tr>
      <th>role</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ACTOR</th>
      <td>9.5</td>
      <td>(ACTOR, Anna Gunn)</td>
    </tr>
    <tr>
      <th>DIRECTOR</th>
      <td>9.1</td>
      <td>(DIRECTOR, Jason Hehir)</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> netflix-tv-shows-and-movies/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average TMDB popularity of movies released each year?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>movies = titles[titles['type']=='MOVIE']
movies.groupby('release_year').tmdb_popularity.mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>movies = titles[titles['type']=='MOVIE']
movies.groupby('release_year').tmdb_popularity.mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>movies = titles[titles['type'] == 'MOVIE']
__output__ = movies.groupby('release_year').tmdb_popularity.mean()
</code></pre>
        <p><span onclick="$('#var_output_1e7ca744').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1e7ca744" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>release_year
1953      1.826000
1954      5.788000
1956      1.044000
1958      3.556000
1959      0.998000
           ...    
2018      9.053329
2019      9.199696
2020     13.585808
2021     38.215703
2022    155.378766
Name: tmdb_popularity, Length: 66, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> movies, __output__ </p>
    
          <p>movies (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>title</th>
      <th>type</th>
      <th>description</th>
      <th>release_year</th>
      <th>age_certification</th>
      <th>runtime</th>
      <th>genres</th>
      <th>production_countries</th>
      <th>seasons</th>
      <th>imdb_id</th>
      <th>imdb_score</th>
      <th>imdb_votes</th>
      <th>tmdb_popularity</th>
      <th>tmdb_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>crime, drama</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0075314</td>
      <td>8.3</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>tm127384</td>
      <td>Monty Python and the Holy Grail</td>
      <td>MOVIE</td>
      <td>King Arthur, accompanied by his squire, recruits his Knights of the Round Table, including Sir Bedevere the Wise, Sir Lancelot the Brave, Sir Robin the Not-Quite-So-Brave-As-Sir-Lancelot and Sir Galahad the Pure. On the way, Arthur battles the Black Knight who, despite having had all his limbs chopped off, insists he can still fight. They reach Camelot, but Arthur decides not  to enter, as "it is a silly place".</td>
      <td>1975</td>
      <td>PG</td>
      <td>91</td>
      <td>comedy, fantasy</td>
      <td>GB</td>
      <td>NaN</td>
      <td>tt0071853</td>
      <td>8.2</td>
      <td>530877.0</td>
      <td>18.216</td>
      <td>7.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>tm70993</td>
      <td>Life of Brian</td>
      <td>MOVIE</td>
      <td>Brian Cohen is an average young Jewish man, but through a series of ridiculous events, he gains a reputation as the Messiah. When he's not dodging his followers or being scolded by his shrill mother, the hapless Brian has to contend with the pompous Pontius Pilate and acronym-obsessed members of a separatist movement. Rife with Monty Python's signature absurdity, the tale finds Brian's life paralleling Biblical lore, albeit with many more laughs.</td>
      <td>1979</td>
      <td>R</td>
      <td>94</td>
      <td>comedy</td>
      <td>GB</td>
      <td>NaN</td>
      <td>tt0079470</td>
      <td>8.0</td>
      <td>392419.0</td>
      <td>17.505</td>
      <td>7.8</td>
    </tr>
    <tr>
      <th>4</th>
      <td>tm190788</td>
      <td>The Exorcist</td>
      <td>MOVIE</td>
      <td>12-year-old Regan MacNeil begins to adapt an explicit new personality as strange events befall the local area of Georgetown. Her mother becomes torn between science and superstition in a desperate bid to save her daughter, and ultimately turns to her last hope: Father Damien Karras, a troubled priest who is struggling with his own faith.</td>
      <td>1973</td>
      <td>R</td>
      <td>133</td>
      <td>horror</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0070047</td>
      <td>8.1</td>
      <td>391942.0</td>
      <td>95.337</td>
      <td>7.7</td>
    </tr>
    <tr>
      <th>6</th>
      <td>tm14873</td>
      <td>Dirty Harry</td>
      <td>MOVIE</td>
      <td>When a madman dubbed 'Scorpio' terrorizes San Francisco, hard-nosed cop, Harry Callahan – famous for his take-no-prisoners approach to law enforcement – is tasked with hunting down the psychopath. Harry eventually collars Scorpio in the process of rescuing a kidnap victim, only to see him walk on technicalities. Now, the maverick detective is determined to nail the maniac himself.</td>
      <td>1971</td>
      <td>R</td>
      <td>102</td>
      <td>thriller, crime, action</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0066999</td>
      <td>7.7</td>
      <td>153463.0</td>
      <td>14.745</td>
      <td>7.5</td>
    </tr>
    <tr>
      <th>7</th>
      <td>tm185072</td>
      <td>My Fair Lady</td>
      <td>MOVIE</td>
      <td>A snobbish phonetics professor agrees to a wager that he can take a flower girl and make her presentable in high society.</td>
      <td>1964</td>
      <td>G</td>
      <td>170</td>
      <td>drama, music, romance, family</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0058385</td>
      <td>7.8</td>
      <td>94121.0</td>
      <td>15.949</td>
      <td>7.6</td>
    </tr>
    <tr>
      <th>8</th>
      <td>tm98978</td>
      <td>The Blue Lagoon</td>
      <td>MOVIE</td>
      <td>Two small children and a ship's cook survive a shipwreck and find safety on an idyllic tropical island. Soon, however, the cook dies and the young boy and girl are left on their own. Days become years and Emmeline and Richard make a home for themselves surrounded by exotic creatures and nature's beauty. But will they ever see civilization again?</td>
      <td>1980</td>
      <td>R</td>
      <td>104</td>
      <td>romance, drama</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0080453</td>
      <td>5.8</td>
      <td>69053.0</td>
      <td>44.038</td>
      <td>6.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>5797</th>
      <td>tm985215</td>
      <td>Princess 'Daya'Reese</td>
      <td>MOVIE</td>
      <td>Reese is a con artist from Manila who dreams of living like royalty. An opportunity arrives in the form of Princess Ulap, a runaway princess from the mysterious kingdom of Oro, who looks exactly like her. Switching places in exchange for gold, Reese flies to Ulap's kingdom where she meets Caleb, a young and determined reporter who is doing a documentary on the island of Oro. The road to happily ever after becomes bumpy when the man in search for truth begins to fall in love with the fake princess.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>115</td>
      <td>romance, comedy</td>
      <td>PH</td>
      <td>NaN</td>
      <td>tt13399802</td>
      <td>7.2</td>
      <td>45.0</td>
      <td>3.063</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5798</th>
      <td>tm1004011</td>
      <td>Time to Dance</td>
      <td>MOVIE</td>
      <td>When a ballroom dancer’s shot at a crucial tournament is jeopardized, a street dancer must face his own painful past and step up as her new partner.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>107</td>
      <td>drama, romance</td>
      <td>IN</td>
      <td>NaN</td>
      <td>tt8622232</td>
      <td>2.2</td>
      <td>950.0</td>
      <td>2.911</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>5800</th>
      <td>tm1040816</td>
      <td>Momshies! Your Soul is Mine</td>
      <td>MOVIE</td>
      <td>Three women with totally different lives accidentally get their souls switched as they struggle with the comedic misadventures of their new worlds, they realize that their own lives and families are worth loving and living for. Jolene, a famous person who always has fans in public, Mylene - an overprotected lady who always gets pleasure and love and Karlene - a rich famous social media influencer all switch bodies but their lives did not just change, but their souls switched that leaves them with no choice but to stick together to live the peculiar lives of each other. Karlene then has to convince a group of investors to invest in her near-bankrupt hotel, but no one believes her because she is trapped in Mylene’s body. In the process of all of their imaginative scenarios, they drew closer to each other into becoming the soul sisters they are destined to be.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>108</td>
      <td>comedy</td>
      <td>PH</td>
      <td>NaN</td>
      <td>tt14412240</td>
      <td>5.8</td>
      <td>26.0</td>
      <td>4.112</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5801</th>
      <td>tm1014599</td>
      <td>Fine Wine</td>
      <td>MOVIE</td>
      <td>A beautiful love story that can happen between two people regardless of their age gaps.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>100</td>
      <td>romance, drama</td>
      <td>NG</td>
      <td>NaN</td>
      <td>tt13857480</td>
      <td>6.9</td>
      <td>39.0</td>
      <td>0.966</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5802</th>
      <td>tm1108171</td>
      <td>Edis Starlight</td>
      <td>MOVIE</td>
      <td>Rising star Edis's career journey with ups and downs.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>74</td>
      <td>music, documentation</td>
      <td></td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.036</td>
      <td>8.5</td>
    </tr>
    <tr>
      <th>5803</th>
      <td>tm1045018</td>
      <td>Clash</td>
      <td>MOVIE</td>
      <td>A man from Nigeria returns to his family in Canada and discovers that Western culture has changed his children in ways that he does not approve.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>88</td>
      <td>family, drama</td>
      <td>NG, CA</td>
      <td>NaN</td>
      <td>tt14620732</td>
      <td>6.5</td>
      <td>32.0</td>
      <td>0.709</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5804</th>
      <td>tm1098060</td>
      <td>Shadow Parties</td>
      <td>MOVIE</td>
      <td>A family faces destruction in a long-running conflict between communities that pits relatives against each other amid attacks and reprisals.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>116</td>
      <td>action, thriller</td>
      <td></td>
      <td>NaN</td>
      <td>tt10168094</td>
      <td>6.2</td>
      <td>9.0</td>
      <td>2.186</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>3759 rows × 15 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>release_year
1953      1.826000
1954      5.788000
1956      1.044000
1958      3.556000
1959      0.998000
           ...    
2018      9.053329
2019      9.199696
2020     13.585808
2021     38.215703
2022    155.378766
Name: tmdb_popularity, Length: 66, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> netflix-tv-shows-and-movies/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the ranges of run time durations for each age category? Return a dataframe with the shortest and longest run times for each age category.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>titles.groupby('age_certification').agg({'runtime':['min','max']})</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>titles.groupby('age_certification').agg({'runtime':['min','max']})</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = titles.groupby('age_certification').agg({'runtime': ['min',
    'max']})
</code></pre>
        <p><span onclick="$('#var_output_7d104393').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7d104393" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">runtime</th>
    </tr>
    <tr>
      <th></th>
      <th>min</th>
      <th>max</th>
    </tr>
    <tr>
      <th>age_certification</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>G</th>
      <td>9</td>
      <td>210</td>
    </tr>
    <tr>
      <th>NC-17</th>
      <td>30</td>
      <td>176</td>
    </tr>
    <tr>
      <th>PG</th>
      <td>12</td>
      <td>224</td>
    </tr>
    <tr>
      <th>PG-13</th>
      <td>8</td>
      <td>240</td>
    </tr>
    <tr>
      <th>R</th>
      <td>29</td>
      <td>229</td>
    </tr>
    <tr>
      <th>TV-14</th>
      <td>0</td>
      <td>225</td>
    </tr>
    <tr>
      <th>TV-G</th>
      <td>2</td>
      <td>96</td>
    </tr>
    <tr>
      <th>TV-MA</th>
      <td>0</td>
      <td>199</td>
    </tr>
    <tr>
      <th>TV-PG</th>
      <td>0</td>
      <td>97</td>
    </tr>
    <tr>
      <th>TV-Y</th>
      <td>0</td>
      <td>46</td>
    </tr>
    <tr>
      <th>TV-Y7</th>
      <td>2</td>
      <td>131</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">runtime</th>
    </tr>
    <tr>
      <th></th>
      <th>min</th>
      <th>max</th>
    </tr>
    <tr>
      <th>age_certification</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>G</th>
      <td>9</td>
      <td>210</td>
    </tr>
    <tr>
      <th>NC-17</th>
      <td>30</td>
      <td>176</td>
    </tr>
    <tr>
      <th>PG</th>
      <td>12</td>
      <td>224</td>
    </tr>
    <tr>
      <th>PG-13</th>
      <td>8</td>
      <td>240</td>
    </tr>
    <tr>
      <th>R</th>
      <td>29</td>
      <td>229</td>
    </tr>
    <tr>
      <th>TV-14</th>
      <td>0</td>
      <td>225</td>
    </tr>
    <tr>
      <th>TV-G</th>
      <td>2</td>
      <td>96</td>
    </tr>
    <tr>
      <th>TV-MA</th>
      <td>0</td>
      <td>199</td>
    </tr>
    <tr>
      <th>TV-PG</th>
      <td>0</td>
      <td>97</td>
    </tr>
    <tr>
      <th>TV-Y</th>
      <td>0</td>
      <td>46</td>
    </tr>
    <tr>
      <th>TV-Y7</th>
      <td>2</td>
      <td>131</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> netflix-tv-shows-and-movies/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top five listings having the highest number of actors involved?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>listings[listings['role']=='ACTOR'].groupby('title').person_id.nunique().sort_values(ascending=False).head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>listings[listings['role']=='ACTOR'].groupby('title').person_id.nunique().sort_values(ascending=False).head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = listings[listings['role'] == 'ACTOR'].groupby('title'
    ).person_id.nunique().sort_values(ascending=False).head(5)
</code></pre>
        <p><span onclick="$('#var_output_68cf6a0f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_68cf6a0f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>title
Les Misérables                   207
The Irishman                     173
Hairspray                        149
Homecoming: A Film by Beyoncé    137
Contagion                        136
Name: person_id, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>title
Les Misérables                   207
The Irishman                     173
Hairspray                        149
Homecoming: A Film by Beyoncé    137
Contagion                        136
Name: person_id, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> netflix-tv-shows-and-movies/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average TMDB popularity of movies belonging to comedy and drama genres?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>comedy_movies = titles[(titles['type']=='MOVIE') & (titles['genres'].str.contains('comedy'))]
drama_movies = titles[(titles['type']=='MOVIE') & (titles['genres'].str.contains('drama'))]

comedy_movies.tmdb_popularity.mean(), drama_movies.tmdb_popularity.mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>comedy_movies = titles[(titles['type']=='MOVIE') & (titles['genres'].str.contains('comedy'))]
drama_movies = titles[(titles['type']=='MOVIE') & (titles['genres'].str.contains('drama'))]

comedy_movies.tmdb_popularity.mean(), drama_movies.tmdb_popularity.mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>comedy_movies = titles[(titles['type'] == 'MOVIE') & titles['genres'].str.
    contains('comedy')]
drama_movies = titles[(titles['type'] == 'MOVIE') & titles['genres'].str.
    contains('drama')]
__output__ = comedy_movies.tmdb_popularity.mean(
    ), drama_movies.tmdb_popularity.mean()
</code></pre>
        <p><span onclick="$('#var_output_2e417bfd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2e417bfd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (tuple):</p>
          <pre><code>(16.038537655533727, 20.35662008754758)</code></pre>
      
        <p><strong>Hyp output variables:</strong> comedy_movies, drama_movies, __output__ </p>
    
          <p>comedy_movies (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>title</th>
      <th>type</th>
      <th>description</th>
      <th>release_year</th>
      <th>age_certification</th>
      <th>runtime</th>
      <th>genres</th>
      <th>production_countries</th>
      <th>seasons</th>
      <th>imdb_id</th>
      <th>imdb_score</th>
      <th>imdb_votes</th>
      <th>tmdb_popularity</th>
      <th>tmdb_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>tm127384</td>
      <td>Monty Python and the Holy Grail</td>
      <td>MOVIE</td>
      <td>King Arthur, accompanied by his squire, recruits his Knights of the Round Table, including Sir Bedevere the Wise, Sir Lancelot the Brave, Sir Robin the Not-Quite-So-Brave-As-Sir-Lancelot and Sir Galahad the Pure. On the way, Arthur battles the Black Knight who, despite having had all his limbs chopped off, insists he can still fight. They reach Camelot, but Arthur decides not  to enter, as "it is a silly place".</td>
      <td>1975</td>
      <td>PG</td>
      <td>91</td>
      <td>comedy, fantasy</td>
      <td>GB</td>
      <td>NaN</td>
      <td>tt0071853</td>
      <td>8.2</td>
      <td>530877.0</td>
      <td>18.216</td>
      <td>7.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>tm70993</td>
      <td>Life of Brian</td>
      <td>MOVIE</td>
      <td>Brian Cohen is an average young Jewish man, but through a series of ridiculous events, he gains a reputation as the Messiah. When he's not dodging his followers or being scolded by his shrill mother, the hapless Brian has to contend with the pompous Pontius Pilate and acronym-obsessed members of a separatist movement. Rife with Monty Python's signature absurdity, the tale finds Brian's life paralleling Biblical lore, albeit with many more laughs.</td>
      <td>1979</td>
      <td>R</td>
      <td>94</td>
      <td>comedy</td>
      <td>GB</td>
      <td>NaN</td>
      <td>tt0079470</td>
      <td>8.0</td>
      <td>392419.0</td>
      <td>17.505</td>
      <td>7.8</td>
    </tr>
    <tr>
      <th>12</th>
      <td>tm69778</td>
      <td>Lupin the Third: The Castle of Cagliostro</td>
      <td>MOVIE</td>
      <td>After a successful robbery leaves famed thief Lupin the Third and his partner Jigen with nothing but a large amount of expertly crafted counterfeit bills, he decides to track down the forgers responsible—and steal any other treasures he may find in the Castle of Cagliostro, including the 'damsel in distress' he finds imprisoned there.</td>
      <td>1979</td>
      <td>PG</td>
      <td>100</td>
      <td>comedy, animation, action, fantasy, family</td>
      <td>JP</td>
      <td>NaN</td>
      <td>tt0079833</td>
      <td>7.6</td>
      <td>30277.0</td>
      <td>14.008</td>
      <td>7.5</td>
    </tr>
    <tr>
      <th>13</th>
      <td>tm69997</td>
      <td>Richard Pryor: Live in Concert</td>
      <td>MOVIE</td>
      <td>Richard Pryor delivers monologues on race, sex, family and his favorite target—himself, live at the Terrace Theatre in Long Beach, California.</td>
      <td>1979</td>
      <td>R</td>
      <td>78</td>
      <td>comedy, documentation</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0079807</td>
      <td>8.1</td>
      <td>5141.0</td>
      <td>4.681</td>
      <td>7.5</td>
    </tr>
    <tr>
      <th>15</th>
      <td>tm16479</td>
      <td>White Christmas</td>
      <td>MOVIE</td>
      <td>Two talented song-and-dance men team up after the war to become one of the hottest acts in show business. In time they befriend and become romantically involved with the beautiful Haynes sisters who comprise a sister act.</td>
      <td>1954</td>
      <td>NaN</td>
      <td>115</td>
      <td>romance, comedy, music</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0047673</td>
      <td>7.5</td>
      <td>42373.0</td>
      <td>9.710</td>
      <td>7.2</td>
    </tr>
    <tr>
      <th>16</th>
      <td>tm135083</td>
      <td>Cairo Station</td>
      <td>MOVIE</td>
      <td>Qinawi, a physically challenged peddler who makes his living selling newspapers in the central Cairo train station, is obsessed by Hanuma, an attractive young woman who sells drinks. While she jokes with him about a possible relationship, she is actually in love with Abu Siri, a strong and respected porter at the station who is struggling to unionize his fellow workers to combat their boss' exploitative and abusive treatment.</td>
      <td>1958</td>
      <td>NaN</td>
      <td>77</td>
      <td>drama, crime, comedy</td>
      <td>EG</td>
      <td>NaN</td>
      <td>tt0051390</td>
      <td>7.5</td>
      <td>4385.0</td>
      <td>3.556</td>
      <td>7.4</td>
    </tr>
    <tr>
      <th>19</th>
      <td>tm156453</td>
      <td>FTA</td>
      <td>MOVIE</td>
      <td>A documentary about a political troupe headed by actors Jane Fonda and Donald Sutherland which traveled to towns near military bases in the US in the early 1970s. The group put on shows called "F.T.A.", which stood for "F**k the Army", and was aimed at convincing soldiers to voice their opposition to the Vietnam War, which was raging at the time. Various singers, actors and other entertainers performed antiwar songs and skits during the show.</td>
      <td>1972</td>
      <td>R</td>
      <td>97</td>
      <td>comedy, documentation, music</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0068562</td>
      <td>6.2</td>
      <td>411.0</td>
      <td>2.466</td>
      <td>6.1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>5787</th>
      <td>tm1040832</td>
      <td>Mommy Issues</td>
      <td>MOVIE</td>
      <td>“Mommy Issues” revolves around Ella (Pokwang), a hardworking single mother who has devoted her life for her only daughter Katya (Sue). Her zealousness to protect her daughter leads to conflict but thanks to grandmother Fenny (Gloria Diaz), they blow over because of the quirky and fun ways she helps bridge the gap between her loved ones.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>89</td>
      <td>comedy</td>
      <td>PH</td>
      <td>NaN</td>
      <td>tt14880428</td>
      <td>5.4</td>
      <td>38.0</td>
      <td>2.043</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>5788</th>
      <td>tm1025616</td>
      <td>Loyiso Gola: Unlearning</td>
      <td>MOVIE</td>
      <td>South African comedian Loyiso Gola serves up filter-free humor as he riffs about race, identity, politics, and a school prank gone embarrassingly wrong!</td>
      <td>2021</td>
      <td>NaN</td>
      <td>60</td>
      <td>comedy</td>
      <td></td>
      <td>NaN</td>
      <td>tt14111708</td>
      <td>5.9</td>
      <td>202.0</td>
      <td>1.672</td>
      <td>7.5</td>
    </tr>
    <tr>
      <th>5791</th>
      <td>tm996479</td>
      <td>Tuesdays And Fridays</td>
      <td>MOVIE</td>
      <td>Two millennials get into a relationship where they are allowed to meet only on 'Tuesdays &amp; Fridays'.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>106</td>
      <td>romance, comedy</td>
      <td>IN, GB</td>
      <td>NaN</td>
      <td>tt9176102</td>
      <td>4.5</td>
      <td>758.0</td>
      <td>1.658</td>
      <td>5.3</td>
    </tr>
    <tr>
      <th>5792</th>
      <td>tm1097142</td>
      <td>My Bride</td>
      <td>MOVIE</td>
      <td>The story follows a young man and woman who go through various situations in their journey to find the right partner, which raises questions about traditional marriage and marriage based on love.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>93</td>
      <td>comedy, drama, romance</td>
      <td>EG</td>
      <td>NaN</td>
      <td>tt14216488</td>
      <td>4.9</td>
      <td>281.0</td>
      <td>2.923</td>
      <td>5.3</td>
    </tr>
    <tr>
      <th>5795</th>
      <td>tm878575</td>
      <td>The Heartbreak Club</td>
      <td>MOVIE</td>
      <td>Coping with heartbreak, the shy owner of floundering cafe find solace in the Javanese love songs of Didi Kempot.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>101</td>
      <td>comedy, drama, romance</td>
      <td>ID</td>
      <td>NaN</td>
      <td>tt11841144</td>
      <td>6.2</td>
      <td>188.0</td>
      <td>2.227</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>5797</th>
      <td>tm985215</td>
      <td>Princess 'Daya'Reese</td>
      <td>MOVIE</td>
      <td>Reese is a con artist from Manila who dreams of living like royalty. An opportunity arrives in the form of Princess Ulap, a runaway princess from the mysterious kingdom of Oro, who looks exactly like her. Switching places in exchange for gold, Reese flies to Ulap's kingdom where she meets Caleb, a young and determined reporter who is doing a documentary on the island of Oro. The road to happily ever after becomes bumpy when the man in search for truth begins to fall in love with the fake princess.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>115</td>
      <td>romance, comedy</td>
      <td>PH</td>
      <td>NaN</td>
      <td>tt13399802</td>
      <td>7.2</td>
      <td>45.0</td>
      <td>3.063</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5800</th>
      <td>tm1040816</td>
      <td>Momshies! Your Soul is Mine</td>
      <td>MOVIE</td>
      <td>Three women with totally different lives accidentally get their souls switched as they struggle with the comedic misadventures of their new worlds, they realize that their own lives and families are worth loving and living for. Jolene, a famous person who always has fans in public, Mylene - an overprotected lady who always gets pleasure and love and Karlene - a rich famous social media influencer all switch bodies but their lives did not just change, but their souls switched that leaves them with no choice but to stick together to live the peculiar lives of each other. Karlene then has to convince a group of investors to invest in her near-bankrupt hotel, but no one believes her because she is trapped in Mylene’s body. In the process of all of their imaginative scenarios, they drew closer to each other into becoming the soul sisters they are destined to be.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>108</td>
      <td>comedy</td>
      <td>PH</td>
      <td>NaN</td>
      <td>tt14412240</td>
      <td>5.8</td>
      <td>26.0</td>
      <td>4.112</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>1543 rows × 15 columns</p>
      
          <p>drama_movies (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>title</th>
      <th>type</th>
      <th>description</th>
      <th>release_year</th>
      <th>age_certification</th>
      <th>runtime</th>
      <th>genres</th>
      <th>production_countries</th>
      <th>seasons</th>
      <th>imdb_id</th>
      <th>imdb_score</th>
      <th>imdb_votes</th>
      <th>tmdb_popularity</th>
      <th>tmdb_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>tm84618</td>
      <td>Taxi Driver</td>
      <td>MOVIE</td>
      <td>A mentally unstable Vietnam War veteran works as a night-time taxi driver in New York City where the perceived decadence and sleaze feed his urge for violent action, attempting to save a preadolescent prostitute in the process.</td>
      <td>1976</td>
      <td>R</td>
      <td>113</td>
      <td>crime, drama</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0075314</td>
      <td>8.3</td>
      <td>795222.0</td>
      <td>27.612</td>
      <td>8.2</td>
    </tr>
    <tr>
      <th>7</th>
      <td>tm185072</td>
      <td>My Fair Lady</td>
      <td>MOVIE</td>
      <td>A snobbish phonetics professor agrees to a wager that he can take a flower girl and make her presentable in high society.</td>
      <td>1964</td>
      <td>G</td>
      <td>170</td>
      <td>drama, music, romance, family</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0058385</td>
      <td>7.8</td>
      <td>94121.0</td>
      <td>15.949</td>
      <td>7.6</td>
    </tr>
    <tr>
      <th>8</th>
      <td>tm98978</td>
      <td>The Blue Lagoon</td>
      <td>MOVIE</td>
      <td>Two small children and a ship's cook survive a shipwreck and find safety on an idyllic tropical island. Soon, however, the cook dies and the young boy and girl are left on their own. Days become years and Emmeline and Richard make a home for themselves surrounded by exotic creatures and nature's beauty. But will they ever see civilization again?</td>
      <td>1980</td>
      <td>R</td>
      <td>104</td>
      <td>romance, drama</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0080453</td>
      <td>5.8</td>
      <td>69053.0</td>
      <td>44.038</td>
      <td>6.2</td>
    </tr>
    <tr>
      <th>9</th>
      <td>tm119281</td>
      <td>Bonnie and Clyde</td>
      <td>MOVIE</td>
      <td>In the 1930s, bored waitress Bonnie Parker falls in love with an ex-con named Clyde Barrow and together they start a violent crime spree through the country, stealing cars and robbing banks.</td>
      <td>1967</td>
      <td>R</td>
      <td>110</td>
      <td>drama, crime, action</td>
      <td>US</td>
      <td>NaN</td>
      <td>tt0061418</td>
      <td>7.7</td>
      <td>111189.0</td>
      <td>15.309</td>
      <td>7.5</td>
    </tr>
    <tr>
      <th>11</th>
      <td>tm44204</td>
      <td>The Guns of Navarone</td>
      <td>MOVIE</td>
      <td>A team of allied saboteurs are assigned an impossible mission: infiltrate an impregnable Nazi-held island and destroy the two enormous long-range field guns that prevent the rescue of 2,000 trapped British soldiers.</td>
      <td>1961</td>
      <td>NaN</td>
      <td>158</td>
      <td>war, action, drama</td>
      <td>US, GB</td>
      <td>NaN</td>
      <td>tt0054953</td>
      <td>7.5</td>
      <td>50150.0</td>
      <td>15.405</td>
      <td>7.4</td>
    </tr>
    <tr>
      <th>16</th>
      <td>tm135083</td>
      <td>Cairo Station</td>
      <td>MOVIE</td>
      <td>Qinawi, a physically challenged peddler who makes his living selling newspapers in the central Cairo train station, is obsessed by Hanuma, an attractive young woman who sells drinks. While she jokes with him about a possible relationship, she is actually in love with Abu Siri, a strong and respected porter at the station who is struggling to unionize his fellow workers to combat their boss' exploitative and abusive treatment.</td>
      <td>1958</td>
      <td>NaN</td>
      <td>77</td>
      <td>drama, crime, comedy</td>
      <td>EG</td>
      <td>NaN</td>
      <td>tt0051390</td>
      <td>7.5</td>
      <td>4385.0</td>
      <td>3.556</td>
      <td>7.4</td>
    </tr>
    <tr>
      <th>20</th>
      <td>tm27298</td>
      <td>Saladin the Victorious</td>
      <td>MOVIE</td>
      <td>Saladin, the first sultan of Egypt and Syria, leads the Muslim military campaign against the invading Christians from Europe during the Third Crusade.</td>
      <td>1963</td>
      <td>NaN</td>
      <td>186</td>
      <td>drama, war, action, history, romance</td>
      <td>EG</td>
      <td>NaN</td>
      <td>tt0057357</td>
      <td>7.6</td>
      <td>2470.0</td>
      <td>4.816</td>
      <td>7.1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>5789</th>
      <td>tm846586</td>
      <td>Layla Majnun</td>
      <td>MOVIE</td>
      <td>While in Azerbaijan, Layla, an Indonesian scholar, falls for Samir, an admirer of her work — but her arranged marriage stands in the way.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>119</td>
      <td>drama, romance</td>
      <td>ID</td>
      <td>NaN</td>
      <td>tt11313944</td>
      <td>6.1</td>
      <td>272.0</td>
      <td>3.646</td>
      <td>7.5</td>
    </tr>
    <tr>
      <th>5790</th>
      <td>tm1106888</td>
      <td>Meeting Point</td>
      <td>MOVIE</td>
      <td>She is 24, has completed a postgraduate course, and speaks three languages. She likes the gothic style, rides a motorcycle and is an atheist. She is against any restrictions. But the environment she is in, the music she listens to, and the conversation she makes has never satisfied her. She is obsessed with her question: “Why am I here?”. He is 54. He is a sarcastic manager and workaholic. Successful, principled, proper and moral. He is Muslim, but drinks alcohol. He is at war with himself due to his strict adherence to his principles. He’s worried about his life passing by. He doesn’t feel that he belongs where he is. They meet at night on the pavement, having emerged from two different establishments for some fresh air. They will spend a few hours together. Very important hours… A warm, night-time story about loneliness and community, distance and closeness.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>90</td>
      <td>drama</td>
      <td>TR</td>
      <td>NaN</td>
      <td>tt15484242</td>
      <td>4.2</td>
      <td>423.0</td>
      <td>2.065</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>5792</th>
      <td>tm1097142</td>
      <td>My Bride</td>
      <td>MOVIE</td>
      <td>The story follows a young man and woman who go through various situations in their journey to find the right partner, which raises questions about traditional marriage and marriage based on love.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>93</td>
      <td>comedy, drama, romance</td>
      <td>EG</td>
      <td>NaN</td>
      <td>tt14216488</td>
      <td>4.9</td>
      <td>281.0</td>
      <td>2.923</td>
      <td>5.3</td>
    </tr>
    <tr>
      <th>5795</th>
      <td>tm878575</td>
      <td>The Heartbreak Club</td>
      <td>MOVIE</td>
      <td>Coping with heartbreak, the shy owner of floundering cafe find solace in the Javanese love songs of Didi Kempot.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>101</td>
      <td>comedy, drama, romance</td>
      <td>ID</td>
      <td>NaN</td>
      <td>tt11841144</td>
      <td>6.2</td>
      <td>188.0</td>
      <td>2.227</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>5798</th>
      <td>tm1004011</td>
      <td>Time to Dance</td>
      <td>MOVIE</td>
      <td>When a ballroom dancer’s shot at a crucial tournament is jeopardized, a street dancer must face his own painful past and step up as her new partner.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>107</td>
      <td>drama, romance</td>
      <td>IN</td>
      <td>NaN</td>
      <td>tt8622232</td>
      <td>2.2</td>
      <td>950.0</td>
      <td>2.911</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>5801</th>
      <td>tm1014599</td>
      <td>Fine Wine</td>
      <td>MOVIE</td>
      <td>A beautiful love story that can happen between two people regardless of their age gaps.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>100</td>
      <td>romance, drama</td>
      <td>NG</td>
      <td>NaN</td>
      <td>tt13857480</td>
      <td>6.9</td>
      <td>39.0</td>
      <td>0.966</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5803</th>
      <td>tm1045018</td>
      <td>Clash</td>
      <td>MOVIE</td>
      <td>A man from Nigeria returns to his family in Canada and discovers that Western culture has changed his children in ways that he does not approve.</td>
      <td>2021</td>
      <td>NaN</td>
      <td>88</td>
      <td>family, drama</td>
      <td>NG, CA</td>
      <td>NaN</td>
      <td>tt14620732</td>
      <td>6.5</td>
      <td>32.0</td>
      <td>0.709</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>1864 rows × 15 columns</p>
      
          <p>__output__ (tuple):</p>
          <pre><code>(16.038537655533727, 20.35662008754758)</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> netflix-tv-shows-and-movies/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many actors and directors contributed to movies produced in the US?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>listings[(listings['type']=='MOVIE') & (listings['production_countries'].str.contains('US'))].groupby(['role']).person_id.nunique()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>listings[(listings['type']=='MOVIE') & (listings['production_countries'].str.contains('US'))].groupby(['role']).person_id.nunique()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = listings[(listings['type'] == 'MOVIE') & listings[
    'production_countries'].str.contains('US')].groupby(['role']
    ).person_id.nunique()
</code></pre>
        <p><span onclick="$('#var_output_f1b91b31').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f1b91b31" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>role
ACTOR       25057
DIRECTOR     1233
Name: person_id, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>role
ACTOR       25057
DIRECTOR     1233
Name: person_id, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> netflix-tv-shows-and-movies/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the five most popluar shows having a runtime duration of less than an hour?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>titles[(titles['type']=='SHOW') & (titles['runtime']<60)].sort_values(by='tmdb_popularity', ascending=False).head()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>titles[(titles['type']=='SHOW') & (titles['runtime']<60)].sort_values(by='tmdb_popularity', ascending=False).head()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = titles[(titles['type'] == 'SHOW') & (titles['runtime'] < 60)
    ].sort_values(by='tmdb_popularity', ascending=False).head()
</code></pre>
        <p><span onclick="$('#var_output_ac68e2fa').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ac68e2fa" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>title</th>
      <th>type</th>
      <th>description</th>
      <th>release_year</th>
      <th>age_certification</th>
      <th>runtime</th>
      <th>genres</th>
      <th>production_countries</th>
      <th>seasons</th>
      <th>imdb_id</th>
      <th>imdb_score</th>
      <th>imdb_votes</th>
      <th>tmdb_popularity</th>
      <th>tmdb_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4875</th>
      <td>ts340376</td>
      <td>The Marked Heart</td>
      <td>SHOW</td>
      <td>This new Colombian telenovela is about a man who has to watch his wife die and have her heart extracted to give to another woman. He’s out for revenge in the world of organ trafficking.</td>
      <td>2022</td>
      <td>TV-MA</td>
      <td>44</td>
      <td>thriller, drama</td>
      <td>CO</td>
      <td>2.0</td>
      <td>tt18974572</td>
      <td>6.3</td>
      <td>1103.0</td>
      <td>1455.085</td>
      <td>6.8</td>
    </tr>
    <tr>
      <th>64</th>
      <td>ts25028</td>
      <td>Wheel of Fortune</td>
      <td>SHOW</td>
      <td>This game show sees contestants solve word puzzles, similar to those used in Hangman, to win cash and prizes determined by spinning a giant carnival wheel.</td>
      <td>1983</td>
      <td>TV-G</td>
      <td>26</td>
      <td>family</td>
      <td>US</td>
      <td>39.0</td>
      <td>tt0072584</td>
      <td>6.7</td>
      <td>3126.0</td>
      <td>1440.855</td>
      <td>6.7</td>
    </tr>
    <tr>
      <th>247</th>
      <td>ts21469</td>
      <td>Grey's Anatomy</td>
      <td>SHOW</td>
      <td>Follows the personal and professional lives of a group of doctors at Seattle’s Grey Sloan Memorial Hospital.</td>
      <td>2005</td>
      <td>TV-14</td>
      <td>49</td>
      <td>drama, romance</td>
      <td>US</td>
      <td>18.0</td>
      <td>tt0413573</td>
      <td>7.6</td>
      <td>293618.0</td>
      <td>1215.393</td>
      <td>8.3</td>
    </tr>
    <tr>
      <th>916</th>
      <td>ts20110</td>
      <td>Peaky Blinders</td>
      <td>SHOW</td>
      <td>A gangster family epic set in 1919 Birmingham, England and centered on a gang who sew razor blades in the peaks of their caps, and their fierce boss Tommy Shelby, who means to move up in the world.</td>
      <td>2013</td>
      <td>TV-MA</td>
      <td>58</td>
      <td>drama, crime, european</td>
      <td>GB</td>
      <td>6.0</td>
      <td>tt2442560</td>
      <td>8.8</td>
      <td>485506.0</td>
      <td>971.727</td>
      <td>8.6</td>
    </tr>
    <tr>
      <th>4832</th>
      <td>ts217231</td>
      <td>Heartstopper</td>
      <td>SHOW</td>
      <td>Teens Charlie and Nick discover their unlikely friendship might be something more as they navigate school and young love in this coming-of-age series.</td>
      <td>2022</td>
      <td>TV-14</td>
      <td>28</td>
      <td>drama, romance</td>
      <td>GB</td>
      <td>1.0</td>
      <td>tt10638036</td>
      <td>8.9</td>
      <td>28978.0</td>
      <td>926.362</td>
      <td>8.9</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 15 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>title</th>
      <th>type</th>
      <th>description</th>
      <th>release_year</th>
      <th>age_certification</th>
      <th>runtime</th>
      <th>genres</th>
      <th>production_countries</th>
      <th>seasons</th>
      <th>imdb_id</th>
      <th>imdb_score</th>
      <th>imdb_votes</th>
      <th>tmdb_popularity</th>
      <th>tmdb_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4875</th>
      <td>ts340376</td>
      <td>The Marked Heart</td>
      <td>SHOW</td>
      <td>This new Colombian telenovela is about a man who has to watch his wife die and have her heart extracted to give to another woman. He’s out for revenge in the world of organ trafficking.</td>
      <td>2022</td>
      <td>TV-MA</td>
      <td>44</td>
      <td>thriller, drama</td>
      <td>CO</td>
      <td>2.0</td>
      <td>tt18974572</td>
      <td>6.3</td>
      <td>1103.0</td>
      <td>1455.085</td>
      <td>6.8</td>
    </tr>
    <tr>
      <th>64</th>
      <td>ts25028</td>
      <td>Wheel of Fortune</td>
      <td>SHOW</td>
      <td>This game show sees contestants solve word puzzles, similar to those used in Hangman, to win cash and prizes determined by spinning a giant carnival wheel.</td>
      <td>1983</td>
      <td>TV-G</td>
      <td>26</td>
      <td>family</td>
      <td>US</td>
      <td>39.0</td>
      <td>tt0072584</td>
      <td>6.7</td>
      <td>3126.0</td>
      <td>1440.855</td>
      <td>6.7</td>
    </tr>
    <tr>
      <th>247</th>
      <td>ts21469</td>
      <td>Grey's Anatomy</td>
      <td>SHOW</td>
      <td>Follows the personal and professional lives of a group of doctors at Seattle’s Grey Sloan Memorial Hospital.</td>
      <td>2005</td>
      <td>TV-14</td>
      <td>49</td>
      <td>drama, romance</td>
      <td>US</td>
      <td>18.0</td>
      <td>tt0413573</td>
      <td>7.6</td>
      <td>293618.0</td>
      <td>1215.393</td>
      <td>8.3</td>
    </tr>
    <tr>
      <th>916</th>
      <td>ts20110</td>
      <td>Peaky Blinders</td>
      <td>SHOW</td>
      <td>A gangster family epic set in 1919 Birmingham, England and centered on a gang who sew razor blades in the peaks of their caps, and their fierce boss Tommy Shelby, who means to move up in the world.</td>
      <td>2013</td>
      <td>TV-MA</td>
      <td>58</td>
      <td>drama, crime, european</td>
      <td>GB</td>
      <td>6.0</td>
      <td>tt2442560</td>
      <td>8.8</td>
      <td>485506.0</td>
      <td>971.727</td>
      <td>8.6</td>
    </tr>
    <tr>
      <th>4832</th>
      <td>ts217231</td>
      <td>Heartstopper</td>
      <td>SHOW</td>
      <td>Teens Charlie and Nick discover their unlikely friendship might be something more as they navigate school and young love in this coming-of-age series.</td>
      <td>2022</td>
      <td>TV-14</td>
      <td>28</td>
      <td>drama, romance</td>
      <td>GB</td>
      <td>1.0</td>
      <td>tt10638036</td>
      <td>8.9</td>
      <td>28978.0</td>
      <td>926.362</td>
      <td>8.9</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 15 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> netflix-tv-shows-and-movies/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the highest IMDB rated movie within each age category?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>max_movie_scores = titles[titles['type']=='MOVIE'].groupby(['age_certification'], as_index=False).imdb_score.max()
max_movie_scores.merge(titles)[['age_certification','title','imdb_score']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>max_movie_scores = titles[titles['type']=='MOVIE'].groupby(['age_certification'], as_index=False).imdb_score.max()
max_movie_scores.merge(titles)[['age_certification','title','imdb_score']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>max_movie_scores = titles[titles['type'] == 'MOVIE'].groupby([
    'age_certification'], as_index=False).imdb_score.max()
__output__ = max_movie_scores.merge(titles)[['age_certification', 'title',
    'imdb_score']]
</code></pre>
        <p><span onclick="$('#var_output_d9857d85').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d9857d85" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age_certification</th>
      <th>title</th>
      <th>imdb_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>G</td>
      <td>Chhota Bheem &amp; Krishna in Mayanagari</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NC-17</td>
      <td>Super Deluxe</td>
      <td>8.4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>PG</td>
      <td>C/o Kancharapalem</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>PG</td>
      <td>David Attenborough: A Life on Our Planet</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>PG-13</td>
      <td>Forrest Gump</td>
      <td>8.8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>PG-13</td>
      <td>Inception</td>
      <td>8.8</td>
    </tr>
    <tr>
      <th>6</th>
      <td>R</td>
      <td>Bo Burnham: Inside</td>
      <td>8.7</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> max_movie_scores, __output__ </p>
    
          <p>max_movie_scores (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age_certification</th>
      <th>imdb_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>G</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NC-17</td>
      <td>8.4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>PG</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>PG-13</td>
      <td>8.8</td>
    </tr>
    <tr>
      <th>4</th>
      <td>R</td>
      <td>8.7</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age_certification</th>
      <th>title</th>
      <th>imdb_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>G</td>
      <td>Chhota Bheem &amp; Krishna in Mayanagari</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NC-17</td>
      <td>Super Deluxe</td>
      <td>8.4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>PG</td>
      <td>C/o Kancharapalem</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>PG</td>
      <td>David Attenborough: A Life on Our Planet</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>PG-13</td>
      <td>Forrest Gump</td>
      <td>8.8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>PG-13</td>
      <td>Inception</td>
      <td>8.8</td>
    </tr>
    <tr>
      <th>6</th>
      <td>R</td>
      <td>Bo Burnham: Inside</td>
      <td>8.7</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> netflix-tv-shows-and-movies/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Who is the actor who worked with the same director the most?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>director_listings = listings[listings.role=='DIRECTOR'].set_index(['name','title']).index.to_frame().reset_index(drop=True)
directors_actors = director_listings.merge(listings[listings['role']=='ACTOR'][['title','role','name']], on='title', suffixes=['_director','_actor'])
most_frequent = directors_actors.groupby(['name_actor','name_director']).size().sort_values(ascending=False)

most_frequent[most_frequent == most_frequent.max()]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>director_listings = listings[listings.role=='DIRECTOR'].set_index(['name','title']).index.to_frame().reset_index(drop=True)
directors_actors = director_listings.merge(listings[listings['role']=='ACTOR'][['title','role','name']], on='title', suffixes=['_director','_actor'])
most_frequent = directors_actors.groupby(['name_actor','name_director']).size().sort_values(ascending=False)

most_frequent[most_frequent == most_frequent.max()]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>director_listings = listings[listings.role == 'DIRECTOR'].set_index(['name',
    'title']).index.to_frame().reset_index(drop=True)
directors_actors = director_listings.merge(listings[listings['role'] ==
    'ACTOR'][['title', 'role', 'name']], on='title', suffixes=['_director',
    '_actor'])
most_frequent = directors_actors.groupby(['name_actor', 'name_director']).size(
    ).sort_values(ascending=False)
__output__ = most_frequent[most_frequent == most_frequent.max()]
</code></pre>
        <p><span onclick="$('#var_output_5e001518').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5e001518" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>name_actor     name_director      
Joross Gamboa  Cathy Garcia-Molina    7
dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> director_listings, directors_actors, most_frequent, __output__ </p>
    
          <p>director_listings (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Martin Scorsese</td>
      <td>Taxi Driver</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Terry Jones</td>
      <td>Monty Python and the Holy Grail</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Terry Gilliam</td>
      <td>Monty Python and the Holy Grail</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Terry Jones</td>
      <td>Life of Brian</td>
    </tr>
    <tr>
      <th>4</th>
      <td>William Friedkin</td>
      <td>The Exorcist</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Don Siegel</td>
      <td>Dirty Harry</td>
    </tr>
    <tr>
      <th>6</th>
      <td>George Cukor</td>
      <td>My Fair Lady</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4516</th>
      <td>Barry Gonzalez</td>
      <td>Princess 'Daya'Reese</td>
    </tr>
    <tr>
      <th>4517</th>
      <td>Stanley D'Costa</td>
      <td>Time to Dance</td>
    </tr>
    <tr>
      <th>4518</th>
      <td>Easy Ferrer</td>
      <td>Momshies! Your Soul is Mine</td>
    </tr>
    <tr>
      <th>4519</th>
      <td>Seyi Babatope</td>
      <td>Fine Wine</td>
    </tr>
    <tr>
      <th>4520</th>
      <td>Kürşad  Bayhan</td>
      <td>Edis Starlight</td>
    </tr>
    <tr>
      <th>4521</th>
      <td>Pascal Atuma</td>
      <td>Clash</td>
    </tr>
    <tr>
      <th>4522</th>
      <td>Yemi Amodu</td>
      <td>Shadow Parties</td>
    </tr>
  </tbody>
</table>
<p>4523 rows × 2 columns</p>
      
          <p>directors_actors (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name_director</th>
      <th>title</th>
      <th>role</th>
      <th>name_actor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Martin Scorsese</td>
      <td>Taxi Driver</td>
      <td>ACTOR</td>
      <td>Robert De Niro</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Martin Scorsese</td>
      <td>Taxi Driver</td>
      <td>ACTOR</td>
      <td>Jodie Foster</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Martin Scorsese</td>
      <td>Taxi Driver</td>
      <td>ACTOR</td>
      <td>Albert Brooks</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Martin Scorsese</td>
      <td>Taxi Driver</td>
      <td>ACTOR</td>
      <td>Harvey Keitel</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Martin Scorsese</td>
      <td>Taxi Driver</td>
      <td>ACTOR</td>
      <td>Cybill Shepherd</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Martin Scorsese</td>
      <td>Taxi Driver</td>
      <td>ACTOR</td>
      <td>Peter Boyle</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Martin Scorsese</td>
      <td>Taxi Driver</td>
      <td>ACTOR</td>
      <td>Leonard Harris</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>69771</th>
      <td>Yemi Amodu</td>
      <td>Shadow Parties</td>
      <td>ACTOR</td>
      <td>Jibola Dabo</td>
    </tr>
    <tr>
      <th>69772</th>
      <td>Yemi Amodu</td>
      <td>Shadow Parties</td>
      <td>ACTOR</td>
      <td>Rotimi Salami</td>
    </tr>
    <tr>
      <th>69773</th>
      <td>Yemi Amodu</td>
      <td>Shadow Parties</td>
      <td>ACTOR</td>
      <td>Pa Jimi Solanke</td>
    </tr>
    <tr>
      <th>69774</th>
      <td>Yemi Amodu</td>
      <td>Shadow Parties</td>
      <td>ACTOR</td>
      <td>Nnenna Rachael Okonkwo</td>
    </tr>
    <tr>
      <th>69775</th>
      <td>Yemi Amodu</td>
      <td>Shadow Parties</td>
      <td>ACTOR</td>
      <td>Lucien Morgan</td>
    </tr>
    <tr>
      <th>69776</th>
      <td>Yemi Amodu</td>
      <td>Shadow Parties</td>
      <td>ACTOR</td>
      <td>Magdalena Korpas</td>
    </tr>
    <tr>
      <th>69777</th>
      <td>Yemi Amodu</td>
      <td>Shadow Parties</td>
      <td>ACTOR</td>
      <td>Mistura Olusanya</td>
    </tr>
  </tbody>
</table>
<p>69778 rows × 4 columns</p>
      
          <p>most_frequent (Series):</p>
          <pre><code>name_actor         name_director      
Joross Gamboa      Cathy Garcia-Molina    7
Gulshan Grover     Umesh Mehra            6
Robb Wells         Mike Clattenburg       5
Wataru Ichinose    Shigeaki Kubo          5
Adam Sandler       Dennis Dugan           5
                                         ..
Hannah Jelinovic   Tarsem Singh           1
                   Charles Stone III      1
Hannah Hwang       Rob Marshall           1
Hannah Herzsprung  Baran bo Odar          1
Hannah Ledesma     Veronica Velasco       1
Length: 67483, dtype: int64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>name_actor     name_director      
Joross Gamboa  Cathy Garcia-Molina    7
dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> petrolgas-prices-worldwide/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the incorrect data types of numeric columns into numeric format.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>oil['Daily Oil Consumption (Barrels)'] = oil['Daily Oil Consumption (Barrels)'].str.replace(',','').astype(int)
oil['GDP Per Capita ( USD )'] = oil['GDP Per Capita ( USD )'].str.replace(',','').astype(int)
oil['Gallons GDP Per Capita Can Buy'] = oil['Gallons GDP Per Capita Can Buy'].str.replace(',','').astype(int)
oil['World Share'] = oil['World Share'].str.replace('%','').astype(float)

oil.info()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>oil['Daily Oil Consumption (Barrels)'] = oil['Daily Oil Consumption (Barrels)'].str.replace(',','').astype(int)
oil['GDP Per Capita ( USD )'] = oil['GDP Per Capita ( USD )'].str.replace(',','').astype(int)
oil['Gallons GDP Per Capita Can Buy'] = oil['Gallons GDP Per Capita Can Buy'].str.replace(',','').astype(int)
oil['World Share'] = oil['World Share'].str.replace('%','').astype(float)

oil.info()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>oil['Daily Oil Consumption (Barrels)'] = oil['Daily Oil Consumption (Barrels)'
    ].str.replace(',', '').astype(int)
oil['GDP Per Capita ( USD )'] = oil['GDP Per Capita ( USD )'].str.replace(',',
    '').astype(int)
oil['Gallons GDP Per Capita Can Buy'] = oil['Gallons GDP Per Capita Can Buy'
    ].str.replace(',', '').astype(int)
oil['World Share'] = oil['World Share'].str.replace('%', '').astype(float)
__output__ = oil.info()
</code></pre>
        <p><span onclick="$('#var_output_a556c6dd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a556c6dd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> oil </p>
    
          <p>oil (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>S#</th>
      <th>Country</th>
      <th>Daily Oil Consumption (Barrels)</th>
      <th>World Share</th>
      <th>Yearly Gallons Per Capita</th>
      <th>Price Per Gallon (USD)</th>
      <th>Price Per Liter (USD)</th>
      <th>Price Per Liter (PKR)</th>
      <th>GDP Per Capita ( USD )</th>
      <th>Gallons GDP Per Capita Can Buy</th>
      <th>xTimes Yearly Gallons Per Capita Buy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>United States</td>
      <td>19687287</td>
      <td>20.0</td>
      <td>934.3</td>
      <td>5.19</td>
      <td>1.37</td>
      <td>289.97</td>
      <td>63414</td>
      <td>12218</td>
      <td>13</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>China</td>
      <td>12791553</td>
      <td>13.0</td>
      <td>138.7</td>
      <td>5.42</td>
      <td>1.43</td>
      <td>302.87</td>
      <td>10435</td>
      <td>1925</td>
      <td>14</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>India</td>
      <td>4443000</td>
      <td>5.0</td>
      <td>51.4</td>
      <td>5.05</td>
      <td>1.33</td>
      <td>281.93</td>
      <td>1901</td>
      <td>376</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Japan</td>
      <td>4012877</td>
      <td>4.0</td>
      <td>481.5</td>
      <td>4.69</td>
      <td>1.24</td>
      <td>262.05</td>
      <td>40193</td>
      <td>8570</td>
      <td>18</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Russia</td>
      <td>3631287</td>
      <td>4.0</td>
      <td>383.2</td>
      <td>3.41</td>
      <td>0.90</td>
      <td>190.56</td>
      <td>10127</td>
      <td>2970</td>
      <td>8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>Saudi Arabia</td>
      <td>3302000</td>
      <td>3.0</td>
      <td>1560.2</td>
      <td>2.35</td>
      <td>0.62</td>
      <td>131.34</td>
      <td>20110</td>
      <td>8557</td>
      <td>5</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>Brazil</td>
      <td>2984000</td>
      <td>3.0</td>
      <td>221.9</td>
      <td>5.36</td>
      <td>1.42</td>
      <td>299.27</td>
      <td>6797</td>
      <td>1268</td>
      <td>6</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>174</th>
      <td>175</td>
      <td>Central African Republic</td>
      <td>2800</td>
      <td>0.0</td>
      <td>9.5</td>
      <td>9.06</td>
      <td>2.39</td>
      <td>506.12</td>
      <td>477</td>
      <td>53</td>
      <td>6</td>
    </tr>
    <tr>
      <th>175</th>
      <td>176</td>
      <td>Dominica</td>
      <td>1301</td>
      <td>0.0</td>
      <td>279.7</td>
      <td>4.78</td>
      <td>1.26</td>
      <td>267.34</td>
      <td>7268</td>
      <td>1521</td>
      <td>5</td>
    </tr>
    <tr>
      <th>176</th>
      <td>177</td>
      <td>Belize</td>
      <td>4001</td>
      <td>0.0</td>
      <td>166.5</td>
      <td>6.68</td>
      <td>1.76</td>
      <td>373.09</td>
      <td>4436</td>
      <td>664</td>
      <td>4</td>
    </tr>
    <tr>
      <th>177</th>
      <td>178</td>
      <td>Niue</td>
      <td>51</td>
      <td>0.0</td>
      <td>484.4</td>
      <td>11.43</td>
      <td>3.02</td>
      <td>638.73</td>
      <td>15586</td>
      <td>1364</td>
      <td>3</td>
    </tr>
    <tr>
      <th>178</th>
      <td>179</td>
      <td>Saint Pierre &amp; Miquelon</td>
      <td>660</td>
      <td>0.0</td>
      <td>1705.1</td>
      <td>8.27</td>
      <td>2.19</td>
      <td>462.13</td>
      <td>34900</td>
      <td>4220</td>
      <td>2</td>
    </tr>
    <tr>
      <th>179</th>
      <td>180</td>
      <td>Montserrat</td>
      <td>400</td>
      <td>0.0</td>
      <td>1231.1</td>
      <td>4.57</td>
      <td>1.21</td>
      <td>255.07</td>
      <td>12589</td>
      <td>2755</td>
      <td>2</td>
    </tr>
    <tr>
      <th>180</th>
      <td>181</td>
      <td>Tonga</td>
      <td>899</td>
      <td>0.0</td>
      <td>136.3</td>
      <td>16.20</td>
      <td>4.28</td>
      <td>905.22</td>
      <td>4903</td>
      <td>303</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>181 rows × 11 columns</p>
      
        <p><strong>Hyp output variables:</strong> oil </p>
    
          <p>oil (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>S#</th>
      <th>Country</th>
      <th>Daily Oil Consumption (Barrels)</th>
      <th>World Share</th>
      <th>Yearly Gallons Per Capita</th>
      <th>Price Per Gallon (USD)</th>
      <th>Price Per Liter (USD)</th>
      <th>Price Per Liter (PKR)</th>
      <th>GDP Per Capita ( USD )</th>
      <th>Gallons GDP Per Capita Can Buy</th>
      <th>xTimes Yearly Gallons Per Capita Buy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>United States</td>
      <td>19687287</td>
      <td>20.0</td>
      <td>934.3</td>
      <td>5.19</td>
      <td>1.37</td>
      <td>289.97</td>
      <td>63414</td>
      <td>12218</td>
      <td>13</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>China</td>
      <td>12791553</td>
      <td>13.0</td>
      <td>138.7</td>
      <td>5.42</td>
      <td>1.43</td>
      <td>302.87</td>
      <td>10435</td>
      <td>1925</td>
      <td>14</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>India</td>
      <td>4443000</td>
      <td>5.0</td>
      <td>51.4</td>
      <td>5.05</td>
      <td>1.33</td>
      <td>281.93</td>
      <td>1901</td>
      <td>376</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Japan</td>
      <td>4012877</td>
      <td>4.0</td>
      <td>481.5</td>
      <td>4.69</td>
      <td>1.24</td>
      <td>262.05</td>
      <td>40193</td>
      <td>8570</td>
      <td>18</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Russia</td>
      <td>3631287</td>
      <td>4.0</td>
      <td>383.2</td>
      <td>3.41</td>
      <td>0.90</td>
      <td>190.56</td>
      <td>10127</td>
      <td>2970</td>
      <td>8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>Saudi Arabia</td>
      <td>3302000</td>
      <td>3.0</td>
      <td>1560.2</td>
      <td>2.35</td>
      <td>0.62</td>
      <td>131.34</td>
      <td>20110</td>
      <td>8557</td>
      <td>5</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>Brazil</td>
      <td>2984000</td>
      <td>3.0</td>
      <td>221.9</td>
      <td>5.36</td>
      <td>1.42</td>
      <td>299.27</td>
      <td>6797</td>
      <td>1268</td>
      <td>6</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>174</th>
      <td>175</td>
      <td>Central African Republic</td>
      <td>2800</td>
      <td>0.0</td>
      <td>9.5</td>
      <td>9.06</td>
      <td>2.39</td>
      <td>506.12</td>
      <td>477</td>
      <td>53</td>
      <td>6</td>
    </tr>
    <tr>
      <th>175</th>
      <td>176</td>
      <td>Dominica</td>
      <td>1301</td>
      <td>0.0</td>
      <td>279.7</td>
      <td>4.78</td>
      <td>1.26</td>
      <td>267.34</td>
      <td>7268</td>
      <td>1521</td>
      <td>5</td>
    </tr>
    <tr>
      <th>176</th>
      <td>177</td>
      <td>Belize</td>
      <td>4001</td>
      <td>0.0</td>
      <td>166.5</td>
      <td>6.68</td>
      <td>1.76</td>
      <td>373.09</td>
      <td>4436</td>
      <td>664</td>
      <td>4</td>
    </tr>
    <tr>
      <th>177</th>
      <td>178</td>
      <td>Niue</td>
      <td>51</td>
      <td>0.0</td>
      <td>484.4</td>
      <td>11.43</td>
      <td>3.02</td>
      <td>638.73</td>
      <td>15586</td>
      <td>1364</td>
      <td>3</td>
    </tr>
    <tr>
      <th>178</th>
      <td>179</td>
      <td>Saint Pierre &amp; Miquelon</td>
      <td>660</td>
      <td>0.0</td>
      <td>1705.1</td>
      <td>8.27</td>
      <td>2.19</td>
      <td>462.13</td>
      <td>34900</td>
      <td>4220</td>
      <td>2</td>
    </tr>
    <tr>
      <th>179</th>
      <td>180</td>
      <td>Montserrat</td>
      <td>400</td>
      <td>0.0</td>
      <td>1231.1</td>
      <td>4.57</td>
      <td>1.21</td>
      <td>255.07</td>
      <td>12589</td>
      <td>2755</td>
      <td>2</td>
    </tr>
    <tr>
      <th>180</th>
      <td>181</td>
      <td>Tonga</td>
      <td>899</td>
      <td>0.0</td>
      <td>136.3</td>
      <td>16.20</td>
      <td>4.28</td>
      <td>905.22</td>
      <td>4903</td>
      <td>303</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>181 rows × 11 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('oil', 'oil', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> petrolgas-prices-worldwide/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average price per gallon in countries having a global share of daily oil consumption of less than 3%?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>oil[oil['World Share'] < 3]['Price Per Gallon (USD)'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>oil[oil['World Share'] < 3]['Price Per Gallon (USD)'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = oil[oil['World Share'] < 3]['Price Per Gallon (USD)'].mean()
</code></pre>
        <p><span onclick="$('#var_output_fc94c8db').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_fc94c8db" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>5.724853801169591</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>5.724853801169591</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> petrolgas-prices-worldwide/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a column, 'population', representing each country's population.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>gallons_per_barrel = 42
daily_gallon_consumption = 42 * oil['Daily Oil Consumption (Barrels)']
yearly_gallon_consumption = daily_gallon_consumption * 365
oil['population'] = yearly_gallon_consumption / oil['Yearly Gallons Per Capita']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>gallons_per_barrel = 42
daily_gallon_consumption = 42 * oil['Daily Oil Consumption (Barrels)']
yearly_gallon_consumption = daily_gallon_consumption * 365
oil['population'] = yearly_gallon_consumption / oil['Yearly Gallons Per Capita']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>gallons_per_barrel = 42
daily_gallon_consumption = 42 * oil['Daily Oil Consumption (Barrels)']
yearly_gallon_consumption = daily_gallon_consumption * 365
__output__ = oil['population'] = yearly_gallon_consumption / oil[
    'Yearly Gallons Per Capita']
</code></pre>
        <p><span onclick="$('#var_output_6dc8e502').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6dc8e502" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      3.230291e+08
1      1.413803e+09
2      1.325120e+09
3      1.277620e+08
4      1.452704e+08
           ...     
176    3.683804e+05
177    1.614017e+03
178    5.933846e+03
179    4.980911e+03
180    1.011128e+05
Length: 181, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> oil, gallons_per_barrel, daily_gallon_consumption, yearly_gallon_consumption, __output__ </p>
    
          <p>oil (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>S#</th>
      <th>Country</th>
      <th>Daily Oil Consumption (Barrels)</th>
      <th>World Share</th>
      <th>Yearly Gallons Per Capita</th>
      <th>Price Per Gallon (USD)</th>
      <th>Price Per Liter (USD)</th>
      <th>Price Per Liter (PKR)</th>
      <th>GDP Per Capita ( USD )</th>
      <th>Gallons GDP Per Capita Can Buy</th>
      <th>xTimes Yearly Gallons Per Capita Buy</th>
      <th>population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>United States</td>
      <td>19687287</td>
      <td>20.0</td>
      <td>934.3</td>
      <td>5.19</td>
      <td>1.37</td>
      <td>289.97</td>
      <td>63414</td>
      <td>12218</td>
      <td>13</td>
      <td>3.230291e+08</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>China</td>
      <td>12791553</td>
      <td>13.0</td>
      <td>138.7</td>
      <td>5.42</td>
      <td>1.43</td>
      <td>302.87</td>
      <td>10435</td>
      <td>1925</td>
      <td>14</td>
      <td>1.413803e+09</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>India</td>
      <td>4443000</td>
      <td>5.0</td>
      <td>51.4</td>
      <td>5.05</td>
      <td>1.33</td>
      <td>281.93</td>
      <td>1901</td>
      <td>376</td>
      <td>7</td>
      <td>1.325120e+09</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Japan</td>
      <td>4012877</td>
      <td>4.0</td>
      <td>481.5</td>
      <td>4.69</td>
      <td>1.24</td>
      <td>262.05</td>
      <td>40193</td>
      <td>8570</td>
      <td>18</td>
      <td>1.277620e+08</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Russia</td>
      <td>3631287</td>
      <td>4.0</td>
      <td>383.2</td>
      <td>3.41</td>
      <td>0.90</td>
      <td>190.56</td>
      <td>10127</td>
      <td>2970</td>
      <td>8</td>
      <td>1.452704e+08</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>Saudi Arabia</td>
      <td>3302000</td>
      <td>3.0</td>
      <td>1560.2</td>
      <td>2.35</td>
      <td>0.62</td>
      <td>131.34</td>
      <td>20110</td>
      <td>8557</td>
      <td>5</td>
      <td>3.244434e+07</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>Brazil</td>
      <td>2984000</td>
      <td>3.0</td>
      <td>221.9</td>
      <td>5.36</td>
      <td>1.42</td>
      <td>299.27</td>
      <td>6797</td>
      <td>1268</td>
      <td>6</td>
      <td>2.061502e+08</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>174</th>
      <td>175</td>
      <td>Central African Republic</td>
      <td>2800</td>
      <td>0.0</td>
      <td>9.5</td>
      <td>9.06</td>
      <td>2.39</td>
      <td>506.12</td>
      <td>477</td>
      <td>53</td>
      <td>6</td>
      <td>4.518316e+06</td>
    </tr>
    <tr>
      <th>175</th>
      <td>176</td>
      <td>Dominica</td>
      <td>1301</td>
      <td>0.0</td>
      <td>279.7</td>
      <td>4.78</td>
      <td>1.26</td>
      <td>267.34</td>
      <td>7268</td>
      <td>1521</td>
      <td>5</td>
      <td>7.130615e+04</td>
    </tr>
    <tr>
      <th>176</th>
      <td>177</td>
      <td>Belize</td>
      <td>4001</td>
      <td>0.0</td>
      <td>166.5</td>
      <td>6.68</td>
      <td>1.76</td>
      <td>373.09</td>
      <td>4436</td>
      <td>664</td>
      <td>4</td>
      <td>3.683804e+05</td>
    </tr>
    <tr>
      <th>177</th>
      <td>178</td>
      <td>Niue</td>
      <td>51</td>
      <td>0.0</td>
      <td>484.4</td>
      <td>11.43</td>
      <td>3.02</td>
      <td>638.73</td>
      <td>15586</td>
      <td>1364</td>
      <td>3</td>
      <td>1.614017e+03</td>
    </tr>
    <tr>
      <th>178</th>
      <td>179</td>
      <td>Saint Pierre &amp; Miquelon</td>
      <td>660</td>
      <td>0.0</td>
      <td>1705.1</td>
      <td>8.27</td>
      <td>2.19</td>
      <td>462.13</td>
      <td>34900</td>
      <td>4220</td>
      <td>2</td>
      <td>5.933846e+03</td>
    </tr>
    <tr>
      <th>179</th>
      <td>180</td>
      <td>Montserrat</td>
      <td>400</td>
      <td>0.0</td>
      <td>1231.1</td>
      <td>4.57</td>
      <td>1.21</td>
      <td>255.07</td>
      <td>12589</td>
      <td>2755</td>
      <td>2</td>
      <td>4.980911e+03</td>
    </tr>
    <tr>
      <th>180</th>
      <td>181</td>
      <td>Tonga</td>
      <td>899</td>
      <td>0.0</td>
      <td>136.3</td>
      <td>16.20</td>
      <td>4.28</td>
      <td>905.22</td>
      <td>4903</td>
      <td>303</td>
      <td>2</td>
      <td>1.011128e+05</td>
    </tr>
  </tbody>
</table>
<p>181 rows × 12 columns</p>
      
          <p>gallons_per_barrel (int):</p>
          <pre><code>42</code></pre>
      
          <p>daily_gallon_consumption (Series):</p>
          <pre><code>0      826866054
1      537245226
2      186606000
3      168540834
4      152514054
         ...    
176       168042
177         2142
178        27720
179        16800
180        37758
Name: Daily Oil Consumption (Barrels), Length: 181, dtype: int64</code></pre>
      
          <p>yearly_gallon_consumption (Series):</p>
          <pre><code>0      301806109710
1      196094507490
2       68111190000
3       61517404410
4       55667629710
           ...     
176        61335330
177          781830
178        10117800
179         6132000
180        13781670
Name: Daily Oil Consumption (Barrels), Length: 181, dtype: int64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>0      3.230291e+08
1      1.413803e+09
2      1.325120e+09
3      1.277620e+08
4      1.452704e+08
           ...     
176    3.683804e+05
177    1.614017e+03
178    5.933846e+03
179    4.980911e+03
180    1.011128e+05
Length: 181, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.2, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> petrolgas-prices-worldwide/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a column, 'GDP', representing the GDP in USD for each country?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>oil['GDP'] = oil['GDP Per Capita ( USD )'] * oil['population']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>oil['GDP'] = oil['GDP Per Capita ( USD )'] * oil['population']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = oil['GDP'] = oil['GDP Per Capita ( USD )'] * oil['population']
</code></pre>
        <p><span onclick="$('#var_output_cb659486').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_cb659486" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      2.048457e+13
1      1.475304e+13
2      2.519054e+12
3      5.135138e+12
4      1.471154e+12
           ...     
176    1.634135e+09
177    2.515607e+07
178    2.070912e+08
179    6.270469e+07
180    4.957559e+08
Length: 181, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> oil, __output__ </p>
    
          <p>oil (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>S#</th>
      <th>Country</th>
      <th>Daily Oil Consumption (Barrels)</th>
      <th>World Share</th>
      <th>Yearly Gallons Per Capita</th>
      <th>Price Per Gallon (USD)</th>
      <th>Price Per Liter (USD)</th>
      <th>Price Per Liter (PKR)</th>
      <th>GDP Per Capita ( USD )</th>
      <th>Gallons GDP Per Capita Can Buy</th>
      <th>xTimes Yearly Gallons Per Capita Buy</th>
      <th>population</th>
      <th>GDP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>United States</td>
      <td>19687287</td>
      <td>20.0</td>
      <td>934.3</td>
      <td>5.19</td>
      <td>1.37</td>
      <td>289.97</td>
      <td>63414</td>
      <td>12218</td>
      <td>13</td>
      <td>3.230291e+08</td>
      <td>2.048457e+13</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>China</td>
      <td>12791553</td>
      <td>13.0</td>
      <td>138.7</td>
      <td>5.42</td>
      <td>1.43</td>
      <td>302.87</td>
      <td>10435</td>
      <td>1925</td>
      <td>14</td>
      <td>1.413803e+09</td>
      <td>1.475304e+13</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>India</td>
      <td>4443000</td>
      <td>5.0</td>
      <td>51.4</td>
      <td>5.05</td>
      <td>1.33</td>
      <td>281.93</td>
      <td>1901</td>
      <td>376</td>
      <td>7</td>
      <td>1.325120e+09</td>
      <td>2.519054e+12</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Japan</td>
      <td>4012877</td>
      <td>4.0</td>
      <td>481.5</td>
      <td>4.69</td>
      <td>1.24</td>
      <td>262.05</td>
      <td>40193</td>
      <td>8570</td>
      <td>18</td>
      <td>1.277620e+08</td>
      <td>5.135138e+12</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Russia</td>
      <td>3631287</td>
      <td>4.0</td>
      <td>383.2</td>
      <td>3.41</td>
      <td>0.90</td>
      <td>190.56</td>
      <td>10127</td>
      <td>2970</td>
      <td>8</td>
      <td>1.452704e+08</td>
      <td>1.471154e+12</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>Saudi Arabia</td>
      <td>3302000</td>
      <td>3.0</td>
      <td>1560.2</td>
      <td>2.35</td>
      <td>0.62</td>
      <td>131.34</td>
      <td>20110</td>
      <td>8557</td>
      <td>5</td>
      <td>3.244434e+07</td>
      <td>6.524557e+11</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>Brazil</td>
      <td>2984000</td>
      <td>3.0</td>
      <td>221.9</td>
      <td>5.36</td>
      <td>1.42</td>
      <td>299.27</td>
      <td>6797</td>
      <td>1268</td>
      <td>6</td>
      <td>2.061502e+08</td>
      <td>1.401203e+12</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>174</th>
      <td>175</td>
      <td>Central African Republic</td>
      <td>2800</td>
      <td>0.0</td>
      <td>9.5</td>
      <td>9.06</td>
      <td>2.39</td>
      <td>506.12</td>
      <td>477</td>
      <td>53</td>
      <td>6</td>
      <td>4.518316e+06</td>
      <td>2.155237e+09</td>
    </tr>
    <tr>
      <th>175</th>
      <td>176</td>
      <td>Dominica</td>
      <td>1301</td>
      <td>0.0</td>
      <td>279.7</td>
      <td>4.78</td>
      <td>1.26</td>
      <td>267.34</td>
      <td>7268</td>
      <td>1521</td>
      <td>5</td>
      <td>7.130615e+04</td>
      <td>5.182531e+08</td>
    </tr>
    <tr>
      <th>176</th>
      <td>177</td>
      <td>Belize</td>
      <td>4001</td>
      <td>0.0</td>
      <td>166.5</td>
      <td>6.68</td>
      <td>1.76</td>
      <td>373.09</td>
      <td>4436</td>
      <td>664</td>
      <td>4</td>
      <td>3.683804e+05</td>
      <td>1.634135e+09</td>
    </tr>
    <tr>
      <th>177</th>
      <td>178</td>
      <td>Niue</td>
      <td>51</td>
      <td>0.0</td>
      <td>484.4</td>
      <td>11.43</td>
      <td>3.02</td>
      <td>638.73</td>
      <td>15586</td>
      <td>1364</td>
      <td>3</td>
      <td>1.614017e+03</td>
      <td>2.515607e+07</td>
    </tr>
    <tr>
      <th>178</th>
      <td>179</td>
      <td>Saint Pierre &amp; Miquelon</td>
      <td>660</td>
      <td>0.0</td>
      <td>1705.1</td>
      <td>8.27</td>
      <td>2.19</td>
      <td>462.13</td>
      <td>34900</td>
      <td>4220</td>
      <td>2</td>
      <td>5.933846e+03</td>
      <td>2.070912e+08</td>
    </tr>
    <tr>
      <th>179</th>
      <td>180</td>
      <td>Montserrat</td>
      <td>400</td>
      <td>0.0</td>
      <td>1231.1</td>
      <td>4.57</td>
      <td>1.21</td>
      <td>255.07</td>
      <td>12589</td>
      <td>2755</td>
      <td>2</td>
      <td>4.980911e+03</td>
      <td>6.270469e+07</td>
    </tr>
    <tr>
      <th>180</th>
      <td>181</td>
      <td>Tonga</td>
      <td>899</td>
      <td>0.0</td>
      <td>136.3</td>
      <td>16.20</td>
      <td>4.28</td>
      <td>905.22</td>
      <td>4903</td>
      <td>303</td>
      <td>2</td>
      <td>1.011128e+05</td>
      <td>4.957559e+08</td>
    </tr>
  </tbody>
</table>
<p>181 rows × 13 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      2.048457e+13
1      1.475304e+13
2      2.519054e+12
3      5.135138e+12
4      1.471154e+12
           ...     
176    1.634135e+09
177    2.515607e+07
178    2.070912e+08
179    6.270469e+07
180    4.957559e+08
Length: 181, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> petrolgas-prices-worldwide/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the name and population of the country having the lowest oil price per gallon?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>oil[oil['Price Per Gallon (USD)']==oil['Price Per Gallon (USD)'].min()][['Country','population', 'Price Per Gallon (USD)']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>oil[oil['Price Per Gallon (USD)']==oil['Price Per Gallon (USD)'].min()][['Country','population', 'Price Per Gallon (USD)']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = oil[oil['Price Per Gallon (USD)'] == oil[
    'Price Per Gallon (USD)'].min()][['Country', 'population',
    'Price Per Gallon (USD)']]
</code></pre>
        <p><span onclick="$('#var_output_070bf23c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_070bf23c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>population</th>
      <th>Price Per Gallon (USD)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>30</th>
      <td>Venezuela</td>
      <td>2.985132e+07</td>
      <td>0.08</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>population</th>
      <th>Price Per Gallon (USD)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>30</th>
      <td>Venezuela</td>
      <td>2.985132e+07</td>
      <td>0.08</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> petrolgas-prices-worldwide/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which country has the highest population? Calculate its daily oil consumption as a percentage of global oil consumption? Return a dataframe with the country's name, daily oil consumption and percent of global consumption.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>country_high_pop = oil[oil['population']==oil['population'].max()][['Country','Daily Oil Consumption (Barrels)']]
country_high_pop['percent_global_consumption'] = country_high_pop['Daily Oil Consumption (Barrels)'] / oil['Daily Oil Consumption (Barrels)'].sum() *100
country_high_pop</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>country_high_pop = oil[oil['population']==oil['population'].max()][['Country','Daily Oil Consumption (Barrels)']]
country_high_pop['percent_global_consumption'] = country_high_pop['Daily Oil Consumption (Barrels)'] / oil['Daily Oil Consumption (Barrels)'].sum() *100
country_high_pop</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>country_high_pop = oil[oil['population'] == oil['population'].max()][[
    'Country', 'Daily Oil Consumption (Barrels)']]
country_high_pop['percent_global_consumption'] = country_high_pop[
    'Daily Oil Consumption (Barrels)'] / oil['Daily Oil Consumption (Barrels)'
    ].sum() * 100
__output__ = country_high_pop
</code></pre>
        <p><span onclick="$('#var_output_304c3d76').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_304c3d76" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Daily Oil Consumption (Barrels)</th>
      <th>percent_global_consumption</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>China</td>
      <td>12791553</td>
      <td>13.244965</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> country_high_pop, __output__ </p>
    
          <p>country_high_pop (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Daily Oil Consumption (Barrels)</th>
      <th>percent_global_consumption</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>China</td>
      <td>12791553</td>
      <td>13.244965</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Daily Oil Consumption (Barrels)</th>
      <th>percent_global_consumption</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>China</td>
      <td>12791553</td>
      <td>13.244965</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> petrolgas-prices-worldwide/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the yearly per capita oil consumtion of the United States as a percentage of the global yearly per capita oil consumption?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>oil[(oil['Country']=='United States')]['Yearly Gallons Per Capita'] / oil['Yearly Gallons Per Capita'].sum() *100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>oil[(oil['Country']=='United States')]['Yearly Gallons Per Capita'] / oil['Yearly Gallons Per Capita'].sum() *100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = oil[oil['Country'] == 'United States']['Yearly Gallons Per Capita'
    ] / oil['Yearly Gallons Per Capita'].sum() * 100
</code></pre>
        <p><span onclick="$('#var_output_986b020c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_986b020c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0    1.554752
Name: Yearly Gallons Per Capita, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0    1.554752
Name: Yearly Gallons Per Capita, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> petrolgas-prices-worldwide/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the GDP of the country with the highest share of global daily consumption, as a percentage of global GDP?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>country_high_consumption = oil.loc[oil['World Share'].idxmax()][['Country','GDP']]
country_high_consumption['percent_global_gdp'] = country_high_consumption['GDP'] / oil['GDP'].sum() *100
country_high_consumption</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>country_high_consumption = oil.loc[oil['World Share'].idxmax()][['Country','GDP']]
country_high_consumption['percent_global_gdp'] = country_high_consumption['GDP'] / oil['GDP'].sum() *100
country_high_consumption</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>country_high_consumption = oil.loc[oil['World Share'].idxmax()][['Country',
    'GDP']]
country_high_consumption['percent_global_gdp'] = country_high_consumption['GDP'
    ] / oil['GDP'].sum() * 100
__output__ = country_high_consumption
</code></pre>
        <p><span onclick="$('#var_output_37832e12').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_37832e12" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Country                       United States
GDP                   20484568812105.257812
percent_global_gdp                24.671507
Name: 0, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> country_high_consumption, __output__ </p>
    
          <p>country_high_consumption (Series):</p>
          <pre><code>Country                       United States
GDP                   20484568812105.257812
percent_global_gdp                24.671507
Name: 0, dtype: object</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Country                       United States
GDP                   20484568812105.257812
percent_global_gdp                24.671507
Name: 0, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> petrolgas-prices-worldwide/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the names and oil prices per liter of the top five countries having the highest GDP per capita?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>oil.sort_values(by=['GDP Per Capita ( USD )'], ascending=False)[['Country','Price Per Liter (USD)']].head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>oil.sort_values(by=['GDP Per Capita ( USD )'], ascending=False)[['Country','Price Per Liter (USD)']].head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = oil.sort_values(by=['GDP Per Capita ( USD )'], ascending=False)[[
    'Country', 'Price Per Liter (USD)']].head(5)
</code></pre>
        <p><span onclick="$('#var_output_38b81d67').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_38b81d67" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Price Per Liter (USD)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>92</th>
      <td>Luxembourg</td>
      <td>2.09</td>
    </tr>
    <tr>
      <th>50</th>
      <td>Switzerland</td>
      <td>2.19</td>
    </tr>
    <tr>
      <th>126</th>
      <td>Macao</td>
      <td>1.43</td>
    </tr>
    <tr>
      <th>52</th>
      <td>Ireland</td>
      <td>2.07</td>
    </tr>
    <tr>
      <th>166</th>
      <td>Cayman Islands</td>
      <td>1.66</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Price Per Liter (USD)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>92</th>
      <td>Luxembourg</td>
      <td>2.09</td>
    </tr>
    <tr>
      <th>50</th>
      <td>Switzerland</td>
      <td>2.19</td>
    </tr>
    <tr>
      <th>126</th>
      <td>Macao</td>
      <td>1.43</td>
    </tr>
    <tr>
      <th>52</th>
      <td>Ireland</td>
      <td>2.07</td>
    </tr>
    <tr>
      <th>166</th>
      <td>Cayman Islands</td>
      <td>1.66</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> petrolgas-prices-worldwide/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the name, population and percent of global population of the country having the lowest GDP per capita?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>lowest_GDP = oil.loc[oil['GDP Per Capita ( USD )'].idxmin(), ['Country','population']]
lowest_GDP['percent_global_population'] = lowest_GDP['population'] / oil['population'].sum()
lowest_GDP</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>lowest_GDP = oil.loc[oil['GDP Per Capita ( USD )'].idxmin(), ['Country','population']]
lowest_GDP['percent_global_population'] = lowest_GDP['population'] / oil['population'].sum()
lowest_GDP</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>lowest_GDP = oil.loc[oil['GDP Per Capita ( USD )'].idxmin(), ['Country',
    'population']]
lowest_GDP['percent_global_population'] = lowest_GDP['population'] / oil[
    'population'].sum()
__output__ = lowest_GDP
</code></pre>
        <p><span onclick="$('#var_output_c5520a11').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c5520a11" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Country                              Burundi
population                   10445304.545455
percent_global_population            0.00141
Name: 164, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> lowest_GDP, __output__ </p>
    
          <p>lowest_GDP (Series):</p>
          <pre><code>Country                              Burundi
population                   10445304.545455
percent_global_population            0.00141
Name: 164, dtype: object</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Country                              Burundi
population                   10445304.545455
percent_global_population            0.00141
Name: 164, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> petrolgas-prices-worldwide/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Is the oil price per gallon cheaper or more expensive in the China than in Saudi Arabia? Return an output with the word 'Expensive', 'Cheaper' or 'Equal' if the price is expensive, cheaper or equal, respectively, followed by the price difference.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>price_US = oil[oil['Country']=='China']['Price Per Gallon (USD)'].values
price_SA = oil[oil['Country']=='Saudi Arabia']['Price Per Gallon (USD)'].values
difference = price_US - price_SA

if difference > 0:
  output='Expensive: '+str(abs(difference))
elif difference < 0:
  output='Cheaper: '+str(abs(difference))
else:
  output='Equal: '+str(abs(difference))

output</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>price_US = oil[oil['Country']=='China']['Price Per Gallon (USD)'].values
price_SA = oil[oil['Country']=='Saudi Arabia']['Price Per Gallon (USD)'].values
difference = price_US - price_SA

if difference > 0:
  output='Expensive: '+str(abs(difference))
elif difference < 0:
  output='Cheaper: '+str(abs(difference))
else:
  output='Equal: '+str(abs(difference))

output</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>price_US = oil[oil['Country'] == 'China']['Price Per Gallon (USD)'].values
price_SA = oil[oil['Country'] == 'Saudi Arabia']['Price Per Gallon (USD)'
    ].values
difference = price_US - price_SA
if difference > 0:
    output = 'Expensive: ' + str(abs(difference))
elif difference < 0:
    output = 'Cheaper: ' + str(abs(difference))
else:
    output = 'Equal: ' + str(abs(difference))
__output__ = output
</code></pre>
        <p><span onclick="$('#var_output_2766f913').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2766f913" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Expensive: [3.07]</code></pre>
      
        <p><strong>Hyp output variables:</strong> price_US, price_SA, difference, output, __output__ </p>
    
          <p>price_US (ndarray):</p>
          <pre><code>[5.42]</code></pre>
      
          <p>price_SA (ndarray):</p>
          <pre><code>[2.35]</code></pre>
      
          <p>difference (ndarray):</p>
          <pre><code>[3.07]</code></pre>
      
          <p>output (str):</p>
          <pre><code>Expensive: [3.07]</code></pre>
      
          <p>__output__ (str):</p>
          <pre><code>Expensive: [3.07]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.2, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> advertisement-click-on-ad/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the Ad click rate in percentage accross each gender?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>breakdown = ads.groupby('Male').agg({'Clicked on Ad':['sum','size']})
breakdown.columns = breakdown.columns.get_level_values(1)
breakdown['sum'] / breakdown['size'] * 100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>breakdown = ads.groupby('Male').agg({'Clicked on Ad':['sum','size']})
breakdown.columns = breakdown.columns.get_level_values(1)
breakdown['sum'] / breakdown['size'] * 100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>breakdown = ads.groupby('Male').agg({'Clicked on Ad': ['sum', 'size']})
breakdown.columns = breakdown.columns.get_level_values(1)
__output__ = breakdown['sum'] / breakdown['size'] * 100
</code></pre>
        <p><span onclick="$('#var_output_b7493779').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b7493779" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Male
0    51.830443
1    48.024948
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> breakdown, __output__ </p>
    
          <p>breakdown (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum</th>
      <th>size</th>
    </tr>
    <tr>
      <th>Male</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>269</td>
      <td>519</td>
    </tr>
    <tr>
      <th>1</th>
      <td>231</td>
      <td>481</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Male
0    51.830443
1    48.024948
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> advertisement-click-on-ad/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top ten countries with the highest Ad click rate?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>ads[ads['Clicked on Ad']==1].groupby('Country')['Clicked on Ad'].sum().sort_values(ascending=False).head(10)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>ads[ads['Clicked on Ad']==1].groupby('Country')['Clicked on Ad'].sum().sort_values(ascending=False).head(10)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = ads[ads['Clicked on Ad'] == 1].groupby('Country')['Clicked on Ad'
    ].sum().sort_values(ascending=False).head(10)
</code></pre>
        <p><span onclick="$('#var_output_78af9f7f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_78af9f7f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Country
Turkey           7
Ethiopia         7
Australia        7
South Africa     6
Liberia          6
Liechtenstein    6
Peru             5
Mayotte          5
Senegal          5
Hungary          5
Name: Clicked on Ad, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Country
Turkey           7
Ethiopia         7
Australia        7
South Africa     6
Liberia          6
Liechtenstein    6
Peru             5
Mayotte          5
Senegal          5
Hungary          5
Name: Clicked on Ad, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> advertisement-click-on-ad/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average daily percent of time spent on the site for customers who clicked and did not click on the Ads?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>ads['percent_time_on_site'] = ads['Daily Time Spent on Site'] / ads['Daily Internet Usage']
ads.groupby('Clicked on Ad').percent_time_on_site.mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>ads['percent_time_on_site'] = ads['Daily Time Spent on Site'] / ads['Daily Internet Usage']
ads.groupby('Clicked on Ad').percent_time_on_site.mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>ads['percent_time_on_site'] = ads['Daily Time Spent on Site'] / ads[
    'Daily Internet Usage']
__output__ = ads.groupby('Clicked on Ad').percent_time_on_site.mean()
</code></pre>
        <p><span onclick="$('#var_output_5851e7c6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5851e7c6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Clicked on Ad
0    0.363715
1    0.382782
Name: percent_time_on_site, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> ads, __output__ </p>
    
          <p>ads (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Daily Time Spent on Site</th>
      <th>Age</th>
      <th>Area Income</th>
      <th>Daily Internet Usage</th>
      <th>Ad Topic Line</th>
      <th>City</th>
      <th>Male</th>
      <th>Country</th>
      <th>Timestamp</th>
      <th>Clicked on Ad</th>
      <th>percent_time_on_site</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>68.95</td>
      <td>35</td>
      <td>61833.90</td>
      <td>256.09</td>
      <td>Cloned 5thgeneration orchestration</td>
      <td>Wrightburgh</td>
      <td>0</td>
      <td>Tunisia</td>
      <td>2016-03-27 00:53:11</td>
      <td>0</td>
      <td>0.269241</td>
    </tr>
    <tr>
      <th>1</th>
      <td>80.23</td>
      <td>31</td>
      <td>68441.85</td>
      <td>193.77</td>
      <td>Monitored national standardization</td>
      <td>West Jodi</td>
      <td>1</td>
      <td>Nauru</td>
      <td>2016-04-04 01:39:02</td>
      <td>0</td>
      <td>0.414048</td>
    </tr>
    <tr>
      <th>2</th>
      <td>69.47</td>
      <td>26</td>
      <td>59785.94</td>
      <td>236.50</td>
      <td>Organic bottom-line service-desk</td>
      <td>Davidton</td>
      <td>0</td>
      <td>San Marino</td>
      <td>2016-03-13 20:35:42</td>
      <td>0</td>
      <td>0.293742</td>
    </tr>
    <tr>
      <th>3</th>
      <td>74.15</td>
      <td>29</td>
      <td>54806.18</td>
      <td>245.89</td>
      <td>Triple-buffered reciprocal time-frame</td>
      <td>West Terrifurt</td>
      <td>1</td>
      <td>Italy</td>
      <td>2016-01-10 02:31:19</td>
      <td>0</td>
      <td>0.301558</td>
    </tr>
    <tr>
      <th>4</th>
      <td>68.37</td>
      <td>35</td>
      <td>73889.99</td>
      <td>225.58</td>
      <td>Robust logistical utilization</td>
      <td>South Manuel</td>
      <td>0</td>
      <td>Iceland</td>
      <td>2016-06-03 03:36:18</td>
      <td>0</td>
      <td>0.303085</td>
    </tr>
    <tr>
      <th>5</th>
      <td>59.99</td>
      <td>23</td>
      <td>59761.56</td>
      <td>226.74</td>
      <td>Sharable client-driven software</td>
      <td>Jamieberg</td>
      <td>1</td>
      <td>Norway</td>
      <td>2016-05-19 14:30:17</td>
      <td>0</td>
      <td>0.264576</td>
    </tr>
    <tr>
      <th>6</th>
      <td>88.91</td>
      <td>33</td>
      <td>53852.85</td>
      <td>208.36</td>
      <td>Enhanced dedicated support</td>
      <td>Brandonstad</td>
      <td>0</td>
      <td>Myanmar</td>
      <td>2016-01-28 20:59:32</td>
      <td>0</td>
      <td>0.426713</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>993</th>
      <td>64.20</td>
      <td>27</td>
      <td>66200.96</td>
      <td>227.63</td>
      <td>Phased zero tolerance extranet</td>
      <td>Edwardsmouth</td>
      <td>1</td>
      <td>Isle of Man</td>
      <td>2016-02-11 23:45:01</td>
      <td>0</td>
      <td>0.282037</td>
    </tr>
    <tr>
      <th>994</th>
      <td>43.70</td>
      <td>28</td>
      <td>63126.96</td>
      <td>173.01</td>
      <td>Front-line bifurcated ability</td>
      <td>Nicholasland</td>
      <td>0</td>
      <td>Mayotte</td>
      <td>2016-04-04 03:57:48</td>
      <td>1</td>
      <td>0.252587</td>
    </tr>
    <tr>
      <th>995</th>
      <td>72.97</td>
      <td>30</td>
      <td>71384.57</td>
      <td>208.58</td>
      <td>Fundamental modular algorithm</td>
      <td>Duffystad</td>
      <td>1</td>
      <td>Lebanon</td>
      <td>2016-02-11 21:49:00</td>
      <td>1</td>
      <td>0.349842</td>
    </tr>
    <tr>
      <th>996</th>
      <td>51.30</td>
      <td>45</td>
      <td>67782.17</td>
      <td>134.42</td>
      <td>Grass-roots cohesive monitoring</td>
      <td>New Darlene</td>
      <td>1</td>
      <td>Bosnia and Herzegovina</td>
      <td>2016-04-22 02:07:01</td>
      <td>1</td>
      <td>0.381640</td>
    </tr>
    <tr>
      <th>997</th>
      <td>51.63</td>
      <td>51</td>
      <td>42415.72</td>
      <td>120.37</td>
      <td>Expanded intangible solution</td>
      <td>South Jessica</td>
      <td>1</td>
      <td>Mongolia</td>
      <td>2016-02-01 17:24:57</td>
      <td>1</td>
      <td>0.428927</td>
    </tr>
    <tr>
      <th>998</th>
      <td>55.55</td>
      <td>19</td>
      <td>41920.79</td>
      <td>187.95</td>
      <td>Proactive bandwidth-monitored policy</td>
      <td>West Steven</td>
      <td>0</td>
      <td>Guatemala</td>
      <td>2016-03-24 02:35:54</td>
      <td>0</td>
      <td>0.295557</td>
    </tr>
    <tr>
      <th>999</th>
      <td>45.01</td>
      <td>26</td>
      <td>29875.80</td>
      <td>178.35</td>
      <td>Virtual 5thgeneration emulation</td>
      <td>Ronniemouth</td>
      <td>0</td>
      <td>Brazil</td>
      <td>2016-06-03 21:43:21</td>
      <td>1</td>
      <td>0.252369</td>
    </tr>
  </tbody>
</table>
<p>1000 rows × 11 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Clicked on Ad
0    0.363715
1    0.382782
Name: percent_time_on_site, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> advertisement-click-on-ad/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average Ad click rate for each hour?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>hourly_breakdown = ads.groupby(ads.Timestamp.dt.hour).agg({'Clicked on Ad':['sum','size']})
hourly_breakdown.columns = hourly_breakdown.columns.get_level_values(1)

hourly_breakdown['sum'] / hourly_breakdown['size']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>hourly_breakdown = ads.groupby(ads.Timestamp.dt.hour).agg({'Clicked on Ad':['sum','size']})
hourly_breakdown.columns = hourly_breakdown.columns.get_level_values(1)

hourly_breakdown['sum'] / hourly_breakdown['size']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>hourly_breakdown = ads.groupby(ads.Timestamp.dt.hour).agg({'Clicked on Ad':
    ['sum', 'size']})
hourly_breakdown.columns = hourly_breakdown.columns.get_level_values(1)
__output__ = hourly_breakdown['sum'] / hourly_breakdown['size']
</code></pre>
        <p><span onclick="$('#var_output_4d7ba480').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4d7ba480" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Timestamp
0     0.577778
1     0.500000
2     0.472222
3     0.547619
4     0.500000
        ...   
19    0.487179
20    0.480000
21    0.395833
22    0.441860
23    0.409091
Length: 24, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> hourly_breakdown, __output__ </p>
    
          <p>hourly_breakdown (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum</th>
      <th>size</th>
    </tr>
    <tr>
      <th>Timestamp</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>26</td>
      <td>45</td>
    </tr>
    <tr>
      <th>1</th>
      <td>16</td>
      <td>32</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17</td>
      <td>36</td>
    </tr>
    <tr>
      <th>3</th>
      <td>23</td>
      <td>42</td>
    </tr>
    <tr>
      <th>4</th>
      <td>21</td>
      <td>42</td>
    </tr>
    <tr>
      <th>5</th>
      <td>21</td>
      <td>44</td>
    </tr>
    <tr>
      <th>6</th>
      <td>23</td>
      <td>39</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>17</th>
      <td>23</td>
      <td>41</td>
    </tr>
    <tr>
      <th>18</th>
      <td>25</td>
      <td>41</td>
    </tr>
    <tr>
      <th>19</th>
      <td>19</td>
      <td>39</td>
    </tr>
    <tr>
      <th>20</th>
      <td>24</td>
      <td>50</td>
    </tr>
    <tr>
      <th>21</th>
      <td>19</td>
      <td>48</td>
    </tr>
    <tr>
      <th>22</th>
      <td>19</td>
      <td>43</td>
    </tr>
    <tr>
      <th>23</th>
      <td>18</td>
      <td>44</td>
    </tr>
  </tbody>
</table>
<p>24 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Timestamp
0     0.577778
1     0.500000
2     0.472222
3     0.547619
4     0.500000
        ...   
19    0.487179
20    0.480000
21    0.395833
22    0.441860
23    0.409091
Length: 24, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> advertisement-click-on-ad/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average customers' income per Country for males and females? Return a dataframe with the countries as the index and genders as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>ads.groupby(['Country','Male'],as_index=False)['Area Income'].mean().pivot(index='Country', columns='Male')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>ads.groupby(['Country','Male'],as_index=False)['Area Income'].mean().pivot(index='Country', columns='Male')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = ads.groupby(['Country', 'Male'], as_index=False)['Area Income'
    ].mean().pivot(index='Country', columns='Male')
</code></pre>
        <p><span onclick="$('#var_output_5a20c7f2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5a20c7f2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">Area Income</th>
    </tr>
    <tr>
      <th>Male</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Afghanistan</th>
      <td>45432.303333</td>
      <td>59760.550000</td>
    </tr>
    <tr>
      <th>Albania</th>
      <td>54082.427500</td>
      <td>54808.230000</td>
    </tr>
    <tr>
      <th>Algeria</th>
      <td>47718.778000</td>
      <td>65280.160000</td>
    </tr>
    <tr>
      <th>American Samoa</th>
      <td>50602.455000</td>
      <td>53700.570000</td>
    </tr>
    <tr>
      <th>Andorra</th>
      <td>NaN</td>
      <td>47165.230000</td>
    </tr>
    <tr>
      <th>Angola</th>
      <td>57756.890000</td>
      <td>57395.656667</td>
    </tr>
    <tr>
      <th>Anguilla</th>
      <td>29398.610000</td>
      <td>61876.902000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Venezuela</th>
      <td>65841.282000</td>
      <td>58996.190000</td>
    </tr>
    <tr>
      <th>Vietnam</th>
      <td>48574.583333</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Wallis and Futuna</th>
      <td>54030.155000</td>
      <td>52600.865000</td>
    </tr>
    <tr>
      <th>Western Sahara</th>
      <td>49408.062500</td>
      <td>57776.280000</td>
    </tr>
    <tr>
      <th>Yemen</th>
      <td>54768.810000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Zambia</th>
      <td>67050.160000</td>
      <td>48632.923333</td>
    </tr>
    <tr>
      <th>Zimbabwe</th>
      <td>49620.155000</td>
      <td>53674.025000</td>
    </tr>
  </tbody>
</table>
<p>237 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">Area Income</th>
    </tr>
    <tr>
      <th>Male</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Afghanistan</th>
      <td>45432.303333</td>
      <td>59760.550000</td>
    </tr>
    <tr>
      <th>Albania</th>
      <td>54082.427500</td>
      <td>54808.230000</td>
    </tr>
    <tr>
      <th>Algeria</th>
      <td>47718.778000</td>
      <td>65280.160000</td>
    </tr>
    <tr>
      <th>American Samoa</th>
      <td>50602.455000</td>
      <td>53700.570000</td>
    </tr>
    <tr>
      <th>Andorra</th>
      <td>NaN</td>
      <td>47165.230000</td>
    </tr>
    <tr>
      <th>Angola</th>
      <td>57756.890000</td>
      <td>57395.656667</td>
    </tr>
    <tr>
      <th>Anguilla</th>
      <td>29398.610000</td>
      <td>61876.902000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Venezuela</th>
      <td>65841.282000</td>
      <td>58996.190000</td>
    </tr>
    <tr>
      <th>Vietnam</th>
      <td>48574.583333</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Wallis and Futuna</th>
      <td>54030.155000</td>
      <td>52600.865000</td>
    </tr>
    <tr>
      <th>Western Sahara</th>
      <td>49408.062500</td>
      <td>57776.280000</td>
    </tr>
    <tr>
      <th>Yemen</th>
      <td>54768.810000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Zambia</th>
      <td>67050.160000</td>
      <td>48632.923333</td>
    </tr>
    <tr>
      <th>Zimbabwe</th>
      <td>49620.155000</td>
      <td>53674.025000</td>
    </tr>
  </tbody>
</table>
<p>237 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> advertisement-click-on-ad/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the Ad click rate for customers who spend more than an hour daily on the website compared to those who spend less than an hour? Show the values ">=60mins" and "<60mins" represnting daily time spent greater than or equal to, and lower than an hour, respectively.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>daily_time_spent = ads.groupby(ads['Daily Time Spent on Site']>=60)['Clicked on Ad'].agg(['sum','size'])
daily_time_spent = (daily_time_spent['sum'] / daily_time_spent['size'] * 100).reset_index()
daily_time_spent.columns = ['daily_time_spent','ad_click_rate']
daily_time_spent['daily_time_spent'].replace(True,'>= 60mins', inplace=True)
daily_time_spent['daily_time_spent'].replace(False,'< 60mins', inplace=True)
daily_time_spent</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>daily_time_spent = ads.groupby(ads['Daily Time Spent on Site']>=60)['Clicked on Ad'].agg(['sum','size'])
daily_time_spent = (daily_time_spent['sum'] / daily_time_spent['size'] * 100).reset_index()
daily_time_spent.columns = ['daily_time_spent','ad_click_rate']
daily_time_spent['daily_time_spent'].replace(True,'>= 60mins', inplace=True)
daily_time_spent['daily_time_spent'].replace(False,'< 60mins', inplace=True)
daily_time_spent</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>daily_time_spent = ads.groupby(ads['Daily Time Spent on Site'] >= 60)[
    'Clicked on Ad'].agg(['sum', 'size'])
daily_time_spent = (daily_time_spent['sum'] / daily_time_spent['size'] * 100
    ).reset_index()
daily_time_spent.columns = ['daily_time_spent', 'ad_click_rate']
__tmp_3 = daily_time_spent['daily_time_spent'].replace(True, '>= 60mins',
    inplace=True)
__tmp_4 = daily_time_spent['daily_time_spent'].replace(False, '< 60mins',
    inplace=True)
__output__ = daily_time_spent
</code></pre>
        <p><span onclick="$('#var_output_1bd2fdde').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1bd2fdde" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>daily_time_spent</th>
      <th>ad_click_rate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt; 60mins</td>
      <td>96.185286</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;= 60mins</td>
      <td>23.222749</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> daily_time_spent, __output__ </p>
    
          <p>daily_time_spent (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>daily_time_spent</th>
      <th>ad_click_rate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt; 60mins</td>
      <td>96.185286</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;= 60mins</td>
      <td>23.222749</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>daily_time_spent</th>
      <th>ad_click_rate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt; 60mins</td>
      <td>96.185286</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;= 60mins</td>
      <td>23.222749</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> advertisement-click-on-ad/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the daily percent of time spent on the website accross cities in France for each gender?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>france_ads = ads[ads['Country']=='France'].pivot_table(index='City', columns='Male', values='percent_time_on_site').fillna(0)
france_ads.columns=['Female','Male']
france_ads</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>france_ads = ads[ads['Country']=='France'].pivot_table(index='City', columns='Male', values='percent_time_on_site').fillna(0)
france_ads.columns=['Female','Male']
france_ads</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>france_ads = ads[ads['Country'] == 'France'].pivot_table(index='City',
    columns='Male', values='percent_time_on_site').fillna(0)
france_ads.columns = ['Female', 'Male']
__output__ = france_ads
</code></pre>
        <p><span onclick="$('#var_output_4dd8d5f1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4dd8d5f1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Female</th>
      <th>Male</th>
    </tr>
    <tr>
      <th>City</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adamsbury</th>
      <td>0.293379</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Lindsaymouth</th>
      <td>0.000000</td>
      <td>0.259253</td>
    </tr>
    <tr>
      <th>Mariahview</th>
      <td>0.000000</td>
      <td>0.315005</td>
    </tr>
    <tr>
      <th>Newmanberg</th>
      <td>0.316431</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>North April</th>
      <td>0.667600</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Port Brianfort</th>
      <td>0.000000</td>
      <td>0.589414</td>
    </tr>
    <tr>
      <th>Port Crystal</th>
      <td>0.460489</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Robinsontown</th>
      <td>0.000000</td>
      <td>0.472332</td>
    </tr>
    <tr>
      <th>Smithtown</th>
      <td>0.000000</td>
      <td>0.342385</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> france_ads, __output__ </p>
    
          <p>france_ads (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Female</th>
      <th>Male</th>
    </tr>
    <tr>
      <th>City</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adamsbury</th>
      <td>0.293379</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Lindsaymouth</th>
      <td>0.000000</td>
      <td>0.259253</td>
    </tr>
    <tr>
      <th>Mariahview</th>
      <td>0.000000</td>
      <td>0.315005</td>
    </tr>
    <tr>
      <th>Newmanberg</th>
      <td>0.316431</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>North April</th>
      <td>0.667600</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Port Brianfort</th>
      <td>0.000000</td>
      <td>0.589414</td>
    </tr>
    <tr>
      <th>Port Crystal</th>
      <td>0.460489</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Robinsontown</th>
      <td>0.000000</td>
      <td>0.472332</td>
    </tr>
    <tr>
      <th>Smithtown</th>
      <td>0.000000</td>
      <td>0.342385</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Female</th>
      <th>Male</th>
    </tr>
    <tr>
      <th>City</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adamsbury</th>
      <td>0.293379</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Lindsaymouth</th>
      <td>0.000000</td>
      <td>0.259253</td>
    </tr>
    <tr>
      <th>Mariahview</th>
      <td>0.000000</td>
      <td>0.315005</td>
    </tr>
    <tr>
      <th>Newmanberg</th>
      <td>0.316431</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>North April</th>
      <td>0.667600</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Port Brianfort</th>
      <td>0.000000</td>
      <td>0.589414</td>
    </tr>
    <tr>
      <th>Port Crystal</th>
      <td>0.460489</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Robinsontown</th>
      <td>0.000000</td>
      <td>0.472332</td>
    </tr>
    <tr>
      <th>Smithtown</th>
      <td>0.000000</td>
      <td>0.342385</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-selling-mobile-phones/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the total units sold per year by each manufacturer in the last 5 years?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>past_five_years = phones[phones['year'] >= phones['year'].max() - 5]
past_five_years.groupby(['manufacturer','year'], as_index=False).units_sold_m.sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>past_five_years = phones[phones['year'] >= phones['year'].max() - 5]
past_five_years.groupby(['manufacturer','year'], as_index=False).units_sold_m.sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>past_five_years = phones[phones['year'] >= phones['year'].max() - 5]
__output__ = past_five_years.groupby(['manufacturer', 'year'], as_index=False
    ).units_sold_m.sum()
</code></pre>
        <p><span onclick="$('#var_output_f3bb76da').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f3bb76da" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>manufacturer</th>
      <th>year</th>
      <th>units_sold_m</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Apple</td>
      <td>2016</td>
      <td>159.9</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Apple</td>
      <td>2017</td>
      <td>187.7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Apple</td>
      <td>2018</td>
      <td>151.1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Apple</td>
      <td>2019</td>
      <td>159.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Apple</td>
      <td>2020</td>
      <td>24.2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Google</td>
      <td>2016</td>
      <td>2.1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Huawei</td>
      <td>2016</td>
      <td>15.8</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Samsung</td>
      <td>2017</td>
      <td>51.0</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Samsung</td>
      <td>2018</td>
      <td>71.5</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Samsung</td>
      <td>2019</td>
      <td>171.2</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Samsung</td>
      <td>2020</td>
      <td>62.7</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Samsung</td>
      <td>2021</td>
      <td>13.5</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Xiaomi</td>
      <td>2019</td>
      <td>74.1</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Xiaomi</td>
      <td>2020</td>
      <td>15.0</td>
    </tr>
  </tbody>
</table>
<p>21 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> past_five_years, __output__ </p>
    
          <p>past_five_years (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>manufacturer</th>
      <th>model</th>
      <th>form</th>
      <th>smartphone</th>
      <th>year</th>
      <th>units_sold_m</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7</th>
      <td>Apple</td>
      <td>iPhone 7 and iPhone 7 Plus</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2016</td>
      <td>159.9</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Apple</td>
      <td>iPhone 11, iPhone 11 Pro and iPhone 11 Pro Max</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2019</td>
      <td>159.2</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Apple</td>
      <td>iPhone XR, iPhone XS and iPhone XS Max</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2018</td>
      <td>151.1</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Apple</td>
      <td>iPhone 8 and iPhone 8 Plus</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2017</td>
      <td>124.7</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Apple</td>
      <td>iPhone X</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2017</td>
      <td>63.0</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Samsung</td>
      <td>Galaxy S7 and Galaxy S7 edge</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2016</td>
      <td>55.0</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Samsung</td>
      <td>Galaxy S8 and Galaxy S8+</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2017</td>
      <td>41.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>97</th>
      <td>Xiaomi</td>
      <td>Redmi 8</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2019</td>
      <td>6.8</td>
    </tr>
    <tr>
      <th>98</th>
      <td>Samsung</td>
      <td>Galaxy J4+</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2018</td>
      <td>6.4</td>
    </tr>
    <tr>
      <th>101</th>
      <td>Samsung</td>
      <td>Galaxy J6+</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2018</td>
      <td>4.9</td>
    </tr>
    <tr>
      <th>103</th>
      <td>Samsung</td>
      <td>Galaxy A10s</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2019</td>
      <td>3.9</td>
    </tr>
    <tr>
      <th>104</th>
      <td>Samsung</td>
      <td>Galaxy A30s</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2019</td>
      <td>3.4</td>
    </tr>
    <tr>
      <th>107</th>
      <td>LeTV</td>
      <td>LeEco Le 1s</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2016</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>108</th>
      <td>Google</td>
      <td>Pixel and Pixel XL</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2016</td>
      <td>2.1</td>
    </tr>
  </tbody>
</table>
<p>44 rows × 6 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>manufacturer</th>
      <th>year</th>
      <th>units_sold_m</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Apple</td>
      <td>2016</td>
      <td>159.9</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Apple</td>
      <td>2017</td>
      <td>187.7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Apple</td>
      <td>2018</td>
      <td>151.1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Apple</td>
      <td>2019</td>
      <td>159.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Apple</td>
      <td>2020</td>
      <td>24.2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Google</td>
      <td>2016</td>
      <td>2.1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Huawei</td>
      <td>2016</td>
      <td>15.8</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Samsung</td>
      <td>2017</td>
      <td>51.0</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Samsung</td>
      <td>2018</td>
      <td>71.5</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Samsung</td>
      <td>2019</td>
      <td>171.2</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Samsung</td>
      <td>2020</td>
      <td>62.7</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Samsung</td>
      <td>2021</td>
      <td>13.5</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Xiaomi</td>
      <td>2019</td>
      <td>74.1</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Xiaomi</td>
      <td>2020</td>
      <td>15.0</td>
    </tr>
  </tbody>
</table>
<p>21 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-selling-mobile-phones/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which manufacturer produced the highest number of touchscreen phones?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>phones[phones.form.str.lower().str.contains('touchscreen')].groupby('manufacturer').model.nunique().idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>phones[phones.form.str.lower().str.contains('touchscreen')].groupby('manufacturer').model.nunique().idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = phones[phones.form.str.lower().str.contains('touchscreen')
    ].groupby('manufacturer').model.nunique().idxmax()
</code></pre>
        <p><span onclick="$('#var_output_7aff1667').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7aff1667" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Samsung</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Samsung</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-selling-mobile-phones/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Get the name of the phone model manufactured by Apple that yielded the highest YoY (Year over Year) increase in units sold? Return the model name and YoY unit sales change.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>apple_phones = phones[phones.manufacturer=='Apple'].sort_values(by='year')
apple_phones['units_yoy_change_%'] = ((apple_phones.units_sold_m.shift(-1) - apple_phones.units_sold_m)/apple_phones.units_sold_m).shift(1)
apple_phones.loc[apple_phones['units_yoy_change_%'].idxmax(), ['model','units_yoy_change_%']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>apple_phones = phones[phones.manufacturer=='Apple'].sort_values(by='year')
apple_phones['units_yoy_change_%'] = ((apple_phones.units_sold_m.shift(-1) - apple_phones.units_sold_m)/apple_phones.units_sold_m).shift(1)
apple_phones.loc[apple_phones['units_yoy_change_%'].idxmax(), ['model','units_yoy_change_%']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>apple_phones = phones[phones.manufacturer == 'Apple'].sort_values(by='year')
apple_phones['units_yoy_change_%'] = ((apple_phones.units_sold_m.shift(-1) -
    apple_phones.units_sold_m) / apple_phones.units_sold_m).shift(1)
__output__ = apple_phones.loc[apple_phones['units_yoy_change_%'].idxmax(),
    ['model', 'units_yoy_change_%']]
</code></pre>
        <p><span onclick="$('#var_output_98051def').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_98051def" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>model                 iPhone 3GS
units_yoy_change_%      4.833333
Name: 43, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> apple_phones, __output__ </p>
    
          <p>apple_phones (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>manufacturer</th>
      <th>model</th>
      <th>form</th>
      <th>smartphone</th>
      <th>year</th>
      <th>units_sold_m</th>
      <th>units_yoy_change_%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>99</th>
      <td>Apple</td>
      <td>iPhone</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2007</td>
      <td>6.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Apple</td>
      <td>iPhone 3GS</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2009</td>
      <td>35.0</td>
      <td>4.833333</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Apple</td>
      <td>iPhone 4</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2010</td>
      <td>50.0</td>
      <td>0.428571</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Apple</td>
      <td>iPhone 4S</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2011</td>
      <td>60.0</td>
      <td>0.200000</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Apple</td>
      <td>iPhone 5</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2012</td>
      <td>146.2</td>
      <td>1.436667</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Apple</td>
      <td>iPhone 5S</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2013</td>
      <td>164.5</td>
      <td>0.125171</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Apple</td>
      <td>iPhone 6 and iPhone 6 Plus</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2014</td>
      <td>224.0</td>
      <td>0.361702</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Apple</td>
      <td>iPhone 6S and iPhone 6S Plus</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2015</td>
      <td>174.1</td>
      <td>-0.222768</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Apple</td>
      <td>iPhone 7 and iPhone 7 Plus</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2016</td>
      <td>159.9</td>
      <td>-0.081562</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Apple</td>
      <td>iPhone X</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2017</td>
      <td>63.0</td>
      <td>-0.606004</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Apple</td>
      <td>iPhone 8 and iPhone 8 Plus</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2017</td>
      <td>124.7</td>
      <td>0.979365</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Apple</td>
      <td>iPhone XR, iPhone XS and iPhone XS Max</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2018</td>
      <td>151.1</td>
      <td>0.211708</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Apple</td>
      <td>iPhone 11, iPhone 11 Pro and iPhone 11 Pro Max</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2019</td>
      <td>159.2</td>
      <td>0.053607</td>
    </tr>
    <tr>
      <th>55</th>
      <td>Apple</td>
      <td>iPhone SE (2nd generation)</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2020</td>
      <td>24.2</td>
      <td>-0.847990</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 7 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>model                 iPhone 3GS
units_yoy_change_%      4.833333
Name: 43, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-selling-mobile-phones/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the percentage of bar type phones released each year?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>phones_pivot = phones.pivot_table(index='year', columns='form').fillna(0)
phones_pivot.columns = phones_pivot.columns.get_level_values(1)

phones_pivot.Bar / phones_pivot.sum(1) * 100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>phones_pivot = phones.pivot_table(index='year', columns='form').fillna(0)
phones_pivot.columns = phones_pivot.columns.get_level_values(1)

phones_pivot.Bar / phones_pivot.sum(1) * 100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>phones_pivot = phones.pivot_table(index='year', columns='form').fillna(0)
phones_pivot.columns = phones_pivot.columns.get_level_values(1)
__output__ = phones_pivot.Bar / phones_pivot.sum(1) * 100
</code></pre>
        <p><span onclick="$('#var_output_50380e98').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_50380e98" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>year
1996      0.000000
1999    100.000000
2000    100.000000
2003     89.075630
2004     45.454545
           ...    
2017      0.000000
2018      0.000000
2019      0.000000
2020      0.000000
2021      0.000000
Length: 22, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> phones_pivot, __output__ </p>
    
          <p>phones_pivot (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>form</th>
      <th>Bar</th>
      <th>Flip phone</th>
      <th>Keyboard bar</th>
      <th>Slider</th>
      <th>Taco</th>
      <th>Tilt slider</th>
      <th>Touchscreen</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1996</th>
      <td>0.000000</td>
      <td>60.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>161.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2000</th>
      <td>126.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2003</th>
      <td>106.000000</td>
      <td>10.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2004</th>
      <td>68.750000</td>
      <td>82.5</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2005</th>
      <td>99.500000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2006</th>
      <td>25.666667</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>27.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>109.550000</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>38.142857</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>51.140000</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>33.950000</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>24.788889</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>20.380000</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>13.500000</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 7 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>year
1996      0.000000
1999    100.000000
2000    100.000000
2003     89.075630
2004     45.454545
           ...    
2017      0.000000
2018      0.000000
2019      0.000000
2020      0.000000
2021      0.000000
Length: 22, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-selling-mobile-phones/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the distribution of different phone configurations accross manufacturers for the last fifteen years? Return a dataframe with the year and manufacturer as an index, and phone forms as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>year_phones = phones[phones['year'] >= phones['year'].max()-15]
year_phones.groupby(['year','manufacturer','form'], as_index=False).size().pivot(index=['year','manufacturer'], columns='form').fillna(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>year_phones = phones[phones['year'] >= phones['year'].max()-15]
year_phones.groupby(['year','manufacturer','form'], as_index=False).size().pivot(index=['year','manufacturer'], columns='form').fillna(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>year_phones = phones[phones['year'] >= phones['year'].max() - 15]
__output__ = year_phones.groupby(['year', 'manufacturer', 'form'], as_index
    =False).size().pivot(index=['year', 'manufacturer'], columns='form'
    ).fillna(0)
</code></pre>
        <p><span onclick="$('#var_output_d8fdd568').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d8fdd568" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th colspan="5" halign="left">size</th>
    </tr>
    <tr>
      <th></th>
      <th>form</th>
      <th>Bar</th>
      <th>Keyboard bar</th>
      <th>Slider</th>
      <th>Tilt slider</th>
      <th>Touchscreen</th>
    </tr>
    <tr>
      <th>year</th>
      <th>manufacturer</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="5" valign="top">2006</th>
      <th>LG</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Nokia</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Research In Motion (RIM)</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Samsung</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Sony Ericsson</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">2007</th>
      <th>Apple</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>LG</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">2019</th>
      <th>Oppo</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Samsung</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>Xiaomi</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">2020</th>
      <th>Apple</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Samsung</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Xiaomi</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2021</th>
      <th>Samsung</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>55 rows × 5 columns</p>
      
        <p><strong>Hyp output variables:</strong> year_phones, __output__ </p>
    
          <p>year_phones (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>manufacturer</th>
      <th>model</th>
      <th>form</th>
      <th>smartphone</th>
      <th>year</th>
      <th>units_sold_m</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>Apple</td>
      <td>iPhone 6 and iPhone 6 Plus</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2014</td>
      <td>224.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Nokia</td>
      <td>105 (2013), 105 (2015)</td>
      <td>Bar</td>
      <td>No</td>
      <td>2013</td>
      <td>200.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Apple</td>
      <td>iPhone 6S and iPhone 6S Plus</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2015</td>
      <td>174.1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Apple</td>
      <td>iPhone 5S</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2013</td>
      <td>164.5</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Apple</td>
      <td>iPhone 7 and iPhone 7 Plus</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2016</td>
      <td>159.9</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Apple</td>
      <td>iPhone 11, iPhone 11 Pro and iPhone 11 Pro Max</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2019</td>
      <td>159.2</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Apple</td>
      <td>iPhone XR, iPhone XS and iPhone XS Max</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2018</td>
      <td>151.1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>103</th>
      <td>Samsung</td>
      <td>Galaxy A10s</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2019</td>
      <td>3.9</td>
    </tr>
    <tr>
      <th>104</th>
      <td>Samsung</td>
      <td>Galaxy A30s</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2019</td>
      <td>3.4</td>
    </tr>
    <tr>
      <th>106</th>
      <td>LG</td>
      <td>G2</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2013</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>107</th>
      <td>LeTV</td>
      <td>LeEco Le 1s</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2016</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>108</th>
      <td>Google</td>
      <td>Pixel and Pixel XL</td>
      <td>Touchscreen</td>
      <td>Yes</td>
      <td>2016</td>
      <td>2.1</td>
    </tr>
    <tr>
      <th>109</th>
      <td>Palm</td>
      <td>Centro</td>
      <td>Keyboard bar</td>
      <td>Yes</td>
      <td>2007</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>110</th>
      <td>Nokia</td>
      <td>N97</td>
      <td>Tilt slider</td>
      <td>Yes</td>
      <td>2009</td>
      <td>2.0</td>
    </tr>
  </tbody>
</table>
<p>90 rows × 6 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th colspan="5" halign="left">size</th>
    </tr>
    <tr>
      <th></th>
      <th>form</th>
      <th>Bar</th>
      <th>Keyboard bar</th>
      <th>Slider</th>
      <th>Tilt slider</th>
      <th>Touchscreen</th>
    </tr>
    <tr>
      <th>year</th>
      <th>manufacturer</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="5" valign="top">2006</th>
      <th>LG</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Nokia</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Research In Motion (RIM)</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Samsung</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Sony Ericsson</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">2007</th>
      <th>Apple</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>LG</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">2019</th>
      <th>Oppo</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Samsung</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>Xiaomi</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">2020</th>
      <th>Apple</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Samsung</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Xiaomi</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2021</th>
      <th>Samsung</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>55 rows × 5 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-selling-mobile-phones/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many different smartphones were released each decade?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>yearly_smartphones = phones.groupby(['year', 'smartphone'], as_index=False).size().pivot_table(index='year',columns='smartphone', values='size').fillna(0)
yearly_smartphones.groupby((yearly_smartphones.index//10)*10).Yes.sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>yearly_smartphones = phones.groupby(['year', 'smartphone'], as_index=False).size().pivot_table(index='year',columns='smartphone', values='size').fillna(0)
yearly_smartphones.groupby((yearly_smartphones.index//10)*10).Yes.sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>yearly_smartphones = phones.groupby(['year', 'smartphone'], as_index=False
    ).size().pivot_table(index='year', columns='smartphone', values='size'
    ).fillna(0)
__output__ = yearly_smartphones.groupby(yearly_smartphones.index // 10 * 10
    ).Yes.sum()
</code></pre>
        <p><span onclick="$('#var_output_c8a40f82').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c8a40f82" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>year
1990     0.0
2000    12.0
2010    58.0
2020     6.0
Name: Yes, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> yearly_smartphones, __output__ </p>
    
          <p>yearly_smartphones (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>smartphone</th>
      <th>No</th>
      <th>Yes</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1996</th>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2000</th>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2003</th>
      <td>5.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>2004</th>
      <td>6.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2005</th>
      <td>4.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2006</th>
      <td>5.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0.0</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>0.0</td>
      <td>18.0</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>0.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>year
1990     0.0
2000    12.0
2010    58.0
2020     6.0
Name: Yes, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-selling-mobile-phones/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which manufacturer released the highest number Bar type phones after the year 2000?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>phones[(phones.form.str.contains('bar', case=False)) & (phones['year']>=2000)].manufacturer.value_counts().idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>phones[(phones.form.str.contains('bar', case=False)) & (phones['year']>=2000)].manufacturer.value_counts().idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = phones[phones.form.str.contains('bar', case=False) & (phones[
    'year'] >= 2000)].manufacturer.value_counts().idxmax()
</code></pre>
        <p><span onclick="$('#var_output_76f3815c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_76f3815c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Nokia</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Nokia</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> world-population-by-countries/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the incorrect data types of numerical columns into numeric format.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>population['Population 2020'] = population['Population 2020'].str.replace(",","").astype(int)
population['Yearly Change'] = population['Yearly Change'].str.replace("%","").astype(float)
population['Net Change'] = population['Net Change'].str.replace(",","").astype(int)
population['Density  (P/Km²)'] = population['Density  (P/Km²)'].str.replace(",","").astype(float)
population['Land Area (Km²)'] = population['Land Area (Km²)'].str.replace(",","").astype(int)
population['Migrants (net)'] = population['Migrants (net)'].str.replace(",","").astype(float)
population['Fert. Rate'] = pd.to_numeric(population['Fert. Rate'].str.replace(",","").str.replace("N.A.",''))
population['Med. Age'] = pd.to_numeric(population['Med. Age'].str.replace('N.A.',''))
population['Urban Pop %'] = pd.to_numeric(population['Urban Pop %'].str.replace("%","").str.replace("N.A.",''))
population['World Share'] = pd.to_numeric(population['World Share'].str.replace("%","").astype(float))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>population['Population 2020'] = population['Population 2020'].str.replace(",","").astype(int)
population['Yearly Change'] = population['Yearly Change'].str.replace("%","").astype(float)
population['Net Change'] = population['Net Change'].str.replace(",","").astype(int)
population['Density  (P/Km²)'] = population['Density  (P/Km²)'].str.replace(",","").astype(float)
population['Land Area (Km²)'] = population['Land Area (Km²)'].str.replace(",","").astype(int)
population['Migrants (net)'] = population['Migrants (net)'].str.replace(",","").astype(float)
population['Fert. Rate'] = pd.to_numeric(population['Fert. Rate'].str.replace(",","").str.replace("N.A.",''))
population['Med. Age'] = pd.to_numeric(population['Med. Age'].str.replace('N.A.',''))
population['Urban Pop %'] = pd.to_numeric(population['Urban Pop %'].str.replace("%","").str.replace("N.A.",''))
population['World Share'] = pd.to_numeric(population['World Share'].str.replace("%","").astype(float))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>population['Population 2020'] = population['Population 2020'].str.replace(',',
    '').astype(int)
population['Yearly Change'] = population['Yearly Change'].str.replace('%', ''
    ).astype(float)
population['Net Change'] = population['Net Change'].str.replace(',', ''
    ).astype(int)
population['Density  (P/Km²)'] = population['Density  (P/Km²)'].str.replace(','
    , '').astype(float)
population['Land Area (Km²)'] = population['Land Area (Km²)'].str.replace(',',
    '').astype(int)
population['Migrants (net)'] = population['Migrants (net)'].str.replace(',', ''
    ).astype(float)
population['Fert. Rate'] = pd.to_numeric(population['Fert. Rate'].str.
    replace(',', '').str.replace('N.A.', ''))
population['Med. Age'] = pd.to_numeric(population['Med. Age'].str.replace(
    'N.A.', ''))
population['Urban Pop %'] = pd.to_numeric(population['Urban Pop %'].str.
    replace('%', '').str.replace('N.A.', ''))
__output__ = population['World Share'] = pd.to_numeric(population[
    'World Share'].str.replace('%', '').astype(float))
</code></pre>
        <p><span onclick="$('#var_output_1f46b831').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1f46b831" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      18.47
1      17.70
2       4.25
3       3.51
4       2.83
       ...  
230     0.00
231     0.00
232     0.00
233     0.00
234     0.00
Name: World Share, Length: 235, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> population, __output__ </p>
    
          <p>population (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>no</th>
      <th>Country (or dependency)</th>
      <th>Population 2020</th>
      <th>Yearly Change</th>
      <th>Net Change</th>
      <th>Density  (P/Km²)</th>
      <th>Land Area (Km²)</th>
      <th>Migrants (net)</th>
      <th>Fert. Rate</th>
      <th>Med. Age</th>
      <th>Urban Pop %</th>
      <th>World Share</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>China</td>
      <td>1439323776</td>
      <td>0.39</td>
      <td>5540090</td>
      <td>153.0</td>
      <td>9388211</td>
      <td>-348399.0</td>
      <td>1.7</td>
      <td>38.0</td>
      <td>61.0</td>
      <td>18.47</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>India</td>
      <td>1380004385</td>
      <td>0.99</td>
      <td>13586631</td>
      <td>464.0</td>
      <td>2973190</td>
      <td>-532687.0</td>
      <td>2.2</td>
      <td>28.0</td>
      <td>35.0</td>
      <td>17.70</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>United States</td>
      <td>331002651</td>
      <td>0.59</td>
      <td>1937734</td>
      <td>36.0</td>
      <td>9147420</td>
      <td>954806.0</td>
      <td>1.8</td>
      <td>38.0</td>
      <td>83.0</td>
      <td>4.25</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Indonesia</td>
      <td>273523615</td>
      <td>1.07</td>
      <td>2898047</td>
      <td>151.0</td>
      <td>1811570</td>
      <td>-98955.0</td>
      <td>2.3</td>
      <td>30.0</td>
      <td>56.0</td>
      <td>3.51</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Pakistan</td>
      <td>220892340</td>
      <td>2.00</td>
      <td>4327022</td>
      <td>287.0</td>
      <td>770880</td>
      <td>-233379.0</td>
      <td>3.6</td>
      <td>23.0</td>
      <td>35.0</td>
      <td>2.83</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>Brazil</td>
      <td>212559417</td>
      <td>0.72</td>
      <td>1509890</td>
      <td>25.0</td>
      <td>8358140</td>
      <td>21200.0</td>
      <td>1.7</td>
      <td>33.0</td>
      <td>88.0</td>
      <td>2.73</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>Nigeria</td>
      <td>206139589</td>
      <td>2.58</td>
      <td>5175990</td>
      <td>226.0</td>
      <td>910770</td>
      <td>-60000.0</td>
      <td>5.4</td>
      <td>18.0</td>
      <td>52.0</td>
      <td>2.64</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>228</th>
      <td>229</td>
      <td>Saint Helena</td>
      <td>6077</td>
      <td>0.30</td>
      <td>18</td>
      <td>16.0</td>
      <td>390</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>27.0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>229</th>
      <td>230</td>
      <td>Saint Pierre &amp; Miquelon</td>
      <td>5794</td>
      <td>-0.48</td>
      <td>-28</td>
      <td>25.0</td>
      <td>230</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>100.0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>230</th>
      <td>231</td>
      <td>Montserrat</td>
      <td>4992</td>
      <td>0.06</td>
      <td>3</td>
      <td>50.0</td>
      <td>100</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>10.0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>231</th>
      <td>232</td>
      <td>Falkland Islands</td>
      <td>3480</td>
      <td>3.05</td>
      <td>103</td>
      <td>0.0</td>
      <td>12170</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>66.0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>232</th>
      <td>233</td>
      <td>Niue</td>
      <td>1626</td>
      <td>0.68</td>
      <td>11</td>
      <td>6.0</td>
      <td>260</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>46.0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>233</th>
      <td>234</td>
      <td>Tokelau</td>
      <td>1357</td>
      <td>1.27</td>
      <td>17</td>
      <td>136.0</td>
      <td>10</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>234</th>
      <td>235</td>
      <td>Holy See</td>
      <td>801</td>
      <td>0.25</td>
      <td>2</td>
      <td>2003.0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.00</td>
    </tr>
  </tbody>
</table>
<p>235 rows × 12 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      18.47
1      17.70
2       4.25
3       3.51
4       2.83
       ...  
230     0.00
231     0.00
232     0.00
233     0.00
234     0.00
Name: World Share, Length: 235, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> world-population-by-countries/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average median population age of countries having a fertility rate of more than and less than 2.0? Show the values ">=2.0" and "<2.0" representing fertility rates greater than or equal to, and lower than 2.0 respectively.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>fert_population = population.groupby(population['Fert. Rate']>=2)['Med. Age'].mean().reset_index()
fert_population.columns = ['fert_rate','median_age']
fert_population.fert_rate.replace(True,'>=2.0', inplace=True)
fert_population.fert_rate.replace(False,'<2.0', inplace=True)
fert_population</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>fert_population = population.groupby(population['Fert. Rate']>=2)['Med. Age'].mean().reset_index()
fert_population.columns = ['fert_rate','median_age']
fert_population.fert_rate.replace(True,'>=2.0', inplace=True)
fert_population.fert_rate.replace(False,'<2.0', inplace=True)
fert_population</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>fert_population = population.groupby(population['Fert. Rate'] >= 2)['Med. Age'
    ].mean().reset_index()
fert_population.columns = ['fert_rate', 'median_age']
__tmp_2 = fert_population.fert_rate.replace(True, '>=2.0', inplace=True)
__tmp_3 = fert_population.fert_rate.replace(False, '<2.0', inplace=True)
__output__ = fert_population
</code></pre>
        <p><span onclick="$('#var_output_2a89e89b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2a89e89b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fert_rate</th>
      <th>median_age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt;2.0</td>
      <td>39.960000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;=2.0</td>
      <td>25.063492</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> fert_population, __output__ </p>
    
          <p>fert_population (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fert_rate</th>
      <th>median_age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt;2.0</td>
      <td>39.960000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;=2.0</td>
      <td>25.063492</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fert_rate</th>
      <th>median_age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt;2.0</td>
      <td>39.960000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;=2.0</td>
      <td>25.063492</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> world-population-by-countries/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which country had the lowest population last year?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>population['population_2019'] = population['Population 2020'] - population['Net Change']
population.loc[population['population_2019'].idxmin(),'Country (or dependency)']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>population['population_2019'] = population['Population 2020'] - population['Net Change']
population.loc[population['population_2019'].idxmin(),'Country (or dependency)']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>population['population_2019'] = population['Population 2020'] - population[
    'Net Change']
__output__ = population.loc[population['population_2019'].idxmin(),
    'Country (or dependency)']
</code></pre>
        <p><span onclick="$('#var_output_cb2582d4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_cb2582d4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Holy See</code></pre>
      
        <p><strong>Hyp output variables:</strong> population, __output__ </p>
    
          <p>population (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>no</th>
      <th>Country (or dependency)</th>
      <th>Population 2020</th>
      <th>Yearly Change</th>
      <th>Net Change</th>
      <th>Density  (P/Km²)</th>
      <th>Land Area (Km²)</th>
      <th>Migrants (net)</th>
      <th>Fert. Rate</th>
      <th>Med. Age</th>
      <th>Urban Pop %</th>
      <th>World Share</th>
      <th>population_2019</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>China</td>
      <td>1439323776</td>
      <td>0.39</td>
      <td>5540090</td>
      <td>153.0</td>
      <td>9388211</td>
      <td>-348399.0</td>
      <td>1.7</td>
      <td>38.0</td>
      <td>61.0</td>
      <td>18.47</td>
      <td>1433783686</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>India</td>
      <td>1380004385</td>
      <td>0.99</td>
      <td>13586631</td>
      <td>464.0</td>
      <td>2973190</td>
      <td>-532687.0</td>
      <td>2.2</td>
      <td>28.0</td>
      <td>35.0</td>
      <td>17.70</td>
      <td>1366417754</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>United States</td>
      <td>331002651</td>
      <td>0.59</td>
      <td>1937734</td>
      <td>36.0</td>
      <td>9147420</td>
      <td>954806.0</td>
      <td>1.8</td>
      <td>38.0</td>
      <td>83.0</td>
      <td>4.25</td>
      <td>329064917</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Indonesia</td>
      <td>273523615</td>
      <td>1.07</td>
      <td>2898047</td>
      <td>151.0</td>
      <td>1811570</td>
      <td>-98955.0</td>
      <td>2.3</td>
      <td>30.0</td>
      <td>56.0</td>
      <td>3.51</td>
      <td>270625568</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Pakistan</td>
      <td>220892340</td>
      <td>2.00</td>
      <td>4327022</td>
      <td>287.0</td>
      <td>770880</td>
      <td>-233379.0</td>
      <td>3.6</td>
      <td>23.0</td>
      <td>35.0</td>
      <td>2.83</td>
      <td>216565318</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>Brazil</td>
      <td>212559417</td>
      <td>0.72</td>
      <td>1509890</td>
      <td>25.0</td>
      <td>8358140</td>
      <td>21200.0</td>
      <td>1.7</td>
      <td>33.0</td>
      <td>88.0</td>
      <td>2.73</td>
      <td>211049527</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>Nigeria</td>
      <td>206139589</td>
      <td>2.58</td>
      <td>5175990</td>
      <td>226.0</td>
      <td>910770</td>
      <td>-60000.0</td>
      <td>5.4</td>
      <td>18.0</td>
      <td>52.0</td>
      <td>2.64</td>
      <td>200963599</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>228</th>
      <td>229</td>
      <td>Saint Helena</td>
      <td>6077</td>
      <td>0.30</td>
      <td>18</td>
      <td>16.0</td>
      <td>390</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>27.0</td>
      <td>0.00</td>
      <td>6059</td>
    </tr>
    <tr>
      <th>229</th>
      <td>230</td>
      <td>Saint Pierre &amp; Miquelon</td>
      <td>5794</td>
      <td>-0.48</td>
      <td>-28</td>
      <td>25.0</td>
      <td>230</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>100.0</td>
      <td>0.00</td>
      <td>5822</td>
    </tr>
    <tr>
      <th>230</th>
      <td>231</td>
      <td>Montserrat</td>
      <td>4992</td>
      <td>0.06</td>
      <td>3</td>
      <td>50.0</td>
      <td>100</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>10.0</td>
      <td>0.00</td>
      <td>4989</td>
    </tr>
    <tr>
      <th>231</th>
      <td>232</td>
      <td>Falkland Islands</td>
      <td>3480</td>
      <td>3.05</td>
      <td>103</td>
      <td>0.0</td>
      <td>12170</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>66.0</td>
      <td>0.00</td>
      <td>3377</td>
    </tr>
    <tr>
      <th>232</th>
      <td>233</td>
      <td>Niue</td>
      <td>1626</td>
      <td>0.68</td>
      <td>11</td>
      <td>6.0</td>
      <td>260</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>46.0</td>
      <td>0.00</td>
      <td>1615</td>
    </tr>
    <tr>
      <th>233</th>
      <td>234</td>
      <td>Tokelau</td>
      <td>1357</td>
      <td>1.27</td>
      <td>17</td>
      <td>136.0</td>
      <td>10</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>1340</td>
    </tr>
    <tr>
      <th>234</th>
      <td>235</td>
      <td>Holy See</td>
      <td>801</td>
      <td>0.25</td>
      <td>2</td>
      <td>2003.0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.00</td>
      <td>799</td>
    </tr>
  </tbody>
</table>
<p>235 rows × 13 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>Holy See</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the correlation between flight duration, remaining days until flight and ticket price for the economy class?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>corr_matrix = flights[flights['class']=='Economy'].corr()
corr_matrix.loc[['duration','days_left'],'price']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>corr_matrix = flights[flights['class']=='Economy'].corr()
corr_matrix.loc[['duration','days_left'],'price']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>corr_matrix = flights[flights['class'] == 'Economy'].corr()
__output__ = corr_matrix.loc[['duration', 'days_left'], 'price']
</code></pre>
        <p><span onclick="$('#var_output_7fa2a96b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7fa2a96b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>duration     0.288379
days_left   -0.559551
Name: price, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> corr_matrix, __output__ </p>
    
          <p>corr_matrix (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>duration</th>
      <th>days_left</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>duration</th>
      <td>1.000000</td>
      <td>-0.042537</td>
      <td>0.288379</td>
    </tr>
    <tr>
      <th>days_left</th>
      <td>-0.042537</td>
      <td>1.000000</td>
      <td>-0.559551</td>
    </tr>
    <tr>
      <th>price</th>
      <td>0.288379</td>
      <td>-0.559551</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>duration     0.288379
days_left   -0.559551
Name: price, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent change in the average ticket prices for every hour increase in flight duration for economy and business classes? Round the flight durations to the nearest hour.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>flights['duration_bucket'] = (flights.duration.round()).astype('int')
flights.groupby(['class','duration_bucket']).price.mean().pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>flights['duration_bucket'] = (flights.duration.round()).astype('int')
flights.groupby(['class','duration_bucket']).price.mean().pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>flights['duration_bucket'] = flights.duration.round().astype('int')
__output__ = flights.groupby(['class', 'duration_bucket']).price.mean(
    ).pct_change()
</code></pre>
        <p><span onclick="$('#var_output_c1899445').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c1899445" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>class     duration_bucket
Business  1                       NaN
          2                  0.675760
          3                  0.192272
          4                 -0.091199
          5                  0.695785
                               ...   
Economy   44                 0.612405
          46                -0.605012
          47                 0.344182
          48                -0.566800
          50                 1.776370
Name: price, Length: 86, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> flights, __output__ </p>
    
          <p>flights (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airline</th>
      <th>flight</th>
      <th>source_city</th>
      <th>departure_time</th>
      <th>stops</th>
      <th>arrival_time</th>
      <th>destination_city</th>
      <th>class</th>
      <th>duration</th>
      <th>days_left</th>
      <th>price</th>
      <th>duration_bucket</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SpiceJet</td>
      <td>SG-8709</td>
      <td>Delhi</td>
      <td>Evening</td>
      <td>zero</td>
      <td>Night</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.17</td>
      <td>1</td>
      <td>5953</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SpiceJet</td>
      <td>SG-8157</td>
      <td>Delhi</td>
      <td>Early_Morning</td>
      <td>zero</td>
      <td>Morning</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5953</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AirAsia</td>
      <td>I5-764</td>
      <td>Delhi</td>
      <td>Early_Morning</td>
      <td>zero</td>
      <td>Early_Morning</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.17</td>
      <td>1</td>
      <td>5956</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vistara</td>
      <td>UK-995</td>
      <td>Delhi</td>
      <td>Morning</td>
      <td>zero</td>
      <td>Afternoon</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.25</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Vistara</td>
      <td>UK-963</td>
      <td>Delhi</td>
      <td>Morning</td>
      <td>zero</td>
      <td>Morning</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Vistara</td>
      <td>UK-945</td>
      <td>Delhi</td>
      <td>Morning</td>
      <td>zero</td>
      <td>Afternoon</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Vistara</td>
      <td>UK-927</td>
      <td>Delhi</td>
      <td>Morning</td>
      <td>zero</td>
      <td>Morning</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.08</td>
      <td>1</td>
      <td>6060</td>
      <td>2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>300146</th>
      <td>Air_India</td>
      <td>AI-440</td>
      <td>Chennai</td>
      <td>Early_Morning</td>
      <td>one</td>
      <td>Morning</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>26.83</td>
      <td>49</td>
      <td>51345</td>
      <td>27</td>
    </tr>
    <tr>
      <th>300147</th>
      <td>Air_India</td>
      <td>AI-569</td>
      <td>Chennai</td>
      <td>Early_Morning</td>
      <td>one</td>
      <td>Night</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>17.25</td>
      <td>49</td>
      <td>68739</td>
      <td>17</td>
    </tr>
    <tr>
      <th>300148</th>
      <td>Vistara</td>
      <td>UK-822</td>
      <td>Chennai</td>
      <td>Morning</td>
      <td>one</td>
      <td>Evening</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.08</td>
      <td>49</td>
      <td>69265</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300149</th>
      <td>Vistara</td>
      <td>UK-826</td>
      <td>Chennai</td>
      <td>Afternoon</td>
      <td>one</td>
      <td>Night</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.42</td>
      <td>49</td>
      <td>77105</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300150</th>
      <td>Vistara</td>
      <td>UK-832</td>
      <td>Chennai</td>
      <td>Early_Morning</td>
      <td>one</td>
      <td>Night</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>13.83</td>
      <td>49</td>
      <td>79099</td>
      <td>14</td>
    </tr>
    <tr>
      <th>300151</th>
      <td>Vistara</td>
      <td>UK-828</td>
      <td>Chennai</td>
      <td>Early_Morning</td>
      <td>one</td>
      <td>Evening</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.00</td>
      <td>49</td>
      <td>81585</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300152</th>
      <td>Vistara</td>
      <td>UK-822</td>
      <td>Chennai</td>
      <td>Morning</td>
      <td>one</td>
      <td>Evening</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.08</td>
      <td>49</td>
      <td>81585</td>
      <td>10</td>
    </tr>
  </tbody>
</table>
<p>300153 rows × 12 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>class     duration_bucket
Business  1                       NaN
          2                  0.675760
          3                  0.192272
          4                 -0.091199
          5                  0.695785
                               ...   
Economy   44                 0.612405
          46                -0.605012
          47                 0.344182
          48                -0.566800
          50                 1.776370
Name: price, Length: 86, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average economy and business class ticket prices for each airline travelling to Delhi? Return a dataframe with airlines as an index and ticket class as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>prices = flights[flights.destination_city=='Delhi'].groupby(['airline','class'], as_index=False).price.mean()
prices.pivot(index='airline', columns='class')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>prices = flights[flights.destination_city=='Delhi'].groupby(['airline','class'], as_index=False).price.mean()
prices.pivot(index='airline', columns='class')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>prices = flights[flights.destination_city == 'Delhi'].groupby(['airline',
    'class'], as_index=False).price.mean()
__output__ = prices.pivot(index='airline', columns='class')
</code></pre>
        <p><span onclick="$('#var_output_83bd0c90').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_83bd0c90" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">price</th>
    </tr>
    <tr>
      <th>class</th>
      <th>Business</th>
      <th>Economy</th>
    </tr>
    <tr>
      <th>airline</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>AirAsia</th>
      <td>NaN</td>
      <td>4304.907512</td>
    </tr>
    <tr>
      <th>Air_India</th>
      <td>41740.197903</td>
      <td>6918.451338</td>
    </tr>
    <tr>
      <th>GO_FIRST</th>
      <td>NaN</td>
      <td>5780.163369</td>
    </tr>
    <tr>
      <th>Indigo</th>
      <td>NaN</td>
      <td>5452.485676</td>
    </tr>
    <tr>
      <th>SpiceJet</th>
      <td>NaN</td>
      <td>6113.527351</td>
    </tr>
    <tr>
      <th>Vistara</th>
      <td>51742.462794</td>
      <td>7323.453542</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> prices, __output__ </p>
    
          <p>prices (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airline</th>
      <th>class</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AirAsia</td>
      <td>Economy</td>
      <td>4304.907512</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Air_India</td>
      <td>Business</td>
      <td>41740.197903</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Air_India</td>
      <td>Economy</td>
      <td>6918.451338</td>
    </tr>
    <tr>
      <th>3</th>
      <td>GO_FIRST</td>
      <td>Economy</td>
      <td>5780.163369</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Indigo</td>
      <td>Economy</td>
      <td>5452.485676</td>
    </tr>
    <tr>
      <th>5</th>
      <td>SpiceJet</td>
      <td>Economy</td>
      <td>6113.527351</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Vistara</td>
      <td>Business</td>
      <td>51742.462794</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Vistara</td>
      <td>Economy</td>
      <td>7323.453542</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">price</th>
    </tr>
    <tr>
      <th>class</th>
      <th>Business</th>
      <th>Economy</th>
    </tr>
    <tr>
      <th>airline</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>AirAsia</th>
      <td>NaN</td>
      <td>4304.907512</td>
    </tr>
    <tr>
      <th>Air_India</th>
      <td>41740.197903</td>
      <td>6918.451338</td>
    </tr>
    <tr>
      <th>GO_FIRST</th>
      <td>NaN</td>
      <td>5780.163369</td>
    </tr>
    <tr>
      <th>Indigo</th>
      <td>NaN</td>
      <td>5452.485676</td>
    </tr>
    <tr>
      <th>SpiceJet</th>
      <td>NaN</td>
      <td>6113.527351</td>
    </tr>
    <tr>
      <th>Vistara</th>
      <td>51742.462794</td>
      <td>7323.453542</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Return a matrix with the average ticket prices to and from all the cities for each ticket class.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>flights.groupby(['class','source_city','destination_city']).price.mean().unstack(level=2)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>flights.groupby(['class','source_city','destination_city']).price.mean().unstack(level=2)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = flights.groupby(['class', 'source_city', 'destination_city']
    ).price.mean().unstack(level=2)
</code></pre>
        <p><span onclick="$('#var_output_b69a06f2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b69a06f2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>destination_city</th>
      <th>Bangalore</th>
      <th>Chennai</th>
      <th>Delhi</th>
      <th>Hyderabad</th>
      <th>Kolkata</th>
      <th>Mumbai</th>
    </tr>
    <tr>
      <th>class</th>
      <th>source_city</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="6" valign="top">Business</th>
      <th>Bangalore</th>
      <td>NaN</td>
      <td>52436.915395</td>
      <td>48144.337108</td>
      <td>50395.796948</td>
      <td>58854.693091</td>
      <td>58024.618208</td>
    </tr>
    <tr>
      <th>Chennai</th>
      <td>53113.008692</td>
      <td>NaN</td>
      <td>52443.367242</td>
      <td>51559.874283</td>
      <td>57078.895872</td>
      <td>56223.838086</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>48576.027921</td>
      <td>52031.778099</td>
      <td>NaN</td>
      <td>44457.376775</td>
      <td>56239.853659</td>
      <td>44364.442811</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>50358.290706</td>
      <td>51132.155288</td>
      <td>44250.700281</td>
      <td>NaN</td>
      <td>53729.157762</td>
      <td>52184.424666</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>58681.104437</td>
      <td>56502.775035</td>
      <td>55047.492193</td>
      <td>54732.447908</td>
      <td>NaN</td>
      <td>57422.551724</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>57970.544389</td>
      <td>55703.326197</td>
      <td>43846.329273</td>
      <td>51593.643678</td>
      <td>57106.526385</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th rowspan="6" valign="top">Economy</th>
      <th>Bangalore</th>
      <td>NaN</td>
      <td>7105.953850</td>
      <td>6124.897982</td>
      <td>6360.141698</td>
      <td>7375.638594</td>
      <td>6381.093332</td>
    </tr>
    <tr>
      <th>Chennai</th>
      <td>7175.020192</td>
      <td>NaN</td>
      <td>6075.961190</td>
      <td>5960.788831</td>
      <td>7547.295815</td>
      <td>6529.119453</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>6175.622535</td>
      <td>6102.317245</td>
      <td>NaN</td>
      <td>6031.164261</td>
      <td>7045.621678</td>
      <td>6059.826087</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>6234.882649</td>
      <td>6049.884930</td>
      <td>6072.296659</td>
      <td>NaN</td>
      <td>6881.680392</td>
      <td>5969.259906</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>7471.621990</td>
      <td>8011.745229</td>
      <td>7161.400077</td>
      <td>7489.144374</td>
      <td>NaN</td>
      <td>7405.787239</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>6432.511946</td>
      <td>6420.917984</td>
      <td>5889.281400</td>
      <td>5774.891130</td>
      <td>7227.971735</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 6 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>destination_city</th>
      <th>Bangalore</th>
      <th>Chennai</th>
      <th>Delhi</th>
      <th>Hyderabad</th>
      <th>Kolkata</th>
      <th>Mumbai</th>
    </tr>
    <tr>
      <th>class</th>
      <th>source_city</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="6" valign="top">Business</th>
      <th>Bangalore</th>
      <td>NaN</td>
      <td>52436.915395</td>
      <td>48144.337108</td>
      <td>50395.796948</td>
      <td>58854.693091</td>
      <td>58024.618208</td>
    </tr>
    <tr>
      <th>Chennai</th>
      <td>53113.008692</td>
      <td>NaN</td>
      <td>52443.367242</td>
      <td>51559.874283</td>
      <td>57078.895872</td>
      <td>56223.838086</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>48576.027921</td>
      <td>52031.778099</td>
      <td>NaN</td>
      <td>44457.376775</td>
      <td>56239.853659</td>
      <td>44364.442811</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>50358.290706</td>
      <td>51132.155288</td>
      <td>44250.700281</td>
      <td>NaN</td>
      <td>53729.157762</td>
      <td>52184.424666</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>58681.104437</td>
      <td>56502.775035</td>
      <td>55047.492193</td>
      <td>54732.447908</td>
      <td>NaN</td>
      <td>57422.551724</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>57970.544389</td>
      <td>55703.326197</td>
      <td>43846.329273</td>
      <td>51593.643678</td>
      <td>57106.526385</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th rowspan="6" valign="top">Economy</th>
      <th>Bangalore</th>
      <td>NaN</td>
      <td>7105.953850</td>
      <td>6124.897982</td>
      <td>6360.141698</td>
      <td>7375.638594</td>
      <td>6381.093332</td>
    </tr>
    <tr>
      <th>Chennai</th>
      <td>7175.020192</td>
      <td>NaN</td>
      <td>6075.961190</td>
      <td>5960.788831</td>
      <td>7547.295815</td>
      <td>6529.119453</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>6175.622535</td>
      <td>6102.317245</td>
      <td>NaN</td>
      <td>6031.164261</td>
      <td>7045.621678</td>
      <td>6059.826087</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>6234.882649</td>
      <td>6049.884930</td>
      <td>6072.296659</td>
      <td>NaN</td>
      <td>6881.680392</td>
      <td>5969.259906</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>7471.621990</td>
      <td>8011.745229</td>
      <td>7161.400077</td>
      <td>7489.144374</td>
      <td>NaN</td>
      <td>7405.787239</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>6432.511946</td>
      <td>6420.917984</td>
      <td>5889.281400</td>
      <td>5774.891130</td>
      <td>7227.971735</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 6 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the average economy ticket prices for the different flight departure times within the day? Sort the values from earliest to latest times of the day.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>times = flights.where(flights['class'].eq('Economy')).groupby(['departure_time']).price.mean()
times = times.loc[['Early_Morning','Morning','Afternoon','Evening','Night','Late_Night']]
times</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>times = flights.where(flights['class'].eq('Economy')).groupby(['departure_time']).price.mean()
times = times.loc[['Early_Morning','Morning','Afternoon','Evening','Night','Late_Night']]
times</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>times = flights.where(flights['class'].eq('Economy')).groupby([
    'departure_time']).price.mean()
times = times.loc[['Early_Morning', 'Morning', 'Afternoon', 'Evening',
    'Night', 'Late_Night']]
__output__ = times
</code></pre>
        <p><span onclick="$('#var_output_43f6515b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_43f6515b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>departure_time
Early_Morning    6560.315392
Morning          7119.019664
Afternoon        6473.095872
Evening          6360.750741
Night            6205.964764
Late_Night       4784.699486
Name: price, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> times, __output__ </p>
    
          <p>times (Series):</p>
          <pre><code>departure_time
Early_Morning    6560.315392
Morning          7119.019664
Afternoon        6473.095872
Evening          6360.750741
Night            6205.964764
Late_Night       4784.699486
Name: price, dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>departure_time
Early_Morning    6560.315392
Morning          7119.019664
Afternoon        6473.095872
Evening          6360.750741
Night            6205.964764
Late_Night       4784.699486
Name: price, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the change in average economy ticket prices for every one day change in remaining days until the flight? Show the remaining days, current fare price, next day fare price and change in price.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>days_left_pricing = flights[flights['class']=='Economy'].groupby('days_left', as_index=False).price.mean()
days_left_pricing['next_day_price'] = days_left_pricing.price.shift(1)
days_left_pricing['next_day_price_change'] = days_left_pricing.eval('next_day_price - price')
days_left_pricing</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>days_left_pricing = flights[flights['class']=='Economy'].groupby('days_left', as_index=False).price.mean()
days_left_pricing['next_day_price'] = days_left_pricing.price.shift(1)
days_left_pricing['next_day_price_change'] = days_left_pricing.eval('next_day_price - price')
days_left_pricing</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>days_left_pricing = flights[flights['class'] == 'Economy'].groupby('days_left',
    as_index=False).price.mean()
days_left_pricing['next_day_price'] = days_left_pricing.price.shift(1)
days_left_pricing['next_day_price_change'] = days_left_pricing.eval(
    'next_day_price - price')
__output__ = days_left_pricing
</code></pre>
        <p><span onclick="$('#var_output_09a9970b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_09a9970b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>days_left</th>
      <th>price</th>
      <th>next_day_price</th>
      <th>next_day_price_change</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>14613.179410</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>13980.828244</td>
      <td>14613.179410</td>
      <td>632.351166</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>13174.050992</td>
      <td>13980.828244</td>
      <td>806.777253</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>10901.386284</td>
      <td>13174.050992</td>
      <td>2272.664708</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>10605.918315</td>
      <td>10901.386284</td>
      <td>295.467969</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>10319.679864</td>
      <td>10605.918315</td>
      <td>286.238451</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>10471.873164</td>
      <td>10319.679864</td>
      <td>-152.193301</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>42</th>
      <td>43</td>
      <td>4893.282565</td>
      <td>4783.826966</td>
      <td>-109.455599</td>
    </tr>
    <tr>
      <th>43</th>
      <td>44</td>
      <td>4890.226095</td>
      <td>4893.282565</td>
      <td>3.056470</td>
    </tr>
    <tr>
      <th>44</th>
      <td>45</td>
      <td>4908.194591</td>
      <td>4890.226095</td>
      <td>-17.968496</td>
    </tr>
    <tr>
      <th>45</th>
      <td>46</td>
      <td>4704.503549</td>
      <td>4908.194591</td>
      <td>203.691041</td>
    </tr>
    <tr>
      <th>46</th>
      <td>47</td>
      <td>4669.652956</td>
      <td>4704.503549</td>
      <td>34.850593</td>
    </tr>
    <tr>
      <th>47</th>
      <td>48</td>
      <td>4717.688994</td>
      <td>4669.652956</td>
      <td>-48.036038</td>
    </tr>
    <tr>
      <th>48</th>
      <td>49</td>
      <td>4750.805113</td>
      <td>4717.688994</td>
      <td>-33.116118</td>
    </tr>
  </tbody>
</table>
<p>49 rows × 4 columns</p>
      
        <p><strong>Hyp output variables:</strong> days_left_pricing, __output__ </p>
    
          <p>days_left_pricing (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>days_left</th>
      <th>price</th>
      <th>next_day_price</th>
      <th>next_day_price_change</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>14613.179410</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>13980.828244</td>
      <td>14613.179410</td>
      <td>632.351166</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>13174.050992</td>
      <td>13980.828244</td>
      <td>806.777253</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>10901.386284</td>
      <td>13174.050992</td>
      <td>2272.664708</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>10605.918315</td>
      <td>10901.386284</td>
      <td>295.467969</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>10319.679864</td>
      <td>10605.918315</td>
      <td>286.238451</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>10471.873164</td>
      <td>10319.679864</td>
      <td>-152.193301</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>42</th>
      <td>43</td>
      <td>4893.282565</td>
      <td>4783.826966</td>
      <td>-109.455599</td>
    </tr>
    <tr>
      <th>43</th>
      <td>44</td>
      <td>4890.226095</td>
      <td>4893.282565</td>
      <td>3.056470</td>
    </tr>
    <tr>
      <th>44</th>
      <td>45</td>
      <td>4908.194591</td>
      <td>4890.226095</td>
      <td>-17.968496</td>
    </tr>
    <tr>
      <th>45</th>
      <td>46</td>
      <td>4704.503549</td>
      <td>4908.194591</td>
      <td>203.691041</td>
    </tr>
    <tr>
      <th>46</th>
      <td>47</td>
      <td>4669.652956</td>
      <td>4704.503549</td>
      <td>34.850593</td>
    </tr>
    <tr>
      <th>47</th>
      <td>48</td>
      <td>4717.688994</td>
      <td>4669.652956</td>
      <td>-48.036038</td>
    </tr>
    <tr>
      <th>48</th>
      <td>49</td>
      <td>4750.805113</td>
      <td>4717.688994</td>
      <td>-33.116118</td>
    </tr>
  </tbody>
</table>
<p>49 rows × 4 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>days_left</th>
      <th>price</th>
      <th>next_day_price</th>
      <th>next_day_price_change</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>14613.179410</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>13980.828244</td>
      <td>14613.179410</td>
      <td>632.351166</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>13174.050992</td>
      <td>13980.828244</td>
      <td>806.777253</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>10901.386284</td>
      <td>13174.050992</td>
      <td>2272.664708</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>10605.918315</td>
      <td>10901.386284</td>
      <td>295.467969</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>10319.679864</td>
      <td>10605.918315</td>
      <td>286.238451</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>10471.873164</td>
      <td>10319.679864</td>
      <td>-152.193301</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>42</th>
      <td>43</td>
      <td>4893.282565</td>
      <td>4783.826966</td>
      <td>-109.455599</td>
    </tr>
    <tr>
      <th>43</th>
      <td>44</td>
      <td>4890.226095</td>
      <td>4893.282565</td>
      <td>3.056470</td>
    </tr>
    <tr>
      <th>44</th>
      <td>45</td>
      <td>4908.194591</td>
      <td>4890.226095</td>
      <td>-17.968496</td>
    </tr>
    <tr>
      <th>45</th>
      <td>46</td>
      <td>4704.503549</td>
      <td>4908.194591</td>
      <td>203.691041</td>
    </tr>
    <tr>
      <th>46</th>
      <td>47</td>
      <td>4669.652956</td>
      <td>4704.503549</td>
      <td>34.850593</td>
    </tr>
    <tr>
      <th>47</th>
      <td>48</td>
      <td>4717.688994</td>
      <td>4669.652956</td>
      <td>-48.036038</td>
    </tr>
    <tr>
      <th>48</th>
      <td>49</td>
      <td>4750.805113</td>
      <td>4717.688994</td>
      <td>-33.116118</td>
    </tr>
  </tbody>
</table>
<p>49 rows × 4 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Replace the values of departure times, arrival times and number of stops to numeric values based on their ordinality. Return a dataset 'new_flights' with the replaced values.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>replace_values_time = {'Early_Morning':1, 'Morning':2,'Afternoon':3,'Evening':4,'Night':5,'Late_Night':6 }
replace_values_stops = {'zero':0, 'one':1,'two_or_more':2 }

new_flights = flights.replace({'departure_time' : replace_values_time})
new_flights = new_flights.replace({'arrival_time' : replace_values_time})
new_flights = new_flights.replace({'stops' : replace_values_stops})
new_flights</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>replace_values_time = {'Early_Morning':1, 'Morning':2,'Afternoon':3,'Evening':4,'Night':5,'Late_Night':6 }
replace_values_stops = {'zero':0, 'one':1,'two_or_more':2 }

new_flights = flights.replace({'departure_time' : replace_values_time})
new_flights = new_flights.replace({'arrival_time' : replace_values_time})
new_flights = new_flights.replace({'stops' : replace_values_stops})
new_flights</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>replace_values_time = {'Early_Morning': 1, 'Morning': 2, 'Afternoon': 3,
    'Evening': 4, 'Night': 5, 'Late_Night': 6}
replace_values_stops = {'zero': 0, 'one': 1, 'two_or_more': 2}
new_flights = flights.replace({'departure_time': replace_values_time})
new_flights = new_flights.replace({'arrival_time': replace_values_time})
new_flights = new_flights.replace({'stops': replace_values_stops})
__output__ = new_flights
</code></pre>
        <p><span onclick="$('#var_output_cbdbd9be').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_cbdbd9be" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airline</th>
      <th>flight</th>
      <th>source_city</th>
      <th>departure_time</th>
      <th>stops</th>
      <th>arrival_time</th>
      <th>destination_city</th>
      <th>class</th>
      <th>duration</th>
      <th>days_left</th>
      <th>price</th>
      <th>duration_bucket</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SpiceJet</td>
      <td>SG-8709</td>
      <td>Delhi</td>
      <td>4</td>
      <td>0</td>
      <td>5</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.17</td>
      <td>1</td>
      <td>5953</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SpiceJet</td>
      <td>SG-8157</td>
      <td>Delhi</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5953</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AirAsia</td>
      <td>I5-764</td>
      <td>Delhi</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.17</td>
      <td>1</td>
      <td>5956</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vistara</td>
      <td>UK-995</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.25</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Vistara</td>
      <td>UK-963</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Vistara</td>
      <td>UK-945</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Vistara</td>
      <td>UK-927</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.08</td>
      <td>1</td>
      <td>6060</td>
      <td>2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>300146</th>
      <td>Air_India</td>
      <td>AI-440</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>26.83</td>
      <td>49</td>
      <td>51345</td>
      <td>27</td>
    </tr>
    <tr>
      <th>300147</th>
      <td>Air_India</td>
      <td>AI-569</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>17.25</td>
      <td>49</td>
      <td>68739</td>
      <td>17</td>
    </tr>
    <tr>
      <th>300148</th>
      <td>Vistara</td>
      <td>UK-822</td>
      <td>Chennai</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.08</td>
      <td>49</td>
      <td>69265</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300149</th>
      <td>Vistara</td>
      <td>UK-826</td>
      <td>Chennai</td>
      <td>3</td>
      <td>1</td>
      <td>5</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.42</td>
      <td>49</td>
      <td>77105</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300150</th>
      <td>Vistara</td>
      <td>UK-832</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>13.83</td>
      <td>49</td>
      <td>79099</td>
      <td>14</td>
    </tr>
    <tr>
      <th>300151</th>
      <td>Vistara</td>
      <td>UK-828</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.00</td>
      <td>49</td>
      <td>81585</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300152</th>
      <td>Vistara</td>
      <td>UK-822</td>
      <td>Chennai</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.08</td>
      <td>49</td>
      <td>81585</td>
      <td>10</td>
    </tr>
  </tbody>
</table>
<p>300153 rows × 12 columns</p>
      
        <p><strong>Hyp output variables:</strong> new_flights, __output__ </p>
    
          <p>new_flights (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airline</th>
      <th>flight</th>
      <th>source_city</th>
      <th>departure_time</th>
      <th>stops</th>
      <th>arrival_time</th>
      <th>destination_city</th>
      <th>class</th>
      <th>duration</th>
      <th>days_left</th>
      <th>price</th>
      <th>duration_bucket</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SpiceJet</td>
      <td>SG-8709</td>
      <td>Delhi</td>
      <td>4</td>
      <td>0</td>
      <td>5</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.17</td>
      <td>1</td>
      <td>5953</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SpiceJet</td>
      <td>SG-8157</td>
      <td>Delhi</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5953</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AirAsia</td>
      <td>I5-764</td>
      <td>Delhi</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.17</td>
      <td>1</td>
      <td>5956</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vistara</td>
      <td>UK-995</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.25</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Vistara</td>
      <td>UK-963</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Vistara</td>
      <td>UK-945</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Vistara</td>
      <td>UK-927</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.08</td>
      <td>1</td>
      <td>6060</td>
      <td>2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>300146</th>
      <td>Air_India</td>
      <td>AI-440</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>26.83</td>
      <td>49</td>
      <td>51345</td>
      <td>27</td>
    </tr>
    <tr>
      <th>300147</th>
      <td>Air_India</td>
      <td>AI-569</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>17.25</td>
      <td>49</td>
      <td>68739</td>
      <td>17</td>
    </tr>
    <tr>
      <th>300148</th>
      <td>Vistara</td>
      <td>UK-822</td>
      <td>Chennai</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.08</td>
      <td>49</td>
      <td>69265</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300149</th>
      <td>Vistara</td>
      <td>UK-826</td>
      <td>Chennai</td>
      <td>3</td>
      <td>1</td>
      <td>5</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.42</td>
      <td>49</td>
      <td>77105</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300150</th>
      <td>Vistara</td>
      <td>UK-832</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>13.83</td>
      <td>49</td>
      <td>79099</td>
      <td>14</td>
    </tr>
    <tr>
      <th>300151</th>
      <td>Vistara</td>
      <td>UK-828</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.00</td>
      <td>49</td>
      <td>81585</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300152</th>
      <td>Vistara</td>
      <td>UK-822</td>
      <td>Chennai</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.08</td>
      <td>49</td>
      <td>81585</td>
      <td>10</td>
    </tr>
  </tbody>
</table>
<p>300153 rows × 12 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airline</th>
      <th>flight</th>
      <th>source_city</th>
      <th>departure_time</th>
      <th>stops</th>
      <th>arrival_time</th>
      <th>destination_city</th>
      <th>class</th>
      <th>duration</th>
      <th>days_left</th>
      <th>price</th>
      <th>duration_bucket</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SpiceJet</td>
      <td>SG-8709</td>
      <td>Delhi</td>
      <td>4</td>
      <td>0</td>
      <td>5</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.17</td>
      <td>1</td>
      <td>5953</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SpiceJet</td>
      <td>SG-8157</td>
      <td>Delhi</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5953</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AirAsia</td>
      <td>I5-764</td>
      <td>Delhi</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.17</td>
      <td>1</td>
      <td>5956</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vistara</td>
      <td>UK-995</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.25</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Vistara</td>
      <td>UK-963</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Vistara</td>
      <td>UK-945</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Vistara</td>
      <td>UK-927</td>
      <td>Delhi</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.08</td>
      <td>1</td>
      <td>6060</td>
      <td>2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>300146</th>
      <td>Air_India</td>
      <td>AI-440</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>26.83</td>
      <td>49</td>
      <td>51345</td>
      <td>27</td>
    </tr>
    <tr>
      <th>300147</th>
      <td>Air_India</td>
      <td>AI-569</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>17.25</td>
      <td>49</td>
      <td>68739</td>
      <td>17</td>
    </tr>
    <tr>
      <th>300148</th>
      <td>Vistara</td>
      <td>UK-822</td>
      <td>Chennai</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.08</td>
      <td>49</td>
      <td>69265</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300149</th>
      <td>Vistara</td>
      <td>UK-826</td>
      <td>Chennai</td>
      <td>3</td>
      <td>1</td>
      <td>5</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.42</td>
      <td>49</td>
      <td>77105</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300150</th>
      <td>Vistara</td>
      <td>UK-832</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>13.83</td>
      <td>49</td>
      <td>79099</td>
      <td>14</td>
    </tr>
    <tr>
      <th>300151</th>
      <td>Vistara</td>
      <td>UK-828</td>
      <td>Chennai</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.00</td>
      <td>49</td>
      <td>81585</td>
      <td>10</td>
    </tr>
    <tr>
      <th>300152</th>
      <td>Vistara</td>
      <td>UK-822</td>
      <td>Chennai</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.08</td>
      <td>49</td>
      <td>81585</td>
      <td>10</td>
    </tr>
  </tbody>
</table>
<p>300153 rows × 12 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the correlation between departure time, arrival time, number of stops and price for economy tickets?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>corr_matrix = new_flights[new_flights['class'] == 'Economy'][['departure_time','arrival_time','stops','price']].corr()
corr_matrix.loc[['departure_time','arrival_time','stops'], 'price']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>corr_matrix = new_flights[new_flights['class'] == 'Economy'][['departure_time','arrival_time','stops','price']].corr()
corr_matrix.loc[['departure_time','arrival_time','stops'], 'price']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>corr_matrix = new_flights[new_flights['class'] == 'Economy'][[
    'departure_time', 'arrival_time', 'stops', 'price']].corr()
__output__ = corr_matrix.loc[['departure_time', 'arrival_time', 'stops'],
    'price']
</code></pre>
        <p><span onclick="$('#var_output_b38aac50').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b38aac50" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>departure_time   -0.058540
arrival_time      0.034687
stops             0.306168
Name: price, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> corr_matrix, __output__ </p>
    
          <p>corr_matrix (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>departure_time</th>
      <th>arrival_time</th>
      <th>stops</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>departure_time</th>
      <td>1.000000</td>
      <td>-0.015645</td>
      <td>-0.085084</td>
      <td>-0.058540</td>
    </tr>
    <tr>
      <th>arrival_time</th>
      <td>-0.015645</td>
      <td>1.000000</td>
      <td>0.053558</td>
      <td>0.034687</td>
    </tr>
    <tr>
      <th>stops</th>
      <td>-0.085084</td>
      <td>0.053558</td>
      <td>1.000000</td>
      <td>0.306168</td>
    </tr>
    <tr>
      <th>price</th>
      <td>-0.058540</td>
      <td>0.034687</td>
      <td>0.306168</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 4 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>departure_time   -0.058540
arrival_time      0.034687
stops             0.306168
Name: price, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average duration to and from all the cities for each airline? Return a dataframe with the airlines and departure cities as a nested index and destination cities as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>flights.groupby(['airline', 'source_city', 'destination_city']).duration.mean().unstack(level=-1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>flights.groupby(['airline', 'source_city', 'destination_city']).duration.mean().unstack(level=-1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = flights.groupby(['airline', 'source_city', 'destination_city']
    ).duration.mean().unstack(level=-1)
</code></pre>
        <p><span onclick="$('#var_output_26de26b2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_26de26b2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>destination_city</th>
      <th>Bangalore</th>
      <th>Chennai</th>
      <th>Delhi</th>
      <th>Hyderabad</th>
      <th>Kolkata</th>
      <th>Mumbai</th>
    </tr>
    <tr>
      <th>airline</th>
      <th>source_city</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="6" valign="top">AirAsia</th>
      <th>Bangalore</th>
      <td>NaN</td>
      <td>1.040000</td>
      <td>8.082323</td>
      <td>3.618490</td>
      <td>7.557064</td>
      <td>8.316338</td>
    </tr>
    <tr>
      <th>Chennai</th>
      <td>1.175435</td>
      <td>NaN</td>
      <td>11.963182</td>
      <td>6.801825</td>
      <td>6.310651</td>
      <td>8.745227</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>8.460626</td>
      <td>11.102472</td>
      <td>NaN</td>
      <td>9.191525</td>
      <td>9.523398</td>
      <td>10.318877</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>5.570248</td>
      <td>8.316081</td>
      <td>9.424044</td>
      <td>NaN</td>
      <td>7.957985</td>
      <td>9.408268</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>9.472004</td>
      <td>6.787566</td>
      <td>10.748960</td>
      <td>9.230570</td>
      <td>NaN</td>
      <td>11.204203</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>9.200566</td>
      <td>9.593153</td>
      <td>9.151826</td>
      <td>11.107454</td>
      <td>9.925918</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Air_India</th>
      <th>Bangalore</th>
      <td>NaN</td>
      <td>17.029416</td>
      <td>13.020543</td>
      <td>17.226683</td>
      <td>16.937957</td>
      <td>14.584343</td>
    </tr>
    <tr>
      <th>...</th>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>SpiceJet</th>
      <th>Mumbai</th>
      <td>14.940423</td>
      <td>5.046988</td>
      <td>6.601302</td>
      <td>NaN</td>
      <td>16.830987</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th rowspan="6" valign="top">Vistara</th>
      <th>Bangalore</th>
      <td>NaN</td>
      <td>15.436509</td>
      <td>10.176860</td>
      <td>16.281396</td>
      <td>15.493396</td>
      <td>11.016113</td>
    </tr>
    <tr>
      <th>Chennai</th>
      <td>14.630623</td>
      <td>NaN</td>
      <td>11.706946</td>
      <td>16.568437</td>
      <td>17.568271</td>
      <td>12.228224</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>10.130556</td>
      <td>12.555719</td>
      <td>NaN</td>
      <td>13.396560</td>
      <td>14.765734</td>
      <td>10.323137</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>14.116658</td>
      <td>16.043455</td>
      <td>11.473012</td>
      <td>NaN</td>
      <td>16.217327</td>
      <td>11.854125</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>16.170220</td>
      <td>17.605375</td>
      <td>12.798752</td>
      <td>16.879139</td>
      <td>NaN</td>
      <td>13.078342</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>11.691841</td>
      <td>13.742820</td>
      <td>9.772892</td>
      <td>13.214334</td>
      <td>13.267275</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>36 rows × 6 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>destination_city</th>
      <th>Bangalore</th>
      <th>Chennai</th>
      <th>Delhi</th>
      <th>Hyderabad</th>
      <th>Kolkata</th>
      <th>Mumbai</th>
    </tr>
    <tr>
      <th>airline</th>
      <th>source_city</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="6" valign="top">AirAsia</th>
      <th>Bangalore</th>
      <td>NaN</td>
      <td>1.040000</td>
      <td>8.082323</td>
      <td>3.618490</td>
      <td>7.557064</td>
      <td>8.316338</td>
    </tr>
    <tr>
      <th>Chennai</th>
      <td>1.175435</td>
      <td>NaN</td>
      <td>11.963182</td>
      <td>6.801825</td>
      <td>6.310651</td>
      <td>8.745227</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>8.460626</td>
      <td>11.102472</td>
      <td>NaN</td>
      <td>9.191525</td>
      <td>9.523398</td>
      <td>10.318877</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>5.570248</td>
      <td>8.316081</td>
      <td>9.424044</td>
      <td>NaN</td>
      <td>7.957985</td>
      <td>9.408268</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>9.472004</td>
      <td>6.787566</td>
      <td>10.748960</td>
      <td>9.230570</td>
      <td>NaN</td>
      <td>11.204203</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>9.200566</td>
      <td>9.593153</td>
      <td>9.151826</td>
      <td>11.107454</td>
      <td>9.925918</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Air_India</th>
      <th>Bangalore</th>
      <td>NaN</td>
      <td>17.029416</td>
      <td>13.020543</td>
      <td>17.226683</td>
      <td>16.937957</td>
      <td>14.584343</td>
    </tr>
    <tr>
      <th>...</th>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>SpiceJet</th>
      <th>Mumbai</th>
      <td>14.940423</td>
      <td>5.046988</td>
      <td>6.601302</td>
      <td>NaN</td>
      <td>16.830987</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th rowspan="6" valign="top">Vistara</th>
      <th>Bangalore</th>
      <td>NaN</td>
      <td>15.436509</td>
      <td>10.176860</td>
      <td>16.281396</td>
      <td>15.493396</td>
      <td>11.016113</td>
    </tr>
    <tr>
      <th>Chennai</th>
      <td>14.630623</td>
      <td>NaN</td>
      <td>11.706946</td>
      <td>16.568437</td>
      <td>17.568271</td>
      <td>12.228224</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>10.130556</td>
      <td>12.555719</td>
      <td>NaN</td>
      <td>13.396560</td>
      <td>14.765734</td>
      <td>10.323137</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>14.116658</td>
      <td>16.043455</td>
      <td>11.473012</td>
      <td>NaN</td>
      <td>16.217327</td>
      <td>11.854125</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>16.170220</td>
      <td>17.605375</td>
      <td>12.798752</td>
      <td>16.879139</td>
      <td>NaN</td>
      <td>13.078342</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>11.691841</td>
      <td>13.742820</td>
      <td>9.772892</td>
      <td>13.214334</td>
      <td>13.267275</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>36 rows × 6 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the city that has the highest number of incoming flights? How many incoming flights does each airline have for that city with one week left until departure? Show the city name, airline and number of incoming flights.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>max_incoming_city = flights.groupby('destination_city').flight.nunique().idxmax()
city_airlines = flights[(flights.destination_city==max_incoming_city) & (flights.days_left<=7)].groupby('airline').flight.nunique().reset_index()
city_airlines.insert(0,'city',max_incoming_city)
city_airlines</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>max_incoming_city = flights.groupby('destination_city').flight.nunique().idxmax()
city_airlines = flights[(flights.destination_city==max_incoming_city) & (flights.days_left<=7)].groupby('airline').flight.nunique().reset_index()
city_airlines.insert(0,'city',max_incoming_city)
city_airlines</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>max_incoming_city = flights.groupby('destination_city').flight.nunique(
    ).idxmax()
city_airlines = flights[(flights.destination_city == max_incoming_city) & (
    flights.days_left <= 7)].groupby('airline').flight.nunique().reset_index()
__tmp_2 = city_airlines.insert(0, 'city', max_incoming_city)
__output__ = city_airlines
</code></pre>
        <p><span onclick="$('#var_output_2b2abd3e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2b2abd3e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>city</th>
      <th>airline</th>
      <th>flight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Kolkata</td>
      <td>AirAsia</td>
      <td>39</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Kolkata</td>
      <td>Air_India</td>
      <td>106</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Kolkata</td>
      <td>GO_FIRST</td>
      <td>48</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Kolkata</td>
      <td>Indigo</td>
      <td>227</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Kolkata</td>
      <td>SpiceJet</td>
      <td>44</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Kolkata</td>
      <td>Vistara</td>
      <td>98</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> max_incoming_city, city_airlines, __output__ </p>
    
          <p>max_incoming_city (str):</p>
          <pre><code>Kolkata</code></pre>
      
          <p>city_airlines (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>city</th>
      <th>airline</th>
      <th>flight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Kolkata</td>
      <td>AirAsia</td>
      <td>39</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Kolkata</td>
      <td>Air_India</td>
      <td>106</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Kolkata</td>
      <td>GO_FIRST</td>
      <td>48</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Kolkata</td>
      <td>Indigo</td>
      <td>227</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Kolkata</td>
      <td>SpiceJet</td>
      <td>44</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Kolkata</td>
      <td>Vistara</td>
      <td>98</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>city</th>
      <th>airline</th>
      <th>flight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Kolkata</td>
      <td>AirAsia</td>
      <td>39</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Kolkata</td>
      <td>Air_India</td>
      <td>106</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Kolkata</td>
      <td>GO_FIRST</td>
      <td>48</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Kolkata</td>
      <td>Indigo</td>
      <td>227</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Kolkata</td>
      <td>SpiceJet</td>
      <td>44</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Kolkata</td>
      <td>Vistara</td>
      <td>98</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent change in fare prices of Economy tickets destined to Delhi for each decrease in week's time left until the flight?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>flights['weeks_left'] = flights.days_left // 7
flights[(flights['destination_city']=='Delhi') & (flights['class']=='Economy')].groupby('weeks_left').price.mean().sort_index(ascending=False).pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>flights['weeks_left'] = flights.days_left // 7
flights[(flights['destination_city']=='Delhi') & (flights['class']=='Economy')].groupby('weeks_left').price.mean().sort_index(ascending=False).pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>flights['weeks_left'] = flights.days_left // 7
__output__ = flights[(flights['destination_city'] == 'Delhi') & (flights[
    'class'] == 'Economy')].groupby('weeks_left').price.mean().sort_index(
    ascending=False).pct_change()
</code></pre>
        <p><span onclick="$('#var_output_ccf93e34').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ccf93e34" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>weeks_left
7         NaN
6    0.008270
5    0.057136
4   -0.007450
3    0.019372
2    0.280326
1    0.614824
0    0.156701
Name: price, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> flights, __output__ </p>
    
          <p>flights (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airline</th>
      <th>flight</th>
      <th>source_city</th>
      <th>departure_time</th>
      <th>stops</th>
      <th>arrival_time</th>
      <th>destination_city</th>
      <th>class</th>
      <th>duration</th>
      <th>days_left</th>
      <th>price</th>
      <th>duration_bucket</th>
      <th>weeks_left</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SpiceJet</td>
      <td>SG-8709</td>
      <td>Delhi</td>
      <td>Evening</td>
      <td>zero</td>
      <td>Night</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.17</td>
      <td>1</td>
      <td>5953</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SpiceJet</td>
      <td>SG-8157</td>
      <td>Delhi</td>
      <td>Early_Morning</td>
      <td>zero</td>
      <td>Morning</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5953</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AirAsia</td>
      <td>I5-764</td>
      <td>Delhi</td>
      <td>Early_Morning</td>
      <td>zero</td>
      <td>Early_Morning</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.17</td>
      <td>1</td>
      <td>5956</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vistara</td>
      <td>UK-995</td>
      <td>Delhi</td>
      <td>Morning</td>
      <td>zero</td>
      <td>Afternoon</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.25</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Vistara</td>
      <td>UK-963</td>
      <td>Delhi</td>
      <td>Morning</td>
      <td>zero</td>
      <td>Morning</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Vistara</td>
      <td>UK-945</td>
      <td>Delhi</td>
      <td>Morning</td>
      <td>zero</td>
      <td>Afternoon</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.33</td>
      <td>1</td>
      <td>5955</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Vistara</td>
      <td>UK-927</td>
      <td>Delhi</td>
      <td>Morning</td>
      <td>zero</td>
      <td>Morning</td>
      <td>Mumbai</td>
      <td>Economy</td>
      <td>2.08</td>
      <td>1</td>
      <td>6060</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>300146</th>
      <td>Air_India</td>
      <td>AI-440</td>
      <td>Chennai</td>
      <td>Early_Morning</td>
      <td>one</td>
      <td>Morning</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>26.83</td>
      <td>49</td>
      <td>51345</td>
      <td>27</td>
      <td>7</td>
    </tr>
    <tr>
      <th>300147</th>
      <td>Air_India</td>
      <td>AI-569</td>
      <td>Chennai</td>
      <td>Early_Morning</td>
      <td>one</td>
      <td>Night</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>17.25</td>
      <td>49</td>
      <td>68739</td>
      <td>17</td>
      <td>7</td>
    </tr>
    <tr>
      <th>300148</th>
      <td>Vistara</td>
      <td>UK-822</td>
      <td>Chennai</td>
      <td>Morning</td>
      <td>one</td>
      <td>Evening</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.08</td>
      <td>49</td>
      <td>69265</td>
      <td>10</td>
      <td>7</td>
    </tr>
    <tr>
      <th>300149</th>
      <td>Vistara</td>
      <td>UK-826</td>
      <td>Chennai</td>
      <td>Afternoon</td>
      <td>one</td>
      <td>Night</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.42</td>
      <td>49</td>
      <td>77105</td>
      <td>10</td>
      <td>7</td>
    </tr>
    <tr>
      <th>300150</th>
      <td>Vistara</td>
      <td>UK-832</td>
      <td>Chennai</td>
      <td>Early_Morning</td>
      <td>one</td>
      <td>Night</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>13.83</td>
      <td>49</td>
      <td>79099</td>
      <td>14</td>
      <td>7</td>
    </tr>
    <tr>
      <th>300151</th>
      <td>Vistara</td>
      <td>UK-828</td>
      <td>Chennai</td>
      <td>Early_Morning</td>
      <td>one</td>
      <td>Evening</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.00</td>
      <td>49</td>
      <td>81585</td>
      <td>10</td>
      <td>7</td>
    </tr>
    <tr>
      <th>300152</th>
      <td>Vistara</td>
      <td>UK-822</td>
      <td>Chennai</td>
      <td>Morning</td>
      <td>one</td>
      <td>Evening</td>
      <td>Hyderabad</td>
      <td>Business</td>
      <td>10.08</td>
      <td>49</td>
      <td>81585</td>
      <td>10</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
<p>300153 rows × 13 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>weeks_left
7         NaN
6    0.008270
5    0.057136
4   -0.007450
3    0.019372
2    0.280326
1    0.614824
0    0.156701
Name: price, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_11 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total number of departing journeys available during each time of the day to Bangalore from all other cities? Return a dataframe with cities as an index and times of the day as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>journeys = flights.groupby(['destination_city','source_city','departure_time']).flight.nunique()
journeys.unstack(-1, fill_value=0).loc[('Bangalore')]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>journeys = flights.groupby(['destination_city','source_city','departure_time']).flight.nunique()
journeys.unstack(-1, fill_value=0).loc[('Bangalore')]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>journeys = flights.groupby(['destination_city', 'source_city',
    'departure_time']).flight.nunique()
__output__ = journeys.unstack(-1, fill_value=0).loc['Bangalore']
</code></pre>
        <p><span onclick="$('#var_output_674937b4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_674937b4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>departure_time</th>
      <th>Afternoon</th>
      <th>Early_Morning</th>
      <th>Evening</th>
      <th>Late_Night</th>
      <th>Morning</th>
      <th>Night</th>
    </tr>
    <tr>
      <th>source_city</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Chennai</th>
      <td>16</td>
      <td>10</td>
      <td>11</td>
      <td>0</td>
      <td>9</td>
      <td>10</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>50</td>
      <td>56</td>
      <td>64</td>
      <td>4</td>
      <td>53</td>
      <td>29</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>14</td>
      <td>18</td>
      <td>16</td>
      <td>0</td>
      <td>21</td>
      <td>15</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>24</td>
      <td>26</td>
      <td>24</td>
      <td>0</td>
      <td>21</td>
      <td>18</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>34</td>
      <td>44</td>
      <td>38</td>
      <td>1</td>
      <td>33</td>
      <td>32</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 6 columns</p>
      
        <p><strong>Hyp output variables:</strong> journeys, __output__ </p>
    
          <p>journeys (Series):</p>
          <pre><code>destination_city  source_city  departure_time
Bangalore         Chennai      Afternoon         16
                               Early_Morning     10
                               Evening           11
                               Morning            9
                               Night             10
                                                 ..
Mumbai            Kolkata      Early_Morning     21
                               Evening           22
                               Late_Night         1
                               Morning           28
                               Night             17
Name: flight, Length: 168, dtype: int64</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>departure_time</th>
      <th>Afternoon</th>
      <th>Early_Morning</th>
      <th>Evening</th>
      <th>Late_Night</th>
      <th>Morning</th>
      <th>Night</th>
    </tr>
    <tr>
      <th>source_city</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Chennai</th>
      <td>16</td>
      <td>10</td>
      <td>11</td>
      <td>0</td>
      <td>9</td>
      <td>10</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>50</td>
      <td>56</td>
      <td>64</td>
      <td>4</td>
      <td>53</td>
      <td>29</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>14</td>
      <td>18</td>
      <td>16</td>
      <td>0</td>
      <td>21</td>
      <td>15</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>24</td>
      <td>26</td>
      <td>24</td>
      <td>0</td>
      <td>21</td>
      <td>18</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>34</td>
      <td>44</td>
      <td>38</td>
      <td>1</td>
      <td>33</td>
      <td>32</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 6 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> flight-price-prediction/notebook_1.ipynb|||turn_12 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the least expensive time of the day to depart to Chennai in Economy class across all airlines? Show the time of the day and the fare price for each airline.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>day_prices = flights[(flights['class']=='Economy') & (flights['destination_city']=='Chennai')].groupby(['airline','departure_time']).price.mean()
pd.DataFrame(pd.concat([day_prices.unstack(0).idxmin(), day_prices.unstack(0).min()], axis=1).reset_index().values, columns=['airline','departure_time','price'])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>day_prices = flights[(flights['class']=='Economy') & (flights['destination_city']=='Chennai')].groupby(['airline','departure_time']).price.mean()
pd.DataFrame(pd.concat([day_prices.unstack(0).idxmin(), day_prices.unstack(0).min()], axis=1).reset_index().values, columns=['airline','departure_time','price'])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>day_prices = flights[(flights['class'] == 'Economy') & (flights[
    'destination_city'] == 'Chennai')].groupby(['airline', 'departure_time']
    ).price.mean()
__output__ = pd.DataFrame(pd.concat([day_prices.unstack(0).idxmin(),
    day_prices.unstack(0).min()], axis=1).reset_index().values, columns=[
    'airline', 'departure_time', 'price'])
</code></pre>
        <p><span onclick="$('#var_output_82eae44a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_82eae44a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airline</th>
      <th>departure_time</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AirAsia</td>
      <td>Night</td>
      <td>3224.4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Air_India</td>
      <td>Evening</td>
      <td>6985.887306</td>
    </tr>
    <tr>
      <th>2</th>
      <td>GO_FIRST</td>
      <td>Early_Morning</td>
      <td>4340.609756</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Indigo</td>
      <td>Night</td>
      <td>3898.84975</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SpiceJet</td>
      <td>Afternoon</td>
      <td>4371.727273</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Vistara</td>
      <td>Night</td>
      <td>7163.970494</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> day_prices, __output__ </p>
    
          <p>day_prices (Series):</p>
          <pre><code>airline  departure_time
AirAsia  Afternoon         3270.094675
         Early_Morning     3651.813559
         Evening           3605.297468
         Morning           3250.615672
         Night             3224.400000
                              ...     
Vistara  Afternoon         7912.816062
         Early_Morning     8265.135208
         Evening           7638.293002
         Morning           8866.578768
         Night             7163.970494
Name: price, Length: 33, dtype: float64</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airline</th>
      <th>departure_time</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AirAsia</td>
      <td>Night</td>
      <td>3224.4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Air_India</td>
      <td>Evening</td>
      <td>6985.887306</td>
    </tr>
    <tr>
      <th>2</th>
      <td>GO_FIRST</td>
      <td>Early_Morning</td>
      <td>4340.609756</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Indigo</td>
      <td>Night</td>
      <td>3898.84975</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SpiceJet</td>
      <td>Afternoon</td>
      <td>4371.727273</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Vistara</td>
      <td>Night</td>
      <td>7163.970494</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> latest-laptop-price-list/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the incorrect data types of numeric columns into numeric format, neglecting redundant units and modifiers within these columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>numeric_columns = ['processor_gnrtn', 'ram_gb', 'ssd', 'hdd', 'os_bit', 'display_size']

for column in numeric_columns:
  laptop[column] = pd.to_numeric(laptop[column].str.replace('missing|gb|th| |-bit', '', case=False))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>numeric_columns = ['processor_gnrtn', 'ram_gb', 'ssd', 'hdd', 'os_bit', 'display_size']

for column in numeric_columns:
  laptop[column] = pd.to_numeric(laptop[column].str.replace('missing|gb|th| |-bit', '', case=False))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>numeric_columns = ['processor_gnrtn', 'ram_gb', 'ssd', 'hdd', 'os_bit',
    'display_size']
for column in numeric_columns:
    laptop[column] = pd.to_numeric(laptop[column].str.replace(
        'missing|gb|th| |-bit', '', case=False))
</code></pre>
        <p><span onclick="$('#var_output_bd55a904').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bd55a904" style="display: none;">
          
        <p><strong>Ref output variables:</strong> laptop </p>
    
          <p>laptop (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>brand</th>
      <th>model</th>
      <th>processor_brand</th>
      <th>processor_name</th>
      <th>processor_gnrtn</th>
      <th>ram_gb</th>
      <th>ram_type</th>
      <th>...</th>
      <th>msoffice</th>
      <th>latest_price</th>
      <th>old_price</th>
      <th>discount</th>
      <th>star_rating</th>
      <th>ratings</th>
      <th>reviews</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Lenovo</td>
      <td>A6-9225</td>
      <td>AMD</td>
      <td>A6-9225 Processor</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>24990</td>
      <td>32790</td>
      <td>23</td>
      <td>3.7</td>
      <td>63</td>
      <td>12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Lenovo</td>
      <td>Ideapad</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>19590</td>
      <td>21325</td>
      <td>8</td>
      <td>3.6</td>
      <td>1894</td>
      <td>256</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Avita</td>
      <td>PURA</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>19990</td>
      <td>27990</td>
      <td>28</td>
      <td>3.7</td>
      <td>1153</td>
      <td>159</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Avita</td>
      <td>PURA</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>21490</td>
      <td>27990</td>
      <td>23</td>
      <td>3.7</td>
      <td>1153</td>
      <td>159</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Avita</td>
      <td>PURA</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>24990</td>
      <td>33490</td>
      <td>25</td>
      <td>3.7</td>
      <td>1657</td>
      <td>234</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Avita</td>
      <td>PURA</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>8</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>24990</td>
      <td>33490</td>
      <td>25</td>
      <td>3.7</td>
      <td>1657</td>
      <td>234</td>
    </tr>
    <tr>
      <th>6</th>
      <td>HP</td>
      <td>APU</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>20900</td>
      <td>22825</td>
      <td>8</td>
      <td>3.9</td>
      <td>1185</td>
      <td>141</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>889</th>
      <td>ASUS</td>
      <td>ROG</td>
      <td>AMD</td>
      <td>Ryzen 9</td>
      <td>NaN</td>
      <td>4</td>
      <td>LPDDR4X</td>
      <td>...</td>
      <td>Yes</td>
      <td>234990</td>
      <td>350990</td>
      <td>33</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>890</th>
      <td>ASUS</td>
      <td>ROG</td>
      <td>AMD</td>
      <td>Ryzen 9</td>
      <td>NaN</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>135990</td>
      <td>172990</td>
      <td>21</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>891</th>
      <td>ASUS</td>
      <td>ROG</td>
      <td>AMD</td>
      <td>Ryzen 9</td>
      <td>NaN</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>144990</td>
      <td>194990</td>
      <td>25</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>892</th>
      <td>ASUS</td>
      <td>Ryzen</td>
      <td>AMD</td>
      <td>Ryzen 9</td>
      <td>NaN</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>149990</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>893</th>
      <td>ASUS</td>
      <td>Ryzen</td>
      <td>AMD</td>
      <td>Ryzen 9</td>
      <td>NaN</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>142990</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>894</th>
      <td>SAMSUNG</td>
      <td>Galaxy</td>
      <td>Qualcomm</td>
      <td>Snapdragon 7c</td>
      <td>NaN</td>
      <td>4</td>
      <td>LPDDR4X</td>
      <td>...</td>
      <td>No</td>
      <td>38990</td>
      <td>47990</td>
      <td>18</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>895</th>
      <td>Lenovo</td>
      <td>Thinkpad</td>
      <td>AMD</td>
      <td>Ryzen 5</td>
      <td>10.0</td>
      <td>8</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>57490</td>
      <td>78400</td>
      <td>26</td>
      <td>4.2</td>
      <td>18</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>896 rows × 23 columns</p>
      
        <p><strong>Hyp output variables:</strong> laptop, numeric_columns, column </p>
    
          <p>laptop (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>brand</th>
      <th>model</th>
      <th>processor_brand</th>
      <th>processor_name</th>
      <th>processor_gnrtn</th>
      <th>ram_gb</th>
      <th>ram_type</th>
      <th>...</th>
      <th>msoffice</th>
      <th>latest_price</th>
      <th>old_price</th>
      <th>discount</th>
      <th>star_rating</th>
      <th>ratings</th>
      <th>reviews</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Lenovo</td>
      <td>A6-9225</td>
      <td>AMD</td>
      <td>A6-9225 Processor</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>24990</td>
      <td>32790</td>
      <td>23</td>
      <td>3.7</td>
      <td>63</td>
      <td>12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Lenovo</td>
      <td>Ideapad</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>19590</td>
      <td>21325</td>
      <td>8</td>
      <td>3.6</td>
      <td>1894</td>
      <td>256</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Avita</td>
      <td>PURA</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>19990</td>
      <td>27990</td>
      <td>28</td>
      <td>3.7</td>
      <td>1153</td>
      <td>159</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Avita</td>
      <td>PURA</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>21490</td>
      <td>27990</td>
      <td>23</td>
      <td>3.7</td>
      <td>1153</td>
      <td>159</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Avita</td>
      <td>PURA</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>24990</td>
      <td>33490</td>
      <td>25</td>
      <td>3.7</td>
      <td>1657</td>
      <td>234</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Avita</td>
      <td>PURA</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>8</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>24990</td>
      <td>33490</td>
      <td>25</td>
      <td>3.7</td>
      <td>1657</td>
      <td>234</td>
    </tr>
    <tr>
      <th>6</th>
      <td>HP</td>
      <td>APU</td>
      <td>AMD</td>
      <td>APU Dual</td>
      <td>10.0</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>20900</td>
      <td>22825</td>
      <td>8</td>
      <td>3.9</td>
      <td>1185</td>
      <td>141</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>889</th>
      <td>ASUS</td>
      <td>ROG</td>
      <td>AMD</td>
      <td>Ryzen 9</td>
      <td>NaN</td>
      <td>4</td>
      <td>LPDDR4X</td>
      <td>...</td>
      <td>Yes</td>
      <td>234990</td>
      <td>350990</td>
      <td>33</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>890</th>
      <td>ASUS</td>
      <td>ROG</td>
      <td>AMD</td>
      <td>Ryzen 9</td>
      <td>NaN</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>135990</td>
      <td>172990</td>
      <td>21</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>891</th>
      <td>ASUS</td>
      <td>ROG</td>
      <td>AMD</td>
      <td>Ryzen 9</td>
      <td>NaN</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>144990</td>
      <td>194990</td>
      <td>25</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>892</th>
      <td>ASUS</td>
      <td>Ryzen</td>
      <td>AMD</td>
      <td>Ryzen 9</td>
      <td>NaN</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>149990</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>893</th>
      <td>ASUS</td>
      <td>Ryzen</td>
      <td>AMD</td>
      <td>Ryzen 9</td>
      <td>NaN</td>
      <td>4</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>142990</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>894</th>
      <td>SAMSUNG</td>
      <td>Galaxy</td>
      <td>Qualcomm</td>
      <td>Snapdragon 7c</td>
      <td>NaN</td>
      <td>4</td>
      <td>LPDDR4X</td>
      <td>...</td>
      <td>No</td>
      <td>38990</td>
      <td>47990</td>
      <td>18</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>895</th>
      <td>Lenovo</td>
      <td>Thinkpad</td>
      <td>AMD</td>
      <td>Ryzen 5</td>
      <td>10.0</td>
      <td>8</td>
      <td>DDR4</td>
      <td>...</td>
      <td>No</td>
      <td>57490</td>
      <td>78400</td>
      <td>26</td>
      <td>4.2</td>
      <td>18</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>896 rows × 23 columns</p>
      
          <p>numeric_columns (list):</p>
          <pre><code>['processor_gnrtn', 'ram_gb', 'ssd', 'hdd', 'os_bit', 'display_size']</code></pre>
      
          <p>column (str):</p>
          <pre><code>display_size</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('laptop', 'laptop', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> latest-laptop-price-list/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the feature that has the highest absolute correlation with the laptops' latest price?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>target_columns = ['old_price','latest_price']
laptop.corr().drop(index=target_columns)['latest_price'].abs().sort_values().tail(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>target_columns = ['old_price','latest_price']
laptop.corr().drop(index=target_columns)['latest_price'].abs().sort_values().tail(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>target_columns = ['old_price', 'latest_price']
__output__ = laptop.corr().drop(index=target_columns)['latest_price'].abs(
    ).sort_values().tail(1)
</code></pre>
        <p><span onclick="$('#var_output_f8983730').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f8983730" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>ssd    0.545065
Name: latest_price, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> target_columns, __output__ </p>
    
          <p>target_columns (list):</p>
          <pre><code>['old_price', 'latest_price']</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>ssd    0.545065
Name: latest_price, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> latest-laptop-price-list/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent change in average latest price across every new generation of precessors released by Intel?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>laptop.groupby(['processor_brand','processor_gnrtn']).latest_price.mean().loc[('Intel')].pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>laptop.groupby(['processor_brand','processor_gnrtn']).latest_price.mean().loc[('Intel')].pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = laptop.groupby(['processor_brand', 'processor_gnrtn']
    ).latest_price.mean().loc['Intel'].pct_change()
</code></pre>
        <p><span onclick="$('#var_output_d9f04f4e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d9f04f4e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>processor_gnrtn
4.0          NaN
7.0     0.053434
8.0     0.525286
9.0     0.042108
10.0   -0.016050
11.0   -0.172468
12.0    2.353418
Name: latest_price, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>processor_gnrtn
4.0          NaN
7.0     0.053434
8.0     0.525286
9.0     0.042108
10.0   -0.016050
11.0   -0.172468
12.0    2.353418
Name: latest_price, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> latest-laptop-price-list/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Round the star ratings to the neearest integer and find the change in average latest price of laptops for every increase in star rating?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>laptop.groupby(laptop['star_rating'].apply(lambda x: round(x, 0))).latest_price.mean().diff()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>laptop.groupby(laptop['star_rating'].apply(lambda x: round(x, 0))).latest_price.mean().diff()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = laptop.groupby(laptop['star_rating'].apply(lambda x: round(x, 0))
    ).latest_price.mean().diff()
</code></pre>
        <p><span onclick="$('#var_output_b5efe451').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b5efe451" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>star_rating
0.0             NaN
2.0   -20798.223485
3.0   -10127.804762
4.0      127.598547
5.0    47613.851873
Name: latest_price, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>star_rating
0.0             NaN
2.0   -20798.223485
3.0   -10127.804762
4.0      127.598547
5.0    47613.851873
Name: latest_price, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> latest-laptop-price-list/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which laptop brand releases the largest variety of gaming laptops? Show the brand name and number of different gaming laptops released?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>gaming_brands = laptop.groupby(['brand','weight']).size().unstack(fill_value=0)['Gaming'].reset_index()
gaming_brands.columns=['brand','count']
gaming_brands.loc[gaming_brands['count'].idxmax()]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>gaming_brands = laptop.groupby(['brand','weight']).size().unstack(fill_value=0)['Gaming'].reset_index()
gaming_brands.columns=['brand','count']
gaming_brands.loc[gaming_brands['count'].idxmax()]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>gaming_brands = laptop.groupby(['brand', 'weight']).size().unstack(fill_value=0
    )['Gaming'].reset_index()
gaming_brands.columns = ['brand', 'count']
__output__ = gaming_brands.loc[gaming_brands['count'].idxmax()]
</code></pre>
        <p><span onclick="$('#var_output_078835d4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_078835d4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>brand    ASUS
count      20
Name: 2, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> gaming_brands, __output__ </p>
    
          <p>gaming_brands (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>brand</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ALIENWARE</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>APPLE</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ASUS</td>
      <td>20</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Avita</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>DELL</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>HP</td>
      <td>9</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Infinix</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>14</th>
      <td>SAMSUNG</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Smartron</td>
      <td>0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Vaio</td>
      <td>0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>acer</td>
      <td>0</td>
    </tr>
    <tr>
      <th>18</th>
      <td>iball</td>
      <td>0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>lenovo</td>
      <td>0</td>
    </tr>
    <tr>
      <th>20</th>
      <td>realme</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>21 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>brand    ASUS
count      20
Name: 2, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> students-adaptability-level-in-online-education/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the distribution of student adaptivity level accross each age group? Return a dataframe with age groups as an index and adaptivity levels as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>adptv_distribution = students.groupby(['Adaptivity Level','Age']).size().unstack(level=0).fillna(0)
adptv_distribution</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>adptv_distribution = students.groupby(['Adaptivity Level','Age']).size().unstack(level=0).fillna(0)
adptv_distribution</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>adptv_distribution = students.groupby(['Adaptivity Level', 'Age']).size(
    ).unstack(level=0).fillna(0)
__output__ = adptv_distribution
</code></pre>
        <p><span onclick="$('#var_output_2a5807e7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2a5807e7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Adaptivity Level</th>
      <th>High</th>
      <th>Low</th>
      <th>Moderate</th>
    </tr>
    <tr>
      <th>Age</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1-5</th>
      <td>0.0</td>
      <td>17.0</td>
      <td>64.0</td>
    </tr>
    <tr>
      <th>11-15</th>
      <td>28.0</td>
      <td>120.0</td>
      <td>205.0</td>
    </tr>
    <tr>
      <th>16-20</th>
      <td>5.0</td>
      <td>144.0</td>
      <td>129.0</td>
    </tr>
    <tr>
      <th>21-25</th>
      <td>38.0</td>
      <td>139.0</td>
      <td>197.0</td>
    </tr>
    <tr>
      <th>26-30</th>
      <td>12.0</td>
      <td>36.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>6-10</th>
      <td>17.0</td>
      <td>24.0</td>
      <td>10.0</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> adptv_distribution, __output__ </p>
    
          <p>adptv_distribution (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Adaptivity Level</th>
      <th>High</th>
      <th>Low</th>
      <th>Moderate</th>
    </tr>
    <tr>
      <th>Age</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1-5</th>
      <td>0.0</td>
      <td>17.0</td>
      <td>64.0</td>
    </tr>
    <tr>
      <th>11-15</th>
      <td>28.0</td>
      <td>120.0</td>
      <td>205.0</td>
    </tr>
    <tr>
      <th>16-20</th>
      <td>5.0</td>
      <td>144.0</td>
      <td>129.0</td>
    </tr>
    <tr>
      <th>21-25</th>
      <td>38.0</td>
      <td>139.0</td>
      <td>197.0</td>
    </tr>
    <tr>
      <th>26-30</th>
      <td>12.0</td>
      <td>36.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>6-10</th>
      <td>17.0</td>
      <td>24.0</td>
      <td>10.0</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Adaptivity Level</th>
      <th>High</th>
      <th>Low</th>
      <th>Moderate</th>
    </tr>
    <tr>
      <th>Age</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1-5</th>
      <td>0.0</td>
      <td>17.0</td>
      <td>64.0</td>
    </tr>
    <tr>
      <th>11-15</th>
      <td>28.0</td>
      <td>120.0</td>
      <td>205.0</td>
    </tr>
    <tr>
      <th>16-20</th>
      <td>5.0</td>
      <td>144.0</td>
      <td>129.0</td>
    </tr>
    <tr>
      <th>21-25</th>
      <td>38.0</td>
      <td>139.0</td>
      <td>197.0</td>
    </tr>
    <tr>
      <th>26-30</th>
      <td>12.0</td>
      <td>36.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>6-10</th>
      <td>17.0</td>
      <td>24.0</td>
      <td>10.0</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> students-adaptability-level-in-online-education/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which age group has the highest percentage of low adaptive students? Show the age group and the percentage of students.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pct_low_adptv = (adptv_distribution['Low'] / adptv_distribution.sum(1)).reset_index()
pct_low_adptv.columns = ['age','pct_low_adaptive']
pct_low_adptv[pct_low_adptv['pct_low_adaptive'] == pct_low_adptv['pct_low_adaptive'].max()]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pct_low_adptv = (adptv_distribution['Low'] / adptv_distribution.sum(1)).reset_index()
pct_low_adptv.columns = ['age','pct_low_adaptive']
pct_low_adptv[pct_low_adptv['pct_low_adaptive'] == pct_low_adptv['pct_low_adaptive'].max()]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>pct_low_adptv = (adptv_distribution['Low'] / adptv_distribution.sum(1)
    ).reset_index()
pct_low_adptv.columns = ['age', 'pct_low_adaptive']
__output__ = pct_low_adptv[pct_low_adptv['pct_low_adaptive'] ==
    pct_low_adptv['pct_low_adaptive'].max()]
</code></pre>
        <p><span onclick="$('#var_output_027f4a54').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_027f4a54" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>pct_low_adaptive</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>26-30</td>
      <td>0.529412</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> pct_low_adptv, __output__ </p>
    
          <p>pct_low_adptv (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>pct_low_adaptive</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1-5</td>
      <td>0.209877</td>
    </tr>
    <tr>
      <th>1</th>
      <td>11-15</td>
      <td>0.339943</td>
    </tr>
    <tr>
      <th>2</th>
      <td>16-20</td>
      <td>0.517986</td>
    </tr>
    <tr>
      <th>3</th>
      <td>21-25</td>
      <td>0.371658</td>
    </tr>
    <tr>
      <th>4</th>
      <td>26-30</td>
      <td>0.529412</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6-10</td>
      <td>0.470588</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>pct_low_adaptive</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>26-30</td>
      <td>0.529412</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> students-adaptability-level-in-online-education/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # By how much are non IT students more likely to increase adaptivity for each age group? Return a dataframe with adaptivity level as an index sorted in ascending order, age groups as columns and percent change in student counts as values.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>non_it_adaptive = students[students['IT Student']=='No'].groupby(['Adaptivity Level','Age']).size().unstack(-1).loc[['Low','Moderate','High']]
non_it_adaptive.pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>non_it_adaptive = students[students['IT Student']=='No'].groupby(['Adaptivity Level','Age']).size().unstack(-1).loc[['Low','Moderate','High']]
non_it_adaptive.pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>non_it_adaptive = students[students['IT Student'] == 'No'].groupby([
    'Adaptivity Level', 'Age']).size().unstack(-1).loc[['Low', 'Moderate',
    'High']]
__output__ = non_it_adaptive.pct_change()
</code></pre>
        <p><span onclick="$('#var_output_412b5800').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_412b5800" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Age</th>
      <th>1-5</th>
      <th>11-15</th>
      <th>16-20</th>
      <th>21-25</th>
      <th>26-30</th>
      <th>6-10</th>
    </tr>
    <tr>
      <th>Adaptivity Level</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Low</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Moderate</th>
      <td>2.764706</td>
      <td>0.483333</td>
      <td>-0.150794</td>
      <td>0.067568</td>
      <td>-0.833333</td>
      <td>-0.583333</td>
    </tr>
    <tr>
      <th>High</th>
      <td>0.000000</td>
      <td>-0.842697</td>
      <td>-0.953271</td>
      <td>-0.822785</td>
      <td>-0.400000</td>
      <td>0.700000</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 6 columns</p>
      
        <p><strong>Hyp output variables:</strong> non_it_adaptive, __output__ </p>
    
          <p>non_it_adaptive (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Age</th>
      <th>1-5</th>
      <th>11-15</th>
      <th>16-20</th>
      <th>21-25</th>
      <th>26-30</th>
      <th>6-10</th>
    </tr>
    <tr>
      <th>Adaptivity Level</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Low</th>
      <td>17.0</td>
      <td>120.0</td>
      <td>126.0</td>
      <td>74.0</td>
      <td>30.0</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>Moderate</th>
      <td>64.0</td>
      <td>178.0</td>
      <td>107.0</td>
      <td>79.0</td>
      <td>5.0</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>High</th>
      <td>NaN</td>
      <td>28.0</td>
      <td>5.0</td>
      <td>14.0</td>
      <td>3.0</td>
      <td>17.0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 6 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Age</th>
      <th>1-5</th>
      <th>11-15</th>
      <th>16-20</th>
      <th>21-25</th>
      <th>26-30</th>
      <th>6-10</th>
    </tr>
    <tr>
      <th>Adaptivity Level</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Low</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Moderate</th>
      <td>2.764706</td>
      <td>0.483333</td>
      <td>-0.150794</td>
      <td>0.067568</td>
      <td>-0.833333</td>
      <td>-0.583333</td>
    </tr>
    <tr>
      <th>High</th>
      <td>0.000000</td>
      <td>-0.842697</td>
      <td>-0.953271</td>
      <td>-0.822785</td>
      <td>-0.400000</td>
      <td>0.700000</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 6 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> students-adaptability-level-in-online-education/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the difference between average class duration among students having low and high adaptivity?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>adaptive = students[(students['Adaptivity Level'].str.contains('Low|High'))]
adaptive['avg_class_duration'] = adaptive['Class Duration'].str.split('-', expand=True).fillna(method='ffill', axis=1).astype('float').mean(1)
avg_duration = adaptive.groupby('Adaptivity Level').avg_class_duration.mean()

dur_difference = avg_duration.loc['High'] - avg_duration.loc['Low']
dur_difference</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>adaptive = students[(students['Adaptivity Level'].str.contains('Low|High'))]
adaptive['avg_class_duration'] = adaptive['Class Duration'].str.split('-', expand=True).fillna(method='ffill', axis=1).astype('float').mean(1)
avg_duration = adaptive.groupby('Adaptivity Level').avg_class_duration.mean()

dur_difference = avg_duration.loc['High'] - avg_duration.loc['Low']
dur_difference</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>adaptive = students[students['Adaptivity Level'].str.contains('Low|High')]
adaptive['avg_class_duration'] = adaptive['Class Duration'].str.split('-',
    expand=True).fillna(method='ffill', axis=1).astype('float').mean(1)
avg_duration = adaptive.groupby('Adaptivity Level').avg_class_duration.mean()
dur_difference = avg_duration.loc['High'] - avg_duration.loc['Low']
__output__ = dur_difference
</code></pre>
        <p><span onclick="$('#var_output_70f48790').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_70f48790" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>0.8104166666666668</code></pre>
      
        <p><strong>Hyp output variables:</strong> adaptive, avg_duration, dur_difference, __output__ </p>
    
          <p>adaptive (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Age</th>
      <th>Education Level</th>
      <th>Institution Type</th>
      <th>IT Student</th>
      <th>Location</th>
      <th>Load-shedding</th>
      <th>Financial Condition</th>
      <th>Internet Type</th>
      <th>Network Type</th>
      <th>Class Duration</th>
      <th>Self Lms</th>
      <th>Device</th>
      <th>Adaptivity Level</th>
      <th>avg_class_duration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>Girl</td>
      <td>16-20</td>
      <td>School</td>
      <td>Non Government</td>
      <td>No</td>
      <td>Yes</td>
      <td>Low</td>
      <td>Poor</td>
      <td>Mobile Data</td>
      <td>3G</td>
      <td>0</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Boy</td>
      <td>11-15</td>
      <td>School</td>
      <td>Non Government</td>
      <td>No</td>
      <td>Yes</td>
      <td>Low</td>
      <td>Poor</td>
      <td>Mobile Data</td>
      <td>3G</td>
      <td>1-3</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Boy</td>
      <td>11-15</td>
      <td>School</td>
      <td>Non Government</td>
      <td>No</td>
      <td>Yes</td>
      <td>Low</td>
      <td>Mid</td>
      <td>Wifi</td>
      <td>4G</td>
      <td>0</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Boy</td>
      <td>16-20</td>
      <td>College</td>
      <td>Government</td>
      <td>No</td>
      <td>Yes</td>
      <td>Low</td>
      <td>Mid</td>
      <td>Wifi</td>
      <td>4G</td>
      <td>1-3</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Girl</td>
      <td>16-20</td>
      <td>University</td>
      <td>Government</td>
      <td>No</td>
      <td>Yes</td>
      <td>Low</td>
      <td>Mid</td>
      <td>Wifi</td>
      <td>4G</td>
      <td>1-3</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Girl</td>
      <td>16-20</td>
      <td>College</td>
      <td>Non Government</td>
      <td>No</td>
      <td>Yes</td>
      <td>Low</td>
      <td>Mid</td>
      <td>Wifi</td>
      <td>4G</td>
      <td>1-3</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Girl</td>
      <td>16-20</td>
      <td>College</td>
      <td>Non Government</td>
      <td>No</td>
      <td>No</td>
      <td>Low</td>
      <td>Mid</td>
      <td>Wifi</td>
      <td>4G</td>
      <td>1-3</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1194</th>
      <td>Boy</td>
      <td>11-15</td>
      <td>School</td>
      <td>Non Government</td>
      <td>No</td>
      <td>No</td>
      <td>Low</td>
      <td>Mid</td>
      <td>Mobile Data</td>
      <td>3G</td>
      <td>1-3</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1195</th>
      <td>Boy</td>
      <td>21-25</td>
      <td>University</td>
      <td>Non Government</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>High</td>
      <td>Poor</td>
      <td>Wifi</td>
      <td>4G</td>
      <td>1-3</td>
      <td>Yes</td>
      <td>Computer</td>
      <td>High</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1196</th>
      <td>Boy</td>
      <td>16-20</td>
      <td>College</td>
      <td>Government</td>
      <td>No</td>
      <td>No</td>
      <td>High</td>
      <td>Mid</td>
      <td>Mobile Data</td>
      <td>3G</td>
      <td>1-3</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1198</th>
      <td>Boy</td>
      <td>16-20</td>
      <td>College</td>
      <td>Government</td>
      <td>Yes</td>
      <td>No</td>
      <td>Low</td>
      <td>Mid</td>
      <td>Mobile Data</td>
      <td>4G</td>
      <td>0</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1199</th>
      <td>Boy</td>
      <td>21-25</td>
      <td>University</td>
      <td>Non Government</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>Low</td>
      <td>Mid</td>
      <td>Wifi</td>
      <td>4G</td>
      <td>3-6</td>
      <td>No</td>
      <td>Computer</td>
      <td>Low</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>1200</th>
      <td>Girl</td>
      <td>16-20</td>
      <td>College</td>
      <td>Non Government</td>
      <td>No</td>
      <td>Yes</td>
      <td>Low</td>
      <td>Mid</td>
      <td>Wifi</td>
      <td>4G</td>
      <td>1-3</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1203</th>
      <td>Girl</td>
      <td>16-20</td>
      <td>College</td>
      <td>Non Government</td>
      <td>No</td>
      <td>No</td>
      <td>Low</td>
      <td>Mid</td>
      <td>Wifi</td>
      <td>4G</td>
      <td>1-3</td>
      <td>No</td>
      <td>Mobile</td>
      <td>Low</td>
      <td>2.0</td>
    </tr>
  </tbody>
</table>
<p>580 rows × 15 columns</p>
      
          <p>avg_duration (Series):</p>
          <pre><code>Adaptivity Level
High    2.450000
Low     1.639583
Name: avg_class_duration, dtype: float64</code></pre>
      
          <p>dur_difference (float64):</p>
          <pre><code>0.8104166666666668</code></pre>
      
          <p>__output__ (float64):</p>
          <pre><code>0.8104166666666668</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.2, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> students-adaptability-level-in-online-education/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the least possible age of students having high adaptivity?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>students[students['Adaptivity Level']=='High']['Age'].str.split('-', expand=True).astype('int').min().min()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>students[students['Adaptivity Level']=='High']['Age'].str.split('-', expand=True).astype('int').min().min()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = students[students['Adaptivity Level'] == 'High']['Age'].str.split(
    '-', expand=True).astype('int').min().min()
</code></pre>
        <p><span onclick="$('#var_output_a1ee1e7f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a1ee1e7f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>6</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>6</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> students-adaptability-level-in-online-education/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent change in student adaptivity for every increase in average class duration?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>class_duration = students['Class Duration'].str.split('-', expand=True).fillna(method='ffill', axis=1).astype('float').mean(1)
duration_adaptivity = pd.concat([students['Adaptivity Level'], class_duration], axis=1)
duration_adaptivity.columns=['adaptivity','class_duration']
duration_adaptivity.groupby(['class_duration','adaptivity']).size().unstack().pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>class_duration = students['Class Duration'].str.split('-', expand=True).fillna(method='ffill', axis=1).astype('float').mean(1)
duration_adaptivity = pd.concat([students['Adaptivity Level'], class_duration], axis=1)
duration_adaptivity.columns=['adaptivity','class_duration']
duration_adaptivity.groupby(['class_duration','adaptivity']).size().unstack().pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>class_duration = students['Class Duration'].str.split('-', expand=True).fillna(
    method='ffill', axis=1).astype('float').mean(1)
duration_adaptivity = pd.concat([students['Adaptivity Level'],
    class_duration], axis=1)
duration_adaptivity.columns = ['adaptivity', 'class_duration']
__output__ = duration_adaptivity.groupby(['class_duration', 'adaptivity']
    ).size().unstack().pct_change()
</code></pre>
        <p><span onclick="$('#var_output_05c7a5e2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_05c7a5e2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>adaptivity</th>
      <th>High</th>
      <th>Low</th>
      <th>Moderate</th>
    </tr>
    <tr>
      <th>class_duration</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0.0</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>NaN</td>
      <td>1.013889</td>
      <td>45.800000</td>
    </tr>
    <tr>
      <th>4.5</th>
      <td>-0.780488</td>
      <td>-0.841379</td>
      <td>-0.685897</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> class_duration, duration_adaptivity, __output__ </p>
    
          <p>class_duration (Series):</p>
          <pre><code>0       4.5
1       2.0
2       2.0
3       2.0
4       0.0
       ... 
1200    2.0
1201    4.5
1202    2.0
1203    2.0
1204    2.0
Length: 1205, dtype: float64</code></pre>
      
          <p>duration_adaptivity (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>adaptivity</th>
      <th>class_duration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Moderate</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Moderate</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Moderate</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Moderate</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Low</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Low</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Low</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1198</th>
      <td>Low</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1199</th>
      <td>Low</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>1200</th>
      <td>Low</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1201</th>
      <td>Moderate</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>1202</th>
      <td>Moderate</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1203</th>
      <td>Low</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1204</th>
      <td>Moderate</td>
      <td>2.0</td>
    </tr>
  </tbody>
</table>
<p>1205 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>adaptivity</th>
      <th>High</th>
      <th>Low</th>
      <th>Moderate</th>
    </tr>
    <tr>
      <th>class_duration</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0.0</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>NaN</td>
      <td>1.013889</td>
      <td>45.800000</td>
    </tr>
    <tr>
      <th>4.5</th>
      <td>-0.780488</td>
      <td>-0.841379</td>
      <td>-0.685897</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> students-adaptability-level-in-online-education/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What percentage of the total number of students within each financial status is able to shed high load and achieve high adaptivity?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>total_students = students.groupby('Financial Condition').size()
poor_students = students[(students['Load-shedding']=='High') & (students['Adaptivity Level']=='High')].groupby(['Financial Condition']).size()
poor_students.divide(total_students, fill_value=0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>total_students = students.groupby('Financial Condition').size()
poor_students = students[(students['Load-shedding']=='High') & (students['Adaptivity Level']=='High')].groupby(['Financial Condition']).size()
poor_students.divide(total_students, fill_value=0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>total_students = students.groupby('Financial Condition').size()
poor_students = students[(students['Load-shedding'] == 'High') & (students[
    'Adaptivity Level'] == 'High')].groupby(['Financial Condition']).size()
__output__ = poor_students.divide(total_students, fill_value=0)
</code></pre>
        <p><span onclick="$('#var_output_30023e9c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_30023e9c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Financial Condition
Mid     0.003417
Poor    0.041322
Rich    0.000000
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> total_students, poor_students, __output__ </p>
    
          <p>total_students (Series):</p>
          <pre><code>Financial Condition
Mid     878
Poor    242
Rich     85
dtype: int64</code></pre>
      
          <p>poor_students (Series):</p>
          <pre><code>Financial Condition
Mid      3
Poor    10
dtype: int64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Financial Condition
Mid     0.003417
Poor    0.041322
Rich    0.000000
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> students-adaptability-level-in-online-education/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent of students across each adaptivity level for every combination of device used and class duration? Return a dataframe with device used and class duration as a nested index and adaptivity levels as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = students.groupby(['Device','Class Duration','Adaptivity Level']).size().unstack()
df.divide(df.sum(1), axis=0)[['Low','Moderate','High']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = students.groupby(['Device','Class Duration','Adaptivity Level']).size().unstack()
df.divide(df.sum(1), axis=0)[['Low','Moderate','High']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = students.groupby(['Device', 'Class Duration', 'Adaptivity Level']).size(
    ).unstack()
__output__ = df.divide(df.sum(1), axis=0)[['Low', 'Moderate', 'High']]
</code></pre>
        <p><span onclick="$('#var_output_034f165e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_034f165e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Adaptivity Level</th>
      <th>Low</th>
      <th>Moderate</th>
      <th>High</th>
    </tr>
    <tr>
      <th>Device</th>
      <th>Class Duration</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">Computer</th>
      <th>0</th>
      <td>1.000000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1-3</th>
      <td>0.117647</td>
      <td>0.600000</td>
      <td>0.282353</td>
    </tr>
    <tr>
      <th>3-6</th>
      <td>0.338028</td>
      <td>0.577465</td>
      <td>0.084507</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">Mobile</th>
      <th>0</th>
      <td>0.932432</td>
      <td>0.067568</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1-3</th>
      <td>0.373333</td>
      <td>0.549333</td>
      <td>0.077333</td>
    </tr>
    <tr>
      <th>3-6</th>
      <td>0.173913</td>
      <td>0.739130</td>
      <td>0.086957</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Tab</th>
      <th>1-3</th>
      <td>NaN</td>
      <td>1.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3-6</th>
      <td>0.080000</td>
      <td>0.840000</td>
      <td>0.080000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Adaptivity Level</th>
      <th>High</th>
      <th>Low</th>
      <th>Moderate</th>
    </tr>
    <tr>
      <th>Device</th>
      <th>Class Duration</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">Computer</th>
      <th>0</th>
      <td>NaN</td>
      <td>6.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1-3</th>
      <td>24.0</td>
      <td>10.0</td>
      <td>51.0</td>
    </tr>
    <tr>
      <th>3-6</th>
      <td>6.0</td>
      <td>24.0</td>
      <td>41.0</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">Mobile</th>
      <th>0</th>
      <td>NaN</td>
      <td>138.0</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>1-3</th>
      <td>58.0</td>
      <td>280.0</td>
      <td>412.0</td>
    </tr>
    <tr>
      <th>3-6</th>
      <td>10.0</td>
      <td>20.0</td>
      <td>85.0</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Tab</th>
      <th>1-3</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>3-6</th>
      <td>2.0</td>
      <td>2.0</td>
      <td>21.0</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Adaptivity Level</th>
      <th>Low</th>
      <th>Moderate</th>
      <th>High</th>
    </tr>
    <tr>
      <th>Device</th>
      <th>Class Duration</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">Computer</th>
      <th>0</th>
      <td>1.000000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1-3</th>
      <td>0.117647</td>
      <td>0.600000</td>
      <td>0.282353</td>
    </tr>
    <tr>
      <th>3-6</th>
      <td>0.338028</td>
      <td>0.577465</td>
      <td>0.084507</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">Mobile</th>
      <th>0</th>
      <td>0.932432</td>
      <td>0.067568</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1-3</th>
      <td>0.373333</td>
      <td>0.549333</td>
      <td>0.077333</td>
    </tr>
    <tr>
      <th>3-6</th>
      <td>0.173913</td>
      <td>0.739130</td>
      <td>0.086957</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Tab</th>
      <th>1-3</th>
      <td>NaN</td>
      <td>1.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3-6</th>
      <td>0.080000</td>
      <td>0.840000</td>
      <td>0.080000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the incorrect data types of numeric columns to numeric format.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>drama['Drama Rating'] = pd.to_numeric(drama['Drama Rating'].str.replace('_',''))
drama['Votes'] = pd.to_numeric(drama['Votes'].str.replace('_','').str.replace(' ',''))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>drama['Drama Rating'] = pd.to_numeric(drama['Drama Rating'].str.replace('_',''))
drama['Votes'] = pd.to_numeric(drama['Votes'].str.replace('_','').str.replace(' ',''))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>drama['Drama Rating'] = pd.to_numeric(drama['Drama Rating'].str.replace('_',
    ''))
__output__ = drama['Votes'] = pd.to_numeric(drama['Votes'].str.replace('_',
    '').str.replace(' ', ''))
</code></pre>
        <p><span onclick="$('#var_output_dc906cce').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_dc906cce" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      3949.0
1      8246.0
2       159.0
3      4390.0
4      4003.0
        ...  
401     262.0
402    1927.0
403    1321.0
404     918.0
405      82.0
Name: Votes, Length: 406, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> drama, __output__ </p>
    
          <p>drama (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Drama Name</th>
      <th>Year of Release</th>
      <th>Watch Time</th>
      <th>Drama Rating</th>
      <th>Genre</th>
      <th>Votes</th>
      <th>Actors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>It's Okay, That's Love</td>
      <td>(2014)</td>
      <td>60 min</td>
      <td>8.3</td>
      <td>\nComedy, Drama, Romance</td>
      <td>3949.0</td>
      <td>Dong-il Sung, Kwang-Soo Lee, Jin Kyung, Zo In-sung</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Moon Lovers: Scarlet Heart Ryeo</td>
      <td>(2016)</td>
      <td>60 min</td>
      <td>8.7</td>
      <td>\nAction, Drama, Fantasy</td>
      <td>8246.0</td>
      <td>Lee Joon-Gi, Ji-eun Lee, Kang Ha-neul, Nam Joo-hyuk</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The Lover</td>
      <td>(2015)</td>
      <td>_____</td>
      <td>7.4</td>
      <td>\nDrama, Romance</td>
      <td>159.0</td>
      <td>Yeo-jin Choi, Oh Jeong-Se, Joon-young Jung, Jae-Joon Lee</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Oh My Ghost</td>
      <td>(2015)</td>
      <td>60 min</td>
      <td>8.0</td>
      <td>\nComedy, Drama, Fantasy</td>
      <td>4390.0</td>
      <td>Park Bo-young, Jo Jung-Suk, Ju-hwan Lim, Seul-gi Kim</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Cheese in the Trap</td>
      <td>(2016)</td>
      <td>60 min</td>
      <td>7.3</td>
      <td>\nComedy, Romance</td>
      <td>4003.0</td>
      <td>Park Hae-Jin, Kim Go-eun, Seo Kang-Joon, Nam Joo-hyuk</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Another Miss Oh</td>
      <td>(2016)</td>
      <td>70 min</td>
      <td>7.8</td>
      <td>\nComedy, Fantasy, Romance</td>
      <td>1868.0</td>
      <td>Eric Moon, Hyeon-jin Seo, Ji-won Ye, Ji-seok Kim</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Uncontrollably Fond</td>
      <td>(2016)</td>
      <td>60 min</td>
      <td>7.8</td>
      <td>\nComedy, Drama, Romance</td>
      <td>2892.0</td>
      <td>Woo-bin Kim, Bae Suzy, Ju-hwan Lim, Lim Ju-Eun</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>399</th>
      <td>Peng</td>
      <td>(2021)</td>
      <td>18 min</td>
      <td>6.0</td>
      <td>\nComedy</td>
      <td>26.0</td>
      <td>Won-Myung Choi, Lee Seung Il, Joo Woo Jae, Kim Hyun Jin</td>
    </tr>
    <tr>
      <th>400</th>
      <td>Mama Fairy and the Woodcutter</td>
      <td>(2018– )</td>
      <td>_____</td>
      <td>NaN</td>
      <td>\nComedy, Fantasy, Romance</td>
      <td>141.0</td>
      <td>Mi-na Kang, Seo Ji-Hoon, Jun Soo Jin, Nash Ang</td>
    </tr>
    <tr>
      <th>401</th>
      <td>That Man Oh Soo</td>
      <td>(2018– )</td>
      <td>_____</td>
      <td>NaN</td>
      <td>\nFantasy, Romance</td>
      <td>262.0</td>
      <td>Jong-Hyun Lee, Kim So-eun, Tae-oh Kang, Jeong-min Heo</td>
    </tr>
    <tr>
      <th>402</th>
      <td>To the Beautiful You</td>
      <td>(2012)</td>
      <td>64 min</td>
      <td>7.2</td>
      <td>\nComedy, Romance</td>
      <td>1927.0</td>
      <td>Kim Ji-Won, Kang Ha-neul, Choi Minho, Hyun-Woo Lee</td>
    </tr>
    <tr>
      <th>403</th>
      <td>Man to Man</td>
      <td>(2017)</td>
      <td>80 min</td>
      <td>7.4</td>
      <td>\nAction, Drama, Thriller</td>
      <td>1321.0</td>
      <td>Park Hae-Jin, Park Sung-woong, Min-Jung Kim, Jeong-hun Yeon</td>
    </tr>
    <tr>
      <th>404</th>
      <td>Radio Romance</td>
      <td>(2018)</td>
      <td>70 min</td>
      <td>6.7</td>
      <td>\nDrama, Romance</td>
      <td>918.0</td>
      <td>Doo-Joon Yoon, Kim So-Hyun, Bak Yoon, Hyun-Kyung Oh</td>
    </tr>
    <tr>
      <th>405</th>
      <td>Fluttering Warning</td>
      <td>(2018– )</td>
      <td>60 min</td>
      <td>6.9</td>
      <td>\nRomance</td>
      <td>82.0</td>
      <td>Yun Eun-hye, Jeong-myeong Cheon, Go Eun Han, Joo Woo Jae</td>
    </tr>
  </tbody>
</table>
<p>406 rows × 7 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      3949.0
1      8246.0
2       159.0
3      4390.0
4      4003.0
        ...  
401     262.0
402    1927.0
403    1321.0
404     918.0
405      82.0
Name: Votes, Length: 406, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Extract each show's release year and duration, and correct the convert data type to numeric.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>drama['Year of Release'] = drama['Year of Release'].str.extract('(\d+)').astype('int')
drama['Watch Time'] = pd.to_numeric(drama['Watch Time'].str.extract('(\d+)').values.flatten())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>drama['Year of Release'] = drama['Year of Release'].str.extract('(\d+)').astype('int')
drama['Watch Time'] = pd.to_numeric(drama['Watch Time'].str.extract('(\d+)').values.flatten())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>drama['Year of Release'] = drama['Year of Release'].str.extract('(\\d+)'
    ).astype('int')
__output__ = drama['Watch Time'] = pd.to_numeric(drama['Watch Time'].str.
    extract('(\\d+)').values.flatten())
</code></pre>
        <p><span onclick="$('#var_output_ccfd9f17').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ccfd9f17" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>[ 60.  60.  nan  60.  60.  70.  60.  60.  50.  nan  nan  60.  nan  60.
  35.  70.  nan  70.  75.  nan  75.  35.  60.  nan  70.  70.  62.  nan
  70.  60.  nan  nan  60.  60.  60.  65.  nan  60.  60.  60.  65.  60.
  35.  60.  60.  70.  60.  nan  35.  90.  nan  60.  30.  65.  70.  70.
  35.  30.  60.  75.  70.  59.  30.  45.  70.  60.  60.  nan  67.  60.
  70.  nan  nan  35.  60.  60.  80.  75.  nan  nan  60.  35.  85.  20.
  60.  60.  15.  70.  35.  nan 120.  nan  70.  62.  35.  55.  nan  70.
  80.  60.  90.  60.  35.  nan  10.  50.  60.  65.  65.  15.  65.  nan
  10.  80.  60.  30.  60.  30.  60.  60.  35.  65.  60.  60.  70.  32.
  32.  60.  65.  60.  50.  35.  nan  50.  65.  nan  70.  35.  75.  60.
  30.  35.  nan  nan  30.  65.  40.  60. 960.  60.  nan  65.  60.  nan
  nan  30.  70.  35.  80.  60.  nan  35.  nan  80.  80.  65.  20.  65.
  nan  nan  60.  60.  nan  20.  70.  15.  35.  75.  60.  55.  30.  50.
  nan  70. 120.  70.  70.  nan  60.  70.  60. 240.  30.  30.  70.  nan
  35.  55.  nan  50.  80.  65.  62.  nan  60.  nan  30.  60.  10.  60.
  60.  nan  35.  15.  60.  80.  70.  62.  60.  60.  60.  65.  60.  nan
  84.  60.  70.  80.  70.  35.  nan  nan  60.  55.  nan  30.  nan  45.
  nan  35.  50.  65.  65.  35.  50.  60.  nan  nan  70.  35.  nan  nan
  nan  30.  70.  60.  65.  nan  nan  65.  nan  25.  60.  35.  52.  65.
  70.  75.  60.  55.  nan  70.  60.  70.  nan  nan  35.  65.  nan  10.
  70.  35.  45. 150.  65.  nan  60.  nan  60.  80.  60.  70.  51.  60.
  60.  75.  70.  60.  nan  nan  70.  nan  60.  40.  nan  55.  65.  70.
  70.  nan  nan  nan  75.  70.  66.  nan  nan  65.  70.  nan  35.  60.
  15.  nan  nan  75.  50.  65.  65.  45.  65.  20.  60.  nan  nan  70.
  35.  60.  80.  35.  35.  11.  60.  40.  55.  35.  nan  70.  65.  13.
  60.  60.  60.  13.  35.  70.  nan  60.  60.  60.  60.  60.  70.  44.
  nan  nan  12.  35.  32.  70.  70.  nan  nan  66.  60.  47.  70.  nan
  nan  nan  10.  70.  60.  60.  70.  nan  nan  nan  70.  70.  60.  65.
  70.  20.  15.  65.  70.  10.  32.  18.  nan  nan  64.  80.  70.  60.]</code></pre>
      
        <p><strong>Hyp output variables:</strong> drama, __output__ </p>
    
          <p>drama (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Drama Name</th>
      <th>Year of Release</th>
      <th>Watch Time</th>
      <th>Drama Rating</th>
      <th>Genre</th>
      <th>Votes</th>
      <th>Actors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>It's Okay, That's Love</td>
      <td>2014</td>
      <td>60.0</td>
      <td>8.3</td>
      <td>\nComedy, Drama, Romance</td>
      <td>3949.0</td>
      <td>Dong-il Sung, Kwang-Soo Lee, Jin Kyung, Zo In-sung</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Moon Lovers: Scarlet Heart Ryeo</td>
      <td>2016</td>
      <td>60.0</td>
      <td>8.7</td>
      <td>\nAction, Drama, Fantasy</td>
      <td>8246.0</td>
      <td>Lee Joon-Gi, Ji-eun Lee, Kang Ha-neul, Nam Joo-hyuk</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The Lover</td>
      <td>2015</td>
      <td>NaN</td>
      <td>7.4</td>
      <td>\nDrama, Romance</td>
      <td>159.0</td>
      <td>Yeo-jin Choi, Oh Jeong-Se, Joon-young Jung, Jae-Joon Lee</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Oh My Ghost</td>
      <td>2015</td>
      <td>60.0</td>
      <td>8.0</td>
      <td>\nComedy, Drama, Fantasy</td>
      <td>4390.0</td>
      <td>Park Bo-young, Jo Jung-Suk, Ju-hwan Lim, Seul-gi Kim</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Cheese in the Trap</td>
      <td>2016</td>
      <td>60.0</td>
      <td>7.3</td>
      <td>\nComedy, Romance</td>
      <td>4003.0</td>
      <td>Park Hae-Jin, Kim Go-eun, Seo Kang-Joon, Nam Joo-hyuk</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Another Miss Oh</td>
      <td>2016</td>
      <td>70.0</td>
      <td>7.8</td>
      <td>\nComedy, Fantasy, Romance</td>
      <td>1868.0</td>
      <td>Eric Moon, Hyeon-jin Seo, Ji-won Ye, Ji-seok Kim</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Uncontrollably Fond</td>
      <td>2016</td>
      <td>60.0</td>
      <td>7.8</td>
      <td>\nComedy, Drama, Romance</td>
      <td>2892.0</td>
      <td>Woo-bin Kim, Bae Suzy, Ju-hwan Lim, Lim Ju-Eun</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>399</th>
      <td>Peng</td>
      <td>2021</td>
      <td>18.0</td>
      <td>6.0</td>
      <td>\nComedy</td>
      <td>26.0</td>
      <td>Won-Myung Choi, Lee Seung Il, Joo Woo Jae, Kim Hyun Jin</td>
    </tr>
    <tr>
      <th>400</th>
      <td>Mama Fairy and the Woodcutter</td>
      <td>2018</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>\nComedy, Fantasy, Romance</td>
      <td>141.0</td>
      <td>Mi-na Kang, Seo Ji-Hoon, Jun Soo Jin, Nash Ang</td>
    </tr>
    <tr>
      <th>401</th>
      <td>That Man Oh Soo</td>
      <td>2018</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>\nFantasy, Romance</td>
      <td>262.0</td>
      <td>Jong-Hyun Lee, Kim So-eun, Tae-oh Kang, Jeong-min Heo</td>
    </tr>
    <tr>
      <th>402</th>
      <td>To the Beautiful You</td>
      <td>2012</td>
      <td>64.0</td>
      <td>7.2</td>
      <td>\nComedy, Romance</td>
      <td>1927.0</td>
      <td>Kim Ji-Won, Kang Ha-neul, Choi Minho, Hyun-Woo Lee</td>
    </tr>
    <tr>
      <th>403</th>
      <td>Man to Man</td>
      <td>2017</td>
      <td>80.0</td>
      <td>7.4</td>
      <td>\nAction, Drama, Thriller</td>
      <td>1321.0</td>
      <td>Park Hae-Jin, Park Sung-woong, Min-Jung Kim, Jeong-hun Yeon</td>
    </tr>
    <tr>
      <th>404</th>
      <td>Radio Romance</td>
      <td>2018</td>
      <td>70.0</td>
      <td>6.7</td>
      <td>\nDrama, Romance</td>
      <td>918.0</td>
      <td>Doo-Joon Yoon, Kim So-Hyun, Bak Yoon, Hyun-Kyung Oh</td>
    </tr>
    <tr>
      <th>405</th>
      <td>Fluttering Warning</td>
      <td>2018</td>
      <td>60.0</td>
      <td>6.9</td>
      <td>\nRomance</td>
      <td>82.0</td>
      <td>Yun Eun-hye, Jeong-myeong Cheon, Go Eun Han, Joo Woo Jae</td>
    </tr>
  </tbody>
</table>
<p>406 rows × 7 columns</p>
      
          <p>__output__ (ndarray):</p>
          <pre><code>[ 60.  60.  nan  60.  60.  70.  60.  60.  50.  nan  nan  60.  nan  60.
  35.  70.  nan  70.  75.  nan  75.  35.  60.  nan  70.  70.  62.  nan
  70.  60.  nan  nan  60.  60.  60.  65.  nan  60.  60.  60.  65.  60.
  35.  60.  60.  70.  60.  nan  35.  90.  nan  60.  30.  65.  70.  70.
  35.  30.  60.  75.  70.  59.  30.  45.  70.  60.  60.  nan  67.  60.
  70.  nan  nan  35.  60.  60.  80.  75.  nan  nan  60.  35.  85.  20.
  60.  60.  15.  70.  35.  nan 120.  nan  70.  62.  35.  55.  nan  70.
  80.  60.  90.  60.  35.  nan  10.  50.  60.  65.  65.  15.  65.  nan
  10.  80.  60.  30.  60.  30.  60.  60.  35.  65.  60.  60.  70.  32.
  32.  60.  65.  60.  50.  35.  nan  50.  65.  nan  70.  35.  75.  60.
  30.  35.  nan  nan  30.  65.  40.  60. 960.  60.  nan  65.  60.  nan
  nan  30.  70.  35.  80.  60.  nan  35.  nan  80.  80.  65.  20.  65.
  nan  nan  60.  60.  nan  20.  70.  15.  35.  75.  60.  55.  30.  50.
  nan  70. 120.  70.  70.  nan  60.  70.  60. 240.  30.  30.  70.  nan
  35.  55.  nan  50.  80.  65.  62.  nan  60.  nan  30.  60.  10.  60.
  60.  nan  35.  15.  60.  80.  70.  62.  60.  60.  60.  65.  60.  nan
  84.  60.  70.  80.  70.  35.  nan  nan  60.  55.  nan  30.  nan  45.
  nan  35.  50.  65.  65.  35.  50.  60.  nan  nan  70.  35.  nan  nan
  nan  30.  70.  60.  65.  nan  nan  65.  nan  25.  60.  35.  52.  65.
  70.  75.  60.  55.  nan  70.  60.  70.  nan  nan  35.  65.  nan  10.
  70.  35.  45. 150.  65.  nan  60.  nan  60.  80.  60.  70.  51.  60.
  60.  75.  70.  60.  nan  nan  70.  nan  60.  40.  nan  55.  65.  70.
  70.  nan  nan  nan  75.  70.  66.  nan  nan  65.  70.  nan  35.  60.
  15.  nan  nan  75.  50.  65.  65.  45.  65.  20.  60.  nan  nan  70.
  35.  60.  80.  35.  35.  11.  60.  40.  55.  35.  nan  70.  65.  13.
  60.  60.  60.  13.  35.  70.  nan  60.  60.  60.  60.  60.  70.  44.
  nan  nan  12.  35.  32.  70.  70.  nan  nan  66.  60.  47.  70.  nan
  nan  nan  10.  70.  60.  60.  70.  nan  nan  nan  70.  70.  60.  65.
  70.  20.  15.  65.  70.  10.  32.  18.  nan  nan  64.  80.  70.  60.]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Remove any special characters in the Genre column.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>drama['Genre'] = drama.Genre.str.replace('([^a-zA-Z0-9,])', '')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>drama['Genre'] = drama.Genre.str.replace('([^a-zA-Z0-9,])', '')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = drama['Genre'] = drama.Genre.str.replace('([^a-zA-Z0-9,])', '')
</code></pre>
        <p><span onclick="$('#var_output_3b004881').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3b004881" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0       Comedy,Drama,Romance
1       Action,Drama,Fantasy
2              Drama,Romance
3       Comedy,Drama,Fantasy
4             Comedy,Romance
               ...          
401          Fantasy,Romance
402           Comedy,Romance
403    Action,Drama,Thriller
404            Drama,Romance
405                  Romance
Name: Genre, Length: 406, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> drama, __output__ </p>
    
          <p>drama (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Drama Name</th>
      <th>Year of Release</th>
      <th>Watch Time</th>
      <th>Drama Rating</th>
      <th>Genre</th>
      <th>Votes</th>
      <th>Actors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>It's Okay, That's Love</td>
      <td>2014</td>
      <td>60.0</td>
      <td>8.3</td>
      <td>Comedy,Drama,Romance</td>
      <td>3949.0</td>
      <td>Dong-il Sung, Kwang-Soo Lee, Jin Kyung, Zo In-sung</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Moon Lovers: Scarlet Heart Ryeo</td>
      <td>2016</td>
      <td>60.0</td>
      <td>8.7</td>
      <td>Action,Drama,Fantasy</td>
      <td>8246.0</td>
      <td>Lee Joon-Gi, Ji-eun Lee, Kang Ha-neul, Nam Joo-hyuk</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The Lover</td>
      <td>2015</td>
      <td>NaN</td>
      <td>7.4</td>
      <td>Drama,Romance</td>
      <td>159.0</td>
      <td>Yeo-jin Choi, Oh Jeong-Se, Joon-young Jung, Jae-Joon Lee</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Oh My Ghost</td>
      <td>2015</td>
      <td>60.0</td>
      <td>8.0</td>
      <td>Comedy,Drama,Fantasy</td>
      <td>4390.0</td>
      <td>Park Bo-young, Jo Jung-Suk, Ju-hwan Lim, Seul-gi Kim</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Cheese in the Trap</td>
      <td>2016</td>
      <td>60.0</td>
      <td>7.3</td>
      <td>Comedy,Romance</td>
      <td>4003.0</td>
      <td>Park Hae-Jin, Kim Go-eun, Seo Kang-Joon, Nam Joo-hyuk</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Another Miss Oh</td>
      <td>2016</td>
      <td>70.0</td>
      <td>7.8</td>
      <td>Comedy,Fantasy,Romance</td>
      <td>1868.0</td>
      <td>Eric Moon, Hyeon-jin Seo, Ji-won Ye, Ji-seok Kim</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Uncontrollably Fond</td>
      <td>2016</td>
      <td>60.0</td>
      <td>7.8</td>
      <td>Comedy,Drama,Romance</td>
      <td>2892.0</td>
      <td>Woo-bin Kim, Bae Suzy, Ju-hwan Lim, Lim Ju-Eun</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>399</th>
      <td>Peng</td>
      <td>2021</td>
      <td>18.0</td>
      <td>6.0</td>
      <td>Comedy</td>
      <td>26.0</td>
      <td>Won-Myung Choi, Lee Seung Il, Joo Woo Jae, Kim Hyun Jin</td>
    </tr>
    <tr>
      <th>400</th>
      <td>Mama Fairy and the Woodcutter</td>
      <td>2018</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Comedy,Fantasy,Romance</td>
      <td>141.0</td>
      <td>Mi-na Kang, Seo Ji-Hoon, Jun Soo Jin, Nash Ang</td>
    </tr>
    <tr>
      <th>401</th>
      <td>That Man Oh Soo</td>
      <td>2018</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Fantasy,Romance</td>
      <td>262.0</td>
      <td>Jong-Hyun Lee, Kim So-eun, Tae-oh Kang, Jeong-min Heo</td>
    </tr>
    <tr>
      <th>402</th>
      <td>To the Beautiful You</td>
      <td>2012</td>
      <td>64.0</td>
      <td>7.2</td>
      <td>Comedy,Romance</td>
      <td>1927.0</td>
      <td>Kim Ji-Won, Kang Ha-neul, Choi Minho, Hyun-Woo Lee</td>
    </tr>
    <tr>
      <th>403</th>
      <td>Man to Man</td>
      <td>2017</td>
      <td>80.0</td>
      <td>7.4</td>
      <td>Action,Drama,Thriller</td>
      <td>1321.0</td>
      <td>Park Hae-Jin, Park Sung-woong, Min-Jung Kim, Jeong-hun Yeon</td>
    </tr>
    <tr>
      <th>404</th>
      <td>Radio Romance</td>
      <td>2018</td>
      <td>70.0</td>
      <td>6.7</td>
      <td>Drama,Romance</td>
      <td>918.0</td>
      <td>Doo-Joon Yoon, Kim So-Hyun, Bak Yoon, Hyun-Kyung Oh</td>
    </tr>
    <tr>
      <th>405</th>
      <td>Fluttering Warning</td>
      <td>2018</td>
      <td>60.0</td>
      <td>6.9</td>
      <td>Romance</td>
      <td>82.0</td>
      <td>Yun Eun-hye, Jeong-myeong Cheon, Go Eun Han, Joo Woo Jae</td>
    </tr>
  </tbody>
</table>
<p>406 rows × 7 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0       Comedy,Drama,Romance
1       Action,Drama,Fantasy
2              Drama,Romance
3       Comedy,Drama,Fantasy
4             Comedy,Romance
               ...          
401          Fantasy,Romance
402           Comedy,Romance
403    Action,Drama,Thriller
404            Drama,Romance
405                  Romance
Name: Genre, Length: 406, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a column 'num_actors' which represents the number of actors in each show.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>drama['num_actors'] = drama.Actors.str.replace(' ','').str.split(',').apply(len)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>drama['num_actors'] = drama.Actors.str.replace(' ','').str.split(',').apply(len)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = drama['num_actors'] = drama.Actors.str.replace(' ', '').str.split(
    ',').apply(len)
</code></pre>
        <p><span onclick="$('#var_output_6234fef0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6234fef0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      4
1      4
2      4
3      4
4      4
      ..
401    4
402    4
403    4
404    4
405    4
Name: Actors, Length: 406, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> drama, __output__ </p>
    
          <p>drama (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Drama Name</th>
      <th>Year of Release</th>
      <th>Watch Time</th>
      <th>Drama Rating</th>
      <th>Genre</th>
      <th>Votes</th>
      <th>Actors</th>
      <th>num_actors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>It's Okay, That's Love</td>
      <td>2014</td>
      <td>60.0</td>
      <td>8.3</td>
      <td>Comedy,Drama,Romance</td>
      <td>3949.0</td>
      <td>Dong-il Sung, Kwang-Soo Lee, Jin Kyung, Zo In-sung</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Moon Lovers: Scarlet Heart Ryeo</td>
      <td>2016</td>
      <td>60.0</td>
      <td>8.7</td>
      <td>Action,Drama,Fantasy</td>
      <td>8246.0</td>
      <td>Lee Joon-Gi, Ji-eun Lee, Kang Ha-neul, Nam Joo-hyuk</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The Lover</td>
      <td>2015</td>
      <td>NaN</td>
      <td>7.4</td>
      <td>Drama,Romance</td>
      <td>159.0</td>
      <td>Yeo-jin Choi, Oh Jeong-Se, Joon-young Jung, Jae-Joon Lee</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Oh My Ghost</td>
      <td>2015</td>
      <td>60.0</td>
      <td>8.0</td>
      <td>Comedy,Drama,Fantasy</td>
      <td>4390.0</td>
      <td>Park Bo-young, Jo Jung-Suk, Ju-hwan Lim, Seul-gi Kim</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Cheese in the Trap</td>
      <td>2016</td>
      <td>60.0</td>
      <td>7.3</td>
      <td>Comedy,Romance</td>
      <td>4003.0</td>
      <td>Park Hae-Jin, Kim Go-eun, Seo Kang-Joon, Nam Joo-hyuk</td>
      <td>4</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Another Miss Oh</td>
      <td>2016</td>
      <td>70.0</td>
      <td>7.8</td>
      <td>Comedy,Fantasy,Romance</td>
      <td>1868.0</td>
      <td>Eric Moon, Hyeon-jin Seo, Ji-won Ye, Ji-seok Kim</td>
      <td>4</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Uncontrollably Fond</td>
      <td>2016</td>
      <td>60.0</td>
      <td>7.8</td>
      <td>Comedy,Drama,Romance</td>
      <td>2892.0</td>
      <td>Woo-bin Kim, Bae Suzy, Ju-hwan Lim, Lim Ju-Eun</td>
      <td>4</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>399</th>
      <td>Peng</td>
      <td>2021</td>
      <td>18.0</td>
      <td>6.0</td>
      <td>Comedy</td>
      <td>26.0</td>
      <td>Won-Myung Choi, Lee Seung Il, Joo Woo Jae, Kim Hyun Jin</td>
      <td>4</td>
    </tr>
    <tr>
      <th>400</th>
      <td>Mama Fairy and the Woodcutter</td>
      <td>2018</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Comedy,Fantasy,Romance</td>
      <td>141.0</td>
      <td>Mi-na Kang, Seo Ji-Hoon, Jun Soo Jin, Nash Ang</td>
      <td>4</td>
    </tr>
    <tr>
      <th>401</th>
      <td>That Man Oh Soo</td>
      <td>2018</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Fantasy,Romance</td>
      <td>262.0</td>
      <td>Jong-Hyun Lee, Kim So-eun, Tae-oh Kang, Jeong-min Heo</td>
      <td>4</td>
    </tr>
    <tr>
      <th>402</th>
      <td>To the Beautiful You</td>
      <td>2012</td>
      <td>64.0</td>
      <td>7.2</td>
      <td>Comedy,Romance</td>
      <td>1927.0</td>
      <td>Kim Ji-Won, Kang Ha-neul, Choi Minho, Hyun-Woo Lee</td>
      <td>4</td>
    </tr>
    <tr>
      <th>403</th>
      <td>Man to Man</td>
      <td>2017</td>
      <td>80.0</td>
      <td>7.4</td>
      <td>Action,Drama,Thriller</td>
      <td>1321.0</td>
      <td>Park Hae-Jin, Park Sung-woong, Min-Jung Kim, Jeong-hun Yeon</td>
      <td>4</td>
    </tr>
    <tr>
      <th>404</th>
      <td>Radio Romance</td>
      <td>2018</td>
      <td>70.0</td>
      <td>6.7</td>
      <td>Drama,Romance</td>
      <td>918.0</td>
      <td>Doo-Joon Yoon, Kim So-Hyun, Bak Yoon, Hyun-Kyung Oh</td>
      <td>4</td>
    </tr>
    <tr>
      <th>405</th>
      <td>Fluttering Warning</td>
      <td>2018</td>
      <td>60.0</td>
      <td>6.9</td>
      <td>Romance</td>
      <td>82.0</td>
      <td>Yun Eun-hye, Jeong-myeong Cheon, Go Eun Han, Joo Woo Jae</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>406 rows × 8 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      4
1      4
2      4
3      4
4      4
      ..
401    4
402    4
403    4
404    4
405    4
Name: Actors, Length: 406, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average number of votes and ratings of romance shows released on or after the year 2010?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>drama[(drama.Genre.str.contains('Romance') & 
       (drama['Year of Release']>=2010))].groupby(['Year of Release'])['Drama Rating', 'Votes'].mean().sort_index()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>drama[(drama.Genre.str.contains('Romance') & 
       (drama['Year of Release']>=2010))].groupby(['Year of Release'])['Drama Rating', 'Votes'].mean().sort_index()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = drama[drama.Genre.str.contains('Romance') & (drama[
    'Year of Release'] >= 2010)].groupby(['Year of Release'])[
    'Drama Rating', 'Votes'].mean().sort_index()
</code></pre>
        <p><span onclick="$('#var_output_93312191').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_93312191" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Drama Rating</th>
      <th>Votes</th>
    </tr>
    <tr>
      <th>Year of Release</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>7.400000</td>
      <td>3629.666667</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>6.900000</td>
      <td>773.000000</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>7.757143</td>
      <td>1776.857143</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>7.400000</td>
      <td>2103.750000</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>7.345455</td>
      <td>1608.363636</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>7.186667</td>
      <td>1292.400000</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>7.518182</td>
      <td>1991.863636</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>7.322222</td>
      <td>1369.703704</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>7.275758</td>
      <td>1194.828571</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>7.476000</td>
      <td>2463.080000</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>7.467647</td>
      <td>2771.611111</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>7.414286</td>
      <td>1441.214286</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>7.871429</td>
      <td>2460.750000</td>
    </tr>
  </tbody>
</table>
<p>13 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Drama Rating</th>
      <th>Votes</th>
    </tr>
    <tr>
      <th>Year of Release</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>7.400000</td>
      <td>3629.666667</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>6.900000</td>
      <td>773.000000</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>7.757143</td>
      <td>1776.857143</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>7.400000</td>
      <td>2103.750000</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>7.345455</td>
      <td>1608.363636</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>7.186667</td>
      <td>1292.400000</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>7.518182</td>
      <td>1991.863636</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>7.322222</td>
      <td>1369.703704</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>7.275758</td>
      <td>1194.828571</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>7.476000</td>
      <td>2463.080000</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>7.467647</td>
      <td>2771.611111</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>7.414286</td>
      <td>1441.214286</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>7.871429</td>
      <td>2460.750000</td>
    </tr>
  </tbody>
</table>
<p>13 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent annual change in rating for comedy shows?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>drama[drama.Genre.str.contains('Comedy')].groupby('Year of Release')['Drama Rating'].mean().pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>drama[drama.Genre.str.contains('Comedy')].groupby('Year of Release')['Drama Rating'].mean().pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = drama[drama.Genre.str.contains('Comedy')].groupby(
    'Year of Release')['Drama Rating'].mean().pct_change()
</code></pre>
        <p><span onclick="$('#var_output_702b9c14').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_702b9c14" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Year of Release
2005         NaN
2006   -0.074074
2007    0.093333
2009   -0.048780
2010   -0.023077
          ...   
2018   -0.001768
2019    0.021758
2020   -0.016247
2021   -0.011862
2022    0.089783
Name: Drama Rating, Length: 17, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Year of Release
2005         NaN
2006   -0.074074
2007    0.093333
2009   -0.048780
2010   -0.023077
          ...   
2018   -0.001768
2019    0.021758
2020   -0.016247
2021   -0.011862
2022    0.089783
Name: Drama Rating, Length: 17, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average drama rating for each genre?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>genres = pd.DataFrame(drama.Genre.str.split(',', expand=True).values.flatten())[0].dropna().unique()

genre_ratings = []
for genre in genres:
  rating = drama[drama.Genre.str.contains(genre)]['Drama Rating'].mean()
  genre_ratings.append([genre, rating])

genre_ratings = pd.DataFrame(genre_ratings, columns=['Genre','Rating'])
genre_ratings</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>genres = pd.DataFrame(drama.Genre.str.split(',', expand=True).values.flatten())[0].dropna().unique()

genre_ratings = []
for genre in genres:
  rating = drama[drama.Genre.str.contains(genre)]['Drama Rating'].mean()
  genre_ratings.append([genre, rating])

genre_ratings = pd.DataFrame(genre_ratings, columns=['Genre','Rating'])
genre_ratings</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>genres = pd.DataFrame(drama.Genre.str.split(',', expand=True).values.flatten()
    )[0].dropna().unique()
genre_ratings = []
for genre in genres:
    rating = drama[drama.Genre.str.contains(genre)]['Drama Rating'].mean()
    genre_ratings.append([genre, rating])
genre_ratings = pd.DataFrame(genre_ratings, columns=['Genre', 'Rating'])
__output__ = genre_ratings
</code></pre>
        <p><span onclick="$('#var_output_f1785dc1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f1785dc1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Genre</th>
      <th>Rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Comedy</td>
      <td>7.471921</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Drama</td>
      <td>7.549593</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Romance</td>
      <td>7.421333</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Action</td>
      <td>7.664706</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fantasy</td>
      <td>7.389247</td>
    </tr>
    <tr>
      <th>5</th>
      <td>History</td>
      <td>7.805556</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Mystery</td>
      <td>7.513208</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Thriller</td>
      <td>7.335714</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Family</td>
      <td>9.100000</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Horror</td>
      <td>7.483333</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Music</td>
      <td>7.427273</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Short</td>
      <td>7.154545</td>
    </tr>
    <tr>
      <th>15</th>
      <td></td>
      <td>7.437250</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Sport</td>
      <td>8.100000</td>
    </tr>
  </tbody>
</table>
<p>17 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> genres, genre_ratings, genre, rating, __output__ </p>
    
          <p>genres (ndarray):</p>
          <pre><code>['Comedy' 'Drama' 'Romance' 'Action' 'Fantasy' 'History' 'Mystery'
 'Adventure' 'Crime' 'SciFi' 'Thriller' 'Family' 'Horror' 'Music' 'Short'
 '' 'Sport']</code></pre>
      
          <p>genre_ratings (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Genre</th>
      <th>Rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Comedy</td>
      <td>7.471921</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Drama</td>
      <td>7.549593</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Romance</td>
      <td>7.421333</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Action</td>
      <td>7.664706</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fantasy</td>
      <td>7.389247</td>
    </tr>
    <tr>
      <th>5</th>
      <td>History</td>
      <td>7.805556</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Mystery</td>
      <td>7.513208</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Thriller</td>
      <td>7.335714</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Family</td>
      <td>9.100000</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Horror</td>
      <td>7.483333</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Music</td>
      <td>7.427273</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Short</td>
      <td>7.154545</td>
    </tr>
    <tr>
      <th>15</th>
      <td></td>
      <td>7.437250</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Sport</td>
      <td>8.100000</td>
    </tr>
  </tbody>
</table>
<p>17 rows × 2 columns</p>
      
          <p>genre (str):</p>
          <pre><code>Sport</code></pre>
      
          <p>rating (float64):</p>
          <pre><code>8.1</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Genre</th>
      <th>Rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Comedy</td>
      <td>7.471921</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Drama</td>
      <td>7.549593</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Romance</td>
      <td>7.421333</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Action</td>
      <td>7.664706</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fantasy</td>
      <td>7.389247</td>
    </tr>
    <tr>
      <th>5</th>
      <td>History</td>
      <td>7.805556</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Mystery</td>
      <td>7.513208</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Thriller</td>
      <td>7.335714</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Family</td>
      <td>9.100000</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Horror</td>
      <td>7.483333</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Music</td>
      <td>7.427273</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Short</td>
      <td>7.154545</td>
    </tr>
    <tr>
      <th>15</th>
      <td></td>
      <td>7.437250</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Sport</td>
      <td>8.100000</td>
    </tr>
  </tbody>
</table>
<p>17 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.2, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average show duration of the genre with the highest rating?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>highest_rating = genre_ratings.sort_values('Rating', ascending=False).iloc[0]['Genre']
drama[drama.Genre.str.contains(highest_rating)]['Watch Time'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>highest_rating = genre_ratings.sort_values('Rating', ascending=False).iloc[0]['Genre']
drama[drama.Genre.str.contains(highest_rating)]['Watch Time'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>highest_rating = genre_ratings.sort_values('Rating', ascending=False).iloc[0][
    'Genre']
__output__ = drama[drama.Genre.str.contains(highest_rating)]['Watch Time'
    ].mean()
</code></pre>
        <p><span onclick="$('#var_output_c0162735').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c0162735" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>80.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> highest_rating, __output__ </p>
    
          <p>highest_rating (str):</p>
          <pre><code>Family</code></pre>
      
          <p>__output__ (float64):</p>
          <pre><code>80.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the annual percent change in votes for shows released in the last 10 years?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>shows_5years = drama[drama['Year of Release']>=drama['Year of Release'].max()-10]
pct_change_votes = shows_5years.groupby('Year of Release').Votes.mean().pct_change()
pct_change_votes</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>shows_5years = drama[drama['Year of Release']>=drama['Year of Release'].max()-10]
pct_change_votes = shows_5years.groupby('Year of Release').Votes.mean().pct_change()
pct_change_votes</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>shows_5years = drama[drama['Year of Release'] >= drama['Year of Release'].
    max() - 10]
pct_change_votes = shows_5years.groupby('Year of Release').Votes.mean(
    ).pct_change()
__output__ = pct_change_votes
</code></pre>
        <p><span onclick="$('#var_output_5de85ac2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5de85ac2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Year of Release
2012         NaN
2013    0.510539
2014   -0.355721
2015    0.081237
2016    0.910626
2017   -0.434050
2018   -0.323952
2019    0.482111
2020    0.362849
2021    3.052505
2022   -0.825197
Name: Votes, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> shows_5years, pct_change_votes, __output__ </p>
    
          <p>shows_5years (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Drama Name</th>
      <th>Year of Release</th>
      <th>Watch Time</th>
      <th>Drama Rating</th>
      <th>Genre</th>
      <th>Votes</th>
      <th>Actors</th>
      <th>num_actors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>It's Okay, That's Love</td>
      <td>2014</td>
      <td>60.0</td>
      <td>8.3</td>
      <td>Comedy,Drama,Romance</td>
      <td>3949.0</td>
      <td>Dong-il Sung, Kwang-Soo Lee, Jin Kyung, Zo In-sung</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Moon Lovers: Scarlet Heart Ryeo</td>
      <td>2016</td>
      <td>60.0</td>
      <td>8.7</td>
      <td>Action,Drama,Fantasy</td>
      <td>8246.0</td>
      <td>Lee Joon-Gi, Ji-eun Lee, Kang Ha-neul, Nam Joo-hyuk</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The Lover</td>
      <td>2015</td>
      <td>NaN</td>
      <td>7.4</td>
      <td>Drama,Romance</td>
      <td>159.0</td>
      <td>Yeo-jin Choi, Oh Jeong-Se, Joon-young Jung, Jae-Joon Lee</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Oh My Ghost</td>
      <td>2015</td>
      <td>60.0</td>
      <td>8.0</td>
      <td>Comedy,Drama,Fantasy</td>
      <td>4390.0</td>
      <td>Park Bo-young, Jo Jung-Suk, Ju-hwan Lim, Seul-gi Kim</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Cheese in the Trap</td>
      <td>2016</td>
      <td>60.0</td>
      <td>7.3</td>
      <td>Comedy,Romance</td>
      <td>4003.0</td>
      <td>Park Hae-Jin, Kim Go-eun, Seo Kang-Joon, Nam Joo-hyuk</td>
      <td>4</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Another Miss Oh</td>
      <td>2016</td>
      <td>70.0</td>
      <td>7.8</td>
      <td>Comedy,Fantasy,Romance</td>
      <td>1868.0</td>
      <td>Eric Moon, Hyeon-jin Seo, Ji-won Ye, Ji-seok Kim</td>
      <td>4</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Uncontrollably Fond</td>
      <td>2016</td>
      <td>60.0</td>
      <td>7.8</td>
      <td>Comedy,Drama,Romance</td>
      <td>2892.0</td>
      <td>Woo-bin Kim, Bae Suzy, Ju-hwan Lim, Lim Ju-Eun</td>
      <td>4</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>399</th>
      <td>Peng</td>
      <td>2021</td>
      <td>18.0</td>
      <td>6.0</td>
      <td>Comedy</td>
      <td>26.0</td>
      <td>Won-Myung Choi, Lee Seung Il, Joo Woo Jae, Kim Hyun Jin</td>
      <td>4</td>
    </tr>
    <tr>
      <th>400</th>
      <td>Mama Fairy and the Woodcutter</td>
      <td>2018</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Comedy,Fantasy,Romance</td>
      <td>141.0</td>
      <td>Mi-na Kang, Seo Ji-Hoon, Jun Soo Jin, Nash Ang</td>
      <td>4</td>
    </tr>
    <tr>
      <th>401</th>
      <td>That Man Oh Soo</td>
      <td>2018</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Fantasy,Romance</td>
      <td>262.0</td>
      <td>Jong-Hyun Lee, Kim So-eun, Tae-oh Kang, Jeong-min Heo</td>
      <td>4</td>
    </tr>
    <tr>
      <th>402</th>
      <td>To the Beautiful You</td>
      <td>2012</td>
      <td>64.0</td>
      <td>7.2</td>
      <td>Comedy,Romance</td>
      <td>1927.0</td>
      <td>Kim Ji-Won, Kang Ha-neul, Choi Minho, Hyun-Woo Lee</td>
      <td>4</td>
    </tr>
    <tr>
      <th>403</th>
      <td>Man to Man</td>
      <td>2017</td>
      <td>80.0</td>
      <td>7.4</td>
      <td>Action,Drama,Thriller</td>
      <td>1321.0</td>
      <td>Park Hae-Jin, Park Sung-woong, Min-Jung Kim, Jeong-hun Yeon</td>
      <td>4</td>
    </tr>
    <tr>
      <th>404</th>
      <td>Radio Romance</td>
      <td>2018</td>
      <td>70.0</td>
      <td>6.7</td>
      <td>Drama,Romance</td>
      <td>918.0</td>
      <td>Doo-Joon Yoon, Kim So-Hyun, Bak Yoon, Hyun-Kyung Oh</td>
      <td>4</td>
    </tr>
    <tr>
      <th>405</th>
      <td>Fluttering Warning</td>
      <td>2018</td>
      <td>60.0</td>
      <td>6.9</td>
      <td>Romance</td>
      <td>82.0</td>
      <td>Yun Eun-hye, Jeong-myeong Cheon, Go Eun Han, Joo Woo Jae</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>391 rows × 8 columns</p>
      
          <p>pct_change_votes (Series):</p>
          <pre><code>Year of Release
2012         NaN
2013    0.510539
2014   -0.355721
2015    0.081237
2016    0.910626
2017   -0.434050
2018   -0.323952
2019    0.482111
2020    0.362849
2021    3.052505
2022   -0.825197
Name: Votes, dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Year of Release
2012         NaN
2013    0.510539
2014   -0.355721
2015    0.081237
2016    0.910626
2017   -0.434050
2018   -0.323952
2019    0.482111
2020    0.362849
2021    3.052505
2022   -0.825197
Name: Votes, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the five most common genres for shows released during the year having the highest percent increase in votes?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>genres_pct_change = drama[drama['Year of Release'] == pct_change_votes.idxmax()].Genre.str.split(',',expand=True)
pd.DataFrame(genres_pct_change.values.flatten()).dropna()[0].value_counts().head()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>genres_pct_change = drama[drama['Year of Release'] == pct_change_votes.idxmax()].Genre.str.split(',',expand=True)
pd.DataFrame(genres_pct_change.values.flatten()).dropna()[0].value_counts().head()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>genres_pct_change = drama[drama['Year of Release'] == pct_change_votes.idxmax()
    ].Genre.str.split(',', expand=True)
__output__ = pd.DataFrame(genres_pct_change.values.flatten()).dropna()[0
    ].value_counts().head()
</code></pre>
        <p><span onclick="$('#var_output_0c86e383').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0c86e383" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Drama      38
Romance    28
Comedy     22
Fantasy    16
Mystery    11
Name: 0, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> genres_pct_change, __output__ </p>
    
          <p>genres_pct_change (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7</th>
      <td>Drama</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Drama</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>60</th>
      <td>Comedy</td>
      <td>Drama</td>
      <td>Romance</td>
    </tr>
    <tr>
      <th>140</th>
      <td>Comedy</td>
      <td>Drama</td>
      <td>Romance</td>
    </tr>
    <tr>
      <th>151</th>
      <td>Comedy</td>
      <td>Fantasy</td>
      <td>Horror</td>
    </tr>
    <tr>
      <th>153</th>
      <td>Comedy</td>
      <td>Drama</td>
      <td>Fantasy</td>
    </tr>
    <tr>
      <th>160</th>
      <td>Comedy</td>
      <td>Drama</td>
      <td>Romance</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>378</th>
      <td>Fantasy</td>
      <td>Romance</td>
      <td>None</td>
    </tr>
    <tr>
      <th>383</th>
      <td>Drama</td>
      <td>Romance</td>
      <td>None</td>
    </tr>
    <tr>
      <th>387</th>
      <td>Drama</td>
      <td>Mystery</td>
      <td>Romance</td>
    </tr>
    <tr>
      <th>393</th>
      <td>Comedy</td>
      <td>Romance</td>
      <td>None</td>
    </tr>
    <tr>
      <th>396</th>
      <td>Drama</td>
      <td>Fantasy</td>
      <td>History</td>
    </tr>
    <tr>
      <th>397</th>
      <td>Short</td>
      <td>Drama</td>
      <td>Romance</td>
    </tr>
    <tr>
      <th>399</th>
      <td>Comedy</td>
      <td>None</td>
      <td>None</td>
    </tr>
  </tbody>
</table>
<p>60 rows × 3 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Drama      38
Romance    28
Comedy     22
Fantasy    16
Mystery    11
Name: 0, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Who is the most common actor among all the shows listed? Show the actor's name and number of show appearances.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>actors_common = pd.DataFrame(drama.Actors.str.replace(' ','').str.split(',', expand=True).values.flatten())[0].value_counts()
actor_common = actors_common.agg(['idxmax','max'])
actor_common.index = ['actor', 'show_appearances']
actor_common</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>actors_common = pd.DataFrame(drama.Actors.str.replace(' ','').str.split(',', expand=True).values.flatten())[0].value_counts()
actor_common = actors_common.agg(['idxmax','max'])
actor_common.index = ['actor', 'show_appearances']
actor_common</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>actors_common = pd.DataFrame(drama.Actors.str.replace(' ', '').str.split(
    ',', expand=True).values.flatten())[0].value_counts()
actor_common = actors_common.agg(['idxmax', 'max'])
actor_common.index = ['actor', 'show_appearances']
__output__ = actor_common
</code></pre>
        <p><span onclick="$('#var_output_7c6e29c2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7c6e29c2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>actor               YoonShi-Yoon
show_appearances              10
Name: 0, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> actors_common, actor_common, __output__ </p>
    
          <p>actors_common (Series):</p>
          <pre><code>YoonShi-Yoon     10
NamJoo-hyuk       9
KimSo-Hyun        8
SeoIn-Guk         8
KwakDong-yeon     8
                 ..
YangHong-Seok     1
ChoiBo-Min        1
MinWooPark        1
HyunJoonKim       1
KimHee-won        1
Name: 0, Length: 815, dtype: int64</code></pre>
      
          <p>actor_common (Series):</p>
          <pre><code>actor               YoonShi-Yoon
show_appearances              10
Name: 0, dtype: object</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>actor               YoonShi-Yoon
show_appearances              10
Name: 0, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_11 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common genre of shows acted by this actor?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pd.DataFrame(drama[drama.Actors.str.replace(' ','').str.contains(actor_common.actor)].Genre.str.split(',', expand=True).values.flatten())[0].value_counts().idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pd.DataFrame(drama[drama.Actors.str.replace(' ','').str.contains(actor_common.actor)].Genre.str.split(',', expand=True).values.flatten())[0].value_counts().idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = pd.DataFrame(drama[drama.Actors.str.replace(' ', '').str.
    contains(actor_common.actor)].Genre.str.split(',', expand=True).values.
    flatten())[0].value_counts().idxmax()
</code></pre>
        <p><span onclick="$('#var_output_c0f36945').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c0f36945" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Drama</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Drama</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_12 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average rating and number of votes of shows having the word 'love' in their title?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>drama[drama['Drama Name'].str.contains('love', case=False)][['Drama Rating','Votes']].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>drama[drama['Drama Name'].str.contains('love', case=False)][['Drama Rating','Votes']].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = drama[drama['Drama Name'].str.contains('love', case=False)][[
    'Drama Rating', 'Votes']].mean()
</code></pre>
        <p><span onclick="$('#var_output_61526624').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_61526624" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Drama Rating       7.353125
Votes           1562.636364
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Drama Rating       7.353125
Votes           1562.636364
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ultimate-korean-drama-list/notebook_1.ipynb|||turn_13 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the median rating of shows that incorporate only one unique genre?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>drama[drama.Genre.str.split(',').apply(len)==1].dropna()['Drama Rating'].median()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>drama[drama.Genre.str.split(',').apply(len)==1].dropna()['Drama Rating'].median()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = drama[drama.Genre.str.split(',').apply(len) == 1].dropna()[
    'Drama Rating'].median()
</code></pre>
        <p><span onclick="$('#var_output_8f36c99c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8f36c99c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>7.25</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>7.25</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> carsforsale/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the data type of the car prices to numeric data type.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>cars.Price = pd.to_numeric(cars.Price.str.extractall('(\d+)').unstack().fillna('').sum(axis=1).astype(int))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>cars.Price = pd.to_numeric(cars.Price.str.extractall('(\d+)').unstack().fillna('').sum(axis=1).astype(int))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = cars.Price = pd.to_numeric(cars.Price.str.extractall('(\\d+)')
    .unstack().fillna('').sum(axis=1).astype(int))
</code></pre>
        <p><span onclick="$('#var_output_3cb136bd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3cb136bd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0       39998
1       49985
2       41860
3       28500
4       49000
        ...  
9374    27374
9375    61998
9376    26944
9377    28568
9378    32091
Length: 9374, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> cars, __output__ </p>
    
          <p>cars (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Year</th>
      <th>Make</th>
      <th>Model</th>
      <th>Used/New</th>
      <th>Price</th>
      <th>ConsumerRating</th>
      <th>ConsumerReviews</th>
      <th>...</th>
      <th>MaxMPG</th>
      <th>FuelType</th>
      <th>Transmission</th>
      <th>Engine</th>
      <th>VIN</th>
      <th>Stock#</th>
      <th>Mileage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2019</td>
      <td>Toyota</td>
      <td>Sienna SE</td>
      <td>Used</td>
      <td>39998.0</td>
      <td>4.6</td>
      <td>45</td>
      <td>...</td>
      <td>27</td>
      <td>Gasoline</td>
      <td>8-Speed Automatic</td>
      <td>3.5L V6 24V PDI DOHC</td>
      <td>5TDXZ3DC2KS015402</td>
      <td>22998646</td>
      <td>29403</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2018</td>
      <td>Ford</td>
      <td>F-150 Lariat</td>
      <td>Used</td>
      <td>49985.0</td>
      <td>4.8</td>
      <td>817</td>
      <td>...</td>
      <td>24</td>
      <td>Gasoline</td>
      <td>10-Speed Automatic</td>
      <td>3.5L V6 24V PDI DOHC Twin Turbo</td>
      <td>1FTEW1EG2JFD44217</td>
      <td>22418A</td>
      <td>32929</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2017</td>
      <td>RAM</td>
      <td>1500 Laramie</td>
      <td>Used</td>
      <td>41860.0</td>
      <td>4.7</td>
      <td>495</td>
      <td>...</td>
      <td>21</td>
      <td>Gasoline</td>
      <td>8-Speed Automatic</td>
      <td>5.7L V8 16V MPFI OHV</td>
      <td>1C6RR7VT5HS842283</td>
      <td>NG277871G</td>
      <td>23173</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2021</td>
      <td>Honda</td>
      <td>Accord Sport SE</td>
      <td>Used</td>
      <td>28500.0</td>
      <td>5.0</td>
      <td>36</td>
      <td>...</td>
      <td>35</td>
      <td>Gasoline</td>
      <td>Automatic CVT</td>
      <td>1.5L I4 16V GDI DOHC Turbo</td>
      <td>1HGCV1F49MA038035</td>
      <td>54237</td>
      <td>10598</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2020</td>
      <td>Lexus</td>
      <td>RX 350</td>
      <td>Used</td>
      <td>49000.0</td>
      <td>4.8</td>
      <td>76</td>
      <td>...</td>
      <td>27</td>
      <td>Gasoline</td>
      <td>8-Speed Automatic</td>
      <td>3.5L V6 24V PDI DOHC</td>
      <td>2T2AZMAA8LC156270</td>
      <td>HDT4181A</td>
      <td>28137</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2012</td>
      <td>Toyota</td>
      <td>4Runner SR5</td>
      <td>Used</td>
      <td>23541.0</td>
      <td>4.7</td>
      <td>34</td>
      <td>...</td>
      <td>23</td>
      <td>Gasoline</td>
      <td>5-Speed Automatic</td>
      <td>4.0L V6 24V MPFI DOHC</td>
      <td>JTEZU5JR3C5043790</td>
      <td>C5043790</td>
      <td>105469</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2017</td>
      <td>Honda</td>
      <td>HR-V LX</td>
      <td>Used</td>
      <td>20995.0</td>
      <td>4.6</td>
      <td>200</td>
      <td>...</td>
      <td>34</td>
      <td>Gasoline</td>
      <td>Automatic CVT</td>
      <td>1.8L I4 16V MPFI SOHC</td>
      <td>3CZRU5H32HG703897</td>
      <td>T1480</td>
      <td>10458</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9372</th>
      <td>2019</td>
      <td>Ford</td>
      <td>Edge Titanium</td>
      <td>Used</td>
      <td>31985.0</td>
      <td>4.7</td>
      <td>193</td>
      <td>...</td>
      <td>28</td>
      <td>Gasoline</td>
      <td>8-Speed Automatic</td>
      <td>2.0L I4 16V GDI DOHC Turbo</td>
      <td>2FMPK4K99KBB49872</td>
      <td>U13246</td>
      <td>23016</td>
    </tr>
    <tr>
      <th>9373</th>
      <td>2019</td>
      <td>Honda</td>
      <td>CR-V EX-L</td>
      <td>Used</td>
      <td>31999.0</td>
      <td>4.8</td>
      <td>540</td>
      <td>...</td>
      <td>33</td>
      <td>Gasoline</td>
      <td>Automatic CVT</td>
      <td>1.5L I4 16V GDI DOHC Turbo</td>
      <td>2HKRW2H87KH643043</td>
      <td>10553HB</td>
      <td>44481</td>
    </tr>
    <tr>
      <th>9374</th>
      <td>2019</td>
      <td>Subaru</td>
      <td>Crosstrek 2.0i Premium</td>
      <td>Used</td>
      <td>27374.0</td>
      <td>4.7</td>
      <td>205</td>
      <td>...</td>
      <td>33</td>
      <td>Gasoline</td>
      <td>Automatic CVT</td>
      <td>2.0L H4 16V GDI DOHC</td>
      <td>JF2GTADC4KH318032</td>
      <td>220502A</td>
      <td>15606</td>
    </tr>
    <tr>
      <th>9375</th>
      <td>2019</td>
      <td>Audi</td>
      <td>Q8 3.0T Premium</td>
      <td>Used</td>
      <td>61998.0</td>
      <td>4.8</td>
      <td>27</td>
      <td>...</td>
      <td>22</td>
      <td>Hybrid</td>
      <td>8-Speed Automatic</td>
      <td>3.0L V6 24V GDI DOHC Turbo Hybrid</td>
      <td>WA1AVAF14KD015389</td>
      <td>AB4719</td>
      <td>46855</td>
    </tr>
    <tr>
      <th>9376</th>
      <td>2017</td>
      <td>Buick</td>
      <td>Enclave Leather</td>
      <td>Used</td>
      <td>26944.0</td>
      <td>4.8</td>
      <td>137</td>
      <td>...</td>
      <td>22</td>
      <td>Gasoline</td>
      <td>6-Speed Automatic</td>
      <td>3.6L V6 24V GDI DOHC</td>
      <td>5GAKVBKD4HJ190334</td>
      <td>B221381B</td>
      <td>62649</td>
    </tr>
    <tr>
      <th>9377</th>
      <td>2019</td>
      <td>Subaru</td>
      <td>Forester Premium</td>
      <td>Used</td>
      <td>28568.0</td>
      <td>4.7</td>
      <td>279</td>
      <td>...</td>
      <td>33</td>
      <td>Gasoline</td>
      <td>Automatic CVT</td>
      <td>2.5L H4 16V GDI DOHC</td>
      <td>JF2SKAGC9KH423450</td>
      <td>KH423450</td>
      <td>30760</td>
    </tr>
    <tr>
      <th>9378</th>
      <td>2019</td>
      <td>Hyundai</td>
      <td>Santa Fe Ultimate 2.4</td>
      <td>Used</td>
      <td>32091.0</td>
      <td>4.8</td>
      <td>204</td>
      <td>...</td>
      <td>27</td>
      <td>Gasoline</td>
      <td>8-Speed Automatic</td>
      <td>2.4L I4 16V GDI DOHC</td>
      <td>5NMS5CAD1KH002128</td>
      <td>H48345</td>
      <td>41645</td>
    </tr>
  </tbody>
</table>
<p>9379 rows × 32 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0       39998
1       49985
2       41860
3       28500
4       49000
        ...  
9374    27374
9375    61998
9376    26944
9377    28568
9378    32091
Length: 9374, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> carsforsale/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top ten highest correlated features with car prices? Sort values based on their absolute correlation values.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = cars.corr()['Price'].drop(index='Price').reset_index()
df.columns = ['Feature','Price']
df.reindex(df['Price'].abs().sort_values(ascending=False).index).iloc[:10]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = cars.corr()['Price'].drop(index='Price').reset_index()
df.columns = ['Feature','Price']
df.reindex(df['Price'].abs().sort_values(ascending=False).index).iloc[:10]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = cars.corr()['Price'].drop(index='Price').reset_index()
df.columns = ['Feature', 'Price']
__output__ = df.reindex(df['Price'].abs().sort_values(ascending=False).index
    ).iloc[:10]
</code></pre>
        <p><span onclick="$('#var_output_c10ae3a2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c10ae3a2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Feature</th>
      <th>Price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13</th>
      <td>Mileage</td>
      <td>-0.346460</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Year</td>
      <td>0.324370</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ConsumerReviews</td>
      <td>-0.305610</td>
    </tr>
    <tr>
      <th>8</th>
      <td>ValueForMoneyRating</td>
      <td>-0.252230</td>
    </tr>
    <tr>
      <th>10</th>
      <td>ReliabilityRating</td>
      <td>-0.174621</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ConsumerRating</td>
      <td>-0.107070</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ComfortRating</td>
      <td>-0.092755</td>
    </tr>
    <tr>
      <th>6</th>
      <td>InteriorDesignRating</td>
      <td>0.070688</td>
    </tr>
    <tr>
      <th>11</th>
      <td>MinMPG</td>
      <td>0.053796</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SellerRating</td>
      <td>0.040096</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Feature</th>
      <th>Price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Year</td>
      <td>0.324370</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ConsumerRating</td>
      <td>-0.107070</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ConsumerReviews</td>
      <td>-0.305610</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SellerRating</td>
      <td>0.040096</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SellerReviews</td>
      <td>-0.019923</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ComfortRating</td>
      <td>-0.092755</td>
    </tr>
    <tr>
      <th>6</th>
      <td>InteriorDesignRating</td>
      <td>0.070688</td>
    </tr>
    <tr>
      <th>7</th>
      <td>PerformanceRating</td>
      <td>0.035727</td>
    </tr>
    <tr>
      <th>8</th>
      <td>ValueForMoneyRating</td>
      <td>-0.252230</td>
    </tr>
    <tr>
      <th>9</th>
      <td>ExteriorStylingRating</td>
      <td>0.008863</td>
    </tr>
    <tr>
      <th>10</th>
      <td>ReliabilityRating</td>
      <td>-0.174621</td>
    </tr>
    <tr>
      <th>11</th>
      <td>MinMPG</td>
      <td>0.053796</td>
    </tr>
    <tr>
      <th>12</th>
      <td>MaxMPG</td>
      <td>-0.005576</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Mileage</td>
      <td>-0.346460</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Feature</th>
      <th>Price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13</th>
      <td>Mileage</td>
      <td>-0.346460</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Year</td>
      <td>0.324370</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ConsumerReviews</td>
      <td>-0.305610</td>
    </tr>
    <tr>
      <th>8</th>
      <td>ValueForMoneyRating</td>
      <td>-0.252230</td>
    </tr>
    <tr>
      <th>10</th>
      <td>ReliabilityRating</td>
      <td>-0.174621</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ConsumerRating</td>
      <td>-0.107070</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ComfortRating</td>
      <td>-0.092755</td>
    </tr>
    <tr>
      <th>6</th>
      <td>InteriorDesignRating</td>
      <td>0.070688</td>
    </tr>
    <tr>
      <th>11</th>
      <td>MinMPG</td>
      <td>0.053796</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SellerRating</td>
      <td>0.040096</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> carsforsale/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average price and rating accross all categories of vehicles having a 3.5L engine for differenct car brands?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>rating_cols = list(cars.columns[cars.columns.str.contains('rating',case=False)])
cars[cars.Engine.str.contains('3.5L',case=False)].groupby('Make')[['Price'] + rating_cols].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>rating_cols = list(cars.columns[cars.columns.str.contains('rating',case=False)])
cars[cars.Engine.str.contains('3.5L',case=False)].groupby('Make')[['Price'] + rating_cols].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>rating_cols = list(cars.columns[cars.columns.str.contains('rating', case=
    False)])
__output__ = cars[cars.Engine.str.contains('3.5L', case=False)].groupby('Make'
    )[['Price'] + rating_cols].mean()
</code></pre>
        <p><span onclick="$('#var_output_ec9f4cca').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ec9f4cca" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Price</th>
      <th>ConsumerRating</th>
      <th>SellerRating</th>
      <th>ComfortRating</th>
      <th>InteriorDesignRating</th>
      <th>PerformanceRating</th>
      <th>ValueForMoneyRating</th>
      <th>ExteriorStylingRating</th>
      <th>ReliabilityRating</th>
    </tr>
    <tr>
      <th>Make</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Acura</th>
      <td>34796.982456</td>
      <td>4.740351</td>
      <td>4.386842</td>
      <td>4.781579</td>
      <td>4.712281</td>
      <td>4.722807</td>
      <td>4.642982</td>
      <td>4.719298</td>
      <td>4.804386</td>
    </tr>
    <tr>
      <th>Chevrolet</th>
      <td>7999.000000</td>
      <td>4.200000</td>
      <td>3.700000</td>
      <td>4.400000</td>
      <td>4.000000</td>
      <td>4.200000</td>
      <td>4.100000</td>
      <td>4.200000</td>
      <td>4.200000</td>
    </tr>
    <tr>
      <th>Ford</th>
      <td>39063.208054</td>
      <td>4.768456</td>
      <td>4.391275</td>
      <td>4.868456</td>
      <td>4.780537</td>
      <td>4.759732</td>
      <td>4.602685</td>
      <td>4.826174</td>
      <td>4.732215</td>
    </tr>
    <tr>
      <th>Genesis</th>
      <td>65202.000000</td>
      <td>5.000000</td>
      <td>4.625000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>Honda</th>
      <td>36322.429224</td>
      <td>4.712329</td>
      <td>4.549315</td>
      <td>4.829224</td>
      <td>4.714612</td>
      <td>4.671233</td>
      <td>4.591324</td>
      <td>4.687671</td>
      <td>4.706393</td>
    </tr>
    <tr>
      <th>INFINITI</th>
      <td>34852.509804</td>
      <td>4.669608</td>
      <td>4.282353</td>
      <td>4.833333</td>
      <td>4.646078</td>
      <td>4.584314</td>
      <td>4.555882</td>
      <td>4.731373</td>
      <td>4.695098</td>
    </tr>
    <tr>
      <th>Kia</th>
      <td>13498.333333</td>
      <td>4.400000</td>
      <td>4.466667</td>
      <td>4.400000</td>
      <td>4.500000</td>
      <td>4.200000</td>
      <td>4.400000</td>
      <td>4.600000</td>
      <td>4.400000</td>
    </tr>
    <tr>
      <th>Lexus</th>
      <td>41114.803987</td>
      <td>4.777076</td>
      <td>4.457143</td>
      <td>4.811960</td>
      <td>4.775415</td>
      <td>4.765781</td>
      <td>4.617608</td>
      <td>4.798339</td>
      <td>4.821927</td>
    </tr>
    <tr>
      <th>Lincoln</th>
      <td>60360.764706</td>
      <td>4.811765</td>
      <td>4.694118</td>
      <td>4.823529</td>
      <td>4.817647</td>
      <td>4.911765</td>
      <td>4.682353</td>
      <td>4.911765</td>
      <td>4.847059</td>
    </tr>
    <tr>
      <th>Mercedes-Benz</th>
      <td>28975.584615</td>
      <td>4.744615</td>
      <td>4.121538</td>
      <td>4.867692</td>
      <td>4.769231</td>
      <td>4.773846</td>
      <td>4.515385</td>
      <td>4.829231</td>
      <td>4.776923</td>
    </tr>
    <tr>
      <th>Nissan</th>
      <td>28299.520000</td>
      <td>4.810667</td>
      <td>4.277333</td>
      <td>4.873333</td>
      <td>4.792000</td>
      <td>4.761333</td>
      <td>4.692000</td>
      <td>4.828000</td>
      <td>4.772000</td>
    </tr>
    <tr>
      <th>Toyota</th>
      <td>36503.954545</td>
      <td>4.713636</td>
      <td>4.312879</td>
      <td>4.787121</td>
      <td>4.721212</td>
      <td>4.665909</td>
      <td>4.613636</td>
      <td>4.757576</td>
      <td>4.749242</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 9 columns</p>
      
        <p><strong>Hyp output variables:</strong> rating_cols, __output__ </p>
    
          <p>rating_cols (list):</p>
          <pre><code>['ConsumerRating', 'SellerRating', 'ComfortRating', 'InteriorDesignRating', 'PerformanceRating', 'ValueForMoneyRating', 'ExteriorStylingRating', 'ReliabilityRating']</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Price</th>
      <th>ConsumerRating</th>
      <th>SellerRating</th>
      <th>ComfortRating</th>
      <th>InteriorDesignRating</th>
      <th>PerformanceRating</th>
      <th>ValueForMoneyRating</th>
      <th>ExteriorStylingRating</th>
      <th>ReliabilityRating</th>
    </tr>
    <tr>
      <th>Make</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Acura</th>
      <td>34796.982456</td>
      <td>4.740351</td>
      <td>4.386842</td>
      <td>4.781579</td>
      <td>4.712281</td>
      <td>4.722807</td>
      <td>4.642982</td>
      <td>4.719298</td>
      <td>4.804386</td>
    </tr>
    <tr>
      <th>Chevrolet</th>
      <td>7999.000000</td>
      <td>4.200000</td>
      <td>3.700000</td>
      <td>4.400000</td>
      <td>4.000000</td>
      <td>4.200000</td>
      <td>4.100000</td>
      <td>4.200000</td>
      <td>4.200000</td>
    </tr>
    <tr>
      <th>Ford</th>
      <td>39063.208054</td>
      <td>4.768456</td>
      <td>4.391275</td>
      <td>4.868456</td>
      <td>4.780537</td>
      <td>4.759732</td>
      <td>4.602685</td>
      <td>4.826174</td>
      <td>4.732215</td>
    </tr>
    <tr>
      <th>Genesis</th>
      <td>65202.000000</td>
      <td>5.000000</td>
      <td>4.625000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>Honda</th>
      <td>36322.429224</td>
      <td>4.712329</td>
      <td>4.549315</td>
      <td>4.829224</td>
      <td>4.714612</td>
      <td>4.671233</td>
      <td>4.591324</td>
      <td>4.687671</td>
      <td>4.706393</td>
    </tr>
    <tr>
      <th>INFINITI</th>
      <td>34852.509804</td>
      <td>4.669608</td>
      <td>4.282353</td>
      <td>4.833333</td>
      <td>4.646078</td>
      <td>4.584314</td>
      <td>4.555882</td>
      <td>4.731373</td>
      <td>4.695098</td>
    </tr>
    <tr>
      <th>Kia</th>
      <td>13498.333333</td>
      <td>4.400000</td>
      <td>4.466667</td>
      <td>4.400000</td>
      <td>4.500000</td>
      <td>4.200000</td>
      <td>4.400000</td>
      <td>4.600000</td>
      <td>4.400000</td>
    </tr>
    <tr>
      <th>Lexus</th>
      <td>41114.803987</td>
      <td>4.777076</td>
      <td>4.457143</td>
      <td>4.811960</td>
      <td>4.775415</td>
      <td>4.765781</td>
      <td>4.617608</td>
      <td>4.798339</td>
      <td>4.821927</td>
    </tr>
    <tr>
      <th>Lincoln</th>
      <td>60360.764706</td>
      <td>4.811765</td>
      <td>4.694118</td>
      <td>4.823529</td>
      <td>4.817647</td>
      <td>4.911765</td>
      <td>4.682353</td>
      <td>4.911765</td>
      <td>4.847059</td>
    </tr>
    <tr>
      <th>Mercedes-Benz</th>
      <td>28975.584615</td>
      <td>4.744615</td>
      <td>4.121538</td>
      <td>4.867692</td>
      <td>4.769231</td>
      <td>4.773846</td>
      <td>4.515385</td>
      <td>4.829231</td>
      <td>4.776923</td>
    </tr>
    <tr>
      <th>Nissan</th>
      <td>28299.520000</td>
      <td>4.810667</td>
      <td>4.277333</td>
      <td>4.873333</td>
      <td>4.792000</td>
      <td>4.761333</td>
      <td>4.692000</td>
      <td>4.828000</td>
      <td>4.772000</td>
    </tr>
    <tr>
      <th>Toyota</th>
      <td>36503.954545</td>
      <td>4.713636</td>
      <td>4.312879</td>
      <td>4.787121</td>
      <td>4.721212</td>
      <td>4.665909</td>
      <td>4.613636</td>
      <td>4.757576</td>
      <td>4.749242</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 9 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> carsforsale/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a column 'engine_cap' representing the capacity of the car engines in liters?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>engine_cap = cars.Engine.str.extract('(\d).(\d)L').astype('str').apply('.'.join, axis=1)
engine_cap = pd.to_numeric(engine_cap.str.replace('nan','0').str.replace('0.0',''))
cars['engine_cap'] = engine_cap
cars['engine_cap']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>engine_cap = cars.Engine.str.extract('(\d).(\d)L').astype('str').apply('.'.join, axis=1)
engine_cap = pd.to_numeric(engine_cap.str.replace('nan','0').str.replace('0.0',''))
cars['engine_cap'] = engine_cap
cars['engine_cap']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>engine_cap = cars.Engine.str.extract('(\\d).(\\d)L').astype('str').apply('.'
    .join, axis=1)
engine_cap = pd.to_numeric(engine_cap.str.replace('nan', '0').str.replace(
    '0.0', ''))
cars['engine_cap'] = engine_cap
__output__ = cars['engine_cap']
</code></pre>
        <p><span onclick="$('#var_output_f0b6e686').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f0b6e686" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0       3.5
1       3.5
2       5.7
3       1.5
4       3.5
       ... 
9374    2.0
9375    3.0
9376    3.6
9377    2.5
9378    2.4
Name: engine_cap, Length: 9379, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> cars, engine_cap, __output__ </p>
    
          <p>cars (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Year</th>
      <th>Make</th>
      <th>Model</th>
      <th>Used/New</th>
      <th>Price</th>
      <th>ConsumerRating</th>
      <th>ConsumerReviews</th>
      <th>...</th>
      <th>FuelType</th>
      <th>Transmission</th>
      <th>Engine</th>
      <th>VIN</th>
      <th>Stock#</th>
      <th>Mileage</th>
      <th>engine_cap</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2019</td>
      <td>Toyota</td>
      <td>Sienna SE</td>
      <td>Used</td>
      <td>39998.0</td>
      <td>4.6</td>
      <td>45</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>8-Speed Automatic</td>
      <td>3.5L V6 24V PDI DOHC</td>
      <td>5TDXZ3DC2KS015402</td>
      <td>22998646</td>
      <td>29403</td>
      <td>3.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2018</td>
      <td>Ford</td>
      <td>F-150 Lariat</td>
      <td>Used</td>
      <td>49985.0</td>
      <td>4.8</td>
      <td>817</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>10-Speed Automatic</td>
      <td>3.5L V6 24V PDI DOHC Twin Turbo</td>
      <td>1FTEW1EG2JFD44217</td>
      <td>22418A</td>
      <td>32929</td>
      <td>3.5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2017</td>
      <td>RAM</td>
      <td>1500 Laramie</td>
      <td>Used</td>
      <td>41860.0</td>
      <td>4.7</td>
      <td>495</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>8-Speed Automatic</td>
      <td>5.7L V8 16V MPFI OHV</td>
      <td>1C6RR7VT5HS842283</td>
      <td>NG277871G</td>
      <td>23173</td>
      <td>5.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2021</td>
      <td>Honda</td>
      <td>Accord Sport SE</td>
      <td>Used</td>
      <td>28500.0</td>
      <td>5.0</td>
      <td>36</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>Automatic CVT</td>
      <td>1.5L I4 16V GDI DOHC Turbo</td>
      <td>1HGCV1F49MA038035</td>
      <td>54237</td>
      <td>10598</td>
      <td>1.5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2020</td>
      <td>Lexus</td>
      <td>RX 350</td>
      <td>Used</td>
      <td>49000.0</td>
      <td>4.8</td>
      <td>76</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>8-Speed Automatic</td>
      <td>3.5L V6 24V PDI DOHC</td>
      <td>2T2AZMAA8LC156270</td>
      <td>HDT4181A</td>
      <td>28137</td>
      <td>3.5</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2012</td>
      <td>Toyota</td>
      <td>4Runner SR5</td>
      <td>Used</td>
      <td>23541.0</td>
      <td>4.7</td>
      <td>34</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>5-Speed Automatic</td>
      <td>4.0L V6 24V MPFI DOHC</td>
      <td>JTEZU5JR3C5043790</td>
      <td>C5043790</td>
      <td>105469</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2017</td>
      <td>Honda</td>
      <td>HR-V LX</td>
      <td>Used</td>
      <td>20995.0</td>
      <td>4.6</td>
      <td>200</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>Automatic CVT</td>
      <td>1.8L I4 16V MPFI SOHC</td>
      <td>3CZRU5H32HG703897</td>
      <td>T1480</td>
      <td>10458</td>
      <td>1.8</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9372</th>
      <td>2019</td>
      <td>Ford</td>
      <td>Edge Titanium</td>
      <td>Used</td>
      <td>31985.0</td>
      <td>4.7</td>
      <td>193</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>8-Speed Automatic</td>
      <td>2.0L I4 16V GDI DOHC Turbo</td>
      <td>2FMPK4K99KBB49872</td>
      <td>U13246</td>
      <td>23016</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>9373</th>
      <td>2019</td>
      <td>Honda</td>
      <td>CR-V EX-L</td>
      <td>Used</td>
      <td>31999.0</td>
      <td>4.8</td>
      <td>540</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>Automatic CVT</td>
      <td>1.5L I4 16V GDI DOHC Turbo</td>
      <td>2HKRW2H87KH643043</td>
      <td>10553HB</td>
      <td>44481</td>
      <td>1.5</td>
    </tr>
    <tr>
      <th>9374</th>
      <td>2019</td>
      <td>Subaru</td>
      <td>Crosstrek 2.0i Premium</td>
      <td>Used</td>
      <td>27374.0</td>
      <td>4.7</td>
      <td>205</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>Automatic CVT</td>
      <td>2.0L H4 16V GDI DOHC</td>
      <td>JF2GTADC4KH318032</td>
      <td>220502A</td>
      <td>15606</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>9375</th>
      <td>2019</td>
      <td>Audi</td>
      <td>Q8 3.0T Premium</td>
      <td>Used</td>
      <td>61998.0</td>
      <td>4.8</td>
      <td>27</td>
      <td>...</td>
      <td>Hybrid</td>
      <td>8-Speed Automatic</td>
      <td>3.0L V6 24V GDI DOHC Turbo Hybrid</td>
      <td>WA1AVAF14KD015389</td>
      <td>AB4719</td>
      <td>46855</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>9376</th>
      <td>2017</td>
      <td>Buick</td>
      <td>Enclave Leather</td>
      <td>Used</td>
      <td>26944.0</td>
      <td>4.8</td>
      <td>137</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>6-Speed Automatic</td>
      <td>3.6L V6 24V GDI DOHC</td>
      <td>5GAKVBKD4HJ190334</td>
      <td>B221381B</td>
      <td>62649</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>9377</th>
      <td>2019</td>
      <td>Subaru</td>
      <td>Forester Premium</td>
      <td>Used</td>
      <td>28568.0</td>
      <td>4.7</td>
      <td>279</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>Automatic CVT</td>
      <td>2.5L H4 16V GDI DOHC</td>
      <td>JF2SKAGC9KH423450</td>
      <td>KH423450</td>
      <td>30760</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>9378</th>
      <td>2019</td>
      <td>Hyundai</td>
      <td>Santa Fe Ultimate 2.4</td>
      <td>Used</td>
      <td>32091.0</td>
      <td>4.8</td>
      <td>204</td>
      <td>...</td>
      <td>Gasoline</td>
      <td>8-Speed Automatic</td>
      <td>2.4L I4 16V GDI DOHC</td>
      <td>5NMS5CAD1KH002128</td>
      <td>H48345</td>
      <td>41645</td>
      <td>2.4</td>
    </tr>
  </tbody>
</table>
<p>9379 rows × 33 columns</p>
      
          <p>engine_cap (Series):</p>
          <pre><code>0       3.5
1       3.5
2       5.7
3       1.5
4       3.5
       ... 
9374    2.0
9375    3.0
9376    3.6
9377    2.5
9378    2.4
Length: 9379, dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>0       3.5
1       3.5
2       5.7
3       1.5
4       3.5
       ... 
9374    2.0
9375    3.0
9376    3.6
9377    2.5
9378    2.4
Name: engine_cap, Length: 9379, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> carsforsale/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average fuel consumption in turbo charged and non turbo charged vehicles for each engine capacity? Return a dataframe with engine capacity as an index and whether the engine is turbo chared as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>fuel_consumption = cars.groupby(['engine_cap', cars.Engine.str.contains('turbo',case=False)])['MinMPG','MaxMPG'].mean().mean(1).unstack()
fuel_consumption.rename(columns={True:'is_turbo',False:'not_turbo'}, inplace=True)
fuel_consumption</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>fuel_consumption = cars.groupby(['engine_cap', cars.Engine.str.contains('turbo',case=False)])['MinMPG','MaxMPG'].mean().mean(1).unstack()
fuel_consumption.rename(columns={True:'is_turbo',False:'not_turbo'}, inplace=True)
fuel_consumption</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>fuel_consumption = cars.groupby(['engine_cap', cars.Engine.str.contains(
    'turbo', case=False)])['MinMPG', 'MaxMPG'].mean().mean(1).unstack()
__tmp_1 = fuel_consumption.rename(columns={(True): 'is_turbo', (False):
    'not_turbo'}, inplace=True)
__output__ = fuel_consumption
</code></pre>
        <p><span onclick="$('#var_output_317447fb').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_317447fb" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Engine</th>
      <th>not_turbo</th>
      <th>is_turbo</th>
    </tr>
    <tr>
      <th>engine_cap</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>NaN</td>
      <td>29.166667</td>
    </tr>
    <tr>
      <th>1.2</th>
      <td>38.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1.3</th>
      <td>36.500000</td>
      <td>28.500000</td>
    </tr>
    <tr>
      <th>1.4</th>
      <td>34.000000</td>
      <td>28.944915</td>
    </tr>
    <tr>
      <th>1.5</th>
      <td>31.833333</td>
      <td>30.093182</td>
    </tr>
    <tr>
      <th>1.6</th>
      <td>31.269231</td>
      <td>28.979167</td>
    </tr>
    <tr>
      <th>1.8</th>
      <td>33.842975</td>
      <td>29.083333</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>5.7</th>
      <td>19.347737</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.0</th>
      <td>NaN</td>
      <td>14.333333</td>
    </tr>
    <tr>
      <th>6.2</th>
      <td>17.912500</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.3</th>
      <td>14.500000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.4</th>
      <td>18.625000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.5</th>
      <td>13.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.6</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>43 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> fuel_consumption, __output__ </p>
    
          <p>fuel_consumption (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Engine</th>
      <th>not_turbo</th>
      <th>is_turbo</th>
    </tr>
    <tr>
      <th>engine_cap</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>NaN</td>
      <td>29.166667</td>
    </tr>
    <tr>
      <th>1.2</th>
      <td>38.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1.3</th>
      <td>36.500000</td>
      <td>28.500000</td>
    </tr>
    <tr>
      <th>1.4</th>
      <td>34.000000</td>
      <td>28.944915</td>
    </tr>
    <tr>
      <th>1.5</th>
      <td>31.833333</td>
      <td>30.093182</td>
    </tr>
    <tr>
      <th>1.6</th>
      <td>31.269231</td>
      <td>28.979167</td>
    </tr>
    <tr>
      <th>1.8</th>
      <td>33.842975</td>
      <td>29.083333</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>5.7</th>
      <td>19.347737</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.0</th>
      <td>NaN</td>
      <td>14.333333</td>
    </tr>
    <tr>
      <th>6.2</th>
      <td>17.912500</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.3</th>
      <td>14.500000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.4</th>
      <td>18.625000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.5</th>
      <td>13.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.6</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>43 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Engine</th>
      <th>not_turbo</th>
      <th>is_turbo</th>
    </tr>
    <tr>
      <th>engine_cap</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>NaN</td>
      <td>29.166667</td>
    </tr>
    <tr>
      <th>1.2</th>
      <td>38.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1.3</th>
      <td>36.500000</td>
      <td>28.500000</td>
    </tr>
    <tr>
      <th>1.4</th>
      <td>34.000000</td>
      <td>28.944915</td>
    </tr>
    <tr>
      <th>1.5</th>
      <td>31.833333</td>
      <td>30.093182</td>
    </tr>
    <tr>
      <th>1.6</th>
      <td>31.269231</td>
      <td>28.979167</td>
    </tr>
    <tr>
      <th>1.8</th>
      <td>33.842975</td>
      <td>29.083333</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>5.7</th>
      <td>19.347737</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.0</th>
      <td>NaN</td>
      <td>14.333333</td>
    </tr>
    <tr>
      <th>6.2</th>
      <td>17.912500</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.3</th>
      <td>14.500000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.4</th>
      <td>18.625000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.5</th>
      <td>13.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6.6</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>43 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> carsforsale/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many different electric car models have been produced by each manufacturer each year? Return a data frame with the manufacturers as an index and years as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>cars[cars.FuelType=='Electric'].groupby(['Make','Year']).Model.nunique().unstack(fill_value=0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>cars[cars.FuelType=='Electric'].groupby(['Make','Year']).Model.nunique().unstack(fill_value=0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = cars[cars.FuelType == 'Electric'].groupby(['Make', 'Year']
    ).Model.nunique().unstack(fill_value=0)
</code></pre>
        <p><span onclick="$('#var_output_bc203dd8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bc203dd8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Year</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
      <th>2022</th>
    </tr>
    <tr>
      <th>Make</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Audi</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Ford</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Hyundai</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Nissan</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Porsche</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Tesla</th>
      <td>2</td>
      <td>2</td>
      <td>7</td>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>Toyota</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 7 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Year</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
      <th>2022</th>
    </tr>
    <tr>
      <th>Make</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Audi</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Ford</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Hyundai</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Nissan</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Porsche</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Tesla</th>
      <td>2</td>
      <td>2</td>
      <td>7</td>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>Toyota</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 7 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> carsforsale/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which car has the highest average rating across all categories? Show the manufacturer, model, year of production and price</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>cars.loc[cars[rating_cols].mean(1).idxmax(), ['Make','Model','Year','Price']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>cars.loc[cars[rating_cols].mean(1).idxmax(), ['Make','Model','Year','Price']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = cars.loc[cars[rating_cols].mean(1).idxmax(), ['Make', 'Model',
    'Year', 'Price']]
</code></pre>
        <p><span onclick="$('#var_output_a064e18d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a064e18d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Make           Lexus
Model    ES 350 Base
Year            2021
Price        41439.0
Name: 1252, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Make           Lexus
Model    ES 350 Base
Year            2021
Price        41439.0
Name: 1252, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> carsforsale/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average price of every grade and condition of Nissan Altima models each year? Return a dataframe with car model and condition as a nested index and year of make as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>cars[cars.Model.str.contains('altima',case=False)].groupby(['Year','Model','Used/New']).Price.mean().unstack(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>cars[cars.Model.str.contains('altima',case=False)].groupby(['Year','Model','Used/New']).Price.mean().unstack(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = cars[cars.Model.str.contains('altima', case=False)].groupby([
    'Year', 'Model', 'Used/New']).Price.mean().unstack(0)
</code></pre>
        <p><span onclick="$('#var_output_23c7cdb0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_23c7cdb0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Year</th>
      <th>2015</th>
      <th>2016</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
    <tr>
      <th>Model</th>
      <th>Used/New</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Altima 2.5 Platinum</th>
      <th>Nissan Certified</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>31669.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Altima 2.5 S</th>
      <th>Used</th>
      <td>18998.0</td>
      <td>13149.5</td>
      <td>22944.0</td>
      <td>NaN</td>
      <td>22939.0</td>
      <td>23398.0</td>
    </tr>
    <tr>
      <th>Altima 2.5 SL</th>
      <th>Used</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>24791.0</td>
      <td>24890.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Altima 2.5 SR</th>
      <th>Nissan Certified</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>31000.0</td>
    </tr>
    <tr>
      <th>Used</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>24649.0</td>
      <td>NaN</td>
      <td>27677.5</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 6 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Year</th>
      <th>2015</th>
      <th>2016</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
    <tr>
      <th>Model</th>
      <th>Used/New</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Altima 2.5 Platinum</th>
      <th>Nissan Certified</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>31669.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Altima 2.5 S</th>
      <th>Used</th>
      <td>18998.0</td>
      <td>13149.5</td>
      <td>22944.0</td>
      <td>NaN</td>
      <td>22939.0</td>
      <td>23398.0</td>
    </tr>
    <tr>
      <th>Altima 2.5 SL</th>
      <th>Used</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>24791.0</td>
      <td>24890.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Altima 2.5 SR</th>
      <th>Nissan Certified</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>31000.0</td>
    </tr>
    <tr>
      <th>Used</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>24649.0</td>
      <td>NaN</td>
      <td>27677.5</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 6 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> carsforsale/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average percent change in car prices every year since 2010 for BMW and Merceded Benz vehicles?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>cars[(cars.Make.str.contains('bmw|mercedes',case=False)) & (cars.Year >= 2010)].groupby(['Make','Year']).Price.mean().unstack(0).pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>cars[(cars.Make.str.contains('bmw|mercedes',case=False)) & (cars.Year >= 2010)].groupby(['Make','Year']).Price.mean().unstack(0).pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = cars[cars.Make.str.contains('bmw|mercedes', case=False) & (
    cars.Year >= 2010)].groupby(['Make', 'Year']).Price.mean().unstack(0
    ).pct_change()
</code></pre>
        <p><span onclick="$('#var_output_e449dfb4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e449dfb4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Make</th>
      <th>BMW</th>
      <th>Mercedes-Benz</th>
    </tr>
    <tr>
      <th>Year</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>0.443582</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>0.283601</td>
      <td>0.587279</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>-0.024923</td>
      <td>0.293698</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>0.410354</td>
      <td>-0.185636</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.289381</td>
      <td>0.608933</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0.052207</td>
      <td>-0.148482</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0.171461</td>
      <td>0.423649</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0.042452</td>
      <td>-0.257634</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>0.321342</td>
      <td>0.230705</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>0.182388</td>
      <td>0.175580</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>-0.065118</td>
      <td>-0.031344</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>-0.194051</td>
      <td>-0.170732</td>
    </tr>
  </tbody>
</table>
<p>13 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Make</th>
      <th>BMW</th>
      <th>Mercedes-Benz</th>
    </tr>
    <tr>
      <th>Year</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>0.443582</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>0.283601</td>
      <td>0.587279</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>-0.024923</td>
      <td>0.293698</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>0.410354</td>
      <td>-0.185636</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.289381</td>
      <td>0.608933</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0.052207</td>
      <td>-0.148482</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0.171461</td>
      <td>0.423649</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0.042452</td>
      <td>-0.257634</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>0.321342</td>
      <td>0.230705</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>0.182388</td>
      <td>0.175580</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>-0.065118</td>
      <td>-0.031344</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>-0.194051</td>
      <td>-0.170732</td>
    </tr>
  </tbody>
</table>
<p>13 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> finding-donors-for-charityml/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Find whether the dataset has duplicate rows and drop them if they exist. Show the total number of duplicated rows.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>if census.duplicated().sum() > 0:
  total_duplicates = census.duplicated().sum()
  census.drop_duplicates(inplace=True)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>['total_duplicates']</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>if census.duplicated().sum() > 0:
  total_duplicates = census.duplicated().sum()
  census.drop_duplicates(inplace=True)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>if census.duplicated().sum() > 0:
    total_duplicates = census.duplicated().sum()
    census.drop_duplicates(inplace=True)
</code></pre>
        <p><span onclick="$('#var_output_0660e00b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0660e00b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> total_duplicates </p>
    
          <p>total_duplicates (int64):</p>
          <pre><code>5982</code></pre>
      
        <p><strong>Hyp output variables:</strong> census, total_duplicates </p>
    
          <p>census (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>education_level</th>
      <th>education-num</th>
      <th>marital-status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital-gain</th>
      <th>capital-loss</th>
      <th>hours-per-week</th>
      <th>native-country</th>
      <th>income</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>State-gov</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Never-married</td>
      <td>Adm-clerical</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>2174.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>Self-emp-not-inc</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Married-civ-spouse</td>
      <td>Exec-managerial</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>13.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>Private</td>
      <td>HS-grad</td>
      <td>9.0</td>
      <td>Divorced</td>
      <td>Handlers-cleaners</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>3</th>
      <td>53</td>
      <td>Private</td>
      <td>11th</td>
      <td>7.0</td>
      <td>Married-civ-spouse</td>
      <td>Handlers-cleaners</td>
      <td>Husband</td>
      <td>Black</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>4</th>
      <td>28</td>
      <td>Private</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Married-civ-spouse</td>
      <td>Prof-specialty</td>
      <td>Wife</td>
      <td>Black</td>
      <td>Female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>Cuba</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>5</th>
      <td>37</td>
      <td>Private</td>
      <td>Masters</td>
      <td>14.0</td>
      <td>Married-civ-spouse</td>
      <td>Exec-managerial</td>
      <td>Wife</td>
      <td>White</td>
      <td>Female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>6</th>
      <td>49</td>
      <td>Private</td>
      <td>9th</td>
      <td>5.0</td>
      <td>Married-spouse-absent</td>
      <td>Other-service</td>
      <td>Not-in-family</td>
      <td>Black</td>
      <td>Female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>16.0</td>
      <td>Jamaica</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>45212</th>
      <td>48</td>
      <td>Private</td>
      <td>HS-grad</td>
      <td>9.0</td>
      <td>Married-civ-spouse</td>
      <td>Adm-clerical</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>45213</th>
      <td>61</td>
      <td>Private</td>
      <td>HS-grad</td>
      <td>9.0</td>
      <td>Married-civ-spouse</td>
      <td>Sales</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>48.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>45216</th>
      <td>48</td>
      <td>Local-gov</td>
      <td>Masters</td>
      <td>14.0</td>
      <td>Divorced</td>
      <td>Other-service</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>45217</th>
      <td>33</td>
      <td>Private</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Never-married</td>
      <td>Prof-specialty</td>
      <td>Own-child</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>45218</th>
      <td>39</td>
      <td>Private</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Divorced</td>
      <td>Prof-specialty</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>36.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>45220</th>
      <td>44</td>
      <td>Private</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Divorced</td>
      <td>Adm-clerical</td>
      <td>Own-child</td>
      <td>Asian-Pac-Islander</td>
      <td>Male</td>
      <td>5455.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>45221</th>
      <td>35</td>
      <td>Self-emp-inc</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Married-civ-spouse</td>
      <td>Exec-managerial</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>60.0</td>
      <td>United-States</td>
      <td>&gt;50K</td>
    </tr>
  </tbody>
</table>
<p>39240 rows × 14 columns</p>
      
          <p>total_duplicates (int64):</p>
          <pre><code>5982</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('total_duplicates', 'total_duplicates', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> finding-donors-for-charityml/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the number of donors having capital gains and donors having capital losses as a percentage of the total number of donors?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>capital_tag = ['capital_gain', 'capital_loss']
capital_value = [census[census['capital-gain']>0].shape[0], census[census['capital-loss']>0].shape[0]]
pd.DataFrame(capital_value, index=capital_tag, columns=['percent_donors']) / len(census)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>capital_tag = ['capital_gain', 'capital_loss']
capital_value = [census[census['capital-gain']>0].shape[0], census[census['capital-loss']>0].shape[0]]
pd.DataFrame(capital_value, index=capital_tag, columns=['percent_donors']) / len(census)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>capital_tag = ['capital_gain', 'capital_loss']
capital_value = [census[census['capital-gain'] > 0].shape[0], census[census
    ['capital-loss'] > 0].shape[0]]
__output__ = pd.DataFrame(capital_value, index=capital_tag, columns=[
    'percent_donors']) / len(census)
</code></pre>
        <p><span onclick="$('#var_output_4a4bc32c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4a4bc32c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>percent_donors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>capital_gain</th>
      <td>0.095617</td>
    </tr>
    <tr>
      <th>capital_loss</th>
      <td>0.054103</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> capital_tag, capital_value, __output__ </p>
    
          <p>capital_tag (list):</p>
          <pre><code>['capital_gain', 'capital_loss']</code></pre>
      
          <p>capital_value (list):</p>
          <pre><code>[3752, 2123]</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>percent_donors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>capital_gain</th>
      <td>0.095617</td>
    </tr>
    <tr>
      <th>capital_loss</th>
      <td>0.054103</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> finding-donors-for-charityml/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top three most common education levels of donors having an income level greater than fifty thousand? Show the result as a percentage of the total number of donors.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>census[census['income']=='>50K'].education_level.value_counts(1).head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>census[census['income']=='>50K'].education_level.value_counts(1).head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = census[census['income'] == '>50K'].education_level.value_counts(1
    ).head(3)
</code></pre>
        <p><span onclick="$('#var_output_bd1d2f73').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bd1d2f73" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code> Bachelors       0.271880
 HS-grad         0.205113
 Some-college    0.178446
Name: education_level, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code> Bachelors       0.271880
 HS-grad         0.205113
 Some-college    0.178446
Name: education_level, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> finding-donors-for-charityml/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the donors' count and percent change in the donors' counts for every increase in education level?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>education_num = census.groupby('education-num').size().reset_index().rename(columns={0:'number'})
education_num['pct_change'] = education_num.number.pct_change()
education_num</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>education_num = census.groupby('education-num').size().reset_index().rename(columns={0:'number'})
education_num['pct_change'] = education_num.number.pct_change()
education_num</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>education_num = census.groupby('education-num').size().reset_index().rename(
    columns={(0): 'number'})
education_num['pct_change'] = education_num.number.pct_change()
__output__ = education_num
</code></pre>
        <p><span onclick="$('#var_output_24b9f19b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_24b9f19b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>education-num</th>
      <th>number</th>
      <th>pct_change</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>70</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>217</td>
      <td>2.100000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.0</td>
      <td>438</td>
      <td>1.018433</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>801</td>
      <td>0.828767</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>658</td>
      <td>-0.178527</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6.0</td>
      <td>1136</td>
      <td>0.726444</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7.0</td>
      <td>1422</td>
      <td>0.251761</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10.0</td>
      <td>8457</td>
      <td>-0.295426</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11.0</td>
      <td>1859</td>
      <td>-0.780182</td>
    </tr>
    <tr>
      <th>11</th>
      <td>12.0</td>
      <td>1470</td>
      <td>-0.209252</td>
    </tr>
    <tr>
      <th>12</th>
      <td>13.0</td>
      <td>6522</td>
      <td>3.436735</td>
    </tr>
    <tr>
      <th>13</th>
      <td>14.0</td>
      <td>2357</td>
      <td>-0.638608</td>
    </tr>
    <tr>
      <th>14</th>
      <td>15.0</td>
      <td>764</td>
      <td>-0.675859</td>
    </tr>
    <tr>
      <th>15</th>
      <td>16.0</td>
      <td>526</td>
      <td>-0.311518</td>
    </tr>
  </tbody>
</table>
<p>16 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> education_num, __output__ </p>
    
          <p>education_num (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>education-num</th>
      <th>number</th>
      <th>pct_change</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>70</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>217</td>
      <td>2.100000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.0</td>
      <td>438</td>
      <td>1.018433</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>801</td>
      <td>0.828767</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>658</td>
      <td>-0.178527</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6.0</td>
      <td>1136</td>
      <td>0.726444</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7.0</td>
      <td>1422</td>
      <td>0.251761</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10.0</td>
      <td>8457</td>
      <td>-0.295426</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11.0</td>
      <td>1859</td>
      <td>-0.780182</td>
    </tr>
    <tr>
      <th>11</th>
      <td>12.0</td>
      <td>1470</td>
      <td>-0.209252</td>
    </tr>
    <tr>
      <th>12</th>
      <td>13.0</td>
      <td>6522</td>
      <td>3.436735</td>
    </tr>
    <tr>
      <th>13</th>
      <td>14.0</td>
      <td>2357</td>
      <td>-0.638608</td>
    </tr>
    <tr>
      <th>14</th>
      <td>15.0</td>
      <td>764</td>
      <td>-0.675859</td>
    </tr>
    <tr>
      <th>15</th>
      <td>16.0</td>
      <td>526</td>
      <td>-0.311518</td>
    </tr>
  </tbody>
</table>
<p>16 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>education-num</th>
      <th>number</th>
      <th>pct_change</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>70</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>217</td>
      <td>2.100000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.0</td>
      <td>438</td>
      <td>1.018433</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>801</td>
      <td>0.828767</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>658</td>
      <td>-0.178527</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6.0</td>
      <td>1136</td>
      <td>0.726444</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7.0</td>
      <td>1422</td>
      <td>0.251761</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10.0</td>
      <td>8457</td>
      <td>-0.295426</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11.0</td>
      <td>1859</td>
      <td>-0.780182</td>
    </tr>
    <tr>
      <th>11</th>
      <td>12.0</td>
      <td>1470</td>
      <td>-0.209252</td>
    </tr>
    <tr>
      <th>12</th>
      <td>13.0</td>
      <td>6522</td>
      <td>3.436735</td>
    </tr>
    <tr>
      <th>13</th>
      <td>14.0</td>
      <td>2357</td>
      <td>-0.638608</td>
    </tr>
    <tr>
      <th>14</th>
      <td>15.0</td>
      <td>764</td>
      <td>-0.675859</td>
    </tr>
    <tr>
      <th>15</th>
      <td>16.0</td>
      <td>526</td>
      <td>-0.311518</td>
    </tr>
  </tbody>
</table>
<p>16 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> finding-donors-for-charityml/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total number and average age of donors within each work class and every level of income? Return a dataframe with work class as an index, total number and age as columns and income level as indexed columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>work_class = census.groupby(['workclass', 'income']).agg({'income':'size','age':'mean'})
work_class.columns=['count','age']
work_class.unstack()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>work_class = census.groupby(['workclass', 'income']).agg({'income':'size','age':'mean'})
work_class.columns=['count','age']
work_class.unstack()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>work_class = census.groupby(['workclass', 'income']).agg({'income': 'size',
    'age': 'mean'})
work_class.columns = ['count', 'age']
__output__ = work_class.unstack()
</code></pre>
        <p><span onclick="$('#var_output_1a445034').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1a445034" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">count</th>
      <th colspan="2" halign="left">age</th>
    </tr>
    <tr>
      <th>income</th>
      <th>&lt;=50K</th>
      <th>&gt;50K</th>
      <th>&lt;=50K</th>
      <th>&gt;50K</th>
    </tr>
    <tr>
      <th>workclass</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Federal-gov</th>
      <td>844</td>
      <td>527</td>
      <td>40.636256</td>
      <td>45.732448</td>
    </tr>
    <tr>
      <th>Local-gov</th>
      <td>2102</td>
      <td>873</td>
      <td>40.743102</td>
      <td>44.280641</td>
    </tr>
    <tr>
      <th>Private</th>
      <td>21561</td>
      <td>6156</td>
      <td>36.139975</td>
      <td>42.980994</td>
    </tr>
    <tr>
      <th>Self-emp-inc</th>
      <td>720</td>
      <td>875</td>
      <td>43.218056</td>
      <td>48.022857</td>
    </tr>
    <tr>
      <th>Self-emp-not-inc</th>
      <td>2638</td>
      <td>1031</td>
      <td>44.961334</td>
      <td>46.722599</td>
    </tr>
    <tr>
      <th>State-gov</th>
      <td>1381</td>
      <td>511</td>
      <td>37.610427</td>
      <td>45.289628</td>
    </tr>
    <tr>
      <th>Without-pay</th>
      <td>19</td>
      <td>2</td>
      <td>46.263158</td>
      <td>57.000000</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 4 columns</p>
      
        <p><strong>Hyp output variables:</strong> work_class, __output__ </p>
    
          <p>work_class (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>count</th>
      <th>age</th>
    </tr>
    <tr>
      <th>workclass</th>
      <th>income</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">Federal-gov</th>
      <th>&lt;=50K</th>
      <td>844</td>
      <td>40.636256</td>
    </tr>
    <tr>
      <th>&gt;50K</th>
      <td>527</td>
      <td>45.732448</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Local-gov</th>
      <th>&lt;=50K</th>
      <td>2102</td>
      <td>40.743102</td>
    </tr>
    <tr>
      <th>&gt;50K</th>
      <td>873</td>
      <td>44.280641</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Private</th>
      <th>&lt;=50K</th>
      <td>21561</td>
      <td>36.139975</td>
    </tr>
    <tr>
      <th>&gt;50K</th>
      <td>6156</td>
      <td>42.980994</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Self-emp-inc</th>
      <th>&lt;=50K</th>
      <td>720</td>
      <td>43.218056</td>
    </tr>
    <tr>
      <th>&gt;50K</th>
      <td>875</td>
      <td>48.022857</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Self-emp-not-inc</th>
      <th>&lt;=50K</th>
      <td>2638</td>
      <td>44.961334</td>
    </tr>
    <tr>
      <th>&gt;50K</th>
      <td>1031</td>
      <td>46.722599</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">State-gov</th>
      <th>&lt;=50K</th>
      <td>1381</td>
      <td>37.610427</td>
    </tr>
    <tr>
      <th>&gt;50K</th>
      <td>511</td>
      <td>45.289628</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Without-pay</th>
      <th>&lt;=50K</th>
      <td>19</td>
      <td>46.263158</td>
    </tr>
    <tr>
      <th>&gt;50K</th>
      <td>2</td>
      <td>57.000000</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">count</th>
      <th colspan="2" halign="left">age</th>
    </tr>
    <tr>
      <th>income</th>
      <th>&lt;=50K</th>
      <th>&gt;50K</th>
      <th>&lt;=50K</th>
      <th>&gt;50K</th>
    </tr>
    <tr>
      <th>workclass</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Federal-gov</th>
      <td>844</td>
      <td>527</td>
      <td>40.636256</td>
      <td>45.732448</td>
    </tr>
    <tr>
      <th>Local-gov</th>
      <td>2102</td>
      <td>873</td>
      <td>40.743102</td>
      <td>44.280641</td>
    </tr>
    <tr>
      <th>Private</th>
      <td>21561</td>
      <td>6156</td>
      <td>36.139975</td>
      <td>42.980994</td>
    </tr>
    <tr>
      <th>Self-emp-inc</th>
      <td>720</td>
      <td>875</td>
      <td>43.218056</td>
      <td>48.022857</td>
    </tr>
    <tr>
      <th>Self-emp-not-inc</th>
      <td>2638</td>
      <td>1031</td>
      <td>44.961334</td>
      <td>46.722599</td>
    </tr>
    <tr>
      <th>State-gov</th>
      <td>1381</td>
      <td>511</td>
      <td>37.610427</td>
      <td>45.289628</td>
    </tr>
    <tr>
      <th>Without-pay</th>
      <td>19</td>
      <td>2</td>
      <td>46.263158</td>
      <td>57.000000</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 4 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> finding-donors-for-charityml/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average capital gain and loss of donors with managerial roles?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>census[census.occupation.str.contains('Manager', case=False)][['capital-gain','capital-loss']].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>census[census.occupation.str.contains('Manager', case=False)][['capital-gain','capital-loss']].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = census[census.occupation.str.contains('Manager', case=False)][[
    'capital-gain', 'capital-loss']].mean()
</code></pre>
        <p><span onclick="$('#var_output_da40d782').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_da40d782" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>capital-gain    2444.177933
capital-loss     155.087366
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>capital-gain    2444.177933
capital-loss     155.087366
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> finding-donors-for-charityml/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # By how much is the average capital gain greater than or less than the average capital loss for donors within the most common work class?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>common_wk = census.workclass.value_counts().idxmax()
census_gain_loss = census[census.workclass==common_wk][['capital-gain','capital-loss']].mean()
census_gain_loss['capital-gain'] - census_gain_loss['capital-loss']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>common_wk = census.workclass.value_counts().idxmax()
census_gain_loss = census[census.workclass==common_wk][['capital-gain','capital-loss']].mean()
census_gain_loss['capital-gain'] - census_gain_loss['capital-loss']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>common_wk = census.workclass.value_counts().idxmax()
census_gain_loss = census[census.workclass == common_wk][['capital-gain',
    'capital-loss']].mean()
__output__ = census_gain_loss['capital-gain'] - census_gain_loss['capital-loss'
    ]
</code></pre>
        <p><span onclick="$('#var_output_3db27344').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3db27344" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>948.6936897932676</code></pre>
      
        <p><strong>Hyp output variables:</strong> common_wk, census_gain_loss, __output__ </p>
    
          <p>common_wk (str):</p>
          <pre><code> Private</code></pre>
      
          <p>census_gain_loss (Series):</p>
          <pre><code>capital-gain    1044.675939
capital-loss      95.982249
dtype: float64</code></pre>
      
          <p>__output__ (float64):</p>
          <pre><code>948.6936897932676</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> finding-donors-for-charityml/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new column 'age_group' representing the different age groups of donors at intervals of 10.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>bins = pd.interval_range(start=0, end=census.age.max(), freq=10)
census['age_group'] = pd.cut(census.age, bins=bins)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>bins = pd.interval_range(start=0, end=census.age.max(), freq=10)
census['age_group'] = pd.cut(census.age, bins=bins)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>bins = pd.interval_range(start=0, end=census.age.max(), freq=10)
__output__ = census['age_group'] = pd.cut(census.age, bins=bins)
</code></pre>
        <p><span onclick="$('#var_output_15fe534d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_15fe534d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0        (30, 40]
1        (40, 50]
2        (30, 40]
3        (50, 60]
4        (20, 30]
           ...   
45216    (40, 50]
45217    (30, 40]
45218    (30, 40]
45220    (40, 50]
45221    (30, 40]
Name: age, Length: 39240, dtype: category
Categories (9, interval[int64, right]): [(0, 10] < (10, 20] < (20, 30] < (30, 40] ... (50, 60] <
                                         (60, 70] < (70, 80] < (80, 90]]</code></pre>
      
        <p><strong>Hyp output variables:</strong> census, bins, __output__ </p>
    
          <p>census (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>education_level</th>
      <th>education-num</th>
      <th>marital-status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital-gain</th>
      <th>capital-loss</th>
      <th>hours-per-week</th>
      <th>native-country</th>
      <th>income</th>
      <th>age_group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>State-gov</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Never-married</td>
      <td>Adm-clerical</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>2174.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
      <td>(30, 40]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>Self-emp-not-inc</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Married-civ-spouse</td>
      <td>Exec-managerial</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>13.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
      <td>(40, 50]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>Private</td>
      <td>HS-grad</td>
      <td>9.0</td>
      <td>Divorced</td>
      <td>Handlers-cleaners</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
      <td>(30, 40]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>53</td>
      <td>Private</td>
      <td>11th</td>
      <td>7.0</td>
      <td>Married-civ-spouse</td>
      <td>Handlers-cleaners</td>
      <td>Husband</td>
      <td>Black</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
      <td>(50, 60]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>28</td>
      <td>Private</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Married-civ-spouse</td>
      <td>Prof-specialty</td>
      <td>Wife</td>
      <td>Black</td>
      <td>Female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>Cuba</td>
      <td>&lt;=50K</td>
      <td>(20, 30]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>37</td>
      <td>Private</td>
      <td>Masters</td>
      <td>14.0</td>
      <td>Married-civ-spouse</td>
      <td>Exec-managerial</td>
      <td>Wife</td>
      <td>White</td>
      <td>Female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
      <td>(30, 40]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>49</td>
      <td>Private</td>
      <td>9th</td>
      <td>5.0</td>
      <td>Married-spouse-absent</td>
      <td>Other-service</td>
      <td>Not-in-family</td>
      <td>Black</td>
      <td>Female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>16.0</td>
      <td>Jamaica</td>
      <td>&lt;=50K</td>
      <td>(40, 50]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>45212</th>
      <td>48</td>
      <td>Private</td>
      <td>HS-grad</td>
      <td>9.0</td>
      <td>Married-civ-spouse</td>
      <td>Adm-clerical</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
      <td>(40, 50]</td>
    </tr>
    <tr>
      <th>45213</th>
      <td>61</td>
      <td>Private</td>
      <td>HS-grad</td>
      <td>9.0</td>
      <td>Married-civ-spouse</td>
      <td>Sales</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>48.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
      <td>(60, 70]</td>
    </tr>
    <tr>
      <th>45216</th>
      <td>48</td>
      <td>Local-gov</td>
      <td>Masters</td>
      <td>14.0</td>
      <td>Divorced</td>
      <td>Other-service</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
      <td>(40, 50]</td>
    </tr>
    <tr>
      <th>45217</th>
      <td>33</td>
      <td>Private</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Never-married</td>
      <td>Prof-specialty</td>
      <td>Own-child</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
      <td>(30, 40]</td>
    </tr>
    <tr>
      <th>45218</th>
      <td>39</td>
      <td>Private</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Divorced</td>
      <td>Prof-specialty</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>36.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
      <td>(30, 40]</td>
    </tr>
    <tr>
      <th>45220</th>
      <td>44</td>
      <td>Private</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Divorced</td>
      <td>Adm-clerical</td>
      <td>Own-child</td>
      <td>Asian-Pac-Islander</td>
      <td>Male</td>
      <td>5455.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
      <td>(40, 50]</td>
    </tr>
    <tr>
      <th>45221</th>
      <td>35</td>
      <td>Self-emp-inc</td>
      <td>Bachelors</td>
      <td>13.0</td>
      <td>Married-civ-spouse</td>
      <td>Exec-managerial</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>60.0</td>
      <td>United-States</td>
      <td>&gt;50K</td>
      <td>(30, 40]</td>
    </tr>
  </tbody>
</table>
<p>39240 rows × 15 columns</p>
      
          <p>bins (IntervalIndex):</p>
          <pre><code>IntervalIndex([(0, 10], (10, 20], (20, 30], (30, 40], (40, 50], (50, 60], (60, 70], (70, 80], (80, 90]], dtype='interval[int64, right]')</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>0        (30, 40]
1        (40, 50]
2        (30, 40]
3        (50, 60]
4        (20, 30]
           ...   
45216    (40, 50]
45217    (30, 40]
45218    (30, 40]
45220    (40, 50]
45221    (30, 40]
Name: age, Length: 39240, dtype: category
Categories (9, interval[int64, right]): [(0, 10] < (10, 20] < (20, 30] < (30, 40] ... (50, 60] <
                                         (60, 70] < (70, 80] < (80, 90]]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> finding-donors-for-charityml/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent change in average capital gain and capital loss for each age group?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>census.groupby('age_group')[['capital-gain','capital-loss']].mean().pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>census.groupby('age_group')[['capital-gain','capital-loss']].mean().pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = census.groupby('age_group')[['capital-gain', 'capital-loss']
    ].mean().pct_change()
</code></pre>
        <p><span onclick="$('#var_output_37a03969').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_37a03969" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>capital-gain</th>
      <th>capital-loss</th>
    </tr>
    <tr>
      <th>age_group</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(0, 10]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(10, 20]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(20, 30]</th>
      <td>3.308260</td>
      <td>0.387304</td>
    </tr>
    <tr>
      <th>(30, 40]</th>
      <td>1.542436</td>
      <td>0.596170</td>
    </tr>
    <tr>
      <th>(40, 50]</th>
      <td>0.733133</td>
      <td>0.182940</td>
    </tr>
    <tr>
      <th>(50, 60]</th>
      <td>-0.044578</td>
      <td>-0.016538</td>
    </tr>
    <tr>
      <th>(60, 70]</th>
      <td>-0.012835</td>
      <td>-0.160251</td>
    </tr>
    <tr>
      <th>(70, 80]</th>
      <td>0.130918</td>
      <td>0.291939</td>
    </tr>
    <tr>
      <th>(80, 90]</th>
      <td>-0.289614</td>
      <td>0.254629</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>capital-gain</th>
      <th>capital-loss</th>
    </tr>
    <tr>
      <th>age_group</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(0, 10]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(10, 20]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(20, 30]</th>
      <td>3.308260</td>
      <td>0.387304</td>
    </tr>
    <tr>
      <th>(30, 40]</th>
      <td>1.542436</td>
      <td>0.596170</td>
    </tr>
    <tr>
      <th>(40, 50]</th>
      <td>0.733133</td>
      <td>0.182940</td>
    </tr>
    <tr>
      <th>(50, 60]</th>
      <td>-0.044578</td>
      <td>-0.016538</td>
    </tr>
    <tr>
      <th>(60, 70]</th>
      <td>-0.012835</td>
      <td>-0.160251</td>
    </tr>
    <tr>
      <th>(70, 80]</th>
      <td>0.130918</td>
      <td>0.291939</td>
    </tr>
    <tr>
      <th>(80, 90]</th>
      <td>-0.289614</td>
      <td>0.254629</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> finding-donors-for-charityml/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common work class within each age group? Return the most common workclass and the number of donors within each age group.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>census.groupby(['age_group','occupation']).size().unstack(0).replace(0,np.nan).agg(['idxmax','max']).T</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>census.groupby(['age_group','occupation']).size().unstack(0).replace(0,np.nan).agg(['idxmax','max']).T</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = census.groupby(['age_group', 'occupation']).size().unstack(0
    ).replace(0, np.nan).agg(['idxmax', 'max']).T
</code></pre>
        <p><span onclick="$('#var_output_9be2886e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9be2886e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>idxmax</th>
      <th>max</th>
    </tr>
    <tr>
      <th>age_group</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(0, 10]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(10, 20]</th>
      <td>Other-service</td>
      <td>560.0</td>
    </tr>
    <tr>
      <th>(20, 30]</th>
      <td>Adm-clerical</td>
      <td>1328</td>
    </tr>
    <tr>
      <th>(30, 40]</th>
      <td>Prof-specialty</td>
      <td>1598</td>
    </tr>
    <tr>
      <th>(40, 50]</th>
      <td>Prof-specialty</td>
      <td>1577</td>
    </tr>
    <tr>
      <th>(50, 60]</th>
      <td>Exec-managerial</td>
      <td>910</td>
    </tr>
    <tr>
      <th>(60, 70]</th>
      <td>Exec-managerial</td>
      <td>326.0</td>
    </tr>
    <tr>
      <th>(70, 80]</th>
      <td>Other-service</td>
      <td>81.0</td>
    </tr>
    <tr>
      <th>(80, 90]</th>
      <td>Exec-managerial</td>
      <td>24.0</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>idxmax</th>
      <th>max</th>
    </tr>
    <tr>
      <th>age_group</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(0, 10]</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>(10, 20]</th>
      <td>Other-service</td>
      <td>560.0</td>
    </tr>
    <tr>
      <th>(20, 30]</th>
      <td>Adm-clerical</td>
      <td>1328</td>
    </tr>
    <tr>
      <th>(30, 40]</th>
      <td>Prof-specialty</td>
      <td>1598</td>
    </tr>
    <tr>
      <th>(40, 50]</th>
      <td>Prof-specialty</td>
      <td>1577</td>
    </tr>
    <tr>
      <th>(50, 60]</th>
      <td>Exec-managerial</td>
      <td>910</td>
    </tr>
    <tr>
      <th>(60, 70]</th>
      <td>Exec-managerial</td>
      <td>326.0</td>
    </tr>
    <tr>
      <th>(70, 80]</th>
      <td>Other-service</td>
      <td>81.0</td>
    </tr>
    <tr>
      <th>(80, 90]</th>
      <td>Exec-managerial</td>
      <td>24.0</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Change the incorrect data type of date columns to the correct date data type.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>stocks.Date = pd.to_datetime(stocks.Date)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>stocks.Date = pd.to_datetime(stocks.Date)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = stocks.Date = pd.to_datetime(stocks.Date)
</code></pre>
        <p><span onclick="$('#var_output_11c6d278').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_11c6d278" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0        2020-09-30
1        2020-10-01
2        2020-10-02
3        2020-10-05
4        2020-10-06
            ...    
217806   2022-06-24
217807   2022-06-27
217808   2022-06-28
217809   2022-06-29
217810   2022-06-30
Name: Date, Length: 217811, dtype: datetime64[ns]</code></pre>
      
        <p><strong>Hyp output variables:</strong> stocks, __output__ </p>
    
          <p>stocks (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj Close</th>
      <th>Volume</th>
      <th>...</th>
      <th>News - Corporate Earnings</th>
      <th>News - Mergers &amp; Acquisitions</th>
      <th>News - Store Openings</th>
      <th>News - Product Recalls</th>
      <th>News - Adverse Events</th>
      <th>News - Personnel Changes</th>
      <th>News - Stock Rumors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2020-09-30</td>
      <td>160.929993</td>
      <td>163.100006</td>
      <td>158.610001</td>
      <td>160.179993</td>
      <td>150.921692</td>
      <td>3056900.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2020-10-01</td>
      <td>160.669998</td>
      <td>161.899994</td>
      <td>157.720001</td>
      <td>158.789993</td>
      <td>149.612045</td>
      <td>1989100.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2020-10-02</td>
      <td>156.470001</td>
      <td>161.940002</td>
      <td>156.250000</td>
      <td>160.360001</td>
      <td>151.091309</td>
      <td>1768600.0</td>
      <td>...</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2020-10-05</td>
      <td>162.250000</td>
      <td>163.500000</td>
      <td>161.759995</td>
      <td>162.750000</td>
      <td>153.343170</td>
      <td>1457000.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2020-10-06</td>
      <td>163.440002</td>
      <td>165.699997</td>
      <td>161.830002</td>
      <td>162.229996</td>
      <td>152.853195</td>
      <td>2021900.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2020-10-07</td>
      <td>165.100006</td>
      <td>167.750000</td>
      <td>164.410004</td>
      <td>166.490005</td>
      <td>156.866989</td>
      <td>2155400.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2020-10-08</td>
      <td>167.300003</td>
      <td>168.149994</td>
      <td>166.130005</td>
      <td>167.710007</td>
      <td>158.016479</td>
      <td>1902600.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>217804</th>
      <td>2022-06-22</td>
      <td>161.179993</td>
      <td>166.270004</td>
      <td>161.089996</td>
      <td>164.210007</td>
      <td>164.210007</td>
      <td>2137700.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>14.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>217805</th>
      <td>2022-06-23</td>
      <td>166.020004</td>
      <td>169.380005</td>
      <td>165.589996</td>
      <td>169.169998</td>
      <td>169.169998</td>
      <td>1535600.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>217806</th>
      <td>2022-06-24</td>
      <td>172.000000</td>
      <td>174.679993</td>
      <td>171.389999</td>
      <td>174.610001</td>
      <td>174.610001</td>
      <td>3255000.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>217807</th>
      <td>2022-06-27</td>
      <td>173.839996</td>
      <td>175.210007</td>
      <td>172.929993</td>
      <td>173.600006</td>
      <td>173.600006</td>
      <td>1378400.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>217808</th>
      <td>2022-06-28</td>
      <td>172.960007</td>
      <td>174.669998</td>
      <td>170.009995</td>
      <td>170.119995</td>
      <td>170.119995</td>
      <td>1725800.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>217809</th>
      <td>2022-06-29</td>
      <td>172.000000</td>
      <td>175.149994</td>
      <td>170.149994</td>
      <td>173.919998</td>
      <td>173.919998</td>
      <td>1658000.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>217810</th>
      <td>2022-06-30</td>
      <td>172.440002</td>
      <td>173.550003</td>
      <td>169.830002</td>
      <td>171.889999</td>
      <td>171.889999</td>
      <td>2220700.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>217811 rows × 27 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0        2020-09-30
1        2020-10-01
2        2020-10-02
3        2020-10-05
4        2020-10-06
            ...    
217806   2022-06-24
217807   2022-06-27
217808   2022-06-28
217809   2022-06-29
217810   2022-06-30
Name: Date, Length: 217811, dtype: datetime64[ns]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the correlation between different news types and the closing daily stock prices? Sort the correlated features in descending order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>news_columns = stocks.columns[stocks.columns.str.contains('news',case=False)].to_list()
news_columns.append('Close')
stocks[news_columns].corr()['Close'].sort_values(ascending=False).drop(index='Close')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>news_columns = stocks.columns[stocks.columns.str.contains('news',case=False)].to_list()
news_columns.append('Close')
stocks[news_columns].corr()['Close'].sort_values(ascending=False).drop(index='Close')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>news_columns = stocks.columns[stocks.columns.str.contains('news', case=False)
    ].to_list()
__tmp_1 = news_columns.append('Close')
__output__ = stocks[news_columns].corr()['Close'].sort_values(ascending=False
    ).drop(index='Close')
</code></pre>
        <p><span onclick="$('#var_output_5564ac9e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5564ac9e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>News - Volume                0.139131
News - New Products          0.106288
News - Negative Sentiment    0.097869
News - Positive Sentiment    0.069876
News - Adverse Events        0.049698
                               ...   
News - Analyst Comments      0.006673
News - Layoffs               0.006638
News - Stock Rumors          0.005424
News - All News Volume      -0.000146
News - Dividends            -0.023164
Name: Close, Length: 16, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> news_columns, __output__ </p>
    
          <p>news_columns (list):</p>
          <pre><code>['News - All News Volume', 'News - Volume', 'News - Positive Sentiment', 'News - Negative Sentiment', 'News - New Products', 'News - Layoffs', 'News - Analyst Comments', 'News - Stocks', 'News - Dividends', 'News - Corporate Earnings', 'News - Mergers & Acquisitions', 'News - Store Openings', 'News - Product Recalls', 'News - Adverse Events', 'News - Personnel Changes', 'News - Stock Rumors', 'Close']</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>News - Volume                0.139131
News - New Products          0.106288
News - Negative Sentiment    0.097869
News - Positive Sentiment    0.069876
News - Adverse Events        0.049698
                               ...   
News - Analyst Comments      0.006673
News - Layoffs               0.006638
News - Stock Rumors          0.005424
News - All News Volume      -0.000146
News - Dividends            -0.023164
Name: Close, Length: 16, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the cumulative month-over-month percent change in Amazon's stock closing price?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>stocks[stocks.Security=='Amazon'].groupby(pd.Grouper(key='Date',freq='M')).Close.last().pct_change().cumsum().dropna()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>stocks[stocks.Security=='Amazon'].groupby(pd.Grouper(key='Date',freq='M')).Close.last().pct_change().cumsum().dropna()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = stocks[stocks.Security == 'Amazon'].groupby(pd.Grouper(key=
    'Date', freq='M')).Close.last().pct_change().cumsum().dropna()
</code></pre>
        <p><span onclick="$('#var_output_8249a376').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8249a376" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Date
2020-10-31   -0.035754
2020-11-30    0.007686
2020-12-31    0.035744
2021-01-31    0.020168
2021-02-28   -0.015160
                ...   
2022-02-28    0.000670
2022-03-31    0.062107
2022-04-30   -0.175418
2022-05-31   -0.208183
2022-06-30   -0.324642
Freq: M, Name: Close, Length: 21, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Date
2020-10-31   -0.035754
2020-11-30    0.007686
2020-12-31    0.035744
2021-01-31    0.020168
2021-02-28   -0.015160
                ...   
2022-02-28    0.000670
2022-03-31    0.062107
2022-04-30   -0.175418
2022-05-31   -0.208183
2022-06-30   -0.324642
Freq: M, Name: Close, Length: 21, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Calculate the year-to-date performance of each stock within each sector.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>import datetime as dt

ytd_change = stocks[stocks.Date >= dt.datetime(dt.datetime.now().year,1,1)].groupby(['GICS Sector','Security']).Close.agg(['first','last'])
ytd_change</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>import datetime as dt

ytd_change = stocks[stocks.Date >= dt.datetime(dt.datetime.now().year,1,1)].groupby(['GICS Sector','Security']).Close.agg(['first','last'])
ytd_change</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>import datetime as dt
ytd_change = stocks[stocks.Date >= dt.datetime(dt.datetime.now().year, 1, 1)
    ].groupby(['GICS Sector', 'Security']).Close.agg(['first', 'last'])
__output__ = ytd_change
</code></pre>
        <p><span onclick="$('#var_output_f06586d6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f06586d6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>first</th>
      <th>last</th>
    </tr>
    <tr>
      <th>GICS Sector</th>
      <th>Security</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="7" valign="top">Communication Services</th>
      <th>AT&amp;T</th>
      <td>19.206949</td>
      <td>20.959999</td>
    </tr>
    <tr>
      <th>Activision Blizzard</th>
      <td>67.419998</td>
      <td>77.860001</td>
    </tr>
    <tr>
      <th>Alphabet Inc. (Class A)</th>
      <td>2899.830078</td>
      <td>2179.260010</td>
    </tr>
    <tr>
      <th>Alphabet Inc. (Class C)</th>
      <td>2901.489990</td>
      <td>2187.449951</td>
    </tr>
    <tr>
      <th>Charter Communications</th>
      <td>647.580017</td>
      <td>468.529999</td>
    </tr>
    <tr>
      <th>Comcast</th>
      <td>50.740002</td>
      <td>39.240002</td>
    </tr>
    <tr>
      <th>Dish Network</th>
      <td>33.290001</td>
      <td>17.930000</td>
    </tr>
    <tr>
      <th>...</th>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th rowspan="7" valign="top">Utilities</th>
      <th>PPL Corporation</th>
      <td>30.139999</td>
      <td>27.129999</td>
    </tr>
    <tr>
      <th>Pinnacle West</th>
      <td>69.790001</td>
      <td>73.120003</td>
    </tr>
    <tr>
      <th>Public Service Enterprise Group</th>
      <td>66.160004</td>
      <td>63.279999</td>
    </tr>
    <tr>
      <th>Sempra Energy</th>
      <td>131.990005</td>
      <td>150.270004</td>
    </tr>
    <tr>
      <th>Southern Company</th>
      <td>68.169998</td>
      <td>71.309998</td>
    </tr>
    <tr>
      <th>WEC Energy Group</th>
      <td>96.089996</td>
      <td>100.639999</td>
    </tr>
    <tr>
      <th>Xcel Energy</th>
      <td>67.940002</td>
      <td>70.760002</td>
    </tr>
  </tbody>
</table>
<p>495 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> ytd_change, __output__ </p>
    
          <p>ytd_change (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>first</th>
      <th>last</th>
    </tr>
    <tr>
      <th>GICS Sector</th>
      <th>Security</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="7" valign="top">Communication Services</th>
      <th>AT&amp;T</th>
      <td>19.206949</td>
      <td>20.959999</td>
    </tr>
    <tr>
      <th>Activision Blizzard</th>
      <td>67.419998</td>
      <td>77.860001</td>
    </tr>
    <tr>
      <th>Alphabet Inc. (Class A)</th>
      <td>2899.830078</td>
      <td>2179.260010</td>
    </tr>
    <tr>
      <th>Alphabet Inc. (Class C)</th>
      <td>2901.489990</td>
      <td>2187.449951</td>
    </tr>
    <tr>
      <th>Charter Communications</th>
      <td>647.580017</td>
      <td>468.529999</td>
    </tr>
    <tr>
      <th>Comcast</th>
      <td>50.740002</td>
      <td>39.240002</td>
    </tr>
    <tr>
      <th>Dish Network</th>
      <td>33.290001</td>
      <td>17.930000</td>
    </tr>
    <tr>
      <th>...</th>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th rowspan="7" valign="top">Utilities</th>
      <th>PPL Corporation</th>
      <td>30.139999</td>
      <td>27.129999</td>
    </tr>
    <tr>
      <th>Pinnacle West</th>
      <td>69.790001</td>
      <td>73.120003</td>
    </tr>
    <tr>
      <th>Public Service Enterprise Group</th>
      <td>66.160004</td>
      <td>63.279999</td>
    </tr>
    <tr>
      <th>Sempra Energy</th>
      <td>131.990005</td>
      <td>150.270004</td>
    </tr>
    <tr>
      <th>Southern Company</th>
      <td>68.169998</td>
      <td>71.309998</td>
    </tr>
    <tr>
      <th>WEC Energy Group</th>
      <td>96.089996</td>
      <td>100.639999</td>
    </tr>
    <tr>
      <th>Xcel Energy</th>
      <td>67.940002</td>
      <td>70.760002</td>
    </tr>
  </tbody>
</table>
<p>495 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>first</th>
      <th>last</th>
    </tr>
    <tr>
      <th>GICS Sector</th>
      <th>Security</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="7" valign="top">Communication Services</th>
      <th>AT&amp;T</th>
      <td>19.206949</td>
      <td>20.959999</td>
    </tr>
    <tr>
      <th>Activision Blizzard</th>
      <td>67.419998</td>
      <td>77.860001</td>
    </tr>
    <tr>
      <th>Alphabet Inc. (Class A)</th>
      <td>2899.830078</td>
      <td>2179.260010</td>
    </tr>
    <tr>
      <th>Alphabet Inc. (Class C)</th>
      <td>2901.489990</td>
      <td>2187.449951</td>
    </tr>
    <tr>
      <th>Charter Communications</th>
      <td>647.580017</td>
      <td>468.529999</td>
    </tr>
    <tr>
      <th>Comcast</th>
      <td>50.740002</td>
      <td>39.240002</td>
    </tr>
    <tr>
      <th>Dish Network</th>
      <td>33.290001</td>
      <td>17.930000</td>
    </tr>
    <tr>
      <th>...</th>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th rowspan="7" valign="top">Utilities</th>
      <th>PPL Corporation</th>
      <td>30.139999</td>
      <td>27.129999</td>
    </tr>
    <tr>
      <th>Pinnacle West</th>
      <td>69.790001</td>
      <td>73.120003</td>
    </tr>
    <tr>
      <th>Public Service Enterprise Group</th>
      <td>66.160004</td>
      <td>63.279999</td>
    </tr>
    <tr>
      <th>Sempra Energy</th>
      <td>131.990005</td>
      <td>150.270004</td>
    </tr>
    <tr>
      <th>Southern Company</th>
      <td>68.169998</td>
      <td>71.309998</td>
    </tr>
    <tr>
      <th>WEC Energy Group</th>
      <td>96.089996</td>
      <td>100.639999</td>
    </tr>
    <tr>
      <th>Xcel Energy</th>
      <td>67.940002</td>
      <td>70.760002</td>
    </tr>
  </tbody>
</table>
<p>495 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which stock had the highest year-to-date percent change in closing price?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>((ytd_change['last'] - ytd_change['first']) / ytd_change['first']).sort_values().tail(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>((ytd_change['last'] - ytd_change['first']) / ytd_change['first']).sort_values().tail(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = ((ytd_change['last'] - ytd_change['first']) / ytd_change['first']
    ).sort_values().tail(1)
</code></pre>
        <p><span onclick="$('#var_output_d91c7ad6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d91c7ad6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>GICS Sector  Security            
Energy       Occidental Petroleum    0.895686
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>GICS Sector  Security            
Energy       Occidental Petroleum    0.895686
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Rank the sectors from best to worst based on each sector's year-to-date average stock performance?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>((ytd_change['last'] - ytd_change['first']) / ytd_change['first']).reset_index().groupby('GICS Sector')[0].mean().sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>((ytd_change['last'] - ytd_change['first']) / ytd_change['first']).reset_index().groupby('GICS Sector')[0].mean().sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = ((ytd_change['last'] - ytd_change['first']) / ytd_change['first']
    ).reset_index().groupby('GICS Sector')[0].mean().sort_values(ascending=
    False)
</code></pre>
        <p><span onclick="$('#var_output_23c38f48').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_23c38f48" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>GICS Sector
Energy                    0.241630
Utilities                 0.013651
Consumer Staples         -0.028622
Materials                -0.136379
Health Care              -0.148945
Industrials              -0.176936
Financials               -0.177591
Real Estate              -0.207891
Communication Services   -0.228969
Information Technology   -0.269008
Consumer Discretionary   -0.308507
Name: 0, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>GICS Sector
Energy                    0.241630
Utilities                 0.013651
Consumer Staples         -0.028622
Materials                -0.136379
Health Care              -0.148945
Industrials              -0.176936
Financials               -0.177591
Real Estate              -0.207891
Communication Services   -0.228969
Information Technology   -0.269008
Consumer Discretionary   -0.308507
Name: 0, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the sectors that had the highest share of positive news. Sort them from highest to lowest.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>sentiments = stocks.groupby('GICS Sector')[['News - Positive Sentiment','News - Negative Sentiment']].sum()
sentiments.columns = ['positive','negative']
(sentiments.positive / sentiments.sum(1)).sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>sentiments = stocks.groupby('GICS Sector')[['News - Positive Sentiment','News - Negative Sentiment']].sum()
sentiments.columns = ['positive','negative']
(sentiments.positive / sentiments.sum(1)).sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>sentiments = stocks.groupby('GICS Sector')[['News - Positive Sentiment',
    'News - Negative Sentiment']].sum()
sentiments.columns = ['positive', 'negative']
__output__ = (sentiments.positive / sentiments.sum(1)).sort_values(ascending
    =False)
</code></pre>
        <p><span onclick="$('#var_output_5ff47297').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5ff47297" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>GICS Sector
Information Technology    0.632022
Consumer Discretionary    0.612875
Communication Services    0.596372
Consumer Staples          0.531742
Materials                 0.516967
Financials                0.464623
Real Estate               0.457659
Utilities                 0.448358
Energy                    0.381879
Health Care               0.359660
Industrials               0.271680
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> sentiments, __output__ </p>
    
          <p>sentiments (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>positive</th>
      <th>negative</th>
    </tr>
    <tr>
      <th>GICS Sector</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Communication Services</th>
      <td>236650.0</td>
      <td>160166.0</td>
    </tr>
    <tr>
      <th>Consumer Discretionary</th>
      <td>242970.0</td>
      <td>153473.0</td>
    </tr>
    <tr>
      <th>Consumer Staples</th>
      <td>44896.0</td>
      <td>39536.0</td>
    </tr>
    <tr>
      <th>Energy</th>
      <td>7730.0</td>
      <td>12512.0</td>
    </tr>
    <tr>
      <th>Financials</th>
      <td>78578.0</td>
      <td>90544.0</td>
    </tr>
    <tr>
      <th>Health Care</th>
      <td>50133.0</td>
      <td>89257.0</td>
    </tr>
    <tr>
      <th>Industrials</th>
      <td>37277.0</td>
      <td>99932.0</td>
    </tr>
    <tr>
      <th>Information Technology</th>
      <td>182459.0</td>
      <td>106232.0</td>
    </tr>
    <tr>
      <th>Materials</th>
      <td>12279.0</td>
      <td>11473.0</td>
    </tr>
    <tr>
      <th>Real Estate</th>
      <td>38420.0</td>
      <td>45529.0</td>
    </tr>
    <tr>
      <th>Utilities</th>
      <td>11916.0</td>
      <td>14661.0</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>GICS Sector
Information Technology    0.632022
Consumer Discretionary    0.612875
Communication Services    0.596372
Consumer Staples          0.531742
Materials                 0.516967
Financials                0.464623
Real Estate               0.457659
Utilities                 0.448358
Energy                    0.381879
Health Care               0.359660
Industrials               0.271680
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the monthly percent change in total news volume for each sector. Return a dataframe with the sectors as columns and months as an index.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>monthly_change = stocks.groupby(['GICS Sector',pd.Grouper(key='Date',freq='M')])['News - Volume'].sum().unstack(0).pct_change()
monthly_change.index = monthly_change.index.to_period('M')
monthly_change</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>monthly_change = stocks.groupby(['GICS Sector',pd.Grouper(key='Date',freq='M')])['News - Volume'].sum().unstack(0).pct_change()
monthly_change.index = monthly_change.index.to_period('M')
monthly_change</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>monthly_change = stocks.groupby(['GICS Sector', pd.Grouper(key='Date', freq
    ='M')])['News - Volume'].sum().unstack(0).pct_change()
monthly_change.index = monthly_change.index.to_period('M')
__output__ = monthly_change
</code></pre>
        <p><span onclick="$('#var_output_f2568792').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f2568792" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>GICS Sector</th>
      <th>Communication Services</th>
      <th>Consumer Discretionary</th>
      <th>Consumer Staples</th>
      <th>Energy</th>
      <th>Financials</th>
      <th>Health Care</th>
      <th>Industrials</th>
      <th>Information Technology</th>
      <th>Materials</th>
      <th>Real Estate</th>
      <th>Utilities</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-09</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2020-10</th>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
    </tr>
    <tr>
      <th>2020-11</th>
      <td>-0.292647</td>
      <td>-0.105110</td>
      <td>0.211120</td>
      <td>-0.382744</td>
      <td>-0.212164</td>
      <td>0.206402</td>
      <td>-0.288226</td>
      <td>-0.194011</td>
      <td>-0.089813</td>
      <td>-0.138996</td>
      <td>-0.134540</td>
    </tr>
    <tr>
      <th>2020-12</th>
      <td>0.140605</td>
      <td>-0.198356</td>
      <td>-0.371302</td>
      <td>-0.039051</td>
      <td>-0.080811</td>
      <td>0.151618</td>
      <td>-0.027155</td>
      <td>-0.109249</td>
      <td>-0.257574</td>
      <td>-0.066360</td>
      <td>-0.319858</td>
    </tr>
    <tr>
      <th>2021-01</th>
      <td>-0.205758</td>
      <td>-0.049294</td>
      <td>-0.097919</td>
      <td>0.002279</td>
      <td>-0.105890</td>
      <td>-0.313816</td>
      <td>-0.073853</td>
      <td>-0.057221</td>
      <td>0.001141</td>
      <td>0.067566</td>
      <td>0.000474</td>
    </tr>
    <tr>
      <th>2021-02</th>
      <td>0.194843</td>
      <td>0.111344</td>
      <td>0.247740</td>
      <td>0.397726</td>
      <td>0.110629</td>
      <td>0.069251</td>
      <td>0.140364</td>
      <td>0.027068</td>
      <td>0.212072</td>
      <td>0.040092</td>
      <td>0.303915</td>
    </tr>
    <tr>
      <th>2021-03</th>
      <td>0.024454</td>
      <td>1.365656</td>
      <td>-0.024202</td>
      <td>-0.049829</td>
      <td>0.337315</td>
      <td>0.141191</td>
      <td>-0.021725</td>
      <td>0.139061</td>
      <td>0.042154</td>
      <td>0.171762</td>
      <td>-0.046925</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2021-12</th>
      <td>-0.041934</td>
      <td>-0.215582</td>
      <td>-0.330688</td>
      <td>-0.148775</td>
      <td>-0.093527</td>
      <td>-0.004497</td>
      <td>0.113323</td>
      <td>-0.072781</td>
      <td>0.090073</td>
      <td>0.349289</td>
      <td>-0.102616</td>
    </tr>
    <tr>
      <th>2022-01</th>
      <td>0.149553</td>
      <td>-0.010602</td>
      <td>-0.142393</td>
      <td>0.053549</td>
      <td>0.089701</td>
      <td>-0.191889</td>
      <td>-0.132763</td>
      <td>0.039103</td>
      <td>0.061142</td>
      <td>-0.212871</td>
      <td>-0.001429</td>
    </tr>
    <tr>
      <th>2022-02</th>
      <td>-0.018142</td>
      <td>0.063165</td>
      <td>-0.049462</td>
      <td>0.141640</td>
      <td>0.062643</td>
      <td>-0.033536</td>
      <td>-0.080719</td>
      <td>-0.005256</td>
      <td>0.110827</td>
      <td>0.186085</td>
      <td>0.146150</td>
    </tr>
    <tr>
      <th>2022-03</th>
      <td>0.154446</td>
      <td>1.433152</td>
      <td>0.239352</td>
      <td>0.217172</td>
      <td>0.126356</td>
      <td>0.018108</td>
      <td>0.154101</td>
      <td>0.189380</td>
      <td>-0.002612</td>
      <td>0.073356</td>
      <td>-0.042535</td>
    </tr>
    <tr>
      <th>2022-04</th>
      <td>-0.133884</td>
      <td>-0.516844</td>
      <td>-0.140187</td>
      <td>-0.147754</td>
      <td>-0.126165</td>
      <td>-0.112190</td>
      <td>-0.072109</td>
      <td>-0.242985</td>
      <td>0.025820</td>
      <td>-0.076872</td>
      <td>0.005891</td>
    </tr>
    <tr>
      <th>2022-05</th>
      <td>0.117826</td>
      <td>-0.046265</td>
      <td>0.083578</td>
      <td>-0.023603</td>
      <td>0.023308</td>
      <td>0.108197</td>
      <td>-0.032016</td>
      <td>0.146734</td>
      <td>-0.040180</td>
      <td>0.081905</td>
      <td>0.013778</td>
    </tr>
    <tr>
      <th>2022-06</th>
      <td>-0.048748</td>
      <td>-0.008879</td>
      <td>0.059683</td>
      <td>0.003902</td>
      <td>-0.098289</td>
      <td>0.040415</td>
      <td>-0.017710</td>
      <td>0.072249</td>
      <td>-0.102447</td>
      <td>-0.059646</td>
      <td>-0.155034</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 11 columns</p>
      
        <p><strong>Hyp output variables:</strong> monthly_change, __output__ </p>
    
          <p>monthly_change (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>GICS Sector</th>
      <th>Communication Services</th>
      <th>Consumer Discretionary</th>
      <th>Consumer Staples</th>
      <th>Energy</th>
      <th>Financials</th>
      <th>Health Care</th>
      <th>Industrials</th>
      <th>Information Technology</th>
      <th>Materials</th>
      <th>Real Estate</th>
      <th>Utilities</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-09</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2020-10</th>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
    </tr>
    <tr>
      <th>2020-11</th>
      <td>-0.292647</td>
      <td>-0.105110</td>
      <td>0.211120</td>
      <td>-0.382744</td>
      <td>-0.212164</td>
      <td>0.206402</td>
      <td>-0.288226</td>
      <td>-0.194011</td>
      <td>-0.089813</td>
      <td>-0.138996</td>
      <td>-0.134540</td>
    </tr>
    <tr>
      <th>2020-12</th>
      <td>0.140605</td>
      <td>-0.198356</td>
      <td>-0.371302</td>
      <td>-0.039051</td>
      <td>-0.080811</td>
      <td>0.151618</td>
      <td>-0.027155</td>
      <td>-0.109249</td>
      <td>-0.257574</td>
      <td>-0.066360</td>
      <td>-0.319858</td>
    </tr>
    <tr>
      <th>2021-01</th>
      <td>-0.205758</td>
      <td>-0.049294</td>
      <td>-0.097919</td>
      <td>0.002279</td>
      <td>-0.105890</td>
      <td>-0.313816</td>
      <td>-0.073853</td>
      <td>-0.057221</td>
      <td>0.001141</td>
      <td>0.067566</td>
      <td>0.000474</td>
    </tr>
    <tr>
      <th>2021-02</th>
      <td>0.194843</td>
      <td>0.111344</td>
      <td>0.247740</td>
      <td>0.397726</td>
      <td>0.110629</td>
      <td>0.069251</td>
      <td>0.140364</td>
      <td>0.027068</td>
      <td>0.212072</td>
      <td>0.040092</td>
      <td>0.303915</td>
    </tr>
    <tr>
      <th>2021-03</th>
      <td>0.024454</td>
      <td>1.365656</td>
      <td>-0.024202</td>
      <td>-0.049829</td>
      <td>0.337315</td>
      <td>0.141191</td>
      <td>-0.021725</td>
      <td>0.139061</td>
      <td>0.042154</td>
      <td>0.171762</td>
      <td>-0.046925</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2021-12</th>
      <td>-0.041934</td>
      <td>-0.215582</td>
      <td>-0.330688</td>
      <td>-0.148775</td>
      <td>-0.093527</td>
      <td>-0.004497</td>
      <td>0.113323</td>
      <td>-0.072781</td>
      <td>0.090073</td>
      <td>0.349289</td>
      <td>-0.102616</td>
    </tr>
    <tr>
      <th>2022-01</th>
      <td>0.149553</td>
      <td>-0.010602</td>
      <td>-0.142393</td>
      <td>0.053549</td>
      <td>0.089701</td>
      <td>-0.191889</td>
      <td>-0.132763</td>
      <td>0.039103</td>
      <td>0.061142</td>
      <td>-0.212871</td>
      <td>-0.001429</td>
    </tr>
    <tr>
      <th>2022-02</th>
      <td>-0.018142</td>
      <td>0.063165</td>
      <td>-0.049462</td>
      <td>0.141640</td>
      <td>0.062643</td>
      <td>-0.033536</td>
      <td>-0.080719</td>
      <td>-0.005256</td>
      <td>0.110827</td>
      <td>0.186085</td>
      <td>0.146150</td>
    </tr>
    <tr>
      <th>2022-03</th>
      <td>0.154446</td>
      <td>1.433152</td>
      <td>0.239352</td>
      <td>0.217172</td>
      <td>0.126356</td>
      <td>0.018108</td>
      <td>0.154101</td>
      <td>0.189380</td>
      <td>-0.002612</td>
      <td>0.073356</td>
      <td>-0.042535</td>
    </tr>
    <tr>
      <th>2022-04</th>
      <td>-0.133884</td>
      <td>-0.516844</td>
      <td>-0.140187</td>
      <td>-0.147754</td>
      <td>-0.126165</td>
      <td>-0.112190</td>
      <td>-0.072109</td>
      <td>-0.242985</td>
      <td>0.025820</td>
      <td>-0.076872</td>
      <td>0.005891</td>
    </tr>
    <tr>
      <th>2022-05</th>
      <td>0.117826</td>
      <td>-0.046265</td>
      <td>0.083578</td>
      <td>-0.023603</td>
      <td>0.023308</td>
      <td>0.108197</td>
      <td>-0.032016</td>
      <td>0.146734</td>
      <td>-0.040180</td>
      <td>0.081905</td>
      <td>0.013778</td>
    </tr>
    <tr>
      <th>2022-06</th>
      <td>-0.048748</td>
      <td>-0.008879</td>
      <td>0.059683</td>
      <td>0.003902</td>
      <td>-0.098289</td>
      <td>0.040415</td>
      <td>-0.017710</td>
      <td>0.072249</td>
      <td>-0.102447</td>
      <td>-0.059646</td>
      <td>-0.155034</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 11 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>GICS Sector</th>
      <th>Communication Services</th>
      <th>Consumer Discretionary</th>
      <th>Consumer Staples</th>
      <th>Energy</th>
      <th>Financials</th>
      <th>Health Care</th>
      <th>Industrials</th>
      <th>Information Technology</th>
      <th>Materials</th>
      <th>Real Estate</th>
      <th>Utilities</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-09</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2020-10</th>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
      <td>inf</td>
    </tr>
    <tr>
      <th>2020-11</th>
      <td>-0.292647</td>
      <td>-0.105110</td>
      <td>0.211120</td>
      <td>-0.382744</td>
      <td>-0.212164</td>
      <td>0.206402</td>
      <td>-0.288226</td>
      <td>-0.194011</td>
      <td>-0.089813</td>
      <td>-0.138996</td>
      <td>-0.134540</td>
    </tr>
    <tr>
      <th>2020-12</th>
      <td>0.140605</td>
      <td>-0.198356</td>
      <td>-0.371302</td>
      <td>-0.039051</td>
      <td>-0.080811</td>
      <td>0.151618</td>
      <td>-0.027155</td>
      <td>-0.109249</td>
      <td>-0.257574</td>
      <td>-0.066360</td>
      <td>-0.319858</td>
    </tr>
    <tr>
      <th>2021-01</th>
      <td>-0.205758</td>
      <td>-0.049294</td>
      <td>-0.097919</td>
      <td>0.002279</td>
      <td>-0.105890</td>
      <td>-0.313816</td>
      <td>-0.073853</td>
      <td>-0.057221</td>
      <td>0.001141</td>
      <td>0.067566</td>
      <td>0.000474</td>
    </tr>
    <tr>
      <th>2021-02</th>
      <td>0.194843</td>
      <td>0.111344</td>
      <td>0.247740</td>
      <td>0.397726</td>
      <td>0.110629</td>
      <td>0.069251</td>
      <td>0.140364</td>
      <td>0.027068</td>
      <td>0.212072</td>
      <td>0.040092</td>
      <td>0.303915</td>
    </tr>
    <tr>
      <th>2021-03</th>
      <td>0.024454</td>
      <td>1.365656</td>
      <td>-0.024202</td>
      <td>-0.049829</td>
      <td>0.337315</td>
      <td>0.141191</td>
      <td>-0.021725</td>
      <td>0.139061</td>
      <td>0.042154</td>
      <td>0.171762</td>
      <td>-0.046925</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2021-12</th>
      <td>-0.041934</td>
      <td>-0.215582</td>
      <td>-0.330688</td>
      <td>-0.148775</td>
      <td>-0.093527</td>
      <td>-0.004497</td>
      <td>0.113323</td>
      <td>-0.072781</td>
      <td>0.090073</td>
      <td>0.349289</td>
      <td>-0.102616</td>
    </tr>
    <tr>
      <th>2022-01</th>
      <td>0.149553</td>
      <td>-0.010602</td>
      <td>-0.142393</td>
      <td>0.053549</td>
      <td>0.089701</td>
      <td>-0.191889</td>
      <td>-0.132763</td>
      <td>0.039103</td>
      <td>0.061142</td>
      <td>-0.212871</td>
      <td>-0.001429</td>
    </tr>
    <tr>
      <th>2022-02</th>
      <td>-0.018142</td>
      <td>0.063165</td>
      <td>-0.049462</td>
      <td>0.141640</td>
      <td>0.062643</td>
      <td>-0.033536</td>
      <td>-0.080719</td>
      <td>-0.005256</td>
      <td>0.110827</td>
      <td>0.186085</td>
      <td>0.146150</td>
    </tr>
    <tr>
      <th>2022-03</th>
      <td>0.154446</td>
      <td>1.433152</td>
      <td>0.239352</td>
      <td>0.217172</td>
      <td>0.126356</td>
      <td>0.018108</td>
      <td>0.154101</td>
      <td>0.189380</td>
      <td>-0.002612</td>
      <td>0.073356</td>
      <td>-0.042535</td>
    </tr>
    <tr>
      <th>2022-04</th>
      <td>-0.133884</td>
      <td>-0.516844</td>
      <td>-0.140187</td>
      <td>-0.147754</td>
      <td>-0.126165</td>
      <td>-0.112190</td>
      <td>-0.072109</td>
      <td>-0.242985</td>
      <td>0.025820</td>
      <td>-0.076872</td>
      <td>0.005891</td>
    </tr>
    <tr>
      <th>2022-05</th>
      <td>0.117826</td>
      <td>-0.046265</td>
      <td>0.083578</td>
      <td>-0.023603</td>
      <td>0.023308</td>
      <td>0.108197</td>
      <td>-0.032016</td>
      <td>0.146734</td>
      <td>-0.040180</td>
      <td>0.081905</td>
      <td>0.013778</td>
    </tr>
    <tr>
      <th>2022-06</th>
      <td>-0.048748</td>
      <td>-0.008879</td>
      <td>0.059683</td>
      <td>0.003902</td>
      <td>-0.098289</td>
      <td>0.040415</td>
      <td>-0.017710</td>
      <td>0.072249</td>
      <td>-0.102447</td>
      <td>-0.059646</td>
      <td>-0.155034</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 11 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which week of the year had the highest share of negative news in 2022?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>month_sent = stocks[stocks.Date >= dt.datetime(2022,1,1)].groupby(pd.Grouper(key='Date',freq='W'))[['News - Positive Sentiment','News - Negative Sentiment']].sum()
month_sent.columns = ['positive','negative']
(month_sent.negative / month_sent.sum(1)).idxmax().weekofyear</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>month_sent = stocks[stocks.Date >= dt.datetime(2022,1,1)].groupby(pd.Grouper(key='Date',freq='W'))[['News - Positive Sentiment','News - Negative Sentiment']].sum()
month_sent.columns = ['positive','negative']
(month_sent.negative / month_sent.sum(1)).idxmax().weekofyear</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>month_sent = stocks[stocks.Date >= dt.datetime(2022, 1, 1)].groupby(pd.
    Grouper(key='Date', freq='W'))[['News - Positive Sentiment',
    'News - Negative Sentiment']].sum()
month_sent.columns = ['positive', 'negative']
__output__ = (month_sent.negative / month_sent.sum(1)).idxmax().weekofyear
</code></pre>
        <p><span onclick="$('#var_output_aea5db86').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_aea5db86" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>16</code></pre>
      
        <p><strong>Hyp output variables:</strong> month_sent, __output__ </p>
    
          <p>month_sent (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>positive</th>
      <th>negative</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2022-01-09</th>
      <td>8139.0</td>
      <td>8052.0</td>
    </tr>
    <tr>
      <th>2022-01-16</th>
      <td>8015.0</td>
      <td>8330.0</td>
    </tr>
    <tr>
      <th>2022-01-23</th>
      <td>7934.0</td>
      <td>9219.0</td>
    </tr>
    <tr>
      <th>2022-01-30</th>
      <td>10273.0</td>
      <td>9166.0</td>
    </tr>
    <tr>
      <th>2022-02-06</th>
      <td>9639.0</td>
      <td>9187.0</td>
    </tr>
    <tr>
      <th>2022-02-13</th>
      <td>10704.0</td>
      <td>9195.0</td>
    </tr>
    <tr>
      <th>2022-02-20</th>
      <td>11396.0</td>
      <td>10230.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2022-05-22</th>
      <td>9630.0</td>
      <td>10056.0</td>
    </tr>
    <tr>
      <th>2022-05-29</th>
      <td>9461.0</td>
      <td>9026.0</td>
    </tr>
    <tr>
      <th>2022-06-05</th>
      <td>7322.0</td>
      <td>7332.0</td>
    </tr>
    <tr>
      <th>2022-06-12</th>
      <td>11227.0</td>
      <td>8992.0</td>
    </tr>
    <tr>
      <th>2022-06-19</th>
      <td>11035.0</td>
      <td>10381.0</td>
    </tr>
    <tr>
      <th>2022-06-26</th>
      <td>8061.0</td>
      <td>7794.0</td>
    </tr>
    <tr>
      <th>2022-07-03</th>
      <td>7658.0</td>
      <td>6828.0</td>
    </tr>
  </tbody>
</table>
<p>26 rows × 2 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>16</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which stock has the best year-to-date performance within each sector? Return a dataframe with sectors as an index and stock name and performance as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>best_perf = ((ytd_change['last'] / ytd_change['first']) - 1).unstack(0).agg(['idxmax','max']).T
best_perf.columns = ['stock_name','ytd_performance']
best_perf</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>best_perf = ((ytd_change['last'] / ytd_change['first']) - 1).unstack(0).agg(['idxmax','max']).T
best_perf.columns = ['stock_name','ytd_performance']
best_perf</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>best_perf = (ytd_change['last'] / ytd_change['first'] - 1).unstack(0).agg([
    'idxmax', 'max']).T
best_perf.columns = ['stock_name', 'ytd_performance']
__output__ = best_perf
</code></pre>
        <p><span onclick="$('#var_output_7403ebdc').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7403ebdc" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stock_name</th>
      <th>ytd_performance</th>
    </tr>
    <tr>
      <th>GICS Sector</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Communication Services</th>
      <td>T-Mobile US</td>
      <td>0.175741</td>
    </tr>
    <tr>
      <th>Consumer Discretionary</th>
      <td>Dollar Tree</td>
      <td>0.103988</td>
    </tr>
    <tr>
      <th>Consumer Staples</th>
      <td>Molson Coors Beverage Company</td>
      <td>0.151214</td>
    </tr>
    <tr>
      <th>Energy</th>
      <td>Occidental Petroleum</td>
      <td>0.895686</td>
    </tr>
    <tr>
      <th>Financials</th>
      <td>Berkley</td>
      <td>0.26003</td>
    </tr>
    <tr>
      <th>Health Care</th>
      <td>McKesson</td>
      <td>0.314833</td>
    </tr>
    <tr>
      <th>Industrials</th>
      <td>Northrop Grumman</td>
      <td>0.24133</td>
    </tr>
    <tr>
      <th>Information Technology</th>
      <td>Enphase</td>
      <td>0.058498</td>
    </tr>
    <tr>
      <th>Materials</th>
      <td>CF Industries</td>
      <td>0.214478</td>
    </tr>
    <tr>
      <th>Real Estate</th>
      <td>Ventas</td>
      <td>-0.009628</td>
    </tr>
    <tr>
      <th>Utilities</th>
      <td>Constellation Energy</td>
      <td>0.363333</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> best_perf, __output__ </p>
    
          <p>best_perf (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stock_name</th>
      <th>ytd_performance</th>
    </tr>
    <tr>
      <th>GICS Sector</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Communication Services</th>
      <td>T-Mobile US</td>
      <td>0.175741</td>
    </tr>
    <tr>
      <th>Consumer Discretionary</th>
      <td>Dollar Tree</td>
      <td>0.103988</td>
    </tr>
    <tr>
      <th>Consumer Staples</th>
      <td>Molson Coors Beverage Company</td>
      <td>0.151214</td>
    </tr>
    <tr>
      <th>Energy</th>
      <td>Occidental Petroleum</td>
      <td>0.895686</td>
    </tr>
    <tr>
      <th>Financials</th>
      <td>Berkley</td>
      <td>0.26003</td>
    </tr>
    <tr>
      <th>Health Care</th>
      <td>McKesson</td>
      <td>0.314833</td>
    </tr>
    <tr>
      <th>Industrials</th>
      <td>Northrop Grumman</td>
      <td>0.24133</td>
    </tr>
    <tr>
      <th>Information Technology</th>
      <td>Enphase</td>
      <td>0.058498</td>
    </tr>
    <tr>
      <th>Materials</th>
      <td>CF Industries</td>
      <td>0.214478</td>
    </tr>
    <tr>
      <th>Real Estate</th>
      <td>Ventas</td>
      <td>-0.009628</td>
    </tr>
    <tr>
      <th>Utilities</th>
      <td>Constellation Energy</td>
      <td>0.363333</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stock_name</th>
      <th>ytd_performance</th>
    </tr>
    <tr>
      <th>GICS Sector</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Communication Services</th>
      <td>T-Mobile US</td>
      <td>0.175741</td>
    </tr>
    <tr>
      <th>Consumer Discretionary</th>
      <td>Dollar Tree</td>
      <td>0.103988</td>
    </tr>
    <tr>
      <th>Consumer Staples</th>
      <td>Molson Coors Beverage Company</td>
      <td>0.151214</td>
    </tr>
    <tr>
      <th>Energy</th>
      <td>Occidental Petroleum</td>
      <td>0.895686</td>
    </tr>
    <tr>
      <th>Financials</th>
      <td>Berkley</td>
      <td>0.26003</td>
    </tr>
    <tr>
      <th>Health Care</th>
      <td>McKesson</td>
      <td>0.314833</td>
    </tr>
    <tr>
      <th>Industrials</th>
      <td>Northrop Grumman</td>
      <td>0.24133</td>
    </tr>
    <tr>
      <th>Information Technology</th>
      <td>Enphase</td>
      <td>0.058498</td>
    </tr>
    <tr>
      <th>Materials</th>
      <td>CF Industries</td>
      <td>0.214478</td>
    </tr>
    <tr>
      <th>Real Estate</th>
      <td>Ventas</td>
      <td>-0.009628</td>
    </tr>
    <tr>
      <th>Utilities</th>
      <td>Constellation Energy</td>
      <td>0.363333</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Calculate the monthly volatility of each stock by dividing the monthly standard deviation by the monthly average closing stock price.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>volatility = stocks.groupby(['Security',pd.Grouper(key='Date',freq='M')]).Close.agg(['mean','std'])
volatility = volatility['std'] / volatility['mean']
volatility</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>volatility = stocks.groupby(['Security',pd.Grouper(key='Date',freq='M')]).Close.agg(['mean','std'])
volatility = volatility['std'] / volatility['mean']
volatility</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>volatility = stocks.groupby(['Security', pd.Grouper(key='Date', freq='M')]
    ).Close.agg(['mean', 'std'])
volatility = volatility['std'] / volatility['mean']
__output__ = volatility
</code></pre>
        <p><span onclick="$('#var_output_13336851').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_13336851" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Security  Date      
3M        2020-09-30         NaN
          2020-10-31    0.027164
          2020-11-30    0.031047
          2020-12-31    0.009996
          2021-01-31    0.034005
                          ...   
eBay      2022-02-28    0.036762
          2022-03-31    0.043125
          2022-04-30    0.026068
          2022-05-31    0.063716
          2022-06-30    0.052002
Length: 10866, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> volatility, __output__ </p>
    
          <p>volatility (Series):</p>
          <pre><code>Security  Date      
3M        2020-09-30         NaN
          2020-10-31    0.027164
          2020-11-30    0.031047
          2020-12-31    0.009996
          2021-01-31    0.034005
                          ...   
eBay      2022-02-28    0.036762
          2022-03-31    0.043125
          2022-04-30    0.026068
          2022-05-31    0.063716
          2022-06-30    0.052002
Length: 10866, dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Security  Date      
3M        2020-09-30         NaN
          2020-10-31    0.027164
          2020-11-30    0.031047
          2020-12-31    0.009996
          2021-01-31    0.034005
                          ...   
eBay      2022-02-28    0.036762
          2022-03-31    0.043125
          2022-04-30    0.026068
          2022-05-31    0.063716
          2022-06-30    0.052002
Length: 10866, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_11 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which stock had the highest monthly volatility each month? Show the stock name and volatility.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>high_vol = volatility.unstack(1).agg(['idxmax','max']).T
high_vol.index = high_vol.index.to_period('M')
high_vol</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>high_vol = volatility.unstack(1).agg(['idxmax','max']).T
high_vol.index = high_vol.index.to_period('M')
high_vol</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>high_vol = volatility.unstack(1).agg(['idxmax', 'max']).T
high_vol.index = high_vol.index.to_period('M')
__output__ = high_vol
</code></pre>
        <p><span onclick="$('#var_output_89f006d0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_89f006d0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>idxmax</th>
      <th>max</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-09</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2020-10</th>
      <td>Align Technology</td>
      <td>0.158599</td>
    </tr>
    <tr>
      <th>2020-11</th>
      <td>Moderna</td>
      <td>0.230948</td>
    </tr>
    <tr>
      <th>2020-12</th>
      <td>Enphase</td>
      <td>0.136204</td>
    </tr>
    <tr>
      <th>2021-01</th>
      <td>Moderna</td>
      <td>0.138107</td>
    </tr>
    <tr>
      <th>2021-02</th>
      <td>Marathon Oil</td>
      <td>0.145343</td>
    </tr>
    <tr>
      <th>2021-03</th>
      <td>Paramount Global</td>
      <td>0.235025</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2021-12</th>
      <td>CF Industries</td>
      <td>0.090407</td>
    </tr>
    <tr>
      <th>2022-01</th>
      <td>Netflix</td>
      <td>0.164466</td>
    </tr>
    <tr>
      <th>2022-02</th>
      <td>Meta Platforms</td>
      <td>0.150832</td>
    </tr>
    <tr>
      <th>2022-03</th>
      <td>EPAM Systems</td>
      <td>0.183492</td>
    </tr>
    <tr>
      <th>2022-04</th>
      <td>Netflix</td>
      <td>0.263</td>
    </tr>
    <tr>
      <th>2022-05</th>
      <td>Target Corporation</td>
      <td>0.173371</td>
    </tr>
    <tr>
      <th>2022-06</th>
      <td>Royal Caribbean Group</td>
      <td>0.19219</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> high_vol, __output__ </p>
    
          <p>high_vol (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>idxmax</th>
      <th>max</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-09</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2020-10</th>
      <td>Align Technology</td>
      <td>0.158599</td>
    </tr>
    <tr>
      <th>2020-11</th>
      <td>Moderna</td>
      <td>0.230948</td>
    </tr>
    <tr>
      <th>2020-12</th>
      <td>Enphase</td>
      <td>0.136204</td>
    </tr>
    <tr>
      <th>2021-01</th>
      <td>Moderna</td>
      <td>0.138107</td>
    </tr>
    <tr>
      <th>2021-02</th>
      <td>Marathon Oil</td>
      <td>0.145343</td>
    </tr>
    <tr>
      <th>2021-03</th>
      <td>Paramount Global</td>
      <td>0.235025</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2021-12</th>
      <td>CF Industries</td>
      <td>0.090407</td>
    </tr>
    <tr>
      <th>2022-01</th>
      <td>Netflix</td>
      <td>0.164466</td>
    </tr>
    <tr>
      <th>2022-02</th>
      <td>Meta Platforms</td>
      <td>0.150832</td>
    </tr>
    <tr>
      <th>2022-03</th>
      <td>EPAM Systems</td>
      <td>0.183492</td>
    </tr>
    <tr>
      <th>2022-04</th>
      <td>Netflix</td>
      <td>0.263</td>
    </tr>
    <tr>
      <th>2022-05</th>
      <td>Target Corporation</td>
      <td>0.173371</td>
    </tr>
    <tr>
      <th>2022-06</th>
      <td>Royal Caribbean Group</td>
      <td>0.19219</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>idxmax</th>
      <th>max</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-09</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2020-10</th>
      <td>Align Technology</td>
      <td>0.158599</td>
    </tr>
    <tr>
      <th>2020-11</th>
      <td>Moderna</td>
      <td>0.230948</td>
    </tr>
    <tr>
      <th>2020-12</th>
      <td>Enphase</td>
      <td>0.136204</td>
    </tr>
    <tr>
      <th>2021-01</th>
      <td>Moderna</td>
      <td>0.138107</td>
    </tr>
    <tr>
      <th>2021-02</th>
      <td>Marathon Oil</td>
      <td>0.145343</td>
    </tr>
    <tr>
      <th>2021-03</th>
      <td>Paramount Global</td>
      <td>0.235025</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2021-12</th>
      <td>CF Industries</td>
      <td>0.090407</td>
    </tr>
    <tr>
      <th>2022-01</th>
      <td>Netflix</td>
      <td>0.164466</td>
    </tr>
    <tr>
      <th>2022-02</th>
      <td>Meta Platforms</td>
      <td>0.150832</td>
    </tr>
    <tr>
      <th>2022-03</th>
      <td>EPAM Systems</td>
      <td>0.183492</td>
    </tr>
    <tr>
      <th>2022-04</th>
      <td>Netflix</td>
      <td>0.263</td>
    </tr>
    <tr>
      <th>2022-05</th>
      <td>Target Corporation</td>
      <td>0.173371</td>
    </tr>
    <tr>
      <th>2022-06</th>
      <td>Royal Caribbean Group</td>
      <td>0.19219</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_12 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the year-over-year performance of each sub industry within the Energy Sector?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>stocks[(stocks.Date >= dt.datetime.now() - dt.timedelta(365)) & 
       (stocks['GICS Sector']=='Energy')].groupby(['GICS Sub-Industry']).Close.agg(['first','last']).apply(lambda x: x['last'] / x['first'] - 1, axis=1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>stocks[(stocks.Date >= dt.datetime.now() - dt.timedelta(365)) & 
       (stocks['GICS Sector']=='Energy')].groupby(['GICS Sub-Industry']).Close.agg(['first','last']).apply(lambda x: x['last'] / x['first'] - 1, axis=1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = stocks[(stocks.Date >= dt.datetime.now() - dt.timedelta(365)) &
    (stocks['GICS Sector'] == 'Energy')].groupby(['GICS Sub-Industry']
    ).Close.agg(['first', 'last']).apply(lambda x: x['last'] / x['first'] -
    1, axis=1)
</code></pre>
        <p><span onclick="$('#var_output_14944706').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_14944706" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>GICS Sub-Industry
Integrated Oil & Gas                 -0.085778
Oil & Gas Equipment & Services        0.456026
Oil & Gas Exploration & Production    7.824367
Oil & Gas Refining & Marketing        0.719463
Oil & Gas Storage & Transportation    0.959196
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>GICS Sub-Industry
Integrated Oil & Gas                 -0.085778
Oil & Gas Equipment & Services        0.456026
Oil & Gas Exploration & Production    7.824367
Oil & Gas Refining & Marketing        0.719463
Oil & Gas Storage & Transportation    0.959196
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_13 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the distribution of the volume of news accross all sectors in the last three months? Sort the result in descending order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>qtr_stocks = stocks[(stocks.Date >= dt.datetime.now() - dt.timedelta(365/4))].groupby('GICS Sector')['News - Volume'].sum()
(qtr_stocks/qtr_stocks.sum()).sort_values()[::-1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>qtr_stocks = stocks[(stocks.Date >= dt.datetime.now() - dt.timedelta(365/4))].groupby('GICS Sector')['News - Volume'].sum()
(qtr_stocks/qtr_stocks.sum()).sort_values()[::-1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>qtr_stocks = stocks[stocks.Date >= dt.datetime.now() - dt.timedelta(365 / 4)
    ].groupby('GICS Sector')['News - Volume'].sum()
__output__ = (qtr_stocks / qtr_stocks.sum()).sort_values()[::-1]
</code></pre>
        <p><span onclick="$('#var_output_205e648f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_205e648f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Series([], Name: News - Volume, dtype: float64)</code></pre>
      
        <p><strong>Hyp output variables:</strong> qtr_stocks, __output__ </p>
    
          <p>qtr_stocks (Series):</p>
          <pre><code>Series([], Name: News - Volume, dtype: float64)</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Series([], Name: News - Volume, dtype: float64)</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> stocknewseventssentiment-snes-10/notebook_1.ipynb|||turn_14 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the cumulative quarterly return for each sector? Return a dataframe with the sectors as index and annual quarters as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>stocks.groupby(['GICS Sector', pd.PeriodIndex(stocks.Date, freq='Q')]).Close.last().unstack().pct_change(axis=1).cumsum(axis=1).dropna(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>stocks.groupby(['GICS Sector', pd.PeriodIndex(stocks.Date, freq='Q')]).Close.last().unstack().pct_change(axis=1).cumsum(axis=1).dropna(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = stocks.groupby(['GICS Sector', pd.PeriodIndex(stocks.Date,
    freq='Q')]).Close.last().unstack().pct_change(axis=1).cumsum(axis=1
    ).dropna(1)
</code></pre>
        <p><span onclick="$('#var_output_77f8c632').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_77f8c632" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Date</th>
      <th>2020Q4</th>
      <th>2021Q1</th>
      <th>2021Q2</th>
      <th>2021Q3</th>
      <th>2021Q4</th>
      <th>2022Q1</th>
      <th>2022Q2</th>
    </tr>
    <tr>
      <th>GICS Sector</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Communication Services</th>
      <td>0.382177</td>
      <td>0.826511</td>
      <td>0.532447</td>
      <td>0.359696</td>
      <td>0.287198</td>
      <td>0.345822</td>
      <td>-0.115655</td>
    </tr>
    <tr>
      <th>Consumer Discretionary</th>
      <td>0.189047</td>
      <td>0.185547</td>
      <td>0.248867</td>
      <td>0.312155</td>
      <td>0.447467</td>
      <td>0.301060</td>
      <td>0.258708</td>
    </tr>
    <tr>
      <th>Consumer Staples</th>
      <td>0.030305</td>
      <td>-0.027412</td>
      <td>0.010797</td>
      <td>-0.000832</td>
      <td>0.037265</td>
      <td>0.066500</td>
      <td>-0.117089</td>
    </tr>
    <tr>
      <th>Energy</th>
      <td>0.020356</td>
      <td>0.201902</td>
      <td>0.322628</td>
      <td>0.299653</td>
      <td>0.303508</td>
      <td>0.586534</td>
      <td>0.520685</td>
    </tr>
    <tr>
      <th>Financials</th>
      <td>0.486653</td>
      <td>0.751846</td>
      <td>0.713637</td>
      <td>0.884465</td>
      <td>0.904986</td>
      <td>0.942984</td>
      <td>0.719372</td>
    </tr>
    <tr>
      <th>Health Care</th>
      <td>0.000786</td>
      <td>-0.047673</td>
      <td>0.135715</td>
      <td>0.177462</td>
      <td>0.434442</td>
      <td>0.207257</td>
      <td>0.118705</td>
    </tr>
    <tr>
      <th>Industrials</th>
      <td>0.210057</td>
      <td>0.243361</td>
      <td>0.383882</td>
      <td>0.414892</td>
      <td>0.384491</td>
      <td>0.095465</td>
      <td>0.012425</td>
    </tr>
    <tr>
      <th>Information Technology</th>
      <td>0.522340</td>
      <td>0.784745</td>
      <td>0.876072</td>
      <td>0.849499</td>
      <td>1.004285</td>
      <td>0.699346</td>
      <td>0.409885</td>
    </tr>
    <tr>
      <th>Materials</th>
      <td>0.253022</td>
      <td>0.448749</td>
      <td>0.471228</td>
      <td>0.407530</td>
      <td>0.297757</td>
      <td>0.357946</td>
      <td>0.205065</td>
    </tr>
    <tr>
      <th>Real Estate</th>
      <td>0.175666</td>
      <td>0.237402</td>
      <td>0.204256</td>
      <td>0.237667</td>
      <td>0.395384</td>
      <td>0.315734</td>
      <td>0.189612</td>
    </tr>
    <tr>
      <th>Utilities</th>
      <td>-0.033908</td>
      <td>-0.036308</td>
      <td>-0.045780</td>
      <td>-0.097086</td>
      <td>-0.013886</td>
      <td>0.052141</td>
      <td>0.032604</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 7 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Date</th>
      <th>2020Q4</th>
      <th>2021Q1</th>
      <th>2021Q2</th>
      <th>2021Q3</th>
      <th>2021Q4</th>
      <th>2022Q1</th>
      <th>2022Q2</th>
    </tr>
    <tr>
      <th>GICS Sector</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Communication Services</th>
      <td>0.382177</td>
      <td>0.826511</td>
      <td>0.532447</td>
      <td>0.359696</td>
      <td>0.287198</td>
      <td>0.345822</td>
      <td>-0.115655</td>
    </tr>
    <tr>
      <th>Consumer Discretionary</th>
      <td>0.189047</td>
      <td>0.185547</td>
      <td>0.248867</td>
      <td>0.312155</td>
      <td>0.447467</td>
      <td>0.301060</td>
      <td>0.258708</td>
    </tr>
    <tr>
      <th>Consumer Staples</th>
      <td>0.030305</td>
      <td>-0.027412</td>
      <td>0.010797</td>
      <td>-0.000832</td>
      <td>0.037265</td>
      <td>0.066500</td>
      <td>-0.117089</td>
    </tr>
    <tr>
      <th>Energy</th>
      <td>0.020356</td>
      <td>0.201902</td>
      <td>0.322628</td>
      <td>0.299653</td>
      <td>0.303508</td>
      <td>0.586534</td>
      <td>0.520685</td>
    </tr>
    <tr>
      <th>Financials</th>
      <td>0.486653</td>
      <td>0.751846</td>
      <td>0.713637</td>
      <td>0.884465</td>
      <td>0.904986</td>
      <td>0.942984</td>
      <td>0.719372</td>
    </tr>
    <tr>
      <th>Health Care</th>
      <td>0.000786</td>
      <td>-0.047673</td>
      <td>0.135715</td>
      <td>0.177462</td>
      <td>0.434442</td>
      <td>0.207257</td>
      <td>0.118705</td>
    </tr>
    <tr>
      <th>Industrials</th>
      <td>0.210057</td>
      <td>0.243361</td>
      <td>0.383882</td>
      <td>0.414892</td>
      <td>0.384491</td>
      <td>0.095465</td>
      <td>0.012425</td>
    </tr>
    <tr>
      <th>Information Technology</th>
      <td>0.522340</td>
      <td>0.784745</td>
      <td>0.876072</td>
      <td>0.849499</td>
      <td>1.004285</td>
      <td>0.699346</td>
      <td>0.409885</td>
    </tr>
    <tr>
      <th>Materials</th>
      <td>0.253022</td>
      <td>0.448749</td>
      <td>0.471228</td>
      <td>0.407530</td>
      <td>0.297757</td>
      <td>0.357946</td>
      <td>0.205065</td>
    </tr>
    <tr>
      <th>Real Estate</th>
      <td>0.175666</td>
      <td>0.237402</td>
      <td>0.204256</td>
      <td>0.237667</td>
      <td>0.395384</td>
      <td>0.315734</td>
      <td>0.189612</td>
    </tr>
    <tr>
      <th>Utilities</th>
      <td>-0.033908</td>
      <td>-0.036308</td>
      <td>-0.045780</td>
      <td>-0.097086</td>
      <td>-0.013886</td>
      <td>0.052141</td>
      <td>0.032604</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 7 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> travelleisure-worlds-best-hotels-2022/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the median rating of hotels belonging to the most common company?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>hotels[hotels.Company == hotels.Company.value_counts().idxmax()].Score.median()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>hotels[hotels.Company == hotels.Company.value_counts().idxmax()].Score.median()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = hotels[hotels.Company == hotels.Company.value_counts().idxmax()
    ].Score.median()
</code></pre>
        <p><span onclick="$('#var_output_d71dc680').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d71dc680" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>97.845</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>97.845</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> travelleisure-worlds-best-hotels-2022/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which country within each region has highest average hotel ratings? Show the region, country and average hotel rating.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>country_ratings = hotels.groupby(['Region','Country']).Score.mean().unstack(0).agg(['idxmax','max']).T
country_ratings.columns = ['Country','Score']
country_ratings</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>country_ratings = hotels.groupby(['Region','Country']).Score.mean().unstack(0).agg(['idxmax','max']).T
country_ratings.columns = ['Country','Score']
country_ratings</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>country_ratings = hotels.groupby(['Region', 'Country']).Score.mean().unstack(0
    ).agg(['idxmax', 'max']).T
country_ratings.columns = ['Country', 'Score']
__output__ = country_ratings
</code></pre>
        <p><span onclick="$('#var_output_9db78f51').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9db78f51" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Score</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Africa</th>
      <td>Morocco</td>
      <td>97.946667</td>
    </tr>
    <tr>
      <th>Asia</th>
      <td>Japan</td>
      <td>96.57</td>
    </tr>
    <tr>
      <th>Caribbean</th>
      <td>Dominica</td>
      <td>96.97</td>
    </tr>
    <tr>
      <th>Europe</th>
      <td>Spain</td>
      <td>97.82</td>
    </tr>
    <tr>
      <th>Latin America</th>
      <td>Peru</td>
      <td>97.87</td>
    </tr>
    <tr>
      <th>Middle East</th>
      <td>Turkey</td>
      <td>96.81</td>
    </tr>
    <tr>
      <th>North America</th>
      <td>United States</td>
      <td>96.920526</td>
    </tr>
    <tr>
      <th>Oceania</th>
      <td>Fiji</td>
      <td>96.64</td>
    </tr>
    <tr>
      <th>Southeast Asia</th>
      <td>Maldives</td>
      <td>99.02</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> country_ratings, __output__ </p>
    
          <p>country_ratings (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Score</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Africa</th>
      <td>Morocco</td>
      <td>97.946667</td>
    </tr>
    <tr>
      <th>Asia</th>
      <td>Japan</td>
      <td>96.57</td>
    </tr>
    <tr>
      <th>Caribbean</th>
      <td>Dominica</td>
      <td>96.97</td>
    </tr>
    <tr>
      <th>Europe</th>
      <td>Spain</td>
      <td>97.82</td>
    </tr>
    <tr>
      <th>Latin America</th>
      <td>Peru</td>
      <td>97.87</td>
    </tr>
    <tr>
      <th>Middle East</th>
      <td>Turkey</td>
      <td>96.81</td>
    </tr>
    <tr>
      <th>North America</th>
      <td>United States</td>
      <td>96.920526</td>
    </tr>
    <tr>
      <th>Oceania</th>
      <td>Fiji</td>
      <td>96.64</td>
    </tr>
    <tr>
      <th>Southeast Asia</th>
      <td>Maldives</td>
      <td>99.02</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Score</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Africa</th>
      <td>Morocco</td>
      <td>97.946667</td>
    </tr>
    <tr>
      <th>Asia</th>
      <td>Japan</td>
      <td>96.57</td>
    </tr>
    <tr>
      <th>Caribbean</th>
      <td>Dominica</td>
      <td>96.97</td>
    </tr>
    <tr>
      <th>Europe</th>
      <td>Spain</td>
      <td>97.82</td>
    </tr>
    <tr>
      <th>Latin America</th>
      <td>Peru</td>
      <td>97.87</td>
    </tr>
    <tr>
      <th>Middle East</th>
      <td>Turkey</td>
      <td>96.81</td>
    </tr>
    <tr>
      <th>North America</th>
      <td>United States</td>
      <td>96.920526</td>
    </tr>
    <tr>
      <th>Oceania</th>
      <td>Fiji</td>
      <td>96.64</td>
    </tr>
    <tr>
      <th>Southeast Asia</th>
      <td>Maldives</td>
      <td>99.02</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> travelleisure-worlds-best-hotels-2022/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the correlation between the number of rooms in a hotel and its rating?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>hotels[['Rooms','Score']].corr().loc['Rooms','Score']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>hotels[['Rooms','Score']].corr().loc['Rooms','Score']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = hotels[['Rooms', 'Score']].corr().loc['Rooms', 'Score']
</code></pre>
        <p><span onclick="$('#var_output_d0ebf10c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d0ebf10c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>-0.08902324800422136</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>-0.08902324800422136</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> travelleisure-worlds-best-hotels-2022/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which hotels had a worse ranking this year than in 2021? Show the hotel name, location and the difference in ranking from last year.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>drop_rankings = hotels[(hotels.Rank > hotels.Past_rank) & (hotels['2021']==1)]
drop_rankings['rank_drop'] = drop_rankings.Rank - drop_rankings.Past_rank
drop_rankings[['Hotel','Location','rank_drop']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>drop_rankings = hotels[(hotels.Rank > hotels.Past_rank) & (hotels['2021']==1)]
drop_rankings['rank_drop'] = drop_rankings.Rank - drop_rankings.Past_rank
drop_rankings[['Hotel','Location','rank_drop']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>drop_rankings = hotels[(hotels.Rank > hotels.Past_rank) & (hotels['2021'] == 1)
    ]
drop_rankings['rank_drop'] = drop_rankings.Rank - drop_rankings.Past_rank
__output__ = drop_rankings[['Hotel', 'Location', 'rank_drop']]
</code></pre>
        <p><span onclick="$('#var_output_d10f1bd9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d10f1bd9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Hotel</th>
      <th>Location</th>
      <th>rank_drop</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>Capella Ubud</td>
      <td>Bali</td>
      <td>2</td>
    </tr>
    <tr>
      <th>11</th>
      <td>The Oberoi Udaivilas</td>
      <td>Udaipur</td>
      <td>4</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Shangri-La the Shard</td>
      <td>London</td>
      <td>4</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Nayara Tented Camp</td>
      <td>La Fortuna</td>
      <td>25</td>
    </tr>
    <tr>
      <th>32</th>
      <td>The Oberoi Vanyavilas Wildlife Resort</td>
      <td>Ranthambhore</td>
      <td>19</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Canaves Oia Epitome</td>
      <td>Santorini</td>
      <td>9</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Nihi Sumba</td>
      <td>Sumba</td>
      <td>1</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Manoir Hovey</td>
      <td>North Hatley</td>
      <td>27</td>
    </tr>
    <tr>
      <th>59</th>
      <td>Gibb's Farm</td>
      <td>Karatu</td>
      <td>7</td>
    </tr>
    <tr>
      <th>64</th>
      <td>The Goring</td>
      <td>London</td>
      <td>9</td>
    </tr>
    <tr>
      <th>65</th>
      <td>The Oberoi Rajvilas</td>
      <td>Jaipur</td>
      <td>15</td>
    </tr>
    <tr>
      <th>82</th>
      <td>Taj Holiday Village Resort &amp; Spa</td>
      <td>Goa</td>
      <td>71</td>
    </tr>
    <tr>
      <th>83</th>
      <td>Mandarin Oriental Bangkok</td>
      <td>Bangkok</td>
      <td>43</td>
    </tr>
    <tr>
      <th>89</th>
      <td>Le Bristol Paris</td>
      <td>Paris</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> drop_rankings, __output__ </p>
    
          <p>drop_rankings (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Hotel</th>
      <th>Location</th>
      <th>Country</th>
      <th>Region</th>
      <th>Company</th>
      <th>Score</th>
      <th>Rank</th>
      <th>Rooms</th>
      <th>Theme</th>
      <th>Year</th>
      <th>2021</th>
      <th>Past_rank</th>
      <th>rank_drop</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>Capella Ubud</td>
      <td>Bali</td>
      <td>Indonesia</td>
      <td>Southeast Asia</td>
      <td>Pontiac Land Group</td>
      <td>98.97</td>
      <td>7</td>
      <td>23</td>
      <td>Nature</td>
      <td>2018</td>
      <td>1</td>
      <td>5</td>
      <td>2</td>
    </tr>
    <tr>
      <th>11</th>
      <td>The Oberoi Udaivilas</td>
      <td>Udaipur</td>
      <td>India</td>
      <td>Southeast Asia</td>
      <td>The Oberoi Group</td>
      <td>98.58</td>
      <td>12</td>
      <td>87</td>
      <td>Palace</td>
      <td>2007</td>
      <td>1</td>
      <td>8</td>
      <td>4</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Shangri-La the Shard</td>
      <td>London</td>
      <td>England</td>
      <td>Europe</td>
      <td>Kerry Properties</td>
      <td>97.86</td>
      <td>23</td>
      <td>202</td>
      <td>Contemporary</td>
      <td>2014</td>
      <td>1</td>
      <td>19</td>
      <td>4</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Nayara Tented Camp</td>
      <td>La Fortuna</td>
      <td>Costa Rica</td>
      <td>Latin America</td>
      <td>Nayara Resorts</td>
      <td>97.55</td>
      <td>27</td>
      <td>29</td>
      <td>Nature</td>
      <td>2019</td>
      <td>1</td>
      <td>2</td>
      <td>25</td>
    </tr>
    <tr>
      <th>32</th>
      <td>The Oberoi Vanyavilas Wildlife Resort</td>
      <td>Ranthambhore</td>
      <td>India</td>
      <td>Southeast Asia</td>
      <td>The Oberoi Group</td>
      <td>97.45</td>
      <td>33</td>
      <td>25</td>
      <td>Nature</td>
      <td>2001</td>
      <td>1</td>
      <td>14</td>
      <td>19</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Canaves Oia Epitome</td>
      <td>Santorini</td>
      <td>Greece</td>
      <td>Europe</td>
      <td>Chaidemenos family</td>
      <td>97.41</td>
      <td>33</td>
      <td>24</td>
      <td>Coastal</td>
      <td>2018</td>
      <td>1</td>
      <td>24</td>
      <td>9</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Nihi Sumba</td>
      <td>Sumba</td>
      <td>Indonesia</td>
      <td>Southeast Asia</td>
      <td>Christopher Burch</td>
      <td>97.33</td>
      <td>37</td>
      <td>28</td>
      <td>Beachfront</td>
      <td>2001</td>
      <td>1</td>
      <td>36</td>
      <td>1</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Manoir Hovey</td>
      <td>North Hatley</td>
      <td>Canada</td>
      <td>North America</td>
      <td>Stafford family</td>
      <td>96.83</td>
      <td>50</td>
      <td>36</td>
      <td>Manor</td>
      <td>1900</td>
      <td>1</td>
      <td>23</td>
      <td>27</td>
    </tr>
    <tr>
      <th>59</th>
      <td>Gibb's Farm</td>
      <td>Karatu</td>
      <td>Tanzania</td>
      <td>Africa</td>
      <td>Rick and Judi</td>
      <td>96.63</td>
      <td>60</td>
      <td>21</td>
      <td>Lodge</td>
      <td>1929</td>
      <td>1</td>
      <td>53</td>
      <td>7</td>
    </tr>
    <tr>
      <th>64</th>
      <td>The Goring</td>
      <td>London</td>
      <td>England</td>
      <td>Europe</td>
      <td>The Goring Family</td>
      <td>96.55</td>
      <td>65</td>
      <td>69</td>
      <td>Palace</td>
      <td>1910</td>
      <td>1</td>
      <td>56</td>
      <td>9</td>
    </tr>
    <tr>
      <th>65</th>
      <td>The Oberoi Rajvilas</td>
      <td>Jaipur</td>
      <td>India</td>
      <td>Southeast Asia</td>
      <td>The Oberoi Group</td>
      <td>96.52</td>
      <td>66</td>
      <td>54</td>
      <td>Palace</td>
      <td>1997</td>
      <td>1</td>
      <td>51</td>
      <td>15</td>
    </tr>
    <tr>
      <th>82</th>
      <td>Taj Holiday Village Resort &amp; Spa</td>
      <td>Goa</td>
      <td>India</td>
      <td>Southeast Asia</td>
      <td>India Hotels Company Limited</td>
      <td>96.21</td>
      <td>83</td>
      <td>142</td>
      <td>Beachfront</td>
      <td>1978</td>
      <td>1</td>
      <td>12</td>
      <td>71</td>
    </tr>
    <tr>
      <th>83</th>
      <td>Mandarin Oriental Bangkok</td>
      <td>Bangkok</td>
      <td>Thailand</td>
      <td>Southeast Asia</td>
      <td>Jardine Matheson</td>
      <td>96.18</td>
      <td>84</td>
      <td>331</td>
      <td>Contemporary</td>
      <td>1876</td>
      <td>1</td>
      <td>41</td>
      <td>43</td>
    </tr>
    <tr>
      <th>89</th>
      <td>Le Bristol Paris</td>
      <td>Paris</td>
      <td>France</td>
      <td>Europe</td>
      <td>Oetker Collection</td>
      <td>96.00</td>
      <td>87</td>
      <td>190</td>
      <td>Palace</td>
      <td>1925</td>
      <td>1</td>
      <td>80</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 13 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Hotel</th>
      <th>Location</th>
      <th>rank_drop</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>Capella Ubud</td>
      <td>Bali</td>
      <td>2</td>
    </tr>
    <tr>
      <th>11</th>
      <td>The Oberoi Udaivilas</td>
      <td>Udaipur</td>
      <td>4</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Shangri-La the Shard</td>
      <td>London</td>
      <td>4</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Nayara Tented Camp</td>
      <td>La Fortuna</td>
      <td>25</td>
    </tr>
    <tr>
      <th>32</th>
      <td>The Oberoi Vanyavilas Wildlife Resort</td>
      <td>Ranthambhore</td>
      <td>19</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Canaves Oia Epitome</td>
      <td>Santorini</td>
      <td>9</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Nihi Sumba</td>
      <td>Sumba</td>
      <td>1</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Manoir Hovey</td>
      <td>North Hatley</td>
      <td>27</td>
    </tr>
    <tr>
      <th>59</th>
      <td>Gibb's Farm</td>
      <td>Karatu</td>
      <td>7</td>
    </tr>
    <tr>
      <th>64</th>
      <td>The Goring</td>
      <td>London</td>
      <td>9</td>
    </tr>
    <tr>
      <th>65</th>
      <td>The Oberoi Rajvilas</td>
      <td>Jaipur</td>
      <td>15</td>
    </tr>
    <tr>
      <th>82</th>
      <td>Taj Holiday Village Resort &amp; Spa</td>
      <td>Goa</td>
      <td>71</td>
    </tr>
    <tr>
      <th>83</th>
      <td>Mandarin Oriental Bangkok</td>
      <td>Bangkok</td>
      <td>43</td>
    </tr>
    <tr>
      <th>89</th>
      <td>Le Bristol Paris</td>
      <td>Paris</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> travelleisure-worlds-best-hotels-2022/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average rating of hotels that were opened on or before and after the year 2000?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>ratings_2000 = hotels.groupby(hotels.Year > 2000).Score.mean().reset_index()
ratings_2000.Year.replace([True,False],['After 2000','On or before 2000'], inplace=True)
ratings_2000</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>ratings_2000 = hotels.groupby(hotels.Year > 2000).Score.mean().reset_index()
ratings_2000.Year.replace([True,False],['After 2000','On or before 2000'], inplace=True)
ratings_2000</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>ratings_2000 = hotels.groupby(hotels.Year > 2000).Score.mean().reset_index()
__tmp_1 = ratings_2000.Year.replace([True, False], ['After 2000',
    'On or before 2000'], inplace=True)
__output__ = ratings_2000
</code></pre>
        <p><span onclick="$('#var_output_774f83d1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_774f83d1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Year</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>On or before 2000</td>
      <td>96.849107</td>
    </tr>
    <tr>
      <th>1</th>
      <td>After 2000</td>
      <td>97.326889</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> ratings_2000, __output__ </p>
    
          <p>ratings_2000 (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Year</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>On or before 2000</td>
      <td>96.849107</td>
    </tr>
    <tr>
      <th>1</th>
      <td>After 2000</td>
      <td>97.326889</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Year</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>On or before 2000</td>
      <td>96.849107</td>
    </tr>
    <tr>
      <th>1</th>
      <td>After 2000</td>
      <td>97.326889</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> travelleisure-worlds-best-hotels-2022/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For each hotel theme, which country hosts hotels having the highest rating? Show the theme, country and average hotel rating.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>themes = hotels.groupby(['Country','Theme']).Score.mean().unstack().agg(['idxmax','max']).T
themes.columns = ['country','rating']
themes</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>themes = hotels.groupby(['Country','Theme']).Score.mean().unstack().agg(['idxmax','max']).T
themes.columns = ['country','rating']
themes</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>themes = hotels.groupby(['Country', 'Theme']).Score.mean().unstack().agg([
    'idxmax', 'max']).T
themes.columns = ['country', 'rating']
__output__ = themes
</code></pre>
        <p><span onclick="$('#var_output_b50d26cf').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b50d26cf" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country</th>
      <th>rating</th>
    </tr>
    <tr>
      <th>Theme</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Beachfront</th>
      <td>Greece</td>
      <td>97.87</td>
    </tr>
    <tr>
      <th>Boutique</th>
      <td>United States</td>
      <td>98.54</td>
    </tr>
    <tr>
      <th>Coastal</th>
      <td>Greece</td>
      <td>97.623333</td>
    </tr>
    <tr>
      <th>Contemporary</th>
      <td>France</td>
      <td>98.73</td>
    </tr>
    <tr>
      <th>Countryside</th>
      <td>Italy</td>
      <td>99.25</td>
    </tr>
    <tr>
      <th>Island</th>
      <td>Maldives</td>
      <td>99.02</td>
    </tr>
    <tr>
      <th>Lodge</th>
      <td>Tanzania</td>
      <td>96.63</td>
    </tr>
    <tr>
      <th>Manor</th>
      <td>Canada</td>
      <td>96.505</td>
    </tr>
    <tr>
      <th>Mediterranean</th>
      <td>Italy</td>
      <td>96.6</td>
    </tr>
    <tr>
      <th>Nature</th>
      <td>Indonesia</td>
      <td>98.64</td>
    </tr>
    <tr>
      <th>Palace</th>
      <td>Morocco</td>
      <td>97.946667</td>
    </tr>
    <tr>
      <th>Safari</th>
      <td>Rwanda</td>
      <td>98.29</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> themes, __output__ </p>
    
          <p>themes (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country</th>
      <th>rating</th>
    </tr>
    <tr>
      <th>Theme</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Beachfront</th>
      <td>Greece</td>
      <td>97.87</td>
    </tr>
    <tr>
      <th>Boutique</th>
      <td>United States</td>
      <td>98.54</td>
    </tr>
    <tr>
      <th>Coastal</th>
      <td>Greece</td>
      <td>97.623333</td>
    </tr>
    <tr>
      <th>Contemporary</th>
      <td>France</td>
      <td>98.73</td>
    </tr>
    <tr>
      <th>Countryside</th>
      <td>Italy</td>
      <td>99.25</td>
    </tr>
    <tr>
      <th>Island</th>
      <td>Maldives</td>
      <td>99.02</td>
    </tr>
    <tr>
      <th>Lodge</th>
      <td>Tanzania</td>
      <td>96.63</td>
    </tr>
    <tr>
      <th>Manor</th>
      <td>Canada</td>
      <td>96.505</td>
    </tr>
    <tr>
      <th>Mediterranean</th>
      <td>Italy</td>
      <td>96.6</td>
    </tr>
    <tr>
      <th>Nature</th>
      <td>Indonesia</td>
      <td>98.64</td>
    </tr>
    <tr>
      <th>Palace</th>
      <td>Morocco</td>
      <td>97.946667</td>
    </tr>
    <tr>
      <th>Safari</th>
      <td>Rwanda</td>
      <td>98.29</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country</th>
      <th>rating</th>
    </tr>
    <tr>
      <th>Theme</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Beachfront</th>
      <td>Greece</td>
      <td>97.87</td>
    </tr>
    <tr>
      <th>Boutique</th>
      <td>United States</td>
      <td>98.54</td>
    </tr>
    <tr>
      <th>Coastal</th>
      <td>Greece</td>
      <td>97.623333</td>
    </tr>
    <tr>
      <th>Contemporary</th>
      <td>France</td>
      <td>98.73</td>
    </tr>
    <tr>
      <th>Countryside</th>
      <td>Italy</td>
      <td>99.25</td>
    </tr>
    <tr>
      <th>Island</th>
      <td>Maldives</td>
      <td>99.02</td>
    </tr>
    <tr>
      <th>Lodge</th>
      <td>Tanzania</td>
      <td>96.63</td>
    </tr>
    <tr>
      <th>Manor</th>
      <td>Canada</td>
      <td>96.505</td>
    </tr>
    <tr>
      <th>Mediterranean</th>
      <td>Italy</td>
      <td>96.6</td>
    </tr>
    <tr>
      <th>Nature</th>
      <td>Indonesia</td>
      <td>98.64</td>
    </tr>
    <tr>
      <th>Palace</th>
      <td>Morocco</td>
      <td>97.946667</td>
    </tr>
    <tr>
      <th>Safari</th>
      <td>Rwanda</td>
      <td>98.29</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> aircraft/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which aircraft incident had the highest number of total serious injuries? Show the event registered number and event type description.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>serious = aircraft.columns[aircraft.columns.str.contains('serious',case=False)]
aircraft.loc[aircraft[aircraft.EVENT_TYPE_DESC=='Accident'][serious].sum(1).idxmax(), ['REGIST_NBR', 'EVENT_TYPE_DESC']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>serious = aircraft.columns[aircraft.columns.str.contains('serious',case=False)]
aircraft.loc[aircraft[aircraft.EVENT_TYPE_DESC=='Accident'][serious].sum(1).idxmax(), ['REGIST_NBR', 'EVENT_TYPE_DESC']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>serious = aircraft.columns[aircraft.columns.str.contains('serious', case=False)
    ]
__output__ = aircraft.loc[aircraft[aircraft.EVENT_TYPE_DESC == 'Accident'][
    serious].sum(1).idxmax(), ['REGIST_NBR', 'EVENT_TYPE_DESC']]
</code></pre>
        <p><span onclick="$('#var_output_e50e8cac').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e50e8cac" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>REGIST_NBR           N80918
EVENT_TYPE_DESC    Accident
Name: 5, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> serious, __output__ </p>
    
          <p>serious (Index):</p>
          <pre><code>Index(['FLT_CRW_INJ_SERIOUS', 'CBN_CRW_INJ_SERIOUS', 'PAX_INJ_SERIOUS',
       'GRND_INJ_SERIOUS'],
      dtype='object')</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>REGIST_NBR           N80918
EVENT_TYPE_DESC    Accident
Name: 5, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> aircraft/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which hour of the day had the highest number of reported aircraft events?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>hr_event = aircraft.groupby(pd.Grouper(key='EVENT_LCL_TIME', freq='H')).size().agg(['max','idxmax'])
hr_event.index=['num_events','hour']
hr_event.hour = hr_event.hour.hour
hr_event</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>hr_event = aircraft.groupby(pd.Grouper(key='EVENT_LCL_TIME', freq='H')).size().agg(['max','idxmax'])
hr_event.index=['num_events','hour']
hr_event.hour = hr_event.hour.hour
hr_event</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>hr_event = aircraft.groupby(pd.Grouper(key='EVENT_LCL_TIME', freq='H')).size(
    ).agg(['max', 'idxmax'])
hr_event.index = ['num_events', 'hour']
hr_event.hour = hr_event.hour.hour
__output__ = hr_event
</code></pre>
        <p><span onclick="$('#var_output_d77856aa').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d77856aa" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>num_events    10
hour          23
dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> hr_event, __output__ </p>
    
          <p>hr_event (Series):</p>
          <pre><code>num_events    10
hour          23
dtype: object</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>num_events    10
hour          23
dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> aircraft/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the total number of injuries during that hour?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>inj_cols = aircraft.columns[aircraft.columns.str.contains('inj_minor|inj_serious|inj_fatal|inj_unk',case=False)]
groups = aircraft.groupby(pd.Grouper(key='EVENT_LCL_TIME', freq='H'))
idx = groups.size().idxmax()
groups.get_group(idx)[inj_cols].sum().sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>inj_cols = aircraft.columns[aircraft.columns.str.contains('inj_minor|inj_serious|inj_fatal|inj_unk',case=False)]
groups = aircraft.groupby(pd.Grouper(key='EVENT_LCL_TIME', freq='H'))
idx = groups.size().idxmax()
groups.get_group(idx)[inj_cols].sum().sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>inj_cols = aircraft.columns[aircraft.columns.str.contains(
    'inj_minor|inj_serious|inj_fatal|inj_unk', case=False)]
groups = aircraft.groupby(pd.Grouper(key='EVENT_LCL_TIME', freq='H'))
idx = groups.size().idxmax()
__output__ = groups.get_group(idx)[inj_cols].sum().sum()
</code></pre>
        <p><span onclick="$('#var_output_a146dbb9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a146dbb9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>3.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> inj_cols, __output__ </p>
    
          <p>inj_cols (Index):</p>
          <pre><code>Index(['FLT_CRW_INJ_MINOR', 'FLT_CRW_INJ_SERIOUS', 'FLT_CRW_INJ_FATAL',
       'FLT_CRW_INJ_UNK', 'CBN_CRW_INJ_MINOR', 'CBN_CRW_INJ_SERIOUS',
       'CBN_CRW_INJ_FATAL', 'CBN_CRW_INJ_UNK', 'PAX_INJ_MINOR',
       'PAX_INJ_SERIOUS', 'PAX_INJ_FATAL', 'PAX_INJ_UNK', 'GRND_INJ_MINOR',
       'GRND_INJ_SERIOUS', 'GRND_INJ_FATAL', 'GRND_INJ_UNK'],
      dtype='object')</code></pre>
      
          <p>__output__ (float64):</p>
          <pre><code>3.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> aircraft/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many events occurred in each state during each hour? Show the state names as an index and hours as columns. Replace nans with 0.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>aircraft.groupby([pd.Grouper(key='EVENT_LCL_TIME', freq='H'),'LOC_STATE_NAME']).size().unstack(0, fill_value=0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>aircraft.groupby([pd.Grouper(key='EVENT_LCL_TIME', freq='H'),'LOC_STATE_NAME']).size().unstack(0, fill_value=0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = aircraft.groupby([pd.Grouper(key='EVENT_LCL_TIME', freq='H'),
    'LOC_STATE_NAME']).size().unstack(0, fill_value=0)
</code></pre>
        <p><span onclick="$('#var_output_afc63b60').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_afc63b60" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>EVENT_LCL_TIME</th>
      <th>2022-12-10 00:00:00+00:00</th>
      <th>2022-12-10 01:00:00+00:00</th>
      <th>2022-12-10 02:00:00+00:00</th>
      <th>2022-12-10 07:00:00+00:00</th>
      <th>2022-12-10 10:00:00+00:00</th>
      <th>2022-12-10 11:00:00+00:00</th>
      <th>2022-12-10 13:00:00+00:00</th>
      <th>...</th>
      <th>2022-12-10 17:00:00+00:00</th>
      <th>2022-12-10 18:00:00+00:00</th>
      <th>2022-12-10 19:00:00+00:00</th>
      <th>2022-12-10 20:00:00+00:00</th>
      <th>2022-12-10 21:00:00+00:00</th>
      <th>2022-12-10 22:00:00+00:00</th>
      <th>2022-12-10 23:00:00+00:00</th>
    </tr>
    <tr>
      <th>LOC_STATE_NAME</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Alabama</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Alaska</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Arizona</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Arkansas</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>California</th>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>6</td>
    </tr>
    <tr>
      <th>Colorado</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Florida</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Pennsylvania</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Rhode Island</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>South Dakota</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Tennessee</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Texas</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Virginia</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>West Virginia</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>33 rows × 17 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>EVENT_LCL_TIME</th>
      <th>2022-12-10 00:00:00+00:00</th>
      <th>2022-12-10 01:00:00+00:00</th>
      <th>2022-12-10 02:00:00+00:00</th>
      <th>2022-12-10 07:00:00+00:00</th>
      <th>2022-12-10 10:00:00+00:00</th>
      <th>2022-12-10 11:00:00+00:00</th>
      <th>2022-12-10 13:00:00+00:00</th>
      <th>...</th>
      <th>2022-12-10 17:00:00+00:00</th>
      <th>2022-12-10 18:00:00+00:00</th>
      <th>2022-12-10 19:00:00+00:00</th>
      <th>2022-12-10 20:00:00+00:00</th>
      <th>2022-12-10 21:00:00+00:00</th>
      <th>2022-12-10 22:00:00+00:00</th>
      <th>2022-12-10 23:00:00+00:00</th>
    </tr>
    <tr>
      <th>LOC_STATE_NAME</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Alabama</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Alaska</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Arizona</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Arkansas</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>California</th>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>6</td>
    </tr>
    <tr>
      <th>Colorado</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Florida</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Pennsylvania</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Rhode Island</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>South Dakota</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Tennessee</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Texas</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Virginia</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>West Virginia</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>33 rows × 17 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> aircraft/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # In which state did an aircraft crash into the trees?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>aircraft[aircraft.RMK_TEXT.str.contains('(?=.*crash)(?=.*tree)',case=False)].LOC_STATE_NAME</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>aircraft[aircraft.RMK_TEXT.str.contains('(?=.*crash)(?=.*tree)',case=False)].LOC_STATE_NAME</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = aircraft[aircraft.RMK_TEXT.str.contains(
    '(?=.*crash)(?=.*tree)', case=False)].LOC_STATE_NAME
</code></pre>
        <p><span onclick="$('#var_output_33011089').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_33011089" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0    North Carolina
Name: LOC_STATE_NAME, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0    North Carolina
Name: LOC_STATE_NAME, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-universities-in-the-united-kingdom/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert percentages in 'International_students' and 'Student_satisfaction' to floats.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>uni['International_students'] = uni['International_students'].str.replace('%','').astype(float)
uni['Student_satisfaction'] = uni['Student_satisfaction'].str.replace('%','').astype(float)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>uni['International_students'] = uni['International_students'].str.replace('%','').astype(float)
uni['Student_satisfaction'] = uni['Student_satisfaction'].str.replace('%','').astype(float)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>uni['International_students'] = uni['International_students'].str.replace('%',
    '').astype(float)
__output__ = uni['Student_satisfaction'] = uni['Student_satisfaction'
    ].str.replace('%', '').astype(float)
</code></pre>
        <p><span onclick="$('#var_output_ea0e3aa3').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ea0e3aa3" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      85.5
1      86.5
2      87.9
3      77.9
4      85.8
       ... 
126    76.1
127    77.4
128    76.0
129    74.3
130    66.1
Name: Student_satisfaction, Length: 131, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> uni, __output__ </p>
    
          <p>uni (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>University_name</th>
      <th>Region</th>
      <th>Founded_year</th>
      <th>Motto</th>
      <th>UK_rank</th>
      <th>World_rank</th>
      <th>CWUR_score</th>
      <th>...</th>
      <th>Control_type</th>
      <th>Academic_Calender</th>
      <th>Campus_setting</th>
      <th>Estimated_cost_of_living_per_year_(in_pounds)</th>
      <th>Latitude</th>
      <th>Longitude</th>
      <th>Website</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>University of Cambridge</td>
      <td>East of England</td>
      <td>1209</td>
      <td>From here, light and sacred draughts</td>
      <td>1</td>
      <td>4</td>
      <td>94.1</td>
      <td>...</td>
      <td>Public</td>
      <td>Trimesters</td>
      <td>Urban</td>
      <td>12000</td>
      <td>52.2054</td>
      <td>0.1132</td>
      <td>www.cam.ac.uk</td>
    </tr>
    <tr>
      <th>1</th>
      <td>University of Oxford</td>
      <td>South East England</td>
      <td>1096</td>
      <td>The Lord is my light</td>
      <td>2</td>
      <td>2</td>
      <td>93.3</td>
      <td>...</td>
      <td>Public</td>
      <td>Trimesters</td>
      <td>Urban</td>
      <td>11500</td>
      <td>51.7548</td>
      <td>-1.2544</td>
      <td>www.ox.ac.uk</td>
    </tr>
    <tr>
      <th>2</th>
      <td>University of St Andrews</td>
      <td>Scotland</td>
      <td>1413</td>
      <td>Ever to excel</td>
      <td>3</td>
      <td>86</td>
      <td>75.8</td>
      <td>...</td>
      <td>Public</td>
      <td>Semesters</td>
      <td>Suburban</td>
      <td>12000</td>
      <td>56.3417</td>
      <td>-2.7943</td>
      <td>www.st-andrews.ac.uk</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Imperial College London</td>
      <td>London</td>
      <td>1907</td>
      <td>Knowledge is the adornment and safeguard of the Empire</td>
      <td>4</td>
      <td>8</td>
      <td>86.6</td>
      <td>...</td>
      <td>Public</td>
      <td>Continuous</td>
      <td>Urban</td>
      <td>10700</td>
      <td>51.4988</td>
      <td>-0.1749</td>
      <td>www.ic.ac.uk</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Loughborough University</td>
      <td>East Midlands</td>
      <td>1966</td>
      <td>With Truth, Knowledge and Labour</td>
      <td>5</td>
      <td>404</td>
      <td>72.8</td>
      <td>...</td>
      <td>Public</td>
      <td>Semesters</td>
      <td>Suburban</td>
      <td>9398</td>
      <td>52.7650</td>
      <td>-1.2321</td>
      <td>www.lboro.ac.uk/</td>
    </tr>
    <tr>
      <th>5</th>
      <td>London School of Economics and Political Science</td>
      <td>London</td>
      <td>1895</td>
      <td>To know the causes of things</td>
      <td>6</td>
      <td>23</td>
      <td>76.3</td>
      <td>...</td>
      <td>Public</td>
      <td>Semesters</td>
      <td>Urban</td>
      <td>12000</td>
      <td>51.5144</td>
      <td>-0.1165</td>
      <td>www.lse.ac.uk</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Durham University</td>
      <td>North East England</td>
      <td>1832</td>
      <td>Her foundations are upon the holy hills</td>
      <td>7</td>
      <td>70</td>
      <td>76.3</td>
      <td>...</td>
      <td>Public</td>
      <td>Trimesters</td>
      <td>Urban</td>
      <td>8000</td>
      <td>54.7650</td>
      <td>-1.5782</td>
      <td>www.dur.ac.uk</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>124</th>
      <td>University of Bolton</td>
      <td>North West England</td>
      <td>2004</td>
      <td>Wisdom is over Morus</td>
      <td>125</td>
      <td>2100</td>
      <td>NaN</td>
      <td>...</td>
      <td>Public</td>
      <td>Semesters</td>
      <td>Urban</td>
      <td>5500</td>
      <td>53.5742</td>
      <td>-2.4362</td>
      <td>www.bolton.ac.uk</td>
    </tr>
    <tr>
      <th>125</th>
      <td>London Metropolitan University</td>
      <td>London</td>
      <td>1848</td>
      <td>Knowledge in Abundance</td>
      <td>126</td>
      <td>1025</td>
      <td>NaN</td>
      <td>...</td>
      <td>Public</td>
      <td>Continuous</td>
      <td>Urban</td>
      <td>15000</td>
      <td>51.5526</td>
      <td>-0.1113</td>
      <td>www.londonmet.ac.uk</td>
    </tr>
    <tr>
      <th>126</th>
      <td>University of East London</td>
      <td>London</td>
      <td>1992</td>
      <td>Science and fulfillment of vows</td>
      <td>127</td>
      <td>971</td>
      <td>NaN</td>
      <td>...</td>
      <td>Public</td>
      <td>Semesters</td>
      <td>Suburban</td>
      <td>10229</td>
      <td>51.5076</td>
      <td>0.0651</td>
      <td>www.uel.ac.uk</td>
    </tr>
    <tr>
      <th>127</th>
      <td>University of Bedfordshire</td>
      <td>East of England</td>
      <td>2006</td>
      <td>NaN</td>
      <td>128</td>
      <td>1281</td>
      <td>NaN</td>
      <td>...</td>
      <td>Public</td>
      <td>Semesters</td>
      <td>Urban</td>
      <td>9415</td>
      <td>51.8779</td>
      <td>-0.4093</td>
      <td>www.beds.ac.uk</td>
    </tr>
    <tr>
      <th>128</th>
      <td>University of Suffolk</td>
      <td>East of England</td>
      <td>2007</td>
      <td>Honesty and diligence</td>
      <td>129</td>
      <td>4030</td>
      <td>NaN</td>
      <td>...</td>
      <td>Public</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9415</td>
      <td>52.0523</td>
      <td>1.1629</td>
      <td>www.ucs.ac.uk/</td>
    </tr>
    <tr>
      <th>129</th>
      <td>Wrexham Glyndwr University</td>
      <td>Wales</td>
      <td>2008</td>
      <td>Confidence through Education</td>
      <td>130</td>
      <td>2397</td>
      <td>NaN</td>
      <td>...</td>
      <td>Public</td>
      <td>NaN</td>
      <td>Urban</td>
      <td>7771</td>
      <td>53.0526</td>
      <td>-3.0062</td>
      <td>www.glyndwr.ac.uk/</td>
    </tr>
    <tr>
      <th>130</th>
      <td>Ravensbourne University London</td>
      <td>London</td>
      <td>1962</td>
      <td>Designed for industry</td>
      <td>131</td>
      <td>2759</td>
      <td>NaN</td>
      <td>...</td>
      <td>Public</td>
      <td>Semesters</td>
      <td>Urban</td>
      <td>10229</td>
      <td>51.5017</td>
      <td>0.0055</td>
      <td>www.ravensbourne.ac.uk</td>
    </tr>
  </tbody>
</table>
<p>131 rows × 21 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      85.5
1      86.5
2      87.9
3      77.9
4      85.8
       ... 
126    76.1
127    77.4
128    76.0
129    74.3
130    66.1
Name: Student_satisfaction, Length: 131, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-universities-in-the-united-kingdom/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create two columns, 'lower_enrol' and 'upper_enrol', representing the upper and lower bounds of student enrollments for each university.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = (uni.Student_enrollment.str.split('-',expand=True))
df.columns = ['lower_enrol','upper_enrol']
uni['lower_enrol'] = pd.to_numeric(df['lower_enrol'].str.replace(',',''))
uni['upper_enrol'] = pd.to_numeric(df['upper_enrol'].str.replace(',',''))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>['uni']</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = (uni.Student_enrollment.str.split('-',expand=True))
df.columns = ['lower_enrol','upper_enrol']
uni['lower_enrol'] = pd.to_numeric(df['lower_enrol'].str.replace(',',''))
uni['upper_enrol'] = pd.to_numeric(df['upper_enrol'].str.replace(',',''))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = uni.Student_enrollment.str.split('-', expand=True)
df.columns = ['lower_enrol', 'upper_enrol']
uni['lower_enrol'] = pd.to_numeric(df['lower_enrol'].str.replace(',', ''))
__output__ = uni['upper_enrol'] = pd.to_numeric(df['upper_enrol'].str.
    replace(',', ''))
</code></pre>
        <p><span onclick="$('#var_output_38c27cba').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_38c27cba" style="display: none;">
          
        <p><strong>Ref output variables:</strong> uni </p>
    
          <p>uni (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>University_name</th>
      <th>Region</th>
      <th>Founded_year</th>
      <th>Motto</th>
      <th>UK_rank</th>
      <th>World_rank</th>
      <th>CWUR_score</th>
      <th>...</th>
      <th>Campus_setting</th>
      <th>Estimated_cost_of_living_per_year_(in_pounds)</th>
      <th>Latitude</th>
      <th>Longitude</th>
      <th>Website</th>
      <th>lower_enrol</th>
      <th>upper_enrol</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>University of Cambridge</td>
      <td>East of England</td>
      <td>1209</td>
      <td>From here, light and sacred draughts</td>
      <td>1</td>
      <td>4</td>
      <td>94.1</td>
      <td>...</td>
      <td>Urban</td>
      <td>12000</td>
      <td>52.2054</td>
      <td>0.1132</td>
      <td>www.cam.ac.uk</td>
      <td>20000</td>
      <td>24999</td>
    </tr>
    <tr>
      <th>1</th>
      <td>University of Oxford</td>
      <td>South East England</td>
      <td>1096</td>
      <td>The Lord is my light</td>
      <td>2</td>
      <td>2</td>
      <td>93.3</td>
      <td>...</td>
      <td>Urban</td>
      <td>11500</td>
      <td>51.7548</td>
      <td>-1.2544</td>
      <td>www.ox.ac.uk</td>
      <td>25000</td>
      <td>29999</td>
    </tr>
    <tr>
      <th>2</th>
      <td>University of St Andrews</td>
      <td>Scotland</td>
      <td>1413</td>
      <td>Ever to excel</td>
      <td>3</td>
      <td>86</td>
      <td>75.8</td>
      <td>...</td>
      <td>Suburban</td>
      <td>12000</td>
      <td>56.3417</td>
      <td>-2.7943</td>
      <td>www.st-andrews.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Imperial College London</td>
      <td>London</td>
      <td>1907</td>
      <td>Knowledge is the adornment and safeguard of the Empire</td>
      <td>4</td>
      <td>8</td>
      <td>86.6</td>
      <td>...</td>
      <td>Urban</td>
      <td>10700</td>
      <td>51.4988</td>
      <td>-0.1749</td>
      <td>www.ic.ac.uk</td>
      <td>15000</td>
      <td>19999</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Loughborough University</td>
      <td>East Midlands</td>
      <td>1966</td>
      <td>With Truth, Knowledge and Labour</td>
      <td>5</td>
      <td>404</td>
      <td>72.8</td>
      <td>...</td>
      <td>Suburban</td>
      <td>9398</td>
      <td>52.7650</td>
      <td>-1.2321</td>
      <td>www.lboro.ac.uk/</td>
      <td>15000</td>
      <td>19999</td>
    </tr>
    <tr>
      <th>5</th>
      <td>London School of Economics and Political Science</td>
      <td>London</td>
      <td>1895</td>
      <td>To know the causes of things</td>
      <td>6</td>
      <td>23</td>
      <td>76.3</td>
      <td>...</td>
      <td>Urban</td>
      <td>12000</td>
      <td>51.5144</td>
      <td>-0.1165</td>
      <td>www.lse.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Durham University</td>
      <td>North East England</td>
      <td>1832</td>
      <td>Her foundations are upon the holy hills</td>
      <td>7</td>
      <td>70</td>
      <td>76.3</td>
      <td>...</td>
      <td>Urban</td>
      <td>8000</td>
      <td>54.7650</td>
      <td>-1.5782</td>
      <td>www.dur.ac.uk</td>
      <td>15000</td>
      <td>19999</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>124</th>
      <td>University of Bolton</td>
      <td>North West England</td>
      <td>2004</td>
      <td>Wisdom is over Morus</td>
      <td>125</td>
      <td>2100</td>
      <td>NaN</td>
      <td>...</td>
      <td>Urban</td>
      <td>5500</td>
      <td>53.5742</td>
      <td>-2.4362</td>
      <td>www.bolton.ac.uk</td>
      <td>6000</td>
      <td>6999</td>
    </tr>
    <tr>
      <th>125</th>
      <td>London Metropolitan University</td>
      <td>London</td>
      <td>1848</td>
      <td>Knowledge in Abundance</td>
      <td>126</td>
      <td>1025</td>
      <td>NaN</td>
      <td>...</td>
      <td>Urban</td>
      <td>15000</td>
      <td>51.5526</td>
      <td>-0.1113</td>
      <td>www.londonmet.ac.uk</td>
      <td>9000</td>
      <td>9999</td>
    </tr>
    <tr>
      <th>126</th>
      <td>University of East London</td>
      <td>London</td>
      <td>1992</td>
      <td>Science and fulfillment of vows</td>
      <td>127</td>
      <td>971</td>
      <td>NaN</td>
      <td>...</td>
      <td>Suburban</td>
      <td>10229</td>
      <td>51.5076</td>
      <td>0.0651</td>
      <td>www.uel.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
    </tr>
    <tr>
      <th>127</th>
      <td>University of Bedfordshire</td>
      <td>East of England</td>
      <td>2006</td>
      <td>NaN</td>
      <td>128</td>
      <td>1281</td>
      <td>NaN</td>
      <td>...</td>
      <td>Urban</td>
      <td>9415</td>
      <td>51.8779</td>
      <td>-0.4093</td>
      <td>www.beds.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
    </tr>
    <tr>
      <th>128</th>
      <td>University of Suffolk</td>
      <td>East of England</td>
      <td>2007</td>
      <td>Honesty and diligence</td>
      <td>129</td>
      <td>4030</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>9415</td>
      <td>52.0523</td>
      <td>1.1629</td>
      <td>www.ucs.ac.uk/</td>
      <td>7000</td>
      <td>7999</td>
    </tr>
    <tr>
      <th>129</th>
      <td>Wrexham Glyndwr University</td>
      <td>Wales</td>
      <td>2008</td>
      <td>Confidence through Education</td>
      <td>130</td>
      <td>2397</td>
      <td>NaN</td>
      <td>...</td>
      <td>Urban</td>
      <td>7771</td>
      <td>53.0526</td>
      <td>-3.0062</td>
      <td>www.glyndwr.ac.uk/</td>
      <td>5000</td>
      <td>5999</td>
    </tr>
    <tr>
      <th>130</th>
      <td>Ravensbourne University London</td>
      <td>London</td>
      <td>1962</td>
      <td>Designed for industry</td>
      <td>131</td>
      <td>2759</td>
      <td>NaN</td>
      <td>...</td>
      <td>Urban</td>
      <td>10229</td>
      <td>51.5017</td>
      <td>0.0055</td>
      <td>www.ravensbourne.ac.uk</td>
      <td>2000</td>
      <td>2999</td>
    </tr>
  </tbody>
</table>
<p>131 rows × 23 columns</p>
      
        <p><strong>Hyp output variables:</strong> uni, df, __output__ </p>
    
          <p>uni (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>University_name</th>
      <th>Region</th>
      <th>Founded_year</th>
      <th>Motto</th>
      <th>UK_rank</th>
      <th>World_rank</th>
      <th>CWUR_score</th>
      <th>...</th>
      <th>Campus_setting</th>
      <th>Estimated_cost_of_living_per_year_(in_pounds)</th>
      <th>Latitude</th>
      <th>Longitude</th>
      <th>Website</th>
      <th>lower_enrol</th>
      <th>upper_enrol</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>University of Cambridge</td>
      <td>East of England</td>
      <td>1209</td>
      <td>From here, light and sacred draughts</td>
      <td>1</td>
      <td>4</td>
      <td>94.1</td>
      <td>...</td>
      <td>Urban</td>
      <td>12000</td>
      <td>52.2054</td>
      <td>0.1132</td>
      <td>www.cam.ac.uk</td>
      <td>20000</td>
      <td>24999</td>
    </tr>
    <tr>
      <th>1</th>
      <td>University of Oxford</td>
      <td>South East England</td>
      <td>1096</td>
      <td>The Lord is my light</td>
      <td>2</td>
      <td>2</td>
      <td>93.3</td>
      <td>...</td>
      <td>Urban</td>
      <td>11500</td>
      <td>51.7548</td>
      <td>-1.2544</td>
      <td>www.ox.ac.uk</td>
      <td>25000</td>
      <td>29999</td>
    </tr>
    <tr>
      <th>2</th>
      <td>University of St Andrews</td>
      <td>Scotland</td>
      <td>1413</td>
      <td>Ever to excel</td>
      <td>3</td>
      <td>86</td>
      <td>75.8</td>
      <td>...</td>
      <td>Suburban</td>
      <td>12000</td>
      <td>56.3417</td>
      <td>-2.7943</td>
      <td>www.st-andrews.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Imperial College London</td>
      <td>London</td>
      <td>1907</td>
      <td>Knowledge is the adornment and safeguard of the Empire</td>
      <td>4</td>
      <td>8</td>
      <td>86.6</td>
      <td>...</td>
      <td>Urban</td>
      <td>10700</td>
      <td>51.4988</td>
      <td>-0.1749</td>
      <td>www.ic.ac.uk</td>
      <td>15000</td>
      <td>19999</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Loughborough University</td>
      <td>East Midlands</td>
      <td>1966</td>
      <td>With Truth, Knowledge and Labour</td>
      <td>5</td>
      <td>404</td>
      <td>72.8</td>
      <td>...</td>
      <td>Suburban</td>
      <td>9398</td>
      <td>52.7650</td>
      <td>-1.2321</td>
      <td>www.lboro.ac.uk/</td>
      <td>15000</td>
      <td>19999</td>
    </tr>
    <tr>
      <th>5</th>
      <td>London School of Economics and Political Science</td>
      <td>London</td>
      <td>1895</td>
      <td>To know the causes of things</td>
      <td>6</td>
      <td>23</td>
      <td>76.3</td>
      <td>...</td>
      <td>Urban</td>
      <td>12000</td>
      <td>51.5144</td>
      <td>-0.1165</td>
      <td>www.lse.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Durham University</td>
      <td>North East England</td>
      <td>1832</td>
      <td>Her foundations are upon the holy hills</td>
      <td>7</td>
      <td>70</td>
      <td>76.3</td>
      <td>...</td>
      <td>Urban</td>
      <td>8000</td>
      <td>54.7650</td>
      <td>-1.5782</td>
      <td>www.dur.ac.uk</td>
      <td>15000</td>
      <td>19999</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>124</th>
      <td>University of Bolton</td>
      <td>North West England</td>
      <td>2004</td>
      <td>Wisdom is over Morus</td>
      <td>125</td>
      <td>2100</td>
      <td>NaN</td>
      <td>...</td>
      <td>Urban</td>
      <td>5500</td>
      <td>53.5742</td>
      <td>-2.4362</td>
      <td>www.bolton.ac.uk</td>
      <td>6000</td>
      <td>6999</td>
    </tr>
    <tr>
      <th>125</th>
      <td>London Metropolitan University</td>
      <td>London</td>
      <td>1848</td>
      <td>Knowledge in Abundance</td>
      <td>126</td>
      <td>1025</td>
      <td>NaN</td>
      <td>...</td>
      <td>Urban</td>
      <td>15000</td>
      <td>51.5526</td>
      <td>-0.1113</td>
      <td>www.londonmet.ac.uk</td>
      <td>9000</td>
      <td>9999</td>
    </tr>
    <tr>
      <th>126</th>
      <td>University of East London</td>
      <td>London</td>
      <td>1992</td>
      <td>Science and fulfillment of vows</td>
      <td>127</td>
      <td>971</td>
      <td>NaN</td>
      <td>...</td>
      <td>Suburban</td>
      <td>10229</td>
      <td>51.5076</td>
      <td>0.0651</td>
      <td>www.uel.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
    </tr>
    <tr>
      <th>127</th>
      <td>University of Bedfordshire</td>
      <td>East of England</td>
      <td>2006</td>
      <td>NaN</td>
      <td>128</td>
      <td>1281</td>
      <td>NaN</td>
      <td>...</td>
      <td>Urban</td>
      <td>9415</td>
      <td>51.8779</td>
      <td>-0.4093</td>
      <td>www.beds.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
    </tr>
    <tr>
      <th>128</th>
      <td>University of Suffolk</td>
      <td>East of England</td>
      <td>2007</td>
      <td>Honesty and diligence</td>
      <td>129</td>
      <td>4030</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>9415</td>
      <td>52.0523</td>
      <td>1.1629</td>
      <td>www.ucs.ac.uk/</td>
      <td>7000</td>
      <td>7999</td>
    </tr>
    <tr>
      <th>129</th>
      <td>Wrexham Glyndwr University</td>
      <td>Wales</td>
      <td>2008</td>
      <td>Confidence through Education</td>
      <td>130</td>
      <td>2397</td>
      <td>NaN</td>
      <td>...</td>
      <td>Urban</td>
      <td>7771</td>
      <td>53.0526</td>
      <td>-3.0062</td>
      <td>www.glyndwr.ac.uk/</td>
      <td>5000</td>
      <td>5999</td>
    </tr>
    <tr>
      <th>130</th>
      <td>Ravensbourne University London</td>
      <td>London</td>
      <td>1962</td>
      <td>Designed for industry</td>
      <td>131</td>
      <td>2759</td>
      <td>NaN</td>
      <td>...</td>
      <td>Urban</td>
      <td>10229</td>
      <td>51.5017</td>
      <td>0.0055</td>
      <td>www.ravensbourne.ac.uk</td>
      <td>2000</td>
      <td>2999</td>
    </tr>
  </tbody>
</table>
<p>131 rows × 23 columns</p>
      
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lower_enrol</th>
      <th>upper_enrol</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>20,000</td>
      <td>24,999</td>
    </tr>
    <tr>
      <th>1</th>
      <td>25,000</td>
      <td>29,999</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10,000</td>
      <td>14,999</td>
    </tr>
    <tr>
      <th>3</th>
      <td>15,000</td>
      <td>19,999</td>
    </tr>
    <tr>
      <th>4</th>
      <td>15,000</td>
      <td>19,999</td>
    </tr>
    <tr>
      <th>5</th>
      <td>10,000</td>
      <td>14,999</td>
    </tr>
    <tr>
      <th>6</th>
      <td>15,000</td>
      <td>19,999</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>124</th>
      <td>6,000</td>
      <td>6,999</td>
    </tr>
    <tr>
      <th>125</th>
      <td>9,000</td>
      <td>9,999</td>
    </tr>
    <tr>
      <th>126</th>
      <td>10,000</td>
      <td>14,999</td>
    </tr>
    <tr>
      <th>127</th>
      <td>10,000</td>
      <td>14,999</td>
    </tr>
    <tr>
      <th>128</th>
      <td>7,000</td>
      <td>7,999</td>
    </tr>
    <tr>
      <th>129</th>
      <td>5,000</td>
      <td>5,999</td>
    </tr>
    <tr>
      <th>130</th>
      <td>2,000</td>
      <td>2,999</td>
    </tr>
  </tbody>
</table>
<p>131 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      24999
1      29999
2      14999
3      19999
4      19999
       ...  
126    14999
127    14999
128     7999
129     5999
130     2999
Name: upper_enrol, Length: 131, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('uni', 'uni', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-universities-in-the-united-kingdom/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create two columns, 'lower_staff' and 'upper_staff' similarly. Replace 'over' values with 5000.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = (uni.Academic_staff.str.split('-',expand=True))
df.columns = ['lower_staff','upper_staff']
uni['lower_staff'] = pd.to_numeric(df['lower_staff'].str.replace(',','').str.replace('over','5000'))
uni['upper_staff'] = pd.to_numeric(df['upper_staff'].str.replace(',',''))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = (uni.Academic_staff.str.split('-',expand=True))
df.columns = ['lower_staff','upper_staff']
uni['lower_staff'] = pd.to_numeric(df['lower_staff'].str.replace(',','').str.replace('over','5000'))
uni['upper_staff'] = pd.to_numeric(df['upper_staff'].str.replace(',',''))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = uni.Academic_staff.str.split('-', expand=True)
df.columns = ['lower_staff', 'upper_staff']
uni['lower_staff'] = pd.to_numeric(df['lower_staff'].str.replace(',', '').
    str.replace('over', '5000'))
__output__ = uni['upper_staff'] = pd.to_numeric(df['upper_staff'].str.
    replace(',', ''))
</code></pre>
        <p><span onclick="$('#var_output_68961b8f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_68961b8f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      5000
1      5000
2      1499
3      4499
4      1999
       ... 
126     999
127     599
128     299
129     299
130     199
Name: upper_staff, Length: 131, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> uni, df, __output__ </p>
    
          <p>uni (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>University_name</th>
      <th>Region</th>
      <th>Founded_year</th>
      <th>Motto</th>
      <th>UK_rank</th>
      <th>World_rank</th>
      <th>CWUR_score</th>
      <th>...</th>
      <th>Latitude</th>
      <th>Longitude</th>
      <th>Website</th>
      <th>lower_enrol</th>
      <th>upper_enrol</th>
      <th>lower_staff</th>
      <th>upper_staff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>University of Cambridge</td>
      <td>East of England</td>
      <td>1209</td>
      <td>From here, light and sacred draughts</td>
      <td>1</td>
      <td>4</td>
      <td>94.1</td>
      <td>...</td>
      <td>52.2054</td>
      <td>0.1132</td>
      <td>www.cam.ac.uk</td>
      <td>20000</td>
      <td>24999</td>
      <td>5000</td>
      <td>5000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>University of Oxford</td>
      <td>South East England</td>
      <td>1096</td>
      <td>The Lord is my light</td>
      <td>2</td>
      <td>2</td>
      <td>93.3</td>
      <td>...</td>
      <td>51.7548</td>
      <td>-1.2544</td>
      <td>www.ox.ac.uk</td>
      <td>25000</td>
      <td>29999</td>
      <td>5000</td>
      <td>5000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>University of St Andrews</td>
      <td>Scotland</td>
      <td>1413</td>
      <td>Ever to excel</td>
      <td>3</td>
      <td>86</td>
      <td>75.8</td>
      <td>...</td>
      <td>56.3417</td>
      <td>-2.7943</td>
      <td>www.st-andrews.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
      <td>1000</td>
      <td>1499</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Imperial College London</td>
      <td>London</td>
      <td>1907</td>
      <td>Knowledge is the adornment and safeguard of the Empire</td>
      <td>4</td>
      <td>8</td>
      <td>86.6</td>
      <td>...</td>
      <td>51.4988</td>
      <td>-0.1749</td>
      <td>www.ic.ac.uk</td>
      <td>15000</td>
      <td>19999</td>
      <td>4000</td>
      <td>4499</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Loughborough University</td>
      <td>East Midlands</td>
      <td>1966</td>
      <td>With Truth, Knowledge and Labour</td>
      <td>5</td>
      <td>404</td>
      <td>72.8</td>
      <td>...</td>
      <td>52.7650</td>
      <td>-1.2321</td>
      <td>www.lboro.ac.uk/</td>
      <td>15000</td>
      <td>19999</td>
      <td>1500</td>
      <td>1999</td>
    </tr>
    <tr>
      <th>5</th>
      <td>London School of Economics and Political Science</td>
      <td>London</td>
      <td>1895</td>
      <td>To know the causes of things</td>
      <td>6</td>
      <td>23</td>
      <td>76.3</td>
      <td>...</td>
      <td>51.5144</td>
      <td>-0.1165</td>
      <td>www.lse.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
      <td>1500</td>
      <td>1999</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Durham University</td>
      <td>North East England</td>
      <td>1832</td>
      <td>Her foundations are upon the holy hills</td>
      <td>7</td>
      <td>70</td>
      <td>76.3</td>
      <td>...</td>
      <td>54.7650</td>
      <td>-1.5782</td>
      <td>www.dur.ac.uk</td>
      <td>15000</td>
      <td>19999</td>
      <td>1500</td>
      <td>1999</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>124</th>
      <td>University of Bolton</td>
      <td>North West England</td>
      <td>2004</td>
      <td>Wisdom is over Morus</td>
      <td>125</td>
      <td>2100</td>
      <td>NaN</td>
      <td>...</td>
      <td>53.5742</td>
      <td>-2.4362</td>
      <td>www.bolton.ac.uk</td>
      <td>6000</td>
      <td>6999</td>
      <td>300</td>
      <td>399</td>
    </tr>
    <tr>
      <th>125</th>
      <td>London Metropolitan University</td>
      <td>London</td>
      <td>1848</td>
      <td>Knowledge in Abundance</td>
      <td>126</td>
      <td>1025</td>
      <td>NaN</td>
      <td>...</td>
      <td>51.5526</td>
      <td>-0.1113</td>
      <td>www.londonmet.ac.uk</td>
      <td>9000</td>
      <td>9999</td>
      <td>400</td>
      <td>499</td>
    </tr>
    <tr>
      <th>126</th>
      <td>University of East London</td>
      <td>London</td>
      <td>1992</td>
      <td>Science and fulfillment of vows</td>
      <td>127</td>
      <td>971</td>
      <td>NaN</td>
      <td>...</td>
      <td>51.5076</td>
      <td>0.0651</td>
      <td>www.uel.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
      <td>900</td>
      <td>999</td>
    </tr>
    <tr>
      <th>127</th>
      <td>University of Bedfordshire</td>
      <td>East of England</td>
      <td>2006</td>
      <td>NaN</td>
      <td>128</td>
      <td>1281</td>
      <td>NaN</td>
      <td>...</td>
      <td>51.8779</td>
      <td>-0.4093</td>
      <td>www.beds.ac.uk</td>
      <td>10000</td>
      <td>14999</td>
      <td>500</td>
      <td>599</td>
    </tr>
    <tr>
      <th>128</th>
      <td>University of Suffolk</td>
      <td>East of England</td>
      <td>2007</td>
      <td>Honesty and diligence</td>
      <td>129</td>
      <td>4030</td>
      <td>NaN</td>
      <td>...</td>
      <td>52.0523</td>
      <td>1.1629</td>
      <td>www.ucs.ac.uk/</td>
      <td>7000</td>
      <td>7999</td>
      <td>200</td>
      <td>299</td>
    </tr>
    <tr>
      <th>129</th>
      <td>Wrexham Glyndwr University</td>
      <td>Wales</td>
      <td>2008</td>
      <td>Confidence through Education</td>
      <td>130</td>
      <td>2397</td>
      <td>NaN</td>
      <td>...</td>
      <td>53.0526</td>
      <td>-3.0062</td>
      <td>www.glyndwr.ac.uk/</td>
      <td>5000</td>
      <td>5999</td>
      <td>200</td>
      <td>299</td>
    </tr>
    <tr>
      <th>130</th>
      <td>Ravensbourne University London</td>
      <td>London</td>
      <td>1962</td>
      <td>Designed for industry</td>
      <td>131</td>
      <td>2759</td>
      <td>NaN</td>
      <td>...</td>
      <td>51.5017</td>
      <td>0.0055</td>
      <td>www.ravensbourne.ac.uk</td>
      <td>2000</td>
      <td>2999</td>
      <td>100</td>
      <td>199</td>
    </tr>
  </tbody>
</table>
<p>131 rows × 25 columns</p>
      
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lower_staff</th>
      <th>upper_staff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>over</td>
      <td>5,000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>over</td>
      <td>5,000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1,000</td>
      <td>1,499</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4,000</td>
      <td>4,499</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1,500</td>
      <td>1,999</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1,500</td>
      <td>1,999</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1,500</td>
      <td>1,999</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>124</th>
      <td>300</td>
      <td>399</td>
    </tr>
    <tr>
      <th>125</th>
      <td>400</td>
      <td>499</td>
    </tr>
    <tr>
      <th>126</th>
      <td>900</td>
      <td>999</td>
    </tr>
    <tr>
      <th>127</th>
      <td>500</td>
      <td>599</td>
    </tr>
    <tr>
      <th>128</th>
      <td>200</td>
      <td>299</td>
    </tr>
    <tr>
      <th>129</th>
      <td>200</td>
      <td>299</td>
    </tr>
    <tr>
      <th>130</th>
      <td>100</td>
      <td>199</td>
    </tr>
  </tbody>
</table>
<p>131 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      5000
1      5000
2      1499
3      4499
4      1999
       ... 
126     999
127     599
128     299
129     299
130     199
Name: upper_staff, Length: 131, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-universities-in-the-united-kingdom/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top five highly correlated features with the average post-graduate fees? Sort values based on the absolute correlation value</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = uni.corr()
df = df.reindex(df['PG_average_fees_(in_pounds)'].abs().sort_values(ascending=False).index)['PG_average_fees_(in_pounds)']
df.drop(index='PG_average_fees_(in_pounds)',inplace=True)
df.head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = uni.corr()
df = df.reindex(df['PG_average_fees_(in_pounds)'].abs().sort_values(ascending=False).index)['PG_average_fees_(in_pounds)']
df.drop(index='PG_average_fees_(in_pounds)',inplace=True)
df.head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = uni.corr()
df = df.reindex(df['PG_average_fees_(in_pounds)'].abs().sort_values(
    ascending=False).index)['PG_average_fees_(in_pounds)']
__tmp_2 = df.drop(index='PG_average_fees_(in_pounds)', inplace=True)
__output__ = df.head(5)
</code></pre>
        <p><span onclick="$('#var_output_3f448c54').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3f448c54" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>UG_average_fees_(in_pounds)    0.890149
CWUR_score                     0.655489
UK_rank                       -0.639667
Minimum_IELTS_score            0.624747
upper_staff                    0.604871
Name: PG_average_fees_(in_pounds), dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (Series):</p>
          <pre><code>UG_average_fees_(in_pounds)                      0.890149
CWUR_score                                       0.655489
UK_rank                                         -0.639667
Minimum_IELTS_score                              0.624747
upper_staff                                      0.604871
lower_staff                                      0.594460
International_students                           0.586952
World_rank                                      -0.514784
Founded_year                                    -0.403852
Estimated_cost_of_living_per_year_(in_pounds)    0.393930
upper_enrol                                      0.335800
lower_enrol                                      0.323089
Longitude                                        0.144019
Latitude                                        -0.084959
Student_satisfaction                            -0.027623
Name: PG_average_fees_(in_pounds), dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>UG_average_fees_(in_pounds)    0.890149
CWUR_score                     0.655489
UK_rank                       -0.639667
Minimum_IELTS_score            0.624747
upper_staff                    0.604871
Name: PG_average_fees_(in_pounds), dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-universities-in-the-united-kingdom/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the highest student satisfaction score at different regions having an average cost of living of eight thousand pounds or more?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = uni.groupby('Region')['Estimated_cost_of_living_per_year_(in_pounds)',
                           'Student_satisfaction'].agg({'Estimated_cost_of_living_per_year_(in_pounds)':'mean','Student_satisfaction':'max'})
df = df.groupby(df['Estimated_cost_of_living_per_year_(in_pounds)']>=8000).get_group(True)
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = uni.groupby('Region')['Estimated_cost_of_living_per_year_(in_pounds)',
                           'Student_satisfaction'].agg({'Estimated_cost_of_living_per_year_(in_pounds)':'mean','Student_satisfaction':'max'})
df = df.groupby(df['Estimated_cost_of_living_per_year_(in_pounds)']>=8000).get_group(True)
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = uni.groupby('Region')['Estimated_cost_of_living_per_year_(in_pounds)',
    'Student_satisfaction'].agg({
    'Estimated_cost_of_living_per_year_(in_pounds)': 'mean',
    'Student_satisfaction': 'max'})
df = df.groupby(df['Estimated_cost_of_living_per_year_(in_pounds)'] >= 8000
    ).get_group(True)
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_54e0ed47').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_54e0ed47" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Estimated_cost_of_living_per_year_(in_pounds)</th>
      <th>Student_satisfaction</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>East Midlands</th>
      <td>9398.000000</td>
      <td>85.8</td>
    </tr>
    <tr>
      <th>East of England</th>
      <td>9415.000000</td>
      <td>85.5</td>
    </tr>
    <tr>
      <th>London</th>
      <td>10228.727273</td>
      <td>84.7</td>
    </tr>
    <tr>
      <th>North East England</th>
      <td>8000.000000</td>
      <td>79.5</td>
    </tr>
    <tr>
      <th>Scotland</th>
      <td>8000.000000</td>
      <td>87.9</td>
    </tr>
    <tr>
      <th>South East England</th>
      <td>8990.000000</td>
      <td>86.5</td>
    </tr>
    <tr>
      <th>South West England</th>
      <td>8216.833333</td>
      <td>83.1</td>
    </tr>
    <tr>
      <th>West Midlands</th>
      <td>8096.800000</td>
      <td>82.8</td>
    </tr>
    <tr>
      <th>Yorkshire and the Humber</th>
      <td>8269.909091</td>
      <td>82.1</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Estimated_cost_of_living_per_year_(in_pounds)</th>
      <th>Student_satisfaction</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>East Midlands</th>
      <td>9398.000000</td>
      <td>85.8</td>
    </tr>
    <tr>
      <th>East of England</th>
      <td>9415.000000</td>
      <td>85.5</td>
    </tr>
    <tr>
      <th>London</th>
      <td>10228.727273</td>
      <td>84.7</td>
    </tr>
    <tr>
      <th>North East England</th>
      <td>8000.000000</td>
      <td>79.5</td>
    </tr>
    <tr>
      <th>Scotland</th>
      <td>8000.000000</td>
      <td>87.9</td>
    </tr>
    <tr>
      <th>South East England</th>
      <td>8990.000000</td>
      <td>86.5</td>
    </tr>
    <tr>
      <th>South West England</th>
      <td>8216.833333</td>
      <td>83.1</td>
    </tr>
    <tr>
      <th>West Midlands</th>
      <td>8096.800000</td>
      <td>82.8</td>
    </tr>
    <tr>
      <th>Yorkshire and the Humber</th>
      <td>8269.909091</td>
      <td>82.1</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Estimated_cost_of_living_per_year_(in_pounds)</th>
      <th>Student_satisfaction</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>East Midlands</th>
      <td>9398.000000</td>
      <td>85.8</td>
    </tr>
    <tr>
      <th>East of England</th>
      <td>9415.000000</td>
      <td>85.5</td>
    </tr>
    <tr>
      <th>London</th>
      <td>10228.727273</td>
      <td>84.7</td>
    </tr>
    <tr>
      <th>North East England</th>
      <td>8000.000000</td>
      <td>79.5</td>
    </tr>
    <tr>
      <th>Scotland</th>
      <td>8000.000000</td>
      <td>87.9</td>
    </tr>
    <tr>
      <th>South East England</th>
      <td>8990.000000</td>
      <td>86.5</td>
    </tr>
    <tr>
      <th>South West England</th>
      <td>8216.833333</td>
      <td>83.1</td>
    </tr>
    <tr>
      <th>West Midlands</th>
      <td>8096.800000</td>
      <td>82.8</td>
    </tr>
    <tr>
      <th>Yorkshire and the Humber</th>
      <td>8269.909091</td>
      <td>82.1</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-universities-in-the-united-kingdom/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Among those regions, what is the average rating of universities within the region having the highest average cost of living?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>uni[uni.Region == df['Estimated_cost_of_living_per_year_(in_pounds)'].idxmax()].CWUR_score.mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>uni[uni.Region == df['Estimated_cost_of_living_per_year_(in_pounds)'].idxmax()].CWUR_score.mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = uni[uni.Region == df[
    'Estimated_cost_of_living_per_year_(in_pounds)'].idxmax()].CWUR_score.mean(
    )
</code></pre>
        <p><span onclick="$('#var_output_d7079927').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d7079927" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>73.69333333333334</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>73.69333333333334</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-universities-in-the-united-kingdom/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which university within each region has the highest average percentage of international students? Show the region, university name and percentage of international students</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = uni.groupby(['Region','University_name']).International_students.mean().unstack(0).agg(['idxmax','max']).T
df.columns = ['university_name','international_students']
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = uni.groupby(['Region','University_name']).International_students.mean().unstack(0).agg(['idxmax','max']).T
df.columns = ['university_name','international_students']
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = uni.groupby(['Region', 'University_name']).International_students.mean(
    ).unstack(0).agg(['idxmax', 'max']).T
df.columns = ['university_name', 'international_students']
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_b9927f5d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b9927f5d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>university_name</th>
      <th>international_students</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>East Midlands</th>
      <td>University of Leicester</td>
      <td>22.2</td>
    </tr>
    <tr>
      <th>East of England</th>
      <td>University of Essex</td>
      <td>30.2</td>
    </tr>
    <tr>
      <th>London</th>
      <td>London School of Economics and Political Science</td>
      <td>46.8</td>
    </tr>
    <tr>
      <th>North East England</th>
      <td>University of Sunderland</td>
      <td>25.1</td>
    </tr>
    <tr>
      <th>North West England</th>
      <td>Lancaster University</td>
      <td>29.6</td>
    </tr>
    <tr>
      <th>Northern Ireland</th>
      <td>Queen's University Belfast</td>
      <td>8.7</td>
    </tr>
    <tr>
      <th>Scotland</th>
      <td>University of St Andrews</td>
      <td>40.4</td>
    </tr>
    <tr>
      <th>South East England</th>
      <td>University of Buckingham</td>
      <td>50.5</td>
    </tr>
    <tr>
      <th>South West England</th>
      <td>University of Bath</td>
      <td>21.7</td>
    </tr>
    <tr>
      <th>Wales</th>
      <td>Wrexham Glyndwr University</td>
      <td>23.0</td>
    </tr>
    <tr>
      <th>West Midlands</th>
      <td>University of Warwick</td>
      <td>28.3</td>
    </tr>
    <tr>
      <th>Yorkshire and the Humber</th>
      <td>University of York</td>
      <td>23.0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>university_name</th>
      <th>international_students</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>East Midlands</th>
      <td>University of Leicester</td>
      <td>22.2</td>
    </tr>
    <tr>
      <th>East of England</th>
      <td>University of Essex</td>
      <td>30.2</td>
    </tr>
    <tr>
      <th>London</th>
      <td>London School of Economics and Political Science</td>
      <td>46.8</td>
    </tr>
    <tr>
      <th>North East England</th>
      <td>University of Sunderland</td>
      <td>25.1</td>
    </tr>
    <tr>
      <th>North West England</th>
      <td>Lancaster University</td>
      <td>29.6</td>
    </tr>
    <tr>
      <th>Northern Ireland</th>
      <td>Queen's University Belfast</td>
      <td>8.7</td>
    </tr>
    <tr>
      <th>Scotland</th>
      <td>University of St Andrews</td>
      <td>40.4</td>
    </tr>
    <tr>
      <th>South East England</th>
      <td>University of Buckingham</td>
      <td>50.5</td>
    </tr>
    <tr>
      <th>South West England</th>
      <td>University of Bath</td>
      <td>21.7</td>
    </tr>
    <tr>
      <th>Wales</th>
      <td>Wrexham Glyndwr University</td>
      <td>23.0</td>
    </tr>
    <tr>
      <th>West Midlands</th>
      <td>University of Warwick</td>
      <td>28.3</td>
    </tr>
    <tr>
      <th>Yorkshire and the Humber</th>
      <td>University of York</td>
      <td>23.0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>university_name</th>
      <th>international_students</th>
    </tr>
    <tr>
      <th>Region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>East Midlands</th>
      <td>University of Leicester</td>
      <td>22.2</td>
    </tr>
    <tr>
      <th>East of England</th>
      <td>University of Essex</td>
      <td>30.2</td>
    </tr>
    <tr>
      <th>London</th>
      <td>London School of Economics and Political Science</td>
      <td>46.8</td>
    </tr>
    <tr>
      <th>North East England</th>
      <td>University of Sunderland</td>
      <td>25.1</td>
    </tr>
    <tr>
      <th>North West England</th>
      <td>Lancaster University</td>
      <td>29.6</td>
    </tr>
    <tr>
      <th>Northern Ireland</th>
      <td>Queen's University Belfast</td>
      <td>8.7</td>
    </tr>
    <tr>
      <th>Scotland</th>
      <td>University of St Andrews</td>
      <td>40.4</td>
    </tr>
    <tr>
      <th>South East England</th>
      <td>University of Buckingham</td>
      <td>50.5</td>
    </tr>
    <tr>
      <th>South West England</th>
      <td>University of Bath</td>
      <td>21.7</td>
    </tr>
    <tr>
      <th>Wales</th>
      <td>Wrexham Glyndwr University</td>
      <td>23.0</td>
    </tr>
    <tr>
      <th>West Midlands</th>
      <td>University of Warwick</td>
      <td>28.3</td>
    </tr>
    <tr>
      <th>Yorkshire and the Humber</th>
      <td>University of York</td>
      <td>23.0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-universities-in-the-united-kingdom/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average CWUR score for universities having an average student satisfaction of more than or equal eighty compared to those having less than eighty?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = uni.groupby(uni.Student_satisfaction>80)['CWUR_score'].mean().reset_index()
df['Student_satisfaction'].replace({True:'>=80',False:'<80'},inplace=True)
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = uni.groupby(uni.Student_satisfaction>80)['CWUR_score'].mean().reset_index()
df['Student_satisfaction'].replace({True:'>=80',False:'<80'},inplace=True)
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = uni.groupby(uni.Student_satisfaction > 80)['CWUR_score'].mean(
    ).reset_index()
__tmp_1 = df['Student_satisfaction'].replace({(True): '>=80', (False):
    '<80'}, inplace=True)
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_c97275bc').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c97275bc" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Student_satisfaction</th>
      <th>CWUR_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt;80</td>
      <td>73.487097</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;=80</td>
      <td>75.295455</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Student_satisfaction</th>
      <th>CWUR_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt;80</td>
      <td>73.487097</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;=80</td>
      <td>75.295455</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Student_satisfaction</th>
      <th>CWUR_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt;80</td>
      <td>73.487097</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;=80</td>
      <td>75.295455</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-universities-in-the-united-kingdom/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which university within each campus setting has the highest average student satisfaction score? Show the campus setting, university name and student satisfaction</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = uni.groupby(['Campus_setting','University_name']).Student_satisfaction.mean().unstack(0).agg(['idxmax','max']).T
df.columns = ['university_name','student_satisfaction']
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = uni.groupby(['Campus_setting','University_name']).Student_satisfaction.mean().unstack(0).agg(['idxmax','max']).T
df.columns = ['university_name','student_satisfaction']
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = uni.groupby(['Campus_setting', 'University_name']
    ).Student_satisfaction.mean().unstack(0).agg(['idxmax', 'max']).T
df.columns = ['university_name', 'student_satisfaction']
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_5a3ef9c7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5a3ef9c7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>university_name</th>
      <th>student_satisfaction</th>
    </tr>
    <tr>
      <th>Campus_setting</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Rural</th>
      <td>Keele University</td>
      <td>82.5</td>
    </tr>
    <tr>
      <th>Suburban</th>
      <td>University of St Andrews</td>
      <td>87.9</td>
    </tr>
    <tr>
      <th>Urban</th>
      <td>University of Oxford</td>
      <td>86.5</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>university_name</th>
      <th>student_satisfaction</th>
    </tr>
    <tr>
      <th>Campus_setting</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Rural</th>
      <td>Keele University</td>
      <td>82.5</td>
    </tr>
    <tr>
      <th>Suburban</th>
      <td>University of St Andrews</td>
      <td>87.9</td>
    </tr>
    <tr>
      <th>Urban</th>
      <td>University of Oxford</td>
      <td>86.5</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>university_name</th>
      <th>student_satisfaction</th>
    </tr>
    <tr>
      <th>Campus_setting</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Rural</th>
      <td>Keele University</td>
      <td>82.5</td>
    </tr>
    <tr>
      <th>Suburban</th>
      <td>University of St Andrews</td>
      <td>87.9</td>
    </tr>
    <tr>
      <th>Urban</th>
      <td>University of Oxford</td>
      <td>86.5</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> best-universities-in-the-united-kingdom/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average academic staff enrollment of the universities that were founded within the 19th and the 20th century?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>uni[uni.Founded_year.between(1801,2000)][['lower_staff','upper_staff']].mean(1).mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>uni[uni.Founded_year.between(1801,2000)][['lower_staff','upper_staff']].mean(1).mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = uni[uni.Founded_year.between(1801, 2000)][['lower_staff',
    'upper_staff']].mean(1).mean()
</code></pre>
        <p><span onclick="$('#var_output_37e232b7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_37e232b7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>1606.8383838383838</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>1606.8383838383838</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> global-landslide-catalog/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many events occurred in each country every quarter of every year? Show the quarter as an index and country names as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>time_periods = glc.groupby([pd.Grouper(key='event_date', freq='Q'),'country_name']).size().unstack(fill_value=0)
time_periods</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>time_periods = glc.groupby([pd.Grouper(key='event_date', freq='Q'),'country_name']).size().unstack(fill_value=0)
time_periods</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>time_periods = glc.groupby([pd.Grouper(key='event_date', freq='Q'),
    'country_name']).size().unstack(fill_value=0)
__output__ = time_periods
</code></pre>
        <p><span onclick="$('#var_output_e6eb6e16').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e6eb6e16" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>country_name</th>
      <th>Afghanistan</th>
      <th>Albania</th>
      <th>Algeria</th>
      <th>American Samoa</th>
      <th>Angola</th>
      <th>Argentina</th>
      <th>Armenia</th>
      <th>...</th>
      <th>United States</th>
      <th>Uzbekistan</th>
      <th>Vanuatu</th>
      <th>Venezuela</th>
      <th>Vietnam</th>
      <th>Yemen</th>
      <th>Zambia</th>
    </tr>
    <tr>
      <th>event_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1988-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1993-06-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1995-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1996-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1997-03-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1997-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1998-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>12</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2015-06-30</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>82</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2015-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>91</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>12</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2015-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>218</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-03-31</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>164</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-06-30</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>67</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>57</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>17</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>53 rows × 141 columns</p>
      
        <p><strong>Hyp output variables:</strong> time_periods, __output__ </p>
    
          <p>time_periods (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>country_name</th>
      <th>Afghanistan</th>
      <th>Albania</th>
      <th>Algeria</th>
      <th>American Samoa</th>
      <th>Angola</th>
      <th>Argentina</th>
      <th>Armenia</th>
      <th>...</th>
      <th>United States</th>
      <th>Uzbekistan</th>
      <th>Vanuatu</th>
      <th>Venezuela</th>
      <th>Vietnam</th>
      <th>Yemen</th>
      <th>Zambia</th>
    </tr>
    <tr>
      <th>event_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1988-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1993-06-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1995-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1996-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1997-03-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1997-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1998-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>12</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2015-06-30</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>82</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2015-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>91</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>12</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2015-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>218</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-03-31</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>164</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-06-30</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>67</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>57</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>17</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>53 rows × 141 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>country_name</th>
      <th>Afghanistan</th>
      <th>Albania</th>
      <th>Algeria</th>
      <th>American Samoa</th>
      <th>Angola</th>
      <th>Argentina</th>
      <th>Armenia</th>
      <th>...</th>
      <th>United States</th>
      <th>Uzbekistan</th>
      <th>Vanuatu</th>
      <th>Venezuela</th>
      <th>Vietnam</th>
      <th>Yemen</th>
      <th>Zambia</th>
    </tr>
    <tr>
      <th>event_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1988-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1993-06-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1995-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1996-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1997-03-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1997-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1998-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>12</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2015-06-30</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>82</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2015-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>91</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>12</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2015-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>218</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-03-31</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>164</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-06-30</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>67</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-09-30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>57</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2016-12-31</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>17</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>53 rows × 141 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> global-landslide-catalog/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which country had the highest number of reported events in each of those time periods? Show the period as an index and country name and event counts as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>countries_max = time_periods.T.agg(['idxmax','max']).T
countries_max.columns = ['country_name','event_count']
countries_max</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>countries_max = time_periods.T.agg(['idxmax','max']).T
countries_max.columns = ['country_name','event_count']
countries_max</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>countries_max = time_periods.T.agg(['idxmax', 'max']).T
countries_max.columns = ['country_name', 'event_count']
__output__ = countries_max
</code></pre>
        <p><span onclick="$('#var_output_0caaaa28').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0caaaa28" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_name</th>
      <th>event_count</th>
    </tr>
    <tr>
      <th>event_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1988-12-31</th>
      <td>Philippines</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1993-06-30</th>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1995-09-30</th>
      <td>Switzerland</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1996-12-31</th>
      <td>United States</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1997-03-31</th>
      <td>United States</td>
      <td>9</td>
    </tr>
    <tr>
      <th>1997-09-30</th>
      <td>Luxembourg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1998-12-31</th>
      <td>United States</td>
      <td>12</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2015-06-30</th>
      <td>United States</td>
      <td>82</td>
    </tr>
    <tr>
      <th>2015-09-30</th>
      <td>India</td>
      <td>132</td>
    </tr>
    <tr>
      <th>2015-12-31</th>
      <td>United States</td>
      <td>218</td>
    </tr>
    <tr>
      <th>2016-03-31</th>
      <td>United States</td>
      <td>164</td>
    </tr>
    <tr>
      <th>2016-06-30</th>
      <td>United States</td>
      <td>67</td>
    </tr>
    <tr>
      <th>2016-09-30</th>
      <td>United States</td>
      <td>57</td>
    </tr>
    <tr>
      <th>2016-12-31</th>
      <td>Philippines</td>
      <td>31</td>
    </tr>
  </tbody>
</table>
<p>53 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> countries_max, __output__ </p>
    
          <p>countries_max (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_name</th>
      <th>event_count</th>
    </tr>
    <tr>
      <th>event_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1988-12-31</th>
      <td>Philippines</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1993-06-30</th>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1995-09-30</th>
      <td>Switzerland</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1996-12-31</th>
      <td>United States</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1997-03-31</th>
      <td>United States</td>
      <td>9</td>
    </tr>
    <tr>
      <th>1997-09-30</th>
      <td>Luxembourg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1998-12-31</th>
      <td>United States</td>
      <td>12</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2015-06-30</th>
      <td>United States</td>
      <td>82</td>
    </tr>
    <tr>
      <th>2015-09-30</th>
      <td>India</td>
      <td>132</td>
    </tr>
    <tr>
      <th>2015-12-31</th>
      <td>United States</td>
      <td>218</td>
    </tr>
    <tr>
      <th>2016-03-31</th>
      <td>United States</td>
      <td>164</td>
    </tr>
    <tr>
      <th>2016-06-30</th>
      <td>United States</td>
      <td>67</td>
    </tr>
    <tr>
      <th>2016-09-30</th>
      <td>United States</td>
      <td>57</td>
    </tr>
    <tr>
      <th>2016-12-31</th>
      <td>Philippines</td>
      <td>31</td>
    </tr>
  </tbody>
</table>
<p>53 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_name</th>
      <th>event_count</th>
    </tr>
    <tr>
      <th>event_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1988-12-31</th>
      <td>Philippines</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1993-06-30</th>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1995-09-30</th>
      <td>Switzerland</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1996-12-31</th>
      <td>United States</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1997-03-31</th>
      <td>United States</td>
      <td>9</td>
    </tr>
    <tr>
      <th>1997-09-30</th>
      <td>Luxembourg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1998-12-31</th>
      <td>United States</td>
      <td>12</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2015-06-30</th>
      <td>United States</td>
      <td>82</td>
    </tr>
    <tr>
      <th>2015-09-30</th>
      <td>India</td>
      <td>132</td>
    </tr>
    <tr>
      <th>2015-12-31</th>
      <td>United States</td>
      <td>218</td>
    </tr>
    <tr>
      <th>2016-03-31</th>
      <td>United States</td>
      <td>164</td>
    </tr>
    <tr>
      <th>2016-06-30</th>
      <td>United States</td>
      <td>67</td>
    </tr>
    <tr>
      <th>2016-09-30</th>
      <td>United States</td>
      <td>57</td>
    </tr>
    <tr>
      <th>2016-12-31</th>
      <td>Philippines</td>
      <td>31</td>
    </tr>
  </tbody>
</table>
<p>53 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> global-landslide-catalog/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many events were reported during each hour of the day for every category of landslides? Show the hours as an index and categories as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = glc.groupby([glc.event_date.dt.hour,'landslide_category']).size().unstack(fill_value=0)
df.index.name = 'hour_of_day'
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = glc.groupby([glc.event_date.dt.hour,'landslide_category']).size().unstack(fill_value=0)
df.index.name = 'hour_of_day'
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = glc.groupby([glc.event_date.dt.hour, 'landslide_category']).size(
    ).unstack(fill_value=0)
df.index.name = 'hour_of_day'
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_1bb8358d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1bb8358d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>landslide_category</th>
      <th>complex</th>
      <th>creep</th>
      <th>debris_flow</th>
      <th>earth_flow</th>
      <th>lahar</th>
      <th>landslide</th>
      <th>mudslide</th>
      <th>other</th>
      <th>riverbank_collapse</th>
      <th>rock_fall</th>
      <th>snow_avalanche</th>
      <th>topple</th>
      <th>translational_slide</th>
      <th>unknown</th>
    </tr>
    <tr>
      <th>hour_of_day</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>157</td>
      <td>3</td>
      <td>99</td>
      <td>2</td>
      <td>3</td>
      <td>4045</td>
      <td>963</td>
      <td>36</td>
      <td>20</td>
      <td>222</td>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>26</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>47</td>
      <td>18</td>
      <td>1</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>76</td>
      <td>27</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>73</td>
      <td>14</td>
      <td>0</td>
      <td>1</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>86</td>
      <td>23</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>67</td>
      <td>15</td>
      <td>1</td>
      <td>0</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>69</td>
      <td>25</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>17</th>
      <td>3</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>151</td>
      <td>45</td>
      <td>0</td>
      <td>1</td>
      <td>13</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>18</th>
      <td>2</td>
      <td>2</td>
      <td>7</td>
      <td>2</td>
      <td>1</td>
      <td>262</td>
      <td>77</td>
      <td>3</td>
      <td>3</td>
      <td>29</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>19</th>
      <td>4</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>121</td>
      <td>47</td>
      <td>2</td>
      <td>0</td>
      <td>23</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>20</th>
      <td>1</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>136</td>
      <td>51</td>
      <td>0</td>
      <td>1</td>
      <td>31</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>95</td>
      <td>31</td>
      <td>1</td>
      <td>0</td>
      <td>15</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>22</th>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>90</td>
      <td>35</td>
      <td>1</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>23</th>
      <td>5</td>
      <td>0</td>
      <td>11</td>
      <td>0</td>
      <td>0</td>
      <td>360</td>
      <td>127</td>
      <td>3</td>
      <td>0</td>
      <td>41</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>24 rows × 14 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>landslide_category</th>
      <th>complex</th>
      <th>creep</th>
      <th>debris_flow</th>
      <th>earth_flow</th>
      <th>lahar</th>
      <th>landslide</th>
      <th>mudslide</th>
      <th>other</th>
      <th>riverbank_collapse</th>
      <th>rock_fall</th>
      <th>snow_avalanche</th>
      <th>topple</th>
      <th>translational_slide</th>
      <th>unknown</th>
    </tr>
    <tr>
      <th>hour_of_day</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>157</td>
      <td>3</td>
      <td>99</td>
      <td>2</td>
      <td>3</td>
      <td>4045</td>
      <td>963</td>
      <td>36</td>
      <td>20</td>
      <td>222</td>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>26</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>47</td>
      <td>18</td>
      <td>1</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>76</td>
      <td>27</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>73</td>
      <td>14</td>
      <td>0</td>
      <td>1</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>86</td>
      <td>23</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>67</td>
      <td>15</td>
      <td>1</td>
      <td>0</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>69</td>
      <td>25</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>17</th>
      <td>3</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>151</td>
      <td>45</td>
      <td>0</td>
      <td>1</td>
      <td>13</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>18</th>
      <td>2</td>
      <td>2</td>
      <td>7</td>
      <td>2</td>
      <td>1</td>
      <td>262</td>
      <td>77</td>
      <td>3</td>
      <td>3</td>
      <td>29</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>19</th>
      <td>4</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>121</td>
      <td>47</td>
      <td>2</td>
      <td>0</td>
      <td>23</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>20</th>
      <td>1</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>136</td>
      <td>51</td>
      <td>0</td>
      <td>1</td>
      <td>31</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>95</td>
      <td>31</td>
      <td>1</td>
      <td>0</td>
      <td>15</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>22</th>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>90</td>
      <td>35</td>
      <td>1</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>23</th>
      <td>5</td>
      <td>0</td>
      <td>11</td>
      <td>0</td>
      <td>0</td>
      <td>360</td>
      <td>127</td>
      <td>3</td>
      <td>0</td>
      <td>41</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>24 rows × 14 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>landslide_category</th>
      <th>complex</th>
      <th>creep</th>
      <th>debris_flow</th>
      <th>earth_flow</th>
      <th>lahar</th>
      <th>landslide</th>
      <th>mudslide</th>
      <th>other</th>
      <th>riverbank_collapse</th>
      <th>rock_fall</th>
      <th>snow_avalanche</th>
      <th>topple</th>
      <th>translational_slide</th>
      <th>unknown</th>
    </tr>
    <tr>
      <th>hour_of_day</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>157</td>
      <td>3</td>
      <td>99</td>
      <td>2</td>
      <td>3</td>
      <td>4045</td>
      <td>963</td>
      <td>36</td>
      <td>20</td>
      <td>222</td>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>26</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>47</td>
      <td>18</td>
      <td>1</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>76</td>
      <td>27</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>73</td>
      <td>14</td>
      <td>0</td>
      <td>1</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>86</td>
      <td>23</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>67</td>
      <td>15</td>
      <td>1</td>
      <td>0</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>69</td>
      <td>25</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>17</th>
      <td>3</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>151</td>
      <td>45</td>
      <td>0</td>
      <td>1</td>
      <td>13</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>18</th>
      <td>2</td>
      <td>2</td>
      <td>7</td>
      <td>2</td>
      <td>1</td>
      <td>262</td>
      <td>77</td>
      <td>3</td>
      <td>3</td>
      <td>29</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>19</th>
      <td>4</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>121</td>
      <td>47</td>
      <td>2</td>
      <td>0</td>
      <td>23</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>20</th>
      <td>1</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>136</td>
      <td>51</td>
      <td>0</td>
      <td>1</td>
      <td>31</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>95</td>
      <td>31</td>
      <td>1</td>
      <td>0</td>
      <td>15</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>22</th>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>90</td>
      <td>35</td>
      <td>1</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>23</th>
      <td>5</td>
      <td>0</td>
      <td>11</td>
      <td>0</td>
      <td>0</td>
      <td>360</td>
      <td>127</td>
      <td>3</td>
      <td>0</td>
      <td>41</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>24 rows × 14 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> global-landslide-catalog/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are countries impacted by the top five most fatal landslide categories?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>l_cat = glc.groupby('landslide_category').fatality_count.sum().sort_values(ascending=False).head(5)
glc[glc.landslide_category.isin(l_cat.index)].country_name.unique()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>l_cat = glc.groupby('landslide_category').fatality_count.sum().sort_values(ascending=False).head(5)
glc[glc.landslide_category.isin(l_cat.index)].country_name.unique()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>l_cat = glc.groupby('landslide_category').fatality_count.sum().sort_values(
    ascending=False).head(5)
__output__ = glc[glc.landslide_category.isin(l_cat.index)].country_name.unique(
    )
</code></pre>
        <p><span onclick="$('#var_output_f5e1c2bd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f5e1c2bd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>['China' 'United States' 'Peru' 'Nepal' 'Philippines' 'Mexico' nan
 'Algeria' 'Malaysia' 'Indonesia' 'Sierra Leone' 'Brunei' 'Italy' 'India'
 'Australia' 'Japan' 'Brazil' 'Pakistan' 'Canada' 'Ghana'
 'Trinidad and Tobago' 'Panama' 'Austria' 'United Kingdom' 'El Salvador'
 'Thailand' 'Colombia' 'Jamaica' 'Vietnam' 'Bangladesh' 'Switzerland'
 'Costa Rica' 'Honduras' 'Bhutan' 'Fiji' 'Georgia' 'Kenya' 'New Zealand'
 'Yemen' 'Kyrgyzstan' 'Taiwan' 'Ecuador' 'Ireland' 'Ivory Coast'
 'Dominican Republic' 'Spain' 'Dominica' 'Sri Lanka' 'Bulgaria' 'Haiti'
 'Lebanon' 'Iceland' 'Nicaragua' 'France' 'Guatemala'
 'United Arab Emirates' 'Chile' 'Venezuela' 'South Korea' 'Malawi'
 'Myanmar [Burma]' 'Uganda' 'Argentina' 'Egypt' 'Turkey' 'Puerto Rico'
 'Norway' 'South Africa' 'Russia' 'Nigeria' 'Swaziland' 'Belize'
 'Bosnia and Herzegovina' 'Mauritius' 'Solomon Islands' 'Papua New Guinea'
 'Bolivia' 'Laos' 'Cameroon' 'Azerbaijan' 'Tajikistan' 'Slovakia'
 'Germany' 'Barbados' 'Guinea' 'Macedonia' 'Serbia' 'Ethiopia' 'Croatia'
 'Slovenia' 'Vanuatu' 'Portugal' 'Saint Lucia' 'Bermuda' 'American Samoa'
 'Grenada' 'Tanzania' 'Romania' 'Rwanda' 'Czechia' 'Liberia' 'Iran'
 'Armenia' 'Madagascar' 'Afghanistan' 'Saint Vincent and the Grenadines'
 'Greece' 'Ukraine' 'Saudi Arabia' 'Montenegro' 'Israel' 'Hong Kong'
 'Guam' 'Isle of Man' 'Jordan' 'Republic of the Congo'
 'U.S. Virgin Islands' 'Albania' 'Jersey' 'Angola' 'North Korea' 'Cuba'
 'Democratic Republic of the Congo' 'Oman' 'Namibia' 'Czech Republic'
 'Zambia' 'Poland' 'Paraguay' 'Mongolia' 'Burkina Faso' 'Singapore'
 'Uzbekistan' 'East Timor' 'Burundi' 'Sudan' 'Gabon' 'Morocco'
 'Kazakhstan' 'Cambodia' 'Saint Kitts and Nevis' 'Luxembourg']</code></pre>
      
        <p><strong>Hyp output variables:</strong> l_cat, __output__ </p>
    
          <p>l_cat (Series):</p>
          <pre><code>landslide_category
landslide      16912.0
debris_flow     5770.0
mudslide        5624.0
complex         2139.0
rock_fall        319.0
Name: fatality_count, dtype: float64</code></pre>
      
          <p>__output__ (ndarray):</p>
          <pre><code>['China' 'United States' 'Peru' 'Nepal' 'Philippines' 'Mexico' nan
 'Algeria' 'Malaysia' 'Indonesia' 'Sierra Leone' 'Brunei' 'Italy' 'India'
 'Australia' 'Japan' 'Brazil' 'Pakistan' 'Canada' 'Ghana'
 'Trinidad and Tobago' 'Panama' 'Austria' 'United Kingdom' 'El Salvador'
 'Thailand' 'Colombia' 'Jamaica' 'Vietnam' 'Bangladesh' 'Switzerland'
 'Costa Rica' 'Honduras' 'Bhutan' 'Fiji' 'Georgia' 'Kenya' 'New Zealand'
 'Yemen' 'Kyrgyzstan' 'Taiwan' 'Ecuador' 'Ireland' 'Ivory Coast'
 'Dominican Republic' 'Spain' 'Dominica' 'Sri Lanka' 'Bulgaria' 'Haiti'
 'Lebanon' 'Iceland' 'Nicaragua' 'France' 'Guatemala'
 'United Arab Emirates' 'Chile' 'Venezuela' 'South Korea' 'Malawi'
 'Myanmar [Burma]' 'Uganda' 'Argentina' 'Egypt' 'Turkey' 'Puerto Rico'
 'Norway' 'South Africa' 'Russia' 'Nigeria' 'Swaziland' 'Belize'
 'Bosnia and Herzegovina' 'Mauritius' 'Solomon Islands' 'Papua New Guinea'
 'Bolivia' 'Laos' 'Cameroon' 'Azerbaijan' 'Tajikistan' 'Slovakia'
 'Germany' 'Barbados' 'Guinea' 'Macedonia' 'Serbia' 'Ethiopia' 'Croatia'
 'Slovenia' 'Vanuatu' 'Portugal' 'Saint Lucia' 'Bermuda' 'American Samoa'
 'Grenada' 'Tanzania' 'Romania' 'Rwanda' 'Czechia' 'Liberia' 'Iran'
 'Armenia' 'Madagascar' 'Afghanistan' 'Saint Vincent and the Grenadines'
 'Greece' 'Ukraine' 'Saudi Arabia' 'Montenegro' 'Israel' 'Hong Kong'
 'Guam' 'Isle of Man' 'Jordan' 'Republic of the Congo'
 'U.S. Virgin Islands' 'Albania' 'Jersey' 'Angola' 'North Korea' 'Cuba'
 'Democratic Republic of the Congo' 'Oman' 'Namibia' 'Czech Republic'
 'Zambia' 'Poland' 'Paraguay' 'Mongolia' 'Burkina Faso' 'Singapore'
 'Uzbekistan' 'East Timor' 'Burundi' 'Sudan' 'Gabon' 'Morocco'
 'Kazakhstan' 'Cambodia' 'Saint Kitts and Nevis' 'Luxembourg']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', {'functionally_equivalent': True, 'reason': 'compare_lists'})]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> global-landslide-catalog/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average division population for different countries having events involving heavy rain?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>glc.loc[glc.event_description.str.contains('heavy rain', case=False).dropna().index].groupby(['country_name']).admin_division_population.mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>glc.loc[glc.event_description.str.contains('heavy rain', case=False).dropna().index].groupby(['country_name']).admin_division_population.mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = glc.loc[glc.event_description.str.contains('heavy rain', case=
    False).dropna().index].groupby(['country_name']
    ).admin_division_population.mean()
</code></pre>
        <p><span onclick="$('#var_output_23abb7aa').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_23abb7aa" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>country_name
Afghanistan       2.106536e+05
Albania           0.000000e+00
Algeria           1.480000e+05
American Samoa    2.458000e+03
Angola            2.776168e+06
                      ...     
Vanuatu           1.328000e+03
Venezuela         1.330325e+06
Vietnam           3.430915e+04
Yemen             9.681800e+04
Zambia            8.547000e+03
Name: admin_division_population, Length: 141, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>country_name
Afghanistan       2.106536e+05
Albania           0.000000e+00
Algeria           1.480000e+05
American Samoa    2.458000e+03
Angola            2.776168e+06
                      ...     
Vanuatu           1.328000e+03
Venezuela         1.330325e+06
Vietnam           3.430915e+04
Yemen             9.681800e+04
Zambia            8.547000e+03
Name: admin_division_population, Length: 141, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> global-landslide-catalog/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the location_accuracy column to the the correct numeric data type. Represent the values in kilometer units and replace 'unknown' and 'exact' values with null and 0, respectively.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>glc.location_accuracy = pd.to_numeric(glc.location_accuracy.str.replace('unknown','').str.replace('exact','0').str.replace('km',''))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>glc.location_accuracy = pd.to_numeric(glc.location_accuracy.str.replace('unknown','').str.replace('exact','0').str.replace('km',''))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = glc.location_accuracy = pd.to_numeric(glc.location_accuracy.
    str.replace('unknown', '').str.replace('exact', '0').str.replace('km', ''))
</code></pre>
        <p><span onclick="$('#var_output_6f08f166').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6f08f166" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0         NaN
1         5.0
2        10.0
3         NaN
4         5.0
         ... 
11028     5.0
11029     5.0
11030     1.0
11031     1.0
11032     1.0
Name: location_accuracy, Length: 11033, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> glc, __output__ </p>
    
          <p>glc (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>source_name</th>
      <th>source_link</th>
      <th>event_id</th>
      <th>event_date</th>
      <th>event_time</th>
      <th>event_title</th>
      <th>event_description</th>
      <th>...</th>
      <th>gazeteer_closest_point</th>
      <th>gazeteer_distance</th>
      <th>submitted_date</th>
      <th>created_date</th>
      <th>last_edited_date</th>
      <th>longitude</th>
      <th>latitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AGU</td>
      <td>https://blogs.agu.org/landslideblog/2008/10/14/the-lifan-landslide-from-natural-disaster-to-cover-up/</td>
      <td>684</td>
      <td>2008-08-01 00:00:00</td>
      <td>NaN</td>
      <td>Sigou Village, Loufan County, Shanxi Province</td>
      <td>occurred early in morning, 11 villagers buried in 7 houses</td>
      <td>...</td>
      <td>Jingyang</td>
      <td>41.02145</td>
      <td>2014-04-01 00:00:00</td>
      <td>2017-11-20 15:17:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>107.450000</td>
      <td>32.562500</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Oregonian</td>
      <td>http://www.oregonlive.com/news/index.ssf/2009/01/landslide_plows_through_lake_o.html</td>
      <td>956</td>
      <td>2009-01-02 02:00:00</td>
      <td>NaN</td>
      <td>Lake Oswego, Oregon</td>
      <td>Hours of heavy rain are to blame for an overnight mudslide in Lake Oswego.</td>
      <td>...</td>
      <td>Lake Oswego</td>
      <td>0.60342</td>
      <td>2014-04-01 00:00:00</td>
      <td>2017-11-20 15:17:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>-122.663000</td>
      <td>45.420000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>CBS News</td>
      <td>https://www.cbsnews.com/news/dozens-missing-after-peru-landslides/</td>
      <td>973</td>
      <td>2007-01-19 00:00:00</td>
      <td>NaN</td>
      <td>San Ramon district, 195 miles northeast of the capital, Lima,</td>
      <td>(CBS/AP) At least 10 people died and as many as 80 were still missing Wednesday in central Peru after torrential rains swelled three rivers, forcing them over their banks and causing devastating landslides earlier in the week.</td>
      <td>...</td>
      <td>San Ramón</td>
      <td>0.85548</td>
      <td>2014-04-01 00:00:00</td>
      <td>2017-11-20 15:17:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>-75.358700</td>
      <td>-11.129500</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Reuters</td>
      <td>https://in.reuters.com/article/idINIndia-41450420090731</td>
      <td>1067</td>
      <td>2009-07-31 00:00:00</td>
      <td>NaN</td>
      <td>Dailekh district</td>
      <td>One person was killed in Dailekh district, police said.</td>
      <td>...</td>
      <td>Dailekh</td>
      <td>0.75395</td>
      <td>2014-04-01 00:00:00</td>
      <td>2017-11-20 15:17:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>81.708000</td>
      <td>28.837800</td>
    </tr>
    <tr>
      <th>4</th>
      <td>The Freeman</td>
      <td>http://www.philstar.com/cebu-news/621414/landslides-hit-upland-barangays</td>
      <td>2603</td>
      <td>2010-10-16 12:00:00</td>
      <td>NaN</td>
      <td>sitio Bakilid in barangay Lahug</td>
      <td>Another landslide in sitio Bakilid in barangay Lahug also left two families homeless. Lilibeth Magsuling was breastfeeding her two-month-old baby outside their house at 12 noon yesterday when she heard a loud blast behind her. She immediately hugged her baby boy and ran. When she looked back, she saw bamboo trees and soil covering her house. “It’s fortunate that we were outside the house. I was about to put my baby in the cradle inside the house,” she said. Elenit Villaflor was also outside her house in sitio Bakilid with her two-month-old baby when the landslide struck.</td>
      <td>...</td>
      <td>Cebu City</td>
      <td>2.02204</td>
      <td>2014-04-01 00:00:00</td>
      <td>2017-11-20 15:17:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>123.897800</td>
      <td>10.333600</td>
    </tr>
    <tr>
      <th>5</th>
      <td>BusinessWorld Online</td>
      <td>http://www.bworldonline.com/content.php?section=Nation&amp;title=-death-toll-from-rains-rises-nationwide-floods-displace-hundreds-in-leyte&amp;id=46961</td>
      <td>4203</td>
      <td>2012-02-16 00:00:00</td>
      <td>NaN</td>
      <td>Paguite, Abuyog, Leyte</td>
      <td>Thursday’s landslides were noted in Barangays Burubudan, Tadoc and Paguite in Abuyog; Barangays Pulahongon, Mahaplag, Leyte; and Barangay Kahupian, Sogod, Southern Leyte.</td>
      <td>...</td>
      <td>Balinsacayao</td>
      <td>2.28967</td>
      <td>2014-04-01 00:00:00</td>
      <td>2017-11-20 15:17:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>124.966800</td>
      <td>10.700400</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The Spokesman-Review</td>
      <td>http://www.spokesman.com/stories/2012/mar/31/flooding-reported-across-region/</td>
      <td>4290</td>
      <td>2012-03-30 00:00:00</td>
      <td>NaN</td>
      <td>Pend Oreille County, State Route 20 near Usk, OR</td>
      <td>In Pend Oreille County, a mudslide on State Route 20 near Usk forced Washington State Patrol to close the highway late Friday, then reduce traffic to one lane.</td>
      <td>...</td>
      <td>Newport</td>
      <td>19.97241</td>
      <td>2014-04-01 00:00:00</td>
      <td>2017-11-20 15:17:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>-117.266500</td>
      <td>48.279700</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>11026</th>
      <td>http://newletter.us/articles/the-transcaucasian</td>
      <td>NaN</td>
      <td>10763</td>
      <td>2017-06-21 13:16:00</td>
      <td>NaN</td>
      <td>Mudslide near Tamisk</td>
      <td>Mudslide blocks Transcaucasian Highway near Tamisk.</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2017-07-07 13:16:00</td>
      <td>2017-12-05 16:33:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>44.211414</td>
      <td>42.954914</td>
    </tr>
    <tr>
      <th>11027</th>
      <td>St. Maries Gazette Record</td>
      <td>http://www.gazetterecord.com/news/article_ac60c4ce-1408-11e7-9a2a-5b04a1adf9b7.html</td>
      <td>10518</td>
      <td>2017-03-23 16:36:00</td>
      <td>NaN</td>
      <td>Mudslide above Highway 97</td>
      <td>Reported on March 29, the city of Harrison continues to monitor a mudslide above Highway 97, which is below a residence  at 509 Sunset Terrace. The home is owned by Tom and Ida Enlow, who moved into the residence in September. Mayor Wanda Irish said the city took notice to the situation about a week ago Thursday (3/23/17)  and it only continued to get worse. From CDA Press: Recent rain and snow melt is increasing ground saturation, according to the Kootenai County Office of Emergency Management, making conditions ripe for landslides and debris flow on steep slopes.</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2017-09-15 16:36:00</td>
      <td>2017-11-27 20:24:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>-116.777680</td>
      <td>47.449165</td>
    </tr>
    <tr>
      <th>11028</th>
      <td>The Jakarta Post</td>
      <td>http://www.thejakartapost.com/news/2017/04/02/28-missing-feared-dead-in-east-java-landslide.html</td>
      <td>11109</td>
      <td>2017-04-01 13:34:00</td>
      <td>NaN</td>
      <td>Major landslide in Banaran</td>
      <td>Landslide exacerbated by deforestation and bad irrigation practices. Article: At least 27 people are feared to be buried after a 100-meter-high hill collapsed on Saturday morning during heavy rains in a hamlet in Ponorogo regency, East Java.  The Ponorogo Disaster Mitigation Agency (BPBD) reported that the landslide, which took place at 8 a.m., buried 23 houses in the area and injured dozens of people.     The 27 missing people also include workers who were harvesting ginger on the slopes of the hill during the incident. The landslide buried the affected area up to five meters in depth.</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2017-07-28 13:34:00</td>
      <td>2017-12-19 21:42:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>111.679944</td>
      <td>-7.853409</td>
    </tr>
    <tr>
      <th>11029</th>
      <td>Greater Kashmir</td>
      <td>http://www.greaterkashmir.com/news/jammu/landslides-kill-2-teenage-girls-in-kishtwar/244688.html</td>
      <td>10845</td>
      <td>2017-03-25 17:32:00</td>
      <td>NaN</td>
      <td>Barnari Sigdi Landslide</td>
      <td>Two teenage girls died after they were buried under landslide triggered due to loosened rocks in remote Barnari Sigdi area of Tehsil Mughalmaidan in Kishtwar District on Saturday. "Two other girls who were with them, however, escaped unhurt as they were on other side of the Nallah," SSP added.</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2017-09-21 17:32:00</td>
      <td>2017-12-05 18:45:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>75.680611</td>
      <td>33.403080</td>
    </tr>
    <tr>
      <th>11030</th>
      <td>NBC Daily</td>
      <td>http://www.nbcdaily.com/separate-landslides-kill-two-in-assam/85170/</td>
      <td>10973</td>
      <td>2016-12-15 05:00:00</td>
      <td>NaN</td>
      <td>Landslide at Pub Sarania Hill</td>
      <td>An octogenarian was killed when a sudden landslide buried his house at Pub Sarania hill.</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2017-07-26 13:22:00</td>
      <td>2017-12-08 20:37:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>91.772042</td>
      <td>26.181606</td>
    </tr>
    <tr>
      <th>11031</th>
      <td>AGU Landslide Blog</td>
      <td>http://blogs.agu.org/landslideblog/2017/05/02/ayu-1/</td>
      <td>10901</td>
      <td>2017-04-29 19:03:00</td>
      <td>NaN</td>
      <td>Mayor landslide at Ayu village</td>
      <td>Landslide triggered by heavy rainfall buried 11 houses an kills 24 people.  Article: "this looks to be a large, deep-seated landslide in loess.  Interesting the main scarp appears to be predominantly translational, but with an unusually deep shear surface."</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2017-07-14 19:03:00</td>
      <td>2017-12-07 21:19:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>73.472379</td>
      <td>40.886395</td>
    </tr>
    <tr>
      <th>11032</th>
      <td>The Times of India</td>
      <td>https://timesofindia.indiatimes.com/city/hyderabad/2-workers-killed-in-mudslide-at-kondapur-complex-site/articleshow/57623325.cms</td>
      <td>10949</td>
      <td>2017-03-13 14:32:00</td>
      <td>NaN</td>
      <td>Kondapur Commercial Complex Construction Mudslide</td>
      <td>A mudslide at an under-construction commercial complex in Kondapur on Monday morning killed two workers. A mound of loose soil and mud, that was dug up to create space for three cellars, fell in a heap on workers early in the morning. The tragedy struck barely half an hour after they began removing mud from pillars being constructed at the site at around 8.30 am and were working nearly 40 feet below the ground level.</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2017-10-05 14:32:00</td>
      <td>2017-12-08 19:57:00</td>
      <td>2018-02-15 15:51:00</td>
      <td>78.356505</td>
      <td>17.465630</td>
    </tr>
  </tbody>
</table>
<p>11033 rows × 31 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0         NaN
1         5.0
2        10.0
3         NaN
4         5.0
         ... 
11028     5.0
11029     5.0
11030     1.0
11031     1.0
11032     1.0
Name: location_accuracy, Length: 11033, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> global-landslide-catalog/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the average injuries and fatalities for each category of landslides for events occurring at a location accuracy between five and fifty kilometers?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>inj_fatal = glc[glc.location_accuracy.between(5,50)].groupby('landslide_category')[['injury_count','fatality_count']].mean()
inj_fatal</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>inj_fatal = glc[glc.location_accuracy.between(5,50)].groupby('landslide_category')[['injury_count','fatality_count']].mean()
inj_fatal</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>inj_fatal = glc[glc.location_accuracy.between(5, 50)].groupby(
    'landslide_category')[['injury_count', 'fatality_count']].mean()
__output__ = inj_fatal
</code></pre>
        <p><span onclick="$('#var_output_8955c147').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8955c147" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>injury_count</th>
      <th>fatality_count</th>
    </tr>
    <tr>
      <th>landslide_category</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>complex</th>
      <td>5.833333</td>
      <td>15.433071</td>
    </tr>
    <tr>
      <th>creep</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>debris_flow</th>
      <td>1.042254</td>
      <td>0.894737</td>
    </tr>
    <tr>
      <th>earth_flow</th>
      <td>0.000000</td>
      <td>2.500000</td>
    </tr>
    <tr>
      <th>lahar</th>
      <td>NaN</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>landslide</th>
      <td>1.168403</td>
      <td>2.956533</td>
    </tr>
    <tr>
      <th>mudslide</th>
      <td>0.622517</td>
      <td>3.180979</td>
    </tr>
    <tr>
      <th>other</th>
      <td>0.885714</td>
      <td>1.307692</td>
    </tr>
    <tr>
      <th>riverbank_collapse</th>
      <td>0.272727</td>
      <td>0.304348</td>
    </tr>
    <tr>
      <th>rock_fall</th>
      <td>0.831579</td>
      <td>0.686391</td>
    </tr>
    <tr>
      <th>snow_avalanche</th>
      <td>1.333333</td>
      <td>6.625000</td>
    </tr>
    <tr>
      <th>translational_slide</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>unknown</th>
      <td>0.187500</td>
      <td>0.235294</td>
    </tr>
  </tbody>
</table>
<p>13 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> inj_fatal, __output__ </p>
    
          <p>inj_fatal (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>injury_count</th>
      <th>fatality_count</th>
    </tr>
    <tr>
      <th>landslide_category</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>complex</th>
      <td>5.833333</td>
      <td>15.433071</td>
    </tr>
    <tr>
      <th>creep</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>debris_flow</th>
      <td>1.042254</td>
      <td>0.894737</td>
    </tr>
    <tr>
      <th>earth_flow</th>
      <td>0.000000</td>
      <td>2.500000</td>
    </tr>
    <tr>
      <th>lahar</th>
      <td>NaN</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>landslide</th>
      <td>1.168403</td>
      <td>2.956533</td>
    </tr>
    <tr>
      <th>mudslide</th>
      <td>0.622517</td>
      <td>3.180979</td>
    </tr>
    <tr>
      <th>other</th>
      <td>0.885714</td>
      <td>1.307692</td>
    </tr>
    <tr>
      <th>riverbank_collapse</th>
      <td>0.272727</td>
      <td>0.304348</td>
    </tr>
    <tr>
      <th>rock_fall</th>
      <td>0.831579</td>
      <td>0.686391</td>
    </tr>
    <tr>
      <th>snow_avalanche</th>
      <td>1.333333</td>
      <td>6.625000</td>
    </tr>
    <tr>
      <th>translational_slide</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>unknown</th>
      <td>0.187500</td>
      <td>0.235294</td>
    </tr>
  </tbody>
</table>
<p>13 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>injury_count</th>
      <th>fatality_count</th>
    </tr>
    <tr>
      <th>landslide_category</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>complex</th>
      <td>5.833333</td>
      <td>15.433071</td>
    </tr>
    <tr>
      <th>creep</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>debris_flow</th>
      <td>1.042254</td>
      <td>0.894737</td>
    </tr>
    <tr>
      <th>earth_flow</th>
      <td>0.000000</td>
      <td>2.500000</td>
    </tr>
    <tr>
      <th>lahar</th>
      <td>NaN</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>landslide</th>
      <td>1.168403</td>
      <td>2.956533</td>
    </tr>
    <tr>
      <th>mudslide</th>
      <td>0.622517</td>
      <td>3.180979</td>
    </tr>
    <tr>
      <th>other</th>
      <td>0.885714</td>
      <td>1.307692</td>
    </tr>
    <tr>
      <th>riverbank_collapse</th>
      <td>0.272727</td>
      <td>0.304348</td>
    </tr>
    <tr>
      <th>rock_fall</th>
      <td>0.831579</td>
      <td>0.686391</td>
    </tr>
    <tr>
      <th>snow_avalanche</th>
      <td>1.333333</td>
      <td>6.625000</td>
    </tr>
    <tr>
      <th>translational_slide</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>unknown</th>
      <td>0.187500</td>
      <td>0.235294</td>
    </tr>
  </tbody>
</table>
<p>13 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> global-landslide-catalog/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which countries were at all impacted by those categories having an average fatality count of five or more? Show the country names and number of events as percentage of the total.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>glc[glc.landslide_category.isin(inj_fatal[inj_fatal.fatality_count>=5].index)].country_name.value_counts(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>glc[glc.landslide_category.isin(inj_fatal[inj_fatal.fatality_count>=5].index)].country_name.value_counts(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = glc[glc.landslide_category.isin(inj_fatal[inj_fatal.
    fatality_count >= 5].index)].country_name.value_counts(1)
</code></pre>
        <p><span onclick="$('#var_output_af40269c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_af40269c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>United States      0.271967
Philippines        0.083682
China              0.062762
India              0.058577
Indonesia          0.037657
                     ...   
Fiji               0.004184
Puerto Rico        0.004184
Iran               0.004184
El Salvador        0.004184
Myanmar [Burma]    0.004184
Name: country_name, Length: 53, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>United States      0.271967
Philippines        0.083682
China              0.062762
India              0.058577
Indonesia          0.037657
                     ...   
Fiji               0.004184
Puerto Rico        0.004184
Iran               0.004184
El Salvador        0.004184
Myanmar [Burma]    0.004184
Name: country_name, Length: 53, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> global-landslide-catalog/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which trigger caused the highest total number of fatalities in each country? Show the countries as index and trigger and total fatalities as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>glc.groupby(['landslide_trigger','country_name']).fatality_count.sum().unstack().agg(['idxmax','max']).T.rename(columns={'idxmax':'trigger','max':'total_fatalities'})</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>glc.groupby(['landslide_trigger','country_name']).fatality_count.sum().unstack().agg(['idxmax','max']).T.rename(columns={'idxmax':'trigger','max':'total_fatalities'})</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = glc.groupby(['landslide_trigger', 'country_name']
    ).fatality_count.sum().unstack().agg(['idxmax', 'max']).T.rename(columns
    ={'idxmax': 'trigger', 'max': 'total_fatalities'})
</code></pre>
        <p><span onclick="$('#var_output_aa8b78a2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_aa8b78a2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>trigger</th>
      <th>total_fatalities</th>
    </tr>
    <tr>
      <th>country_name</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Afghanistan</th>
      <td>continuous_rain</td>
      <td>2100.0</td>
    </tr>
    <tr>
      <th>Albania</th>
      <td>downpour</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Algeria</th>
      <td>downpour</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>American Samoa</th>
      <td>downpour</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Angola</th>
      <td>downpour</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Argentina</th>
      <td>downpour</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>Armenia</th>
      <td>downpour</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>United States</th>
      <td>downpour</td>
      <td>49.0</td>
    </tr>
    <tr>
      <th>Uzbekistan</th>
      <td>unknown</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>Vanuatu</th>
      <td>tropical_cyclone</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Venezuela</th>
      <td>downpour</td>
      <td>28.0</td>
    </tr>
    <tr>
      <th>Vietnam</th>
      <td>downpour</td>
      <td>156.0</td>
    </tr>
    <tr>
      <th>Yemen</th>
      <td>downpour</td>
      <td>65.0</td>
    </tr>
    <tr>
      <th>Zambia</th>
      <td>downpour</td>
      <td>9.0</td>
    </tr>
  </tbody>
</table>
<p>141 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>trigger</th>
      <th>total_fatalities</th>
    </tr>
    <tr>
      <th>country_name</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Afghanistan</th>
      <td>continuous_rain</td>
      <td>2100.0</td>
    </tr>
    <tr>
      <th>Albania</th>
      <td>downpour</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Algeria</th>
      <td>downpour</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>American Samoa</th>
      <td>downpour</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Angola</th>
      <td>downpour</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Argentina</th>
      <td>downpour</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>Armenia</th>
      <td>downpour</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>United States</th>
      <td>downpour</td>
      <td>49.0</td>
    </tr>
    <tr>
      <th>Uzbekistan</th>
      <td>unknown</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>Vanuatu</th>
      <td>tropical_cyclone</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Venezuela</th>
      <td>downpour</td>
      <td>28.0</td>
    </tr>
    <tr>
      <th>Vietnam</th>
      <td>downpour</td>
      <td>156.0</td>
    </tr>
    <tr>
      <th>Yemen</th>
      <td>downpour</td>
      <td>65.0</td>
    </tr>
    <tr>
      <th>Zambia</th>
      <td>downpour</td>
      <td>9.0</td>
    </tr>
  </tbody>
</table>
<p>141 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rise-research-innovate-solve-excel/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Merge the relationship dataset with content and user.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>data = relation.merge(content, on='content_id').merge(user, on='user_id')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>data = relation.merge(content, on='content_id').merge(user, on='user_id')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = data = relation.merge(content, on='content_id').merge(user, on
    ='user_id')
</code></pre>
        <p><span onclick="$('#var_output_dc0ef8a9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_dc0ef8a9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>content_id</th>
      <th>duration_x</th>
      <th>date</th>
      <th>start_time</th>
      <th>end_time</th>
      <th>content_type</th>
      <th>...</th>
      <th>rating</th>
      <th>episode_count</th>
      <th>season_count</th>
      <th>user_age</th>
      <th>gender</th>
      <th>location</th>
      <th>joining_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>user_44902@domain.com</td>
      <td>cont_1718_16_7</td>
      <td>1920000</td>
      <td>2020-06-17</td>
      <td>06:19:13</td>
      <td>06:51:13</td>
      <td>series</td>
      <td>...</td>
      <td>6</td>
      <td>7</td>
      <td>16</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>1</th>
      <td>user_44902@domain.com</td>
      <td>cont_1718_13_18</td>
      <td>900000</td>
      <td>2021-06-02</td>
      <td>14:54:10</td>
      <td>15:09:10</td>
      <td>series</td>
      <td>...</td>
      <td>6</td>
      <td>18</td>
      <td>13</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>2</th>
      <td>user_44902@domain.com</td>
      <td>cont_3470_8_11</td>
      <td>2220000</td>
      <td>2021-04-18</td>
      <td>00:10:54</td>
      <td>00:47:54</td>
      <td>series</td>
      <td>...</td>
      <td>8</td>
      <td>11</td>
      <td>8</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>3</th>
      <td>user_44902@domain.com</td>
      <td>cont_1912_4_2</td>
      <td>2220000</td>
      <td>2021-03-15</td>
      <td>17:10:25</td>
      <td>17:47:25</td>
      <td>series</td>
      <td>...</td>
      <td>1</td>
      <td>2</td>
      <td>4</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>4</th>
      <td>user_44902@domain.com</td>
      <td>cont_2_7_50</td>
      <td>1260000</td>
      <td>2019-07-16</td>
      <td>21:38:19</td>
      <td>21:59:19</td>
      <td>series</td>
      <td>...</td>
      <td>8</td>
      <td>50</td>
      <td>7</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>5</th>
      <td>user_44902@domain.com</td>
      <td>cont_2069_2_52</td>
      <td>2400000</td>
      <td>2021-02-28</td>
      <td>23:59:29</td>
      <td>00:39:29</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>52</td>
      <td>2</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>6</th>
      <td>user_44902@domain.com</td>
      <td>cont_658_8_22</td>
      <td>1680000</td>
      <td>2020-03-04</td>
      <td>14:47:33</td>
      <td>15:15:33</td>
      <td>series</td>
      <td>...</td>
      <td>3</td>
      <td>22</td>
      <td>8</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>user_98989@domain.com</td>
      <td>cont_4906_11_25</td>
      <td>3180000</td>
      <td>2020-10-07</td>
      <td>21:36:26</td>
      <td>22:29:26</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>25</td>
      <td>11</td>
      <td>18</td>
      <td>F</td>
      <td>West Bengal</td>
      <td>2020-08-25</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>user_65970@domain.com</td>
      <td>cont_2270_12_5</td>
      <td>960000</td>
      <td>2020-05-11</td>
      <td>04:32:57</td>
      <td>04:48:57</td>
      <td>series</td>
      <td>...</td>
      <td>4</td>
      <td>5</td>
      <td>12</td>
      <td>27</td>
      <td>M</td>
      <td>Madhya Pradesh</td>
      <td>2018-06-11</td>
    </tr>
    <tr>
      <th>100005</th>
      <td>user_39791@domain.com</td>
      <td>cont_2359_1_54</td>
      <td>1260000</td>
      <td>2021-07-12</td>
      <td>13:25:26</td>
      <td>13:46:26</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>54</td>
      <td>1</td>
      <td>23</td>
      <td>M</td>
      <td>Maharashtra</td>
      <td>2019-01-14</td>
    </tr>
    <tr>
      <th>100006</th>
      <td>user_89674@domain.com</td>
      <td>cont_4218_2_26</td>
      <td>660000</td>
      <td>2020-11-11</td>
      <td>05:47:54</td>
      <td>05:58:54</td>
      <td>series</td>
      <td>...</td>
      <td>6</td>
      <td>26</td>
      <td>2</td>
      <td>50</td>
      <td>M</td>
      <td>Madhya Pradesh</td>
      <td>2020-07-16</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>user_43420@domain.com</td>
      <td>cont_4468_2_27</td>
      <td>60000</td>
      <td>2020-10-29</td>
      <td>09:14:34</td>
      <td>09:15:34</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>27</td>
      <td>2</td>
      <td>44</td>
      <td>M</td>
      <td>Madhya Pradesh</td>
      <td>2020-09-10</td>
    </tr>
    <tr>
      <th>100008</th>
      <td>user_14425@domain.com</td>
      <td>cont_3399_6_2</td>
      <td>840000</td>
      <td>2021-02-20</td>
      <td>12:01:24</td>
      <td>12:15:24</td>
      <td>series</td>
      <td>...</td>
      <td>1</td>
      <td>2</td>
      <td>6</td>
      <td>23</td>
      <td>F</td>
      <td>Punjab</td>
      <td>2020-06-01</td>
    </tr>
    <tr>
      <th>100009</th>
      <td>user_72142@domain.com</td>
      <td>cont_2173_5_14</td>
      <td>960000</td>
      <td>2021-04-21</td>
      <td>06:09:30</td>
      <td>06:25:30</td>
      <td>series</td>
      <td>...</td>
      <td>9</td>
      <td>14</td>
      <td>5</td>
      <td>45</td>
      <td>F</td>
      <td>Haryana</td>
      <td>2020-07-19</td>
    </tr>
  </tbody>
</table>
<p>100010 rows × 18 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__, data </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>content_id</th>
      <th>duration_x</th>
      <th>date</th>
      <th>start_time</th>
      <th>end_time</th>
      <th>content_type</th>
      <th>...</th>
      <th>rating</th>
      <th>episode_count</th>
      <th>season_count</th>
      <th>user_age</th>
      <th>gender</th>
      <th>location</th>
      <th>joining_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>user_44902@domain.com</td>
      <td>cont_1718_16_7</td>
      <td>1920000</td>
      <td>2020-06-17</td>
      <td>06:19:13</td>
      <td>06:51:13</td>
      <td>series</td>
      <td>...</td>
      <td>6</td>
      <td>7</td>
      <td>16</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>1</th>
      <td>user_44902@domain.com</td>
      <td>cont_1718_13_18</td>
      <td>900000</td>
      <td>2021-06-02</td>
      <td>14:54:10</td>
      <td>15:09:10</td>
      <td>series</td>
      <td>...</td>
      <td>6</td>
      <td>18</td>
      <td>13</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>2</th>
      <td>user_44902@domain.com</td>
      <td>cont_3470_8_11</td>
      <td>2220000</td>
      <td>2021-04-18</td>
      <td>00:10:54</td>
      <td>00:47:54</td>
      <td>series</td>
      <td>...</td>
      <td>8</td>
      <td>11</td>
      <td>8</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>3</th>
      <td>user_44902@domain.com</td>
      <td>cont_1912_4_2</td>
      <td>2220000</td>
      <td>2021-03-15</td>
      <td>17:10:25</td>
      <td>17:47:25</td>
      <td>series</td>
      <td>...</td>
      <td>1</td>
      <td>2</td>
      <td>4</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>4</th>
      <td>user_44902@domain.com</td>
      <td>cont_2_7_50</td>
      <td>1260000</td>
      <td>2019-07-16</td>
      <td>21:38:19</td>
      <td>21:59:19</td>
      <td>series</td>
      <td>...</td>
      <td>8</td>
      <td>50</td>
      <td>7</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>5</th>
      <td>user_44902@domain.com</td>
      <td>cont_2069_2_52</td>
      <td>2400000</td>
      <td>2021-02-28</td>
      <td>23:59:29</td>
      <td>00:39:29</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>52</td>
      <td>2</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>6</th>
      <td>user_44902@domain.com</td>
      <td>cont_658_8_22</td>
      <td>1680000</td>
      <td>2020-03-04</td>
      <td>14:47:33</td>
      <td>15:15:33</td>
      <td>series</td>
      <td>...</td>
      <td>3</td>
      <td>22</td>
      <td>8</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>user_98989@domain.com</td>
      <td>cont_4906_11_25</td>
      <td>3180000</td>
      <td>2020-10-07</td>
      <td>21:36:26</td>
      <td>22:29:26</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>25</td>
      <td>11</td>
      <td>18</td>
      <td>F</td>
      <td>West Bengal</td>
      <td>2020-08-25</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>user_65970@domain.com</td>
      <td>cont_2270_12_5</td>
      <td>960000</td>
      <td>2020-05-11</td>
      <td>04:32:57</td>
      <td>04:48:57</td>
      <td>series</td>
      <td>...</td>
      <td>4</td>
      <td>5</td>
      <td>12</td>
      <td>27</td>
      <td>M</td>
      <td>Madhya Pradesh</td>
      <td>2018-06-11</td>
    </tr>
    <tr>
      <th>100005</th>
      <td>user_39791@domain.com</td>
      <td>cont_2359_1_54</td>
      <td>1260000</td>
      <td>2021-07-12</td>
      <td>13:25:26</td>
      <td>13:46:26</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>54</td>
      <td>1</td>
      <td>23</td>
      <td>M</td>
      <td>Maharashtra</td>
      <td>2019-01-14</td>
    </tr>
    <tr>
      <th>100006</th>
      <td>user_89674@domain.com</td>
      <td>cont_4218_2_26</td>
      <td>660000</td>
      <td>2020-11-11</td>
      <td>05:47:54</td>
      <td>05:58:54</td>
      <td>series</td>
      <td>...</td>
      <td>6</td>
      <td>26</td>
      <td>2</td>
      <td>50</td>
      <td>M</td>
      <td>Madhya Pradesh</td>
      <td>2020-07-16</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>user_43420@domain.com</td>
      <td>cont_4468_2_27</td>
      <td>60000</td>
      <td>2020-10-29</td>
      <td>09:14:34</td>
      <td>09:15:34</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>27</td>
      <td>2</td>
      <td>44</td>
      <td>M</td>
      <td>Madhya Pradesh</td>
      <td>2020-09-10</td>
    </tr>
    <tr>
      <th>100008</th>
      <td>user_14425@domain.com</td>
      <td>cont_3399_6_2</td>
      <td>840000</td>
      <td>2021-02-20</td>
      <td>12:01:24</td>
      <td>12:15:24</td>
      <td>series</td>
      <td>...</td>
      <td>1</td>
      <td>2</td>
      <td>6</td>
      <td>23</td>
      <td>F</td>
      <td>Punjab</td>
      <td>2020-06-01</td>
    </tr>
    <tr>
      <th>100009</th>
      <td>user_72142@domain.com</td>
      <td>cont_2173_5_14</td>
      <td>960000</td>
      <td>2021-04-21</td>
      <td>06:09:30</td>
      <td>06:25:30</td>
      <td>series</td>
      <td>...</td>
      <td>9</td>
      <td>14</td>
      <td>5</td>
      <td>45</td>
      <td>F</td>
      <td>Haryana</td>
      <td>2020-07-19</td>
    </tr>
  </tbody>
</table>
<p>100010 rows × 18 columns</p>
      
          <p>data (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>content_id</th>
      <th>duration_x</th>
      <th>date</th>
      <th>start_time</th>
      <th>end_time</th>
      <th>content_type</th>
      <th>...</th>
      <th>rating</th>
      <th>episode_count</th>
      <th>season_count</th>
      <th>user_age</th>
      <th>gender</th>
      <th>location</th>
      <th>joining_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>user_44902@domain.com</td>
      <td>cont_1718_16_7</td>
      <td>1920000</td>
      <td>2020-06-17</td>
      <td>06:19:13</td>
      <td>06:51:13</td>
      <td>series</td>
      <td>...</td>
      <td>6</td>
      <td>7</td>
      <td>16</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>1</th>
      <td>user_44902@domain.com</td>
      <td>cont_1718_13_18</td>
      <td>900000</td>
      <td>2021-06-02</td>
      <td>14:54:10</td>
      <td>15:09:10</td>
      <td>series</td>
      <td>...</td>
      <td>6</td>
      <td>18</td>
      <td>13</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>2</th>
      <td>user_44902@domain.com</td>
      <td>cont_3470_8_11</td>
      <td>2220000</td>
      <td>2021-04-18</td>
      <td>00:10:54</td>
      <td>00:47:54</td>
      <td>series</td>
      <td>...</td>
      <td>8</td>
      <td>11</td>
      <td>8</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>3</th>
      <td>user_44902@domain.com</td>
      <td>cont_1912_4_2</td>
      <td>2220000</td>
      <td>2021-03-15</td>
      <td>17:10:25</td>
      <td>17:47:25</td>
      <td>series</td>
      <td>...</td>
      <td>1</td>
      <td>2</td>
      <td>4</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>4</th>
      <td>user_44902@domain.com</td>
      <td>cont_2_7_50</td>
      <td>1260000</td>
      <td>2019-07-16</td>
      <td>21:38:19</td>
      <td>21:59:19</td>
      <td>series</td>
      <td>...</td>
      <td>8</td>
      <td>50</td>
      <td>7</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>5</th>
      <td>user_44902@domain.com</td>
      <td>cont_2069_2_52</td>
      <td>2400000</td>
      <td>2021-02-28</td>
      <td>23:59:29</td>
      <td>00:39:29</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>52</td>
      <td>2</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>6</th>
      <td>user_44902@domain.com</td>
      <td>cont_658_8_22</td>
      <td>1680000</td>
      <td>2020-03-04</td>
      <td>14:47:33</td>
      <td>15:15:33</td>
      <td>series</td>
      <td>...</td>
      <td>3</td>
      <td>22</td>
      <td>8</td>
      <td>59</td>
      <td>F</td>
      <td>Tripura</td>
      <td>2018-11-21</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>user_98989@domain.com</td>
      <td>cont_4906_11_25</td>
      <td>3180000</td>
      <td>2020-10-07</td>
      <td>21:36:26</td>
      <td>22:29:26</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>25</td>
      <td>11</td>
      <td>18</td>
      <td>F</td>
      <td>West Bengal</td>
      <td>2020-08-25</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>user_65970@domain.com</td>
      <td>cont_2270_12_5</td>
      <td>960000</td>
      <td>2020-05-11</td>
      <td>04:32:57</td>
      <td>04:48:57</td>
      <td>series</td>
      <td>...</td>
      <td>4</td>
      <td>5</td>
      <td>12</td>
      <td>27</td>
      <td>M</td>
      <td>Madhya Pradesh</td>
      <td>2018-06-11</td>
    </tr>
    <tr>
      <th>100005</th>
      <td>user_39791@domain.com</td>
      <td>cont_2359_1_54</td>
      <td>1260000</td>
      <td>2021-07-12</td>
      <td>13:25:26</td>
      <td>13:46:26</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>54</td>
      <td>1</td>
      <td>23</td>
      <td>M</td>
      <td>Maharashtra</td>
      <td>2019-01-14</td>
    </tr>
    <tr>
      <th>100006</th>
      <td>user_89674@domain.com</td>
      <td>cont_4218_2_26</td>
      <td>660000</td>
      <td>2020-11-11</td>
      <td>05:47:54</td>
      <td>05:58:54</td>
      <td>series</td>
      <td>...</td>
      <td>6</td>
      <td>26</td>
      <td>2</td>
      <td>50</td>
      <td>M</td>
      <td>Madhya Pradesh</td>
      <td>2020-07-16</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>user_43420@domain.com</td>
      <td>cont_4468_2_27</td>
      <td>60000</td>
      <td>2020-10-29</td>
      <td>09:14:34</td>
      <td>09:15:34</td>
      <td>series</td>
      <td>...</td>
      <td>2</td>
      <td>27</td>
      <td>2</td>
      <td>44</td>
      <td>M</td>
      <td>Madhya Pradesh</td>
      <td>2020-09-10</td>
    </tr>
    <tr>
      <th>100008</th>
      <td>user_14425@domain.com</td>
      <td>cont_3399_6_2</td>
      <td>840000</td>
      <td>2021-02-20</td>
      <td>12:01:24</td>
      <td>12:15:24</td>
      <td>series</td>
      <td>...</td>
      <td>1</td>
      <td>2</td>
      <td>6</td>
      <td>23</td>
      <td>F</td>
      <td>Punjab</td>
      <td>2020-06-01</td>
    </tr>
    <tr>
      <th>100009</th>
      <td>user_72142@domain.com</td>
      <td>cont_2173_5_14</td>
      <td>960000</td>
      <td>2021-04-21</td>
      <td>06:09:30</td>
      <td>06:25:30</td>
      <td>series</td>
      <td>...</td>
      <td>9</td>
      <td>14</td>
      <td>5</td>
      <td>45</td>
      <td>F</td>
      <td>Haryana</td>
      <td>2020-07-19</td>
    </tr>
  </tbody>
</table>
<p>100010 rows × 18 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rise-research-innovate-solve-excel/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common genre within each location? Show the location as an index and the genre and number of users as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>data.groupby(['genre','location']).user_id.nunique().unstack().agg(['idxmax','max']).T.rename(columns={'idxmax':'genre','max':'users'})</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>data.groupby(['genre','location']).user_id.nunique().unstack().agg(['idxmax','max']).T.rename(columns={'idxmax':'genre','max':'users'})</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = data.groupby(['genre', 'location']).user_id.nunique().unstack(
    ).agg(['idxmax', 'max']).T.rename(columns={'idxmax': 'genre', 'max':
    'users'})
</code></pre>
        <p><span onclick="$('#var_output_c57d292d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c57d292d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>genre</th>
      <th>users</th>
    </tr>
    <tr>
      <th>location</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Andhra Pradesh</th>
      <td>drama</td>
      <td>400.0</td>
    </tr>
    <tr>
      <th>Arunachal Pradesh</th>
      <td>drama</td>
      <td>80.0</td>
    </tr>
    <tr>
      <th>Assam</th>
      <td>drama</td>
      <td>58.0</td>
    </tr>
    <tr>
      <th>Bihar</th>
      <td>drama</td>
      <td>147.0</td>
    </tr>
    <tr>
      <th>Chhattisgarh</th>
      <td>drama</td>
      <td>42.0</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>drama</td>
      <td>755.0</td>
    </tr>
    <tr>
      <th>Goa</th>
      <td>drama</td>
      <td>119.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Sikkim</th>
      <td>drama</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>Tamil Nadu</th>
      <td>drama</td>
      <td>486.0</td>
    </tr>
    <tr>
      <th>Telangana</th>
      <td>drama</td>
      <td>621.0</td>
    </tr>
    <tr>
      <th>Tripura</th>
      <td>drama</td>
      <td>59.0</td>
    </tr>
    <tr>
      <th>Uttar Pradesh</th>
      <td>drama</td>
      <td>397.0</td>
    </tr>
    <tr>
      <th>Uttarakhand</th>
      <td>drama</td>
      <td>38.0</td>
    </tr>
    <tr>
      <th>West Bengal</th>
      <td>drama</td>
      <td>840.0</td>
    </tr>
  </tbody>
</table>
<p>29 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>genre</th>
      <th>users</th>
    </tr>
    <tr>
      <th>location</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Andhra Pradesh</th>
      <td>drama</td>
      <td>400.0</td>
    </tr>
    <tr>
      <th>Arunachal Pradesh</th>
      <td>drama</td>
      <td>80.0</td>
    </tr>
    <tr>
      <th>Assam</th>
      <td>drama</td>
      <td>58.0</td>
    </tr>
    <tr>
      <th>Bihar</th>
      <td>drama</td>
      <td>147.0</td>
    </tr>
    <tr>
      <th>Chhattisgarh</th>
      <td>drama</td>
      <td>42.0</td>
    </tr>
    <tr>
      <th>Delhi</th>
      <td>drama</td>
      <td>755.0</td>
    </tr>
    <tr>
      <th>Goa</th>
      <td>drama</td>
      <td>119.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Sikkim</th>
      <td>drama</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>Tamil Nadu</th>
      <td>drama</td>
      <td>486.0</td>
    </tr>
    <tr>
      <th>Telangana</th>
      <td>drama</td>
      <td>621.0</td>
    </tr>
    <tr>
      <th>Tripura</th>
      <td>drama</td>
      <td>59.0</td>
    </tr>
    <tr>
      <th>Uttar Pradesh</th>
      <td>drama</td>
      <td>397.0</td>
    </tr>
    <tr>
      <th>Uttarakhand</th>
      <td>drama</td>
      <td>38.0</td>
    </tr>
    <tr>
      <th>West Bengal</th>
      <td>drama</td>
      <td>840.0</td>
    </tr>
  </tbody>
</table>
<p>29 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rise-research-innovate-solve-excel/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent change in the number of different series and movies released each year? Show the year as an index and movies and series as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = data[data.content_type.isin(['series','movies'])].groupby([pd.Grouper(key='release_date',freq='Y'),
                                                           'content_type']).content_id.nunique().unstack().pct_change()
df.index = df.index.year
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = data[data.content_type.isin(['series','movies'])].groupby([pd.Grouper(key='release_date',freq='Y'),
                                                           'content_type']).content_id.nunique().unstack().pct_change()
df.index = df.index.year
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = data[data.content_type.isin(['series', 'movies'])].groupby([pd.Grouper
    (key='release_date', freq='Y'), 'content_type']).content_id.nunique(
    ).unstack().pct_change()
df.index = df.index.year
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_819a5282').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_819a5282" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>content_type</th>
      <th>movies</th>
      <th>series</th>
    </tr>
    <tr>
      <th>release_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1990</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1991</th>
      <td>3.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1992</th>
      <td>-0.250000</td>
      <td>1.075758</td>
    </tr>
    <tr>
      <th>1993</th>
      <td>-0.666667</td>
      <td>0.492701</td>
    </tr>
    <tr>
      <th>1994</th>
      <td>2.000000</td>
      <td>0.259169</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>0.333333</td>
      <td>0.213592</td>
    </tr>
    <tr>
      <th>1996</th>
      <td>0.000000</td>
      <td>0.208000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>0.000000</td>
      <td>-0.011088</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.333333</td>
      <td>0.088297</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0.250000</td>
      <td>-0.032196</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0.000000</td>
      <td>0.037924</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0.200000</td>
      <td>-0.005769</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>-0.333333</td>
      <td>0.035461</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>-0.250000</td>
      <td>0.052304</td>
    </tr>
  </tbody>
</table>
<p>31 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>content_type</th>
      <th>movies</th>
      <th>series</th>
    </tr>
    <tr>
      <th>release_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1990</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1991</th>
      <td>3.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1992</th>
      <td>-0.250000</td>
      <td>1.075758</td>
    </tr>
    <tr>
      <th>1993</th>
      <td>-0.666667</td>
      <td>0.492701</td>
    </tr>
    <tr>
      <th>1994</th>
      <td>2.000000</td>
      <td>0.259169</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>0.333333</td>
      <td>0.213592</td>
    </tr>
    <tr>
      <th>1996</th>
      <td>0.000000</td>
      <td>0.208000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>0.000000</td>
      <td>-0.011088</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.333333</td>
      <td>0.088297</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0.250000</td>
      <td>-0.032196</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0.000000</td>
      <td>0.037924</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0.200000</td>
      <td>-0.005769</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>-0.333333</td>
      <td>0.035461</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>-0.250000</td>
      <td>0.052304</td>
    </tr>
  </tbody>
</table>
<p>31 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>content_type</th>
      <th>movies</th>
      <th>series</th>
    </tr>
    <tr>
      <th>release_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1990</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1991</th>
      <td>3.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1992</th>
      <td>-0.250000</td>
      <td>1.075758</td>
    </tr>
    <tr>
      <th>1993</th>
      <td>-0.666667</td>
      <td>0.492701</td>
    </tr>
    <tr>
      <th>1994</th>
      <td>2.000000</td>
      <td>0.259169</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>0.333333</td>
      <td>0.213592</td>
    </tr>
    <tr>
      <th>1996</th>
      <td>0.000000</td>
      <td>0.208000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>0.000000</td>
      <td>-0.011088</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.333333</td>
      <td>0.088297</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0.250000</td>
      <td>-0.032196</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0.000000</td>
      <td>0.037924</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0.200000</td>
      <td>-0.005769</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>-0.333333</td>
      <td>0.035461</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>-0.250000</td>
      <td>0.052304</td>
    </tr>
  </tbody>
</table>
<p>31 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rise-research-innovate-solve-excel/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average rating for series having an episode count of more than or equal to ten compared to less than that?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = data[data.content_type=='series'].groupby([data.episode_count>=10]).rating.mean()
df.rename(index={True:'>=10', False:'<10'}, inplace=True)
df</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = data[data.content_type=='series'].groupby([data.episode_count>=10]).rating.mean()
df.rename(index={True:'>=10', False:'<10'}, inplace=True)
df</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = data[data.content_type == 'series'].groupby([data.episode_count >= 10]
    ).rating.mean()
__tmp_1 = df.rename(index={(True): '>=10', (False): '<10'}, inplace=True)
__output__ = df
</code></pre>
        <p><span onclick="$('#var_output_330e2e5b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_330e2e5b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>episode_count
<10     5.543972
>=10    5.308733
Name: rating, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (Series):</p>
          <pre><code>episode_count
<10     5.543972
>=10    5.308733
Name: rating, dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>episode_count
<10     5.543972
>=10    5.308733
Name: rating, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rise-research-innovate-solve-excel/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most watched show that starts every hour? Show the hour as an index and content id and user counts as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>data.groupby(['content_id', pd.Grouper(key='start_time', freq='H')]).user_id.nunique().unstack().agg(['idxmax','max']).T.rename(columns={'idxmax':'content_id','max':'user_count'})</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>data.groupby(['content_id', pd.Grouper(key='start_time', freq='H')]).user_id.nunique().unstack().agg(['idxmax','max']).T.rename(columns={'idxmax':'content_id','max':'user_count'})</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = data.groupby(['content_id', pd.Grouper(key='start_time', freq=
    'H')]).user_id.nunique().unstack().agg(['idxmax', 'max']).T.rename(columns
    ={'idxmax': 'content_id', 'max': 'user_count'})
</code></pre>
        <p><span onclick="$('#var_output_8b47cd93').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8b47cd93" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>content_id</th>
      <th>user_count</th>
    </tr>
    <tr>
      <th>start_time</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2022-12-10 00:00:00</th>
      <td>cont_149_4_36</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2022-12-10 01:00:00</th>
      <td>cont_3512_6_16</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 02:00:00</th>
      <td>cont_149_4_36</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2022-12-10 03:00:00</th>
      <td>cont_1032_1_11</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2022-12-10 04:00:00</th>
      <td>cont_2479_2_17</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 05:00:00</th>
      <td>cont_693_5_14</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 06:00:00</th>
      <td>cont_1327_11_8</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2022-12-10 17:00:00</th>
      <td>cont_1158_27_6</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2022-12-10 18:00:00</th>
      <td>cont_3005_2_4</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>2022-12-10 19:00:00</th>
      <td>cont_2196_2_54</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 20:00:00</th>
      <td>cont_1602_1_19</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2022-12-10 21:00:00</th>
      <td>cont_1327_5_20</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 22:00:00</th>
      <td>cont_1158_19_6</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 23:00:00</th>
      <td>cont_3454_27_8</td>
      <td>4.0</td>
    </tr>
  </tbody>
</table>
<p>24 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>content_id</th>
      <th>user_count</th>
    </tr>
    <tr>
      <th>start_time</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2022-12-10 00:00:00</th>
      <td>cont_149_4_36</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2022-12-10 01:00:00</th>
      <td>cont_3512_6_16</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 02:00:00</th>
      <td>cont_149_4_36</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2022-12-10 03:00:00</th>
      <td>cont_1032_1_11</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2022-12-10 04:00:00</th>
      <td>cont_2479_2_17</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 05:00:00</th>
      <td>cont_693_5_14</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 06:00:00</th>
      <td>cont_1327_11_8</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2022-12-10 17:00:00</th>
      <td>cont_1158_27_6</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2022-12-10 18:00:00</th>
      <td>cont_3005_2_4</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>2022-12-10 19:00:00</th>
      <td>cont_2196_2_54</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 20:00:00</th>
      <td>cont_1602_1_19</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2022-12-10 21:00:00</th>
      <td>cont_1327_5_20</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 22:00:00</th>
      <td>cont_1158_19_6</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2022-12-10 23:00:00</th>
      <td>cont_3454_27_8</td>
      <td>4.0</td>
    </tr>
  </tbody>
</table>
<p>24 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rise-research-innovate-solve-excel/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the number of shows viewed in distinct languages within each genre as a percentage of the total number of shows within each genre? Show the genres as an index and languages as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>data.groupby(['genre','language']).content_id.nunique().unstack(fill_value=0).apply(lambda x: x/x.sum())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>data.groupby(['genre','language']).content_id.nunique().unstack(fill_value=0).apply(lambda x: x/x.sum())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = data.groupby(['genre', 'language']).content_id.nunique().unstack(
    fill_value=0).apply(lambda x: x / x.sum())
</code></pre>
        <p><span onclick="$('#var_output_7b7738e7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7b7738e7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>language</th>
      <th>bengali</th>
      <th>english</th>
      <th>gujarati</th>
      <th>hindi</th>
      <th>kannada</th>
      <th>malayalam</th>
      <th>marathi</th>
      <th>oriya</th>
      <th>punjabi</th>
      <th>tamil</th>
      <th>telugu</th>
    </tr>
    <tr>
      <th>genre</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>action</th>
      <td>0.136253</td>
      <td>0.147438</td>
      <td>0.021118</td>
      <td>0.141112</td>
      <td>0.361528</td>
      <td>0.024527</td>
      <td>0.203135</td>
      <td>0.343558</td>
      <td>0.079327</td>
      <td>0.216730</td>
      <td>0.073258</td>
    </tr>
    <tr>
      <th>adventure</th>
      <td>0.000000</td>
      <td>0.000362</td>
      <td>0.000000</td>
      <td>0.000233</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.003067</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000512</td>
    </tr>
    <tr>
      <th>animation</th>
      <td>0.000000</td>
      <td>0.000241</td>
      <td>0.001242</td>
      <td>0.000058</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000543</td>
      <td>0.000512</td>
    </tr>
    <tr>
      <th>badminton</th>
      <td>0.000000</td>
      <td>0.006751</td>
      <td>0.000000</td>
      <td>0.003025</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>basketball</th>
      <td>0.000000</td>
      <td>0.016757</td>
      <td>0.000000</td>
      <td>0.006922</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>biography</th>
      <td>0.000000</td>
      <td>0.000362</td>
      <td>0.000000</td>
      <td>0.000291</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000543</td>
      <td>0.000256</td>
    </tr>
    <tr>
      <th>comedy</th>
      <td>0.284672</td>
      <td>0.196986</td>
      <td>0.258385</td>
      <td>0.190205</td>
      <td>0.264666</td>
      <td>0.342677</td>
      <td>0.210973</td>
      <td>0.156442</td>
      <td>0.504808</td>
      <td>0.052689</td>
      <td>0.192879</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>horror</th>
      <td>0.138686</td>
      <td>0.036890</td>
      <td>0.059627</td>
      <td>0.047406</td>
      <td>0.077763</td>
      <td>0.035039</td>
      <td>0.039843</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.011407</td>
      <td>0.059682</td>
    </tr>
    <tr>
      <th>musical</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000291</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>mystery</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.001242</td>
      <td>0.000116</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000653</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000256</td>
    </tr>
    <tr>
      <th>sci-fi</th>
      <td>0.000000</td>
      <td>0.031947</td>
      <td>0.084472</td>
      <td>0.029374</td>
      <td>0.000000</td>
      <td>0.033637</td>
      <td>0.031352</td>
      <td>0.131902</td>
      <td>0.000000</td>
      <td>0.016295</td>
      <td>0.063781</td>
    </tr>
    <tr>
      <th>sport</th>
      <td>0.000000</td>
      <td>0.000121</td>
      <td>0.000000</td>
      <td>0.000116</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000512</td>
    </tr>
    <tr>
      <th>tennis</th>
      <td>0.000000</td>
      <td>0.005546</td>
      <td>0.000000</td>
      <td>0.002443</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>thriller</th>
      <td>0.000000</td>
      <td>0.000241</td>
      <td>0.001242</td>
      <td>0.000349</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000653</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000512</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 11 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>language</th>
      <th>bengali</th>
      <th>english</th>
      <th>gujarati</th>
      <th>hindi</th>
      <th>kannada</th>
      <th>malayalam</th>
      <th>marathi</th>
      <th>oriya</th>
      <th>punjabi</th>
      <th>tamil</th>
      <th>telugu</th>
    </tr>
    <tr>
      <th>genre</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>action</th>
      <td>0.136253</td>
      <td>0.147438</td>
      <td>0.021118</td>
      <td>0.141112</td>
      <td>0.361528</td>
      <td>0.024527</td>
      <td>0.203135</td>
      <td>0.343558</td>
      <td>0.079327</td>
      <td>0.216730</td>
      <td>0.073258</td>
    </tr>
    <tr>
      <th>adventure</th>
      <td>0.000000</td>
      <td>0.000362</td>
      <td>0.000000</td>
      <td>0.000233</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.003067</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000512</td>
    </tr>
    <tr>
      <th>animation</th>
      <td>0.000000</td>
      <td>0.000241</td>
      <td>0.001242</td>
      <td>0.000058</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000543</td>
      <td>0.000512</td>
    </tr>
    <tr>
      <th>badminton</th>
      <td>0.000000</td>
      <td>0.006751</td>
      <td>0.000000</td>
      <td>0.003025</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>basketball</th>
      <td>0.000000</td>
      <td>0.016757</td>
      <td>0.000000</td>
      <td>0.006922</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>biography</th>
      <td>0.000000</td>
      <td>0.000362</td>
      <td>0.000000</td>
      <td>0.000291</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000543</td>
      <td>0.000256</td>
    </tr>
    <tr>
      <th>comedy</th>
      <td>0.284672</td>
      <td>0.196986</td>
      <td>0.258385</td>
      <td>0.190205</td>
      <td>0.264666</td>
      <td>0.342677</td>
      <td>0.210973</td>
      <td>0.156442</td>
      <td>0.504808</td>
      <td>0.052689</td>
      <td>0.192879</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>horror</th>
      <td>0.138686</td>
      <td>0.036890</td>
      <td>0.059627</td>
      <td>0.047406</td>
      <td>0.077763</td>
      <td>0.035039</td>
      <td>0.039843</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.011407</td>
      <td>0.059682</td>
    </tr>
    <tr>
      <th>musical</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000291</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>mystery</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.001242</td>
      <td>0.000116</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000653</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000256</td>
    </tr>
    <tr>
      <th>sci-fi</th>
      <td>0.000000</td>
      <td>0.031947</td>
      <td>0.084472</td>
      <td>0.029374</td>
      <td>0.000000</td>
      <td>0.033637</td>
      <td>0.031352</td>
      <td>0.131902</td>
      <td>0.000000</td>
      <td>0.016295</td>
      <td>0.063781</td>
    </tr>
    <tr>
      <th>sport</th>
      <td>0.000000</td>
      <td>0.000121</td>
      <td>0.000000</td>
      <td>0.000116</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000512</td>
    </tr>
    <tr>
      <th>tennis</th>
      <td>0.000000</td>
      <td>0.005546</td>
      <td>0.000000</td>
      <td>0.002443</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>thriller</th>
      <td>0.000000</td>
      <td>0.000241</td>
      <td>0.001242</td>
      <td>0.000349</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000653</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000512</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 11 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> us-foreign-aid-country-foreign-assistance/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the 'fiscal_year' column to numeric data type.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>aid.fiscal_year = aid.fiscal_year.str.extract('(\d+)').astype(int)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>aid.fiscal_year = aid.fiscal_year.str.extract('(\d+)').astype(int)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = aid.fiscal_year = aid.fiscal_year.str.extract('(\\d+)').astype(int
    )
</code></pre>
        <p><span onclick="$('#var_output_bfb3a3b3').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bfb3a3b3" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1999</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2004</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2005</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2006</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2007</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2008</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>21966</th>
      <td>2016</td>
    </tr>
    <tr>
      <th>21967</th>
      <td>2017</td>
    </tr>
    <tr>
      <th>21968</th>
      <td>2018</td>
    </tr>
    <tr>
      <th>21969</th>
      <td>2019</td>
    </tr>
    <tr>
      <th>21970</th>
      <td>2020</td>
    </tr>
    <tr>
      <th>21971</th>
      <td>2021</td>
    </tr>
    <tr>
      <th>21972</th>
      <td>2022</td>
    </tr>
  </tbody>
</table>
<p>21973 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> aid, __output__ </p>
    
          <p>aid (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_code</th>
      <th>country_name</th>
      <th>region_id</th>
      <th>Region Name</th>
      <th>income_roup</th>
      <th>income_group_name</th>
      <th>transaction_type_id</th>
      <th>transaction_type_name</th>
      <th>fiscal_year</th>
      <th>current_amount</th>
      <th>constant_amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>2</td>
      <td>Obligations</td>
      <td>1999</td>
      <td>19000</td>
      <td>28303</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>2</td>
      <td>Obligations</td>
      <td>2000</td>
      <td>50000</td>
      <td>72982</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>2</td>
      <td>Obligations</td>
      <td>2004</td>
      <td>1000</td>
      <td>1346</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>2</td>
      <td>Obligations</td>
      <td>2005</td>
      <td>29270</td>
      <td>38231</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>2</td>
      <td>Obligations</td>
      <td>2006</td>
      <td>1000</td>
      <td>1266</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>2</td>
      <td>Obligations</td>
      <td>2007</td>
      <td>97937</td>
      <td>120671</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>2</td>
      <td>Obligations</td>
      <td>2008</td>
      <td>11138</td>
      <td>13446</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>21966</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2016</td>
      <td>222623373</td>
      <td>239354216</td>
    </tr>
    <tr>
      <th>21967</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2017</td>
      <td>226476888</td>
      <td>239252981</td>
    </tr>
    <tr>
      <th>21968</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2018</td>
      <td>227007897</td>
      <td>234391190</td>
    </tr>
    <tr>
      <th>21969</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2019</td>
      <td>292183847</td>
      <td>295852389</td>
    </tr>
    <tr>
      <th>21970</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2020</td>
      <td>277951083</td>
      <td>277951083</td>
    </tr>
    <tr>
      <th>21971</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2021</td>
      <td>261088574</td>
      <td>256724239</td>
    </tr>
    <tr>
      <th>21972</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2022</td>
      <td>110226960</td>
      <td>106427487</td>
    </tr>
  </tbody>
</table>
<p>21973 rows × 11 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1999</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2004</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2005</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2006</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2007</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2008</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>21966</th>
      <td>2016</td>
    </tr>
    <tr>
      <th>21967</th>
      <td>2017</td>
    </tr>
    <tr>
      <th>21968</th>
      <td>2018</td>
    </tr>
    <tr>
      <th>21969</th>
      <td>2019</td>
    </tr>
    <tr>
      <th>21970</th>
      <td>2020</td>
    </tr>
    <tr>
      <th>21971</th>
      <td>2021</td>
    </tr>
    <tr>
      <th>21972</th>
      <td>2022</td>
    </tr>
  </tbody>
</table>
<p>21973 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> us-foreign-aid-country-foreign-assistance/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the annual percent change in total constant dollar amounts received by high income countries?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>aid[aid.income_group_name == 'High Income Country'].groupby('fiscal_year').constant_amount.sum().pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>aid[aid.income_group_name == 'High Income Country'].groupby('fiscal_year').constant_amount.sum().pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = aid[aid.income_group_name == 'High Income Country'].groupby(
    'fiscal_year').constant_amount.sum().pct_change()
</code></pre>
        <p><span onclick="$('#var_output_d3656fdf').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d3656fdf" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>fiscal_year
1946         NaN
1947    2.047535
1948   -0.589065
1949    1.736712
1950   -0.286911
          ...   
2018   -0.019907
2019    0.058358
2020   -0.217992
2021   -0.765039
2022   -0.029452
Name: constant_amount, Length: 77, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>fiscal_year
1946         NaN
1947    2.047535
1948   -0.589065
1949    1.736712
1950   -0.286911
          ...   
2018   -0.019907
2019    0.058358
2020   -0.217992
2021   -0.765039
2022   -0.029452
Name: constant_amount, Length: 77, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> us-foreign-aid-country-foreign-assistance/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which country within each region has the highest average annual financial aid, in constant dollar amount? Show the region name as an index and countries and dollar amounts as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>max_countries = aid.groupby(['Region Name','country_name']).constant_amount.mean().unstack(0).agg(['max','idxmax']).T
max_countries.columns = ['constant_amount','country']
max_countries</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>max_countries = aid.groupby(['Region Name','country_name']).constant_amount.mean().unstack(0).agg(['max','idxmax']).T
max_countries.columns = ['constant_amount','country']
max_countries</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>max_countries = aid.groupby(['Region Name', 'country_name']
    ).constant_amount.mean().unstack(0).agg(['max', 'idxmax']).T
max_countries.columns = ['constant_amount', 'country']
__output__ = max_countries
</code></pre>
        <p><span onclick="$('#var_output_cc09e5d7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_cc09e5d7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>constant_amount</th>
      <th>country</th>
    </tr>
    <tr>
      <th>Region Name</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>East Asia and Oceania</th>
      <td>5435650815.041667</td>
      <td>Vietnam (former South)</td>
    </tr>
    <tr>
      <th>Europe and Eurasia</th>
      <td>1465428907.666667</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>Middle East and North Africa</th>
      <td>3346687351.029412</td>
      <td>Israel</td>
    </tr>
    <tr>
      <th>South and Central Asia</th>
      <td>2886543940.511278</td>
      <td>Afghanistan</td>
    </tr>
    <tr>
      <th>Sub-Saharan Africa</th>
      <td>467547462.733813</td>
      <td>Ethiopia</td>
    </tr>
    <tr>
      <th>Western Hemisphere</th>
      <td>429031400.176056</td>
      <td>Colombia</td>
    </tr>
    <tr>
      <th>World</th>
      <td>9499810003.831081</td>
      <td>World</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> max_countries, __output__ </p>
    
          <p>max_countries (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>constant_amount</th>
      <th>country</th>
    </tr>
    <tr>
      <th>Region Name</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>East Asia and Oceania</th>
      <td>5435650815.041667</td>
      <td>Vietnam (former South)</td>
    </tr>
    <tr>
      <th>Europe and Eurasia</th>
      <td>1465428907.666667</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>Middle East and North Africa</th>
      <td>3346687351.029412</td>
      <td>Israel</td>
    </tr>
    <tr>
      <th>South and Central Asia</th>
      <td>2886543940.511278</td>
      <td>Afghanistan</td>
    </tr>
    <tr>
      <th>Sub-Saharan Africa</th>
      <td>467547462.733813</td>
      <td>Ethiopia</td>
    </tr>
    <tr>
      <th>Western Hemisphere</th>
      <td>429031400.176056</td>
      <td>Colombia</td>
    </tr>
    <tr>
      <th>World</th>
      <td>9499810003.831081</td>
      <td>World</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>constant_amount</th>
      <th>country</th>
    </tr>
    <tr>
      <th>Region Name</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>East Asia and Oceania</th>
      <td>5435650815.041667</td>
      <td>Vietnam (former South)</td>
    </tr>
    <tr>
      <th>Europe and Eurasia</th>
      <td>1465428907.666667</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>Middle East and North Africa</th>
      <td>3346687351.029412</td>
      <td>Israel</td>
    </tr>
    <tr>
      <th>South and Central Asia</th>
      <td>2886543940.511278</td>
      <td>Afghanistan</td>
    </tr>
    <tr>
      <th>Sub-Saharan Africa</th>
      <td>467547462.733813</td>
      <td>Ethiopia</td>
    </tr>
    <tr>
      <th>Western Hemisphere</th>
      <td>429031400.176056</td>
      <td>Colombia</td>
    </tr>
    <tr>
      <th>World</th>
      <td>9499810003.831081</td>
      <td>World</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> us-foreign-aid-country-foreign-assistance/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which region received the highest total aid, in constant dollar value, for disbursement transactions? Return the region name and the constant dollar amount.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>reg_max = aid[aid.transaction_type_name == 'Disbursements'].groupby('Region Name').constant_amount.sum().agg(['max','idxmax'])
reg_max.index = ['constant_amount','region']
reg_max</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>reg_max = aid[aid.transaction_type_name == 'Disbursements'].groupby('Region Name').constant_amount.sum().agg(['max','idxmax'])
reg_max.index = ['constant_amount','region']
reg_max</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>reg_max = aid[aid.transaction_type_name == 'Disbursements'].groupby(
    'Region Name').constant_amount.sum().agg(['max', 'idxmax'])
reg_max.index = ['constant_amount', 'region']
__output__ = reg_max
</code></pre>
        <p><span onclick="$('#var_output_06a73ed6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_06a73ed6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>constant_amount                    253069458846
region             Middle East and North Africa
Name: constant_amount, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> reg_max, __output__ </p>
    
          <p>reg_max (Series):</p>
          <pre><code>constant_amount                    253069458846
region             Middle East and North Africa
Name: constant_amount, dtype: object</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>constant_amount                    253069458846
region             Middle East and North Africa
Name: constant_amount, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> us-foreign-aid-country-foreign-assistance/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top five countries within that region receiving the highest average annual constant dollar aid amount? Show the country names and aid amounts.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>aid[aid['Region Name']=='Middle East and North Africa'].groupby('country_name').constant_amount.mean().sort_values(ascending=False).head()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>aid[aid['Region Name']=='Middle East and North Africa'].groupby('country_name').constant_amount.mean().sort_values(ascending=False).head()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = aid[aid['Region Name'] == 'Middle East and North Africa'].groupby(
    'country_name').constant_amount.mean().sort_values(ascending=False).head()
</code></pre>
        <p><span onclick="$('#var_output_6b3c2b50').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6b3c2b50" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>country_name
Israel                3.346687e+09
Egypt                 1.900167e+09
Iraq                  1.609522e+09
Jordan                7.894820e+08
West Bank and Gaza    3.453313e+08
Name: constant_amount, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>country_name
Israel                3.346687e+09
Egypt                 1.900167e+09
Iraq                  1.609522e+09
Jordan                7.894820e+08
West Bank and Gaza    3.453313e+08
Name: constant_amount, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> us-foreign-aid-country-foreign-assistance/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the share of total constant dollar aid amounts for disbursements and initial allocations accross different regions as a percentage of the total?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>trans = aid[aid.transaction_type_name.str.contains('disbursements|initial allocations',case=False)]
trans.groupby('Region Name').constant_amount.sum() / trans.groupby('Region Name').constant_amount.sum().sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>trans = aid[aid.transaction_type_name.str.contains('disbursements|initial allocations',case=False)]
trans.groupby('Region Name').constant_amount.sum() / trans.groupby('Region Name').constant_amount.sum().sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>trans = aid[aid.transaction_type_name.str.contains(
    'disbursements|initial allocations', case=False)]
__output__ = trans.groupby('Region Name').constant_amount.sum(
    ) / trans.groupby('Region Name').constant_amount.sum().sum()
</code></pre>
        <p><span onclick="$('#var_output_104db5c5').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_104db5c5" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Region Name
East Asia and Oceania           0.027639
Europe and Eurasia              0.045385
Middle East and North Africa    0.246362
South and Central Asia          0.146351
Sub-Saharan Africa              0.197567
Western Hemisphere              0.055714
World                           0.280981
Name: constant_amount, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> trans, __output__ </p>
    
          <p>trans (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_code</th>
      <th>country_name</th>
      <th>region_id</th>
      <th>Region Name</th>
      <th>income_roup</th>
      <th>income_group_name</th>
      <th>transaction_type_id</th>
      <th>transaction_type_name</th>
      <th>fiscal_year</th>
      <th>current_amount</th>
      <th>constant_amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>11</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2004</td>
      <td>1000</td>
      <td>1346</td>
    </tr>
    <tr>
      <th>12</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2005</td>
      <td>29270</td>
      <td>38231</td>
    </tr>
    <tr>
      <th>13</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2006</td>
      <td>1000</td>
      <td>1266</td>
    </tr>
    <tr>
      <th>14</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2007</td>
      <td>61577</td>
      <td>75870</td>
    </tr>
    <tr>
      <th>15</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2008</td>
      <td>11138</td>
      <td>13445</td>
    </tr>
    <tr>
      <th>16</th>
      <td>ABW</td>
      <td>Aruba</td>
      <td>6</td>
      <td>Western Hemisphere</td>
      <td>HIC</td>
      <td>High Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2009</td>
      <td>5258</td>
      <td>6275</td>
    </tr>
    <tr>
      <th>101</th>
      <td>AFG</td>
      <td>Afghanistan</td>
      <td>4</td>
      <td>South and Central Asia</td>
      <td>LIC</td>
      <td>Low Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2001</td>
      <td>40790880</td>
      <td>58164664</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>21966</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2016</td>
      <td>222623373</td>
      <td>239354216</td>
    </tr>
    <tr>
      <th>21967</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2017</td>
      <td>226476888</td>
      <td>239252981</td>
    </tr>
    <tr>
      <th>21968</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2018</td>
      <td>227007897</td>
      <td>234391190</td>
    </tr>
    <tr>
      <th>21969</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2019</td>
      <td>292183847</td>
      <td>295852389</td>
    </tr>
    <tr>
      <th>21970</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2020</td>
      <td>277951083</td>
      <td>277951083</td>
    </tr>
    <tr>
      <th>21971</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2021</td>
      <td>261088574</td>
      <td>256724239</td>
    </tr>
    <tr>
      <th>21972</th>
      <td>ZWE</td>
      <td>Zimbabwe</td>
      <td>5</td>
      <td>Sub-Saharan Africa</td>
      <td>LMIC</td>
      <td>Lower Middle Income Country</td>
      <td>3</td>
      <td>Disbursements</td>
      <td>2022</td>
      <td>110226960</td>
      <td>106427487</td>
    </tr>
  </tbody>
</table>
<p>6416 rows × 11 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Region Name
East Asia and Oceania           0.027639
Europe and Eurasia              0.045385
Middle East and North Africa    0.246362
South and Central Asia          0.146351
Sub-Saharan Africa              0.197567
Western Hemisphere              0.055714
World                           0.280981
Name: constant_amount, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> us-foreign-aid-country-foreign-assistance/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the cumulative annual financial aid received by countries in the East Asia and Oceania region, in constant dollar value? Show years as an index and countries as columns. Replace nan with 0.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>aid.groupby('Region Name').get_group('East Asia and Oceania').groupby(['country_name','fiscal_year']).constant_amount.sum().cumsum().unstack(0).ffill().fillna(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>aid.groupby('Region Name').get_group('East Asia and Oceania').groupby(['country_name','fiscal_year']).constant_amount.sum().cumsum().unstack(0).ffill().fillna(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = aid.groupby('Region Name').get_group('East Asia and Oceania'
    ).groupby(['country_name', 'fiscal_year']).constant_amount.sum().cumsum(
    ).unstack(0).ffill().fillna(0)
</code></pre>
        <p><span onclick="$('#var_output_6f84a8e0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6f84a8e0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>country_name</th>
      <th>Australia</th>
      <th>Brunei</th>
      <th>Burma (Myanmar)</th>
      <th>Cambodia</th>
      <th>China (Hong Kong, S.A.R., P.R.C.)</th>
      <th>China (Macau, S.A.R., P.R.C.)</th>
      <th>China (P.R.C.)</th>
      <th>...</th>
      <th>Thailand</th>
      <th>Timor-Leste</th>
      <th>Tonga</th>
      <th>Tuvalu</th>
      <th>Vanuatu</th>
      <th>Vietnam</th>
      <th>Vietnam (former South)</th>
    </tr>
    <tr>
      <th>fiscal_year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1946</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.334400e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1947</th>
      <td>65815325.0</td>
      <td>0.0</td>
      <td>9.525125e+08</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.334400e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>65815325.0</td>
      <td>0.0</td>
      <td>9.525125e+08</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.334400e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1949</th>
      <td>77100047.0</td>
      <td>0.0</td>
      <td>9.525125e+08</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.334400e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1950</th>
      <td>77100047.0</td>
      <td>0.0</td>
      <td>9.695574e+08</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.335253e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1951</th>
      <td>77100047.0</td>
      <td>0.0</td>
      <td>1.066466e+09</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.339898e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1952</th>
      <td>77100047.0</td>
      <td>0.0</td>
      <td>1.064860e+09</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.343014e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>901204609.0</td>
      <td>903421865.0</td>
      <td>6.137290e+09</td>
      <td>2.624242e+10</td>
      <td>2.864187e+10</td>
      <td>2.864716e+10</td>
      <td>3.108478e+10</td>
      <td>...</td>
      <td>3.522877e+11</td>
      <td>3.547816e+11</td>
      <td>3.553583e+11</td>
      <td>3.553808e+11</td>
      <td>3.556428e+11</td>
      <td>3.623370e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>901288699.0</td>
      <td>903421865.0</td>
      <td>6.814770e+09</td>
      <td>2.673020e+10</td>
      <td>2.864368e+10</td>
      <td>2.864716e+10</td>
      <td>3.123569e+10</td>
      <td>...</td>
      <td>3.524689e+11</td>
      <td>3.548850e+11</td>
      <td>3.553628e+11</td>
      <td>3.553808e+11</td>
      <td>3.556497e+11</td>
      <td>3.631008e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>901288699.0</td>
      <td>903421865.0</td>
      <td>7.460076e+09</td>
      <td>2.719207e+10</td>
      <td>2.864498e+10</td>
      <td>2.864716e+10</td>
      <td>3.136014e+10</td>
      <td>...</td>
      <td>3.526037e+11</td>
      <td>3.549708e+11</td>
      <td>3.553664e+11</td>
      <td>3.553808e+11</td>
      <td>3.556562e+11</td>
      <td>3.638237e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>901344911.0</td>
      <td>903396593.0</td>
      <td>8.141495e+09</td>
      <td>2.754523e+10</td>
      <td>2.864642e+10</td>
      <td>2.864716e+10</td>
      <td>3.146094e+10</td>
      <td>...</td>
      <td>3.527650e+11</td>
      <td>3.550733e+11</td>
      <td>3.553722e+11</td>
      <td>3.553808e+11</td>
      <td>3.556617e+11</td>
      <td>3.645784e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>901484846.0</td>
      <td>903396593.0</td>
      <td>8.756353e+09</td>
      <td>2.791825e+10</td>
      <td>2.864653e+10</td>
      <td>2.864716e+10</td>
      <td>3.154203e+10</td>
      <td>...</td>
      <td>3.529666e+11</td>
      <td>3.551741e+11</td>
      <td>3.553773e+11</td>
      <td>3.553809e+11</td>
      <td>3.556660e+11</td>
      <td>3.653519e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>901484846.0</td>
      <td>903396593.0</td>
      <td>9.194078e+09</td>
      <td>2.816731e+10</td>
      <td>2.864655e+10</td>
      <td>2.864716e+10</td>
      <td>3.156676e+10</td>
      <td>...</td>
      <td>3.530409e+11</td>
      <td>3.552456e+11</td>
      <td>3.553792e+11</td>
      <td>3.553811e+11</td>
      <td>3.556702e+11</td>
      <td>3.657420e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>901484846.0</td>
      <td>903396593.0</td>
      <td>9.409706e+09</td>
      <td>2.832621e+10</td>
      <td>2.864655e+10</td>
      <td>2.864716e+10</td>
      <td>3.157098e+10</td>
      <td>...</td>
      <td>3.530807e+11</td>
      <td>3.552837e+11</td>
      <td>3.553800e+11</td>
      <td>3.553811e+11</td>
      <td>3.556710e+11</td>
      <td>3.659908e+11</td>
      <td>4.964464e+11</td>
    </tr>
  </tbody>
</table>
<p>77 rows × 42 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>country_name</th>
      <th>Australia</th>
      <th>Brunei</th>
      <th>Burma (Myanmar)</th>
      <th>Cambodia</th>
      <th>China (Hong Kong, S.A.R., P.R.C.)</th>
      <th>China (Macau, S.A.R., P.R.C.)</th>
      <th>China (P.R.C.)</th>
      <th>...</th>
      <th>Thailand</th>
      <th>Timor-Leste</th>
      <th>Tonga</th>
      <th>Tuvalu</th>
      <th>Vanuatu</th>
      <th>Vietnam</th>
      <th>Vietnam (former South)</th>
    </tr>
    <tr>
      <th>fiscal_year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1946</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.334400e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1947</th>
      <td>65815325.0</td>
      <td>0.0</td>
      <td>9.525125e+08</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.334400e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>65815325.0</td>
      <td>0.0</td>
      <td>9.525125e+08</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.334400e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1949</th>
      <td>77100047.0</td>
      <td>0.0</td>
      <td>9.525125e+08</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.334400e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1950</th>
      <td>77100047.0</td>
      <td>0.0</td>
      <td>9.695574e+08</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.335253e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1951</th>
      <td>77100047.0</td>
      <td>0.0</td>
      <td>1.066466e+09</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.339898e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>1952</th>
      <td>77100047.0</td>
      <td>0.0</td>
      <td>1.064860e+09</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>...</td>
      <td>3.343014e+11</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>901204609.0</td>
      <td>903421865.0</td>
      <td>6.137290e+09</td>
      <td>2.624242e+10</td>
      <td>2.864187e+10</td>
      <td>2.864716e+10</td>
      <td>3.108478e+10</td>
      <td>...</td>
      <td>3.522877e+11</td>
      <td>3.547816e+11</td>
      <td>3.553583e+11</td>
      <td>3.553808e+11</td>
      <td>3.556428e+11</td>
      <td>3.623370e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>901288699.0</td>
      <td>903421865.0</td>
      <td>6.814770e+09</td>
      <td>2.673020e+10</td>
      <td>2.864368e+10</td>
      <td>2.864716e+10</td>
      <td>3.123569e+10</td>
      <td>...</td>
      <td>3.524689e+11</td>
      <td>3.548850e+11</td>
      <td>3.553628e+11</td>
      <td>3.553808e+11</td>
      <td>3.556497e+11</td>
      <td>3.631008e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>901288699.0</td>
      <td>903421865.0</td>
      <td>7.460076e+09</td>
      <td>2.719207e+10</td>
      <td>2.864498e+10</td>
      <td>2.864716e+10</td>
      <td>3.136014e+10</td>
      <td>...</td>
      <td>3.526037e+11</td>
      <td>3.549708e+11</td>
      <td>3.553664e+11</td>
      <td>3.553808e+11</td>
      <td>3.556562e+11</td>
      <td>3.638237e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>901344911.0</td>
      <td>903396593.0</td>
      <td>8.141495e+09</td>
      <td>2.754523e+10</td>
      <td>2.864642e+10</td>
      <td>2.864716e+10</td>
      <td>3.146094e+10</td>
      <td>...</td>
      <td>3.527650e+11</td>
      <td>3.550733e+11</td>
      <td>3.553722e+11</td>
      <td>3.553808e+11</td>
      <td>3.556617e+11</td>
      <td>3.645784e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>901484846.0</td>
      <td>903396593.0</td>
      <td>8.756353e+09</td>
      <td>2.791825e+10</td>
      <td>2.864653e+10</td>
      <td>2.864716e+10</td>
      <td>3.154203e+10</td>
      <td>...</td>
      <td>3.529666e+11</td>
      <td>3.551741e+11</td>
      <td>3.553773e+11</td>
      <td>3.553809e+11</td>
      <td>3.556660e+11</td>
      <td>3.653519e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>901484846.0</td>
      <td>903396593.0</td>
      <td>9.194078e+09</td>
      <td>2.816731e+10</td>
      <td>2.864655e+10</td>
      <td>2.864716e+10</td>
      <td>3.156676e+10</td>
      <td>...</td>
      <td>3.530409e+11</td>
      <td>3.552456e+11</td>
      <td>3.553792e+11</td>
      <td>3.553811e+11</td>
      <td>3.556702e+11</td>
      <td>3.657420e+11</td>
      <td>4.964464e+11</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>901484846.0</td>
      <td>903396593.0</td>
      <td>9.409706e+09</td>
      <td>2.832621e+10</td>
      <td>2.864655e+10</td>
      <td>2.864716e+10</td>
      <td>3.157098e+10</td>
      <td>...</td>
      <td>3.530807e+11</td>
      <td>3.552837e+11</td>
      <td>3.553800e+11</td>
      <td>3.553811e+11</td>
      <td>3.556710e+11</td>
      <td>3.659908e+11</td>
      <td>4.964464e+11</td>
    </tr>
  </tbody>
</table>
<p>77 rows × 42 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> us-foreign-aid-country-foreign-assistance/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the annual percent change in aid amounts, in constant dollar value, across all income groups?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>aid.groupby(['income_group_name','fiscal_year']).constant_amount.mean().unstack(0).pct_change()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>aid.groupby(['income_group_name','fiscal_year']).constant_amount.mean().unstack(0).pct_change()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = aid.groupby(['income_group_name', 'fiscal_year']
    ).constant_amount.mean().unstack(0).pct_change()
</code></pre>
        <p><span onclick="$('#var_output_c5e33c7a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c5e33c7a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>income_group_name</th>
      <th>High Income Country</th>
      <th>Low Income Country</th>
      <th>Lower Middle Income Country</th>
      <th>Upper Middle Income Country</th>
    </tr>
    <tr>
      <th>fiscal_year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1946</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1947</th>
      <td>1.757294</td>
      <td>-0.873752</td>
      <td>1.754943</td>
      <td>-0.050161</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>-0.424691</td>
      <td>0.956438</td>
      <td>-0.519843</td>
      <td>1.256590</td>
    </tr>
    <tr>
      <th>1949</th>
      <td>1.052534</td>
      <td>-0.612847</td>
      <td>1.377298</td>
      <td>0.490276</td>
    </tr>
    <tr>
      <th>1950</th>
      <td>-0.286911</td>
      <td>-0.323413</td>
      <td>-0.405237</td>
      <td>0.391383</td>
    </tr>
    <tr>
      <th>1951</th>
      <td>-0.096140</td>
      <td>0.896589</td>
      <td>0.411433</td>
      <td>-0.047983</td>
    </tr>
    <tr>
      <th>1952</th>
      <td>-0.227175</td>
      <td>0.232754</td>
      <td>-0.609624</td>
      <td>0.103012</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0.007949</td>
      <td>-0.225854</td>
      <td>0.049871</td>
      <td>0.189341</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0.014050</td>
      <td>0.037402</td>
      <td>-0.077609</td>
      <td>-0.089655</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0.017312</td>
      <td>-0.148795</td>
      <td>-0.093659</td>
      <td>0.012203</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>-0.022102</td>
      <td>-0.059135</td>
      <td>0.060349</td>
      <td>-0.037351</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>-0.023917</td>
      <td>0.002303</td>
      <td>-0.059449</td>
      <td>0.150506</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>-0.621299</td>
      <td>-0.089173</td>
      <td>-0.190477</td>
      <td>-0.415297</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>0.473153</td>
      <td>-0.398822</td>
      <td>-0.368692</td>
      <td>-0.327212</td>
    </tr>
  </tbody>
</table>
<p>77 rows × 4 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>income_group_name</th>
      <th>High Income Country</th>
      <th>Low Income Country</th>
      <th>Lower Middle Income Country</th>
      <th>Upper Middle Income Country</th>
    </tr>
    <tr>
      <th>fiscal_year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1946</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1947</th>
      <td>1.757294</td>
      <td>-0.873752</td>
      <td>1.754943</td>
      <td>-0.050161</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>-0.424691</td>
      <td>0.956438</td>
      <td>-0.519843</td>
      <td>1.256590</td>
    </tr>
    <tr>
      <th>1949</th>
      <td>1.052534</td>
      <td>-0.612847</td>
      <td>1.377298</td>
      <td>0.490276</td>
    </tr>
    <tr>
      <th>1950</th>
      <td>-0.286911</td>
      <td>-0.323413</td>
      <td>-0.405237</td>
      <td>0.391383</td>
    </tr>
    <tr>
      <th>1951</th>
      <td>-0.096140</td>
      <td>0.896589</td>
      <td>0.411433</td>
      <td>-0.047983</td>
    </tr>
    <tr>
      <th>1952</th>
      <td>-0.227175</td>
      <td>0.232754</td>
      <td>-0.609624</td>
      <td>0.103012</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0.007949</td>
      <td>-0.225854</td>
      <td>0.049871</td>
      <td>0.189341</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0.014050</td>
      <td>0.037402</td>
      <td>-0.077609</td>
      <td>-0.089655</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0.017312</td>
      <td>-0.148795</td>
      <td>-0.093659</td>
      <td>0.012203</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>-0.022102</td>
      <td>-0.059135</td>
      <td>0.060349</td>
      <td>-0.037351</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>-0.023917</td>
      <td>0.002303</td>
      <td>-0.059449</td>
      <td>0.150506</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>-0.621299</td>
      <td>-0.089173</td>
      <td>-0.190477</td>
      <td>-0.415297</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>0.473153</td>
      <td>-0.398822</td>
      <td>-0.368692</td>
      <td>-0.327212</td>
    </tr>
  </tbody>
</table>
<p>77 rows × 4 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> us-foreign-aid-country-foreign-assistance/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # In which year, within the last ten years, did Israel receive the highest amount of financial aid, in constant amount? Show the year and amount received.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>israel = aid[(aid.country_name=='Israel') & 
             (aid.fiscal_year >= dt.datetime.now().year - 10)].groupby('fiscal_year').constant_amount.sum().agg(['max','idxmax'])
israel.index = ['constant_amount','year']
israel</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>israel = aid[(aid.country_name=='Israel') & 
             (aid.fiscal_year >= dt.datetime.now().year - 10)].groupby('fiscal_year').constant_amount.sum().agg(['max','idxmax'])
israel.index = ['constant_amount','year']
israel</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>israel = aid[(aid.country_name == 'Israel') & (aid.fiscal_year >= dt.
    datetime.now().year - 10)].groupby('fiscal_year').constant_amount.sum(
    ).agg(['max', 'idxmax'])
israel.index = ['constant_amount', 'year']
__output__ = israel
</code></pre>
        <p><span onclick="$('#var_output_d85fc34c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d85fc34c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>constant_amount    17667699453
year                      2012
Name: constant_amount, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> israel, __output__ </p>
    
          <p>israel (Series):</p>
          <pre><code>constant_amount    17667699453
year                      2012
Name: constant_amount, dtype: int64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>constant_amount    17667699453
year                      2012
Name: constant_amount, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> us-foreign-aid-country-foreign-assistance/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How does the financial aid constant dollar amount received by Israel compare to the rest of the countries in the same region for that year? Show the result for each country as a percentage of the aid amount received by Israel.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>aid[(aid.fiscal_year == israel.year) & (aid['Region Name'] == 'Middle East and North Africa')].groupby('country_name').constant_amount.sum() / israel.constant_amount</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>aid[(aid.fiscal_year == israel.year) & (aid['Region Name'] == 'Middle East and North Africa')].groupby('country_name').constant_amount.sum() / israel.constant_amount</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = aid[(aid.fiscal_year == israel.year) & (aid['Region Name'] ==
    'Middle East and North Africa')].groupby('country_name'
    ).constant_amount.sum() / israel.constant_amount
</code></pre>
        <p><span onclick="$('#var_output_605489a0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_605489a0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>country_name
Algeria                 0.002626
Bahrain                 0.004565
Egypt                   0.495463
Iran                    0.000123
Iraq                    0.574378
                          ...   
Syria                   0.018102
Tunisia                 0.039933
United Arab Emirates    0.000029
West Bank and Gaza      0.148522
Yemen                   0.048370
Name: constant_amount, Length: 22, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>country_name
Algeria                 0.002626
Bahrain                 0.004565
Egypt                   0.495463
Iran                    0.000123
Iraq                    0.574378
                          ...   
Syria                   0.018102
Tunisia                 0.039933
United Arab Emirates    0.000029
West Bank and Gaza      0.148522
Yemen                   0.048370
Name: constant_amount, Length: 22, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cities-with-the-best-worklife-balance-2022/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Remove "%" from all percentages columns and change the column type to float</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>changing_columns=df_clean.columns[df_clean.columns.tolist().index("Remote Jobs"):]
for column in changing_columns:
    if (df_clean[column].dtype == "object"):
        df_clean[column]=df_clean[column].str.strip("%").astype('float64')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>changing_columns=df_clean.columns[df_clean.columns.tolist().index("Remote Jobs"):]
for column in changing_columns:
    if (df_clean[column].dtype == "object"):
        df_clean[column]=df_clean[column].str.strip("%").astype('float64')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>changing_columns = df_clean.columns[df_clean.columns.tolist().index(
    'Remote Jobs'):]
for column in changing_columns:
    if df_clean[column].dtype == 'object':
        df_clean[column] = df_clean[column].str.strip('%').astype('float64')
</code></pre>
        <p><span onclick="$('#var_output_874f9b33').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_874f9b33" style="display: none;">
          
        <p><strong>Ref output variables:</strong> df_clean </p>
    
          <p>df_clean (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2022</th>
      <th>2021</th>
      <th>City</th>
      <th>Country</th>
      <th>Remote Jobs</th>
      <th>Overworked Population</th>
      <th>Minimum Vacations Offered (Days)</th>
      <th>...</th>
      <th>Affordability</th>
      <th>Happiness, Culture &amp; Leisure</th>
      <th>City Safety</th>
      <th>Outdoor Spaces</th>
      <th>Air Quality</th>
      <th>Wellness and Fitness</th>
      <th>TOTAL SCORE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2</td>
      <td>Oslo</td>
      <td>Norway</td>
      <td>41.72</td>
      <td>11.2</td>
      <td>25</td>
      <td>...</td>
      <td>59.4</td>
      <td>88.8</td>
      <td>86.5</td>
      <td>95.6</td>
      <td>97.5</td>
      <td>65.7</td>
      <td>100.00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>Bern</td>
      <td>Switzerland</td>
      <td>44.86</td>
      <td>11.4</td>
      <td>20</td>
      <td>...</td>
      <td>69.9</td>
      <td>100.0</td>
      <td>91.8</td>
      <td>87.1</td>
      <td>100.0</td>
      <td>69.1</td>
      <td>99.46</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>Helsinki</td>
      <td>Finland</td>
      <td>38.92</td>
      <td>12.7</td>
      <td>25</td>
      <td>...</td>
      <td>65.0</td>
      <td>96.3</td>
      <td>94.9</td>
      <td>86.0</td>
      <td>97.0</td>
      <td>68.3</td>
      <td>99.24</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>3</td>
      <td>Zurich</td>
      <td>Switzerland</td>
      <td>44.86</td>
      <td>11.9</td>
      <td>20</td>
      <td>...</td>
      <td>71.6</td>
      <td>91.5</td>
      <td>92.8</td>
      <td>84.0</td>
      <td>96.2</td>
      <td>68.7</td>
      <td>96.33</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>5</td>
      <td>Copenhagen</td>
      <td>Denmark</td>
      <td>41.42</td>
      <td>10.5</td>
      <td>25</td>
      <td>...</td>
      <td>65.3</td>
      <td>92.5</td>
      <td>95.7</td>
      <td>75.5</td>
      <td>95.1</td>
      <td>66.3</td>
      <td>96.21</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>0</td>
      <td>Geneva</td>
      <td>Switzerland</td>
      <td>44.86</td>
      <td>11.9</td>
      <td>20</td>
      <td>...</td>
      <td>70.7</td>
      <td>100.0</td>
      <td>85.4</td>
      <td>92.0</td>
      <td>96.8</td>
      <td>67.7</td>
      <td>95.82</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>6</td>
      <td>Ottawa</td>
      <td>Canada</td>
      <td>37.81</td>
      <td>10.1</td>
      <td>10</td>
      <td>...</td>
      <td>70.7</td>
      <td>81.4</td>
      <td>84.8</td>
      <td>97.0</td>
      <td>99.2</td>
      <td>68.7</td>
      <td>95.51</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>93</th>
      <td>94</td>
      <td>0</td>
      <td>Montevideo</td>
      <td>Uruguay</td>
      <td>27.29</td>
      <td>16.3</td>
      <td>20</td>
      <td>...</td>
      <td>52.4</td>
      <td>50.0</td>
      <td>56.2</td>
      <td>83.6</td>
      <td>98.5</td>
      <td>62.3</td>
      <td>74.59</td>
    </tr>
    <tr>
      <th>94</th>
      <td>95</td>
      <td>48</td>
      <td>Buenos Aires</td>
      <td>Argentina</td>
      <td>28.39</td>
      <td>8.8</td>
      <td>10</td>
      <td>...</td>
      <td>57.4</td>
      <td>74.3</td>
      <td>38.8</td>
      <td>82.5</td>
      <td>95.6</td>
      <td>60.6</td>
      <td>73.15</td>
    </tr>
    <tr>
      <th>95</th>
      <td>96</td>
      <td>49</td>
      <td>Bangkok</td>
      <td>Thailand</td>
      <td>16.84</td>
      <td>15.1</td>
      <td>6</td>
      <td>...</td>
      <td>50.0</td>
      <td>65.8</td>
      <td>27.8</td>
      <td>70.1</td>
      <td>84.0</td>
      <td>65.4</td>
      <td>70.73</td>
    </tr>
    <tr>
      <th>96</th>
      <td>97</td>
      <td>47</td>
      <td>Sao Paulo</td>
      <td>Brazil</td>
      <td>25.65</td>
      <td>11.8</td>
      <td>10</td>
      <td>...</td>
      <td>55.5</td>
      <td>75.8</td>
      <td>17.4</td>
      <td>76.9</td>
      <td>88.0</td>
      <td>61.9</td>
      <td>66.57</td>
    </tr>
    <tr>
      <th>97</th>
      <td>98</td>
      <td>50</td>
      <td>Kuala Lumpur</td>
      <td>Malaysia</td>
      <td>30.70</td>
      <td>17.1</td>
      <td>8</td>
      <td>...</td>
      <td>70.5</td>
      <td>59.5</td>
      <td>47.2</td>
      <td>62.2</td>
      <td>84.8</td>
      <td>59.7</td>
      <td>66.02</td>
    </tr>
    <tr>
      <th>98</th>
      <td>99</td>
      <td>0</td>
      <td>Dubai</td>
      <td>UAE</td>
      <td>28.89</td>
      <td>23.4</td>
      <td>30</td>
      <td>...</td>
      <td>78.0</td>
      <td>79.2</td>
      <td>97.9</td>
      <td>50.0</td>
      <td>50.0</td>
      <td>58.6</td>
      <td>61.23</td>
    </tr>
    <tr>
      <th>99</th>
      <td>100</td>
      <td>0</td>
      <td>Cape Town</td>
      <td>South Africa</td>
      <td>26.06</td>
      <td>14.8</td>
      <td>15</td>
      <td>...</td>
      <td>71.6</td>
      <td>59.6</td>
      <td>1.0</td>
      <td>87.6</td>
      <td>94.5</td>
      <td>50.0</td>
      <td>50.00</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 24 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_clean, changing_columns, column </p>
    
          <p>df_clean (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2022</th>
      <th>2021</th>
      <th>City</th>
      <th>Country</th>
      <th>Remote Jobs</th>
      <th>Overworked Population</th>
      <th>Minimum Vacations Offered (Days)</th>
      <th>...</th>
      <th>Affordability</th>
      <th>Happiness, Culture &amp; Leisure</th>
      <th>City Safety</th>
      <th>Outdoor Spaces</th>
      <th>Air Quality</th>
      <th>Wellness and Fitness</th>
      <th>TOTAL SCORE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2</td>
      <td>Oslo</td>
      <td>Norway</td>
      <td>41.72</td>
      <td>11.2</td>
      <td>25</td>
      <td>...</td>
      <td>59.4</td>
      <td>88.8</td>
      <td>86.5</td>
      <td>95.6</td>
      <td>97.5</td>
      <td>65.7</td>
      <td>100.00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>Bern</td>
      <td>Switzerland</td>
      <td>44.86</td>
      <td>11.4</td>
      <td>20</td>
      <td>...</td>
      <td>69.9</td>
      <td>100.0</td>
      <td>91.8</td>
      <td>87.1</td>
      <td>100.0</td>
      <td>69.1</td>
      <td>99.46</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>Helsinki</td>
      <td>Finland</td>
      <td>38.92</td>
      <td>12.7</td>
      <td>25</td>
      <td>...</td>
      <td>65.0</td>
      <td>96.3</td>
      <td>94.9</td>
      <td>86.0</td>
      <td>97.0</td>
      <td>68.3</td>
      <td>99.24</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>3</td>
      <td>Zurich</td>
      <td>Switzerland</td>
      <td>44.86</td>
      <td>11.9</td>
      <td>20</td>
      <td>...</td>
      <td>71.6</td>
      <td>91.5</td>
      <td>92.8</td>
      <td>84.0</td>
      <td>96.2</td>
      <td>68.7</td>
      <td>96.33</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>5</td>
      <td>Copenhagen</td>
      <td>Denmark</td>
      <td>41.42</td>
      <td>10.5</td>
      <td>25</td>
      <td>...</td>
      <td>65.3</td>
      <td>92.5</td>
      <td>95.7</td>
      <td>75.5</td>
      <td>95.1</td>
      <td>66.3</td>
      <td>96.21</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>0</td>
      <td>Geneva</td>
      <td>Switzerland</td>
      <td>44.86</td>
      <td>11.9</td>
      <td>20</td>
      <td>...</td>
      <td>70.7</td>
      <td>100.0</td>
      <td>85.4</td>
      <td>92.0</td>
      <td>96.8</td>
      <td>67.7</td>
      <td>95.82</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>6</td>
      <td>Ottawa</td>
      <td>Canada</td>
      <td>37.81</td>
      <td>10.1</td>
      <td>10</td>
      <td>...</td>
      <td>70.7</td>
      <td>81.4</td>
      <td>84.8</td>
      <td>97.0</td>
      <td>99.2</td>
      <td>68.7</td>
      <td>95.51</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>93</th>
      <td>94</td>
      <td>0</td>
      <td>Montevideo</td>
      <td>Uruguay</td>
      <td>27.29</td>
      <td>16.3</td>
      <td>20</td>
      <td>...</td>
      <td>52.4</td>
      <td>50.0</td>
      <td>56.2</td>
      <td>83.6</td>
      <td>98.5</td>
      <td>62.3</td>
      <td>74.59</td>
    </tr>
    <tr>
      <th>94</th>
      <td>95</td>
      <td>48</td>
      <td>Buenos Aires</td>
      <td>Argentina</td>
      <td>28.39</td>
      <td>8.8</td>
      <td>10</td>
      <td>...</td>
      <td>57.4</td>
      <td>74.3</td>
      <td>38.8</td>
      <td>82.5</td>
      <td>95.6</td>
      <td>60.6</td>
      <td>73.15</td>
    </tr>
    <tr>
      <th>95</th>
      <td>96</td>
      <td>49</td>
      <td>Bangkok</td>
      <td>Thailand</td>
      <td>16.84</td>
      <td>15.1</td>
      <td>6</td>
      <td>...</td>
      <td>50.0</td>
      <td>65.8</td>
      <td>27.8</td>
      <td>70.1</td>
      <td>84.0</td>
      <td>65.4</td>
      <td>70.73</td>
    </tr>
    <tr>
      <th>96</th>
      <td>97</td>
      <td>47</td>
      <td>Sao Paulo</td>
      <td>Brazil</td>
      <td>25.65</td>
      <td>11.8</td>
      <td>10</td>
      <td>...</td>
      <td>55.5</td>
      <td>75.8</td>
      <td>17.4</td>
      <td>76.9</td>
      <td>88.0</td>
      <td>61.9</td>
      <td>66.57</td>
    </tr>
    <tr>
      <th>97</th>
      <td>98</td>
      <td>50</td>
      <td>Kuala Lumpur</td>
      <td>Malaysia</td>
      <td>30.70</td>
      <td>17.1</td>
      <td>8</td>
      <td>...</td>
      <td>70.5</td>
      <td>59.5</td>
      <td>47.2</td>
      <td>62.2</td>
      <td>84.8</td>
      <td>59.7</td>
      <td>66.02</td>
    </tr>
    <tr>
      <th>98</th>
      <td>99</td>
      <td>0</td>
      <td>Dubai</td>
      <td>UAE</td>
      <td>28.89</td>
      <td>23.4</td>
      <td>30</td>
      <td>...</td>
      <td>78.0</td>
      <td>79.2</td>
      <td>97.9</td>
      <td>50.0</td>
      <td>50.0</td>
      <td>58.6</td>
      <td>61.23</td>
    </tr>
    <tr>
      <th>99</th>
      <td>100</td>
      <td>0</td>
      <td>Cape Town</td>
      <td>South Africa</td>
      <td>26.06</td>
      <td>14.8</td>
      <td>15</td>
      <td>...</td>
      <td>71.6</td>
      <td>59.6</td>
      <td>1.0</td>
      <td>87.6</td>
      <td>94.5</td>
      <td>50.0</td>
      <td>50.00</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 24 columns</p>
      
          <p>changing_columns (Index):</p>
          <pre><code>Index(['Remote Jobs', 'Overworked Population',
       'Minimum Vacations Offered (Days)', 'Vacations Taken (Days)',
       'Unemployment', 'Multiple Jobholders', 'Inflation',
       'Paid Parental Leave (Days)', 'Covid Impact', 'Covid Support',
       'Healthcare', 'Access to Mental Healthcare', 'Inclusivity & Tolerance',
       'Affordability', 'Happiness, Culture & Leisure', 'City Safety',
       'Outdoor Spaces', 'Air Quality', 'Wellness and Fitness', 'TOTAL SCORE'],
      dtype='object')</code></pre>
      
          <p>column (str):</p>
          <pre><code>TOTAL SCORE</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('df_clean', 'df_clean', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cities-with-the-best-worklife-balance-2022/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Is the average safety score in Switzerland more than eighty?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_clean.groupby('Country').get_group("Switzerland")['City Safety'].mean() > 80</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_clean.groupby('Country').get_group("Switzerland")['City Safety'].mean() > 80</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_clean.groupby('Country').get_group('Switzerland')['City Safety'
    ].mean() > 80
</code></pre>
        <p><span onclick="$('#var_output_25c5962c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_25c5962c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (bool_):</p>
          <pre><code>True</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (bool_):</p>
          <pre><code>True</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cities-with-the-best-worklife-balance-2022/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # From the top twenty cities ranked in 2022, which city was impacted by covid the most?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.loc[df_clean.sort_values("Unemployment",ascending=False).head(20)['Covid Impact'].idxmax(),'City']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.loc[df_clean.sort_values("Unemployment",ascending=False).head(20)['Covid Impact'].idxmax(),'City']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.loc[df_clean.sort_values('Unemployment', ascending=False).
    head(20)['Covid Impact'].idxmax(), 'City']
</code></pre>
        <p><span onclick="$('#var_output_9a3ea4a8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9a3ea4a8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Dubai</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Dubai</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cities-with-the-best-worklife-balance-2022/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many cities in the UK are there whose employees take less than 80% of their minimum vacations?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_clean[df_clean['Minimum Vacations Offered (Days)']*0.80>df_clean['Vacations Taken (Days)']].groupby('Country').get_group('UK').shape[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_clean[df_clean['Minimum Vacations Offered (Days)']*0.80>df_clean['Vacations Taken (Days)']].groupby('Country').get_group('UK').shape[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_clean[df_clean['Minimum Vacations Offered (Days)'] * 0.8 >
    df_clean['Vacations Taken (Days)']].groupby('Country').get_group('UK'
    ).shape[0]
</code></pre>
        <p><span onclick="$('#var_output_37515544').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_37515544" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>4</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>4</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cities-with-the-best-worklife-balance-2022/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average covid support score for cities that have an inflation rate of more than 80% quantile?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_clean[df_clean['Inflation']>df_clean['Inflation'].quantile(0.80)]['Covid Support'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_clean[df_clean['Inflation']>df_clean['Inflation'].quantile(0.80)]['Covid Support'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_clean[df_clean['Inflation'] > df_clean['Inflation'].
    quantile(0.8)]['Covid Support'].mean()
</code></pre>
        <p><span onclick="$('#var_output_31c5b776').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_31c5b776" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>81.88421052631578</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>81.88421052631578</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cities-with-the-best-worklife-balance-2022/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average unemployment score for each country that has an average safety score between 50 and 80?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>unemp_score=df_clean.groupby('Country').mean()[['City Safety','Unemployment']]
unemp_score=unemp_score[unemp_score['City Safety'].between(50,80)]
unemp_score['Unemployment']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>unemp_score=df_clean.groupby('Country').mean()[['City Safety','Unemployment']]
unemp_score=unemp_score[unemp_score['City Safety'].between(50,80)]
unemp_score['Unemployment']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>unemp_score = df_clean.groupby('Country').mean()[['City Safety',
    'Unemployment']]
unemp_score = unemp_score[unemp_score['City Safety'].between(50, 80)]
__output__ = unemp_score['Unemployment']
</code></pre>
        <p><span onclick="$('#var_output_b7e5244b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b7e5244b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Country
Australia      95.200000
Belgium        87.800000
Canada         92.100000
France         88.000000
Germany        90.611111
Hungary        97.500000
Ireland        92.600000
Italy          91.400000
New Zealand    96.200000
Portugal       89.300000
Spain          82.550000
UK             93.925000
USA            95.274510
Uruguay        87.400000
Name: Unemployment, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> unemp_score, __output__ </p>
    
          <p>unemp_score (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>City Safety</th>
      <th>Unemployment</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Australia</th>
      <td>74.900000</td>
      <td>95.200000</td>
    </tr>
    <tr>
      <th>Belgium</th>
      <td>69.900000</td>
      <td>87.800000</td>
    </tr>
    <tr>
      <th>Canada</th>
      <td>78.725000</td>
      <td>92.100000</td>
    </tr>
    <tr>
      <th>France</th>
      <td>61.200000</td>
      <td>88.000000</td>
    </tr>
    <tr>
      <th>Germany</th>
      <td>74.800000</td>
      <td>90.611111</td>
    </tr>
    <tr>
      <th>Hungary</th>
      <td>72.000000</td>
      <td>97.500000</td>
    </tr>
    <tr>
      <th>Ireland</th>
      <td>76.500000</td>
      <td>92.600000</td>
    </tr>
    <tr>
      <th>Italy</th>
      <td>63.000000</td>
      <td>91.400000</td>
    </tr>
    <tr>
      <th>New Zealand</th>
      <td>75.200000</td>
      <td>96.200000</td>
    </tr>
    <tr>
      <th>Portugal</th>
      <td>72.800000</td>
      <td>89.300000</td>
    </tr>
    <tr>
      <th>Spain</th>
      <td>71.300000</td>
      <td>82.550000</td>
    </tr>
    <tr>
      <th>UK</th>
      <td>67.925000</td>
      <td>93.925000</td>
    </tr>
    <tr>
      <th>USA</th>
      <td>55.192157</td>
      <td>95.274510</td>
    </tr>
    <tr>
      <th>Uruguay</th>
      <td>56.200000</td>
      <td>87.400000</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Country
Australia      95.200000
Belgium        87.800000
Canada         92.100000
France         88.000000
Germany        90.611111
Hungary        97.500000
Ireland        92.600000
Italy          91.400000
New Zealand    96.200000
Portugal       89.300000
Spain          82.550000
UK             93.925000
USA            95.274510
Uruguay        87.400000
Name: Unemployment, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cities-with-the-best-worklife-balance-2022/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # From these top five scores, which country has the highest average total score?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>topfivescore=unemp_score['Unemployment'].sort_values(ascending=False).head().index
df_clean[df_clean['Country'].isin(topfivescore)].groupby('Country')['TOTAL SCORE'].mean().idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>topfivescore=unemp_score['Unemployment'].sort_values(ascending=False).head().index
df_clean[df_clean['Country'].isin(topfivescore)].groupby('Country')['TOTAL SCORE'].mean().idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>topfivescore = unemp_score['Unemployment'].sort_values(ascending=False).head(
    ).index
__output__ = df_clean[df_clean['Country'].isin(topfivescore)].groupby('Country'
    )['TOTAL SCORE'].mean().idxmax()
</code></pre>
        <p><span onclick="$('#var_output_d1f80ed8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d1f80ed8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Australia</code></pre>
      
        <p><strong>Hyp output variables:</strong> topfivescore, __output__ </p>
    
          <p>topfivescore (Index):</p>
          <pre><code>Index(['Hungary', 'New Zealand', 'USA', 'Australia', 'UK'], dtype='object', name='Country')</code></pre>
      
          <p>__output__ (str):</p>
          <pre><code>Australia</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cities-with-the-best-worklife-balance-2022/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which cities have their ranks changed by one from 2021 to 2022?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>rank_differance=abs(df_clean['2022']-df_clean['2021'].astype(int))
cities=df_clean[rank_differance==1]['City']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>['cities']</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>rank_differance=abs(df_clean['2022']-df_clean['2021'].astype(int))
cities=df_clean[rank_differance==1]['City']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>rank_differance = abs(df_clean['2022'] - df_clean['2021'].astype(int))
__output__ = cities = df_clean[rank_differance == 1]['City']
</code></pre>
        <p><span onclick="$('#var_output_926a7c0a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_926a7c0a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> cities </p>
    
          <p>cities (Series):</p>
          <pre><code>0         Oslo
3       Zurich
6       Ottawa
16    Auckland
27       Paris
Name: City, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> rank_differance, __output__, cities </p>
    
          <p>rank_differance (Series):</p>
          <pre><code>0       1
1       2
2       2
3       1
4       0
     ... 
95     47
96     50
97     48
98     99
99    100
Length: 100, dtype: int64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>0         Oslo
3       Zurich
6       Ottawa
16    Auckland
27       Paris
Name: City, dtype: object</code></pre>
      
          <p>cities (Series):</p>
          <pre><code>0         Oslo
3       Zurich
6       Ottawa
16    Auckland
27       Paris
Name: City, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', 'cities', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cities-with-the-best-worklife-balance-2022/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which of these cities' country has the highest average score in affordability?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_clean[df_clean['Country'].isin(df_clean[df_clean['City'].isin(cities)]['Country'])].groupby('Country').mean()['Affordability'].idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_clean[df_clean['Country'].isin(df_clean[df_clean['City'].isin(cities)]['Country'])].groupby('Country').mean()['Affordability'].idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_clean[df_clean['Country'].isin(df_clean[df_clean['City'].
    isin(cities)]['Country'])].groupby('Country').mean()['Affordability'
    ].idxmax()
</code></pre>
        <p><span onclick="$('#var_output_ab8427ff').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ab8427ff" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Canada</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Canada</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cities-with-the-best-worklife-balance-2022/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average happiness score for cities that have only two or less points difference between affordability and safety?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_clean[(df_clean['Affordability']-df_clean['City Safety']).between(-2,2)]['Happiness, Culture & Leisure'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_clean[(df_clean['Affordability']-df_clean['City Safety']).between(-2,2)]['Happiness, Culture & Leisure'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_clean[(df_clean['Affordability'] - df_clean['City Safety'])
    .between(-2, 2)]['Happiness, Culture & Leisure'].mean()
</code></pre>
        <p><span onclick="$('#var_output_faa80f7a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_faa80f7a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>87.38571428571429</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>87.38571428571429</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> crf-data-full/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Fill null values in the project description column with the same value in the award description column if it exists</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>columns=crf.columns.tolist()

def fill_projects(x):
    if (pd.isnull(x[columns.index('Project description')])) & (not pd.isnull(x[columns.index('Award description')])):
        return x[columns.index('Award description')]
    else:
        return x[columns.index('Project description')]
crf['Project description']=crf.apply(fill_projects,axis=1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>columns=crf.columns.tolist()

def fill_projects(x):
    if (pd.isnull(x[columns.index('Project description')])) & (not pd.isnull(x[columns.index('Award description')])):
        return x[columns.index('Award description')]
    else:
        return x[columns.index('Project description')]
crf['Project description']=crf.apply(fill_projects,axis=1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>columns = crf.columns.tolist()


def fill_projects(x):
    if pd.isnull(x[columns.index('Project description')]) & (not pd.isnull(
        x[columns.index('Award description')])):
        return x[columns.index('Award description')]
    else:
        return x[columns.index('Project description')]


__output__ = crf['Project description'] = crf.apply(fill_projects, axis=1)
</code></pre>
        <p><span onclick="$('#var_output_142a2c30').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_142a2c30" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0                                    NaN
1         Allocation to school districts
2          Allocation to school district
3          Allocation to school district
4          Allocation to school district
                       ...              
202112                               NaN
202113                               NaN
202114                               NaN
202115                               NaN
202116                               NaN
Length: 202117, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> crf, columns, __output__ </p>
    
          <p>crf (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Prime recipient</th>
      <th>Award amount</th>
      <th>Sub-recipient</th>
      <th>Sub-recipient address1</th>
      <th>City</th>
      <th>State</th>
      <th>Zip</th>
      <th>...</th>
      <th>Award description</th>
      <th>Sub-award amount</th>
      <th>Money spent to date</th>
      <th>Project description</th>
      <th>Project status</th>
      <th>Spending category</th>
      <th>Category description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ABSENTEE SHAWNEE TRIBE OF OKLAHOMA</td>
      <td>33101482.30</td>
      <td>NOT YET AVAILABLE FOR PUBLIC DISPLAY</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>3.310148e+07</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ADAMS, COUNTY OF</td>
      <td>90285974.40</td>
      <td>ADAMS 12 FIVE STAR SCHOOLS</td>
      <td>1500 E 128TH AVE</td>
      <td>DENVER</td>
      <td>CO</td>
      <td>80241-2601</td>
      <td>...</td>
      <td>Allocation to school district</td>
      <td>8.421866e+06</td>
      <td>245268.01</td>
      <td>Allocation to school districts</td>
      <td>Fully completed</td>
      <td>Facilitating Distance Learning</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ADAMS, COUNTY OF</td>
      <td>90285974.40</td>
      <td>ADAMS 12 FIVE STAR SCHOOLS</td>
      <td>1500 E 128TH AVE</td>
      <td>DENVER</td>
      <td>CO</td>
      <td>80241-2601</td>
      <td>...</td>
      <td>Allocation to school district</td>
      <td>8.421866e+06</td>
      <td>5228843.14</td>
      <td>Allocation to school district</td>
      <td>NaN</td>
      <td>Facilitating Distance Learning</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ADAMS, COUNTY OF</td>
      <td>90285974.40</td>
      <td>ADAMS 12 FIVE STAR SCHOOLS</td>
      <td>1500 E 128TH AVE</td>
      <td>DENVER</td>
      <td>CO</td>
      <td>80241-2601</td>
      <td>...</td>
      <td>Allocation to school district</td>
      <td>8.421866e+06</td>
      <td>339483.95</td>
      <td>Allocation to school district</td>
      <td>NaN</td>
      <td>Food Programs</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ADAMS, COUNTY OF</td>
      <td>90285974.40</td>
      <td>ADAMS 12 FIVE STAR SCHOOLS</td>
      <td>1500 E 128TH AVE</td>
      <td>DENVER</td>
      <td>CO</td>
      <td>80241-2601</td>
      <td>...</td>
      <td>Allocation to school district</td>
      <td>8.421866e+06</td>
      <td>75972.24</td>
      <td>Allocation to school district</td>
      <td>NaN</td>
      <td>Improve Telework Capabilities of Public Employees</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ADAMS, COUNTY OF</td>
      <td>90285974.40</td>
      <td>ADAMS 12 FIVE STAR SCHOOLS</td>
      <td>1500 E 128TH AVE</td>
      <td>DENVER</td>
      <td>CO</td>
      <td>80241-2601</td>
      <td>...</td>
      <td>Allocation to school district</td>
      <td>8.421866e+06</td>
      <td>2026730.21</td>
      <td>Allocation to school district</td>
      <td>NaN</td>
      <td>Personal Protective Equipment</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ADAMS, COUNTY OF</td>
      <td>90285974.40</td>
      <td>ADAMS 12 FIVE STAR SCHOOLS</td>
      <td>1500 E 128TH AVE</td>
      <td>DENVER</td>
      <td>CO</td>
      <td>80241-2601</td>
      <td>...</td>
      <td>Allocation to school district</td>
      <td>8.421866e+06</td>
      <td>275480.54</td>
      <td>Allocation to school district</td>
      <td>NaN</td>
      <td>Payroll for Public Health and Safety Employees</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>202110</th>
      <td>YERINGTON PAIUTE TRIBE</td>
      <td>6762748.29</td>
      <td>NOT YET AVAILABLE FOR PUBLIC DISPLAY</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>6.303883e+06</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>202111</th>
      <td>YOCHA DEHE WINTUN NATION</td>
      <td>15436645.02</td>
      <td>NOT YET AVAILABLE FOR PUBLIC DISPLAY</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>1.543665e+07</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>202112</th>
      <td>YOMBA TRIBAL COUNCIL INC</td>
      <td>1367656.36</td>
      <td>NOT YET AVAILABLE FOR PUBLIC DISPLAY</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>202113</th>
      <td>YSLETA DEL SUR PUEBLO</td>
      <td>31042585.67</td>
      <td>NOT YET AVAILABLE FOR PUBLIC DISPLAY</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>3.104259e+07</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>202114</th>
      <td>YUPIIT OF ANDREAFSKI</td>
      <td>352518.23</td>
      <td>NOT YET AVAILABLE FOR PUBLIC DISPLAY</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>3.525182e+05</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>202115</th>
      <td>YUROK TRIBE</td>
      <td>40181880.86</td>
      <td>NOT YET AVAILABLE FOR PUBLIC DISPLAY</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>4.018188e+07</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>202116</th>
      <td>ZUNI, PUEBLO OF</td>
      <td>31466013.03</td>
      <td>NOT YET AVAILABLE FOR PUBLIC DISPLAY</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>3.146601e+07</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>202117 rows × 18 columns</p>
      
          <p>columns (list):</p>
          <pre><code>['Prime recipient', 'Award amount', 'Sub-recipient', 'Sub-recipient address1', 'City', 'State', 'Zip', 'County', 'Sub-recipient congressional district', 'Award number', 'Award type', 'Award description', 'Sub-award amount', 'Money spent to date', 'Project description', 'Project status', 'Spending category', 'Category description']</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>0                                    NaN
1         Allocation to school districts
2          Allocation to school district
3          Allocation to school district
4          Allocation to school district
                       ...              
202112                               NaN
202113                               NaN
202114                               NaN
202115                               NaN
202116                               NaN
Length: 202117, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> crf-data-full/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show a list of the prime recipients who spent more than 95% of the awarded amount</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>percent=crf.groupby(['Prime recipient'])['Money spent to date'].sum() / prime_recp_amount
percent[percent>0.95].index.tolist()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>percent=crf.groupby(['Prime recipient'])['Money spent to date'].sum() / prime_recp_amount
percent[percent>0.95].index.tolist()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>percent = crf.groupby(['Prime recipient'])['Money spent to date'].sum(
    ) / prime_recp_amount
__output__ = percent[percent > 0.95].index.tolist()
</code></pre>
        <p><span onclick="$('#var_output_f11355cd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f11355cd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['ADAMS, COUNTY OF', 'ADMINISTRATION, MONTANA DEPARTMENT OF', 'ADMINISTRATION, WISCONSIN DEPARTMENT OF', 'ALAMEDA, COUNTY OF', 'ALBUQUERQUE, CITY OF', 'ALLEGHENY, COUNTY OF', 'AMERICAN SAMOA GOVERNMENT', 'ANNE ARUNDEL, COUNTY OF', 'ARAPAHOE, COUNTY OF', 'ATLANTA, CITY OF', 'BERGEN, COUNTY OF', 'BERNALILLO, COUNTY OF', 'BEXAR, COUNTY OF', 'BREVARD, COUNTY OF', 'BROWARD, COUNTY OF', 'BUCKS, THE COUNTY OF', 'CAMDEN, COUNTY OF', 'CHARLOTTE, CITY OF', 'CHESTER, COUNTY OF', 'CHICAGO, CITY OF', 'CITY OF INDIANAPOLIS', 'CITY OF LOS ANGELES', 'CITY OF PHOENIX', 'CITY OF TUCSON', 'CLARK, COUNTY OF', 'COLLIN, COUNTY OF', 'COLUMBUS, CITY OF', 'CONTRA COSTA , COUNTY OF', 'COUNTY OF COBB', 'COUNTY OF KERN', 'COUNTY OF PASSAIC GOVERNMENT OFFICE', 'COUNTY OF SAN DIEGO', 'COUNTY OF SPOKANE', 'COUNTY OF TULSA', 'COUNTY OF VENTURA', 'COUNTY OF VOLUSIA', 'CUYAHOGA, COUNTY OF', 'DALLAS, CITY OF', 'DALLAS, COUNTY OF', 'DANE, COUNTY OF', 'DEKALB, COUNTY OF', 'DELAWARE COUNTY, PENNSYLVANIA', 'DENTON, COUNTY OF', 'DENVER, CITY & COUNTY OF', 'DETROIT, CITY OF', 'DOUGLAS COUNTY NEBRASKA', 'DU PAGE, COUNTY OF', 'EL PASO, CITY OF', 'EL PASO, COUNTY OF', 'ERIE, COUNTY OF', 'ESSEX, COUNTY OF', 'EXECUTIVE OFFICE OF THE COMMONWEALTH OF PENNSYLVANIA', 'EXECUTIVE OFFICE OF THE STATE OF HAWAII', 'EXECUTIVE OFFICE OF THE STATE OF IDAHO', 'EXECUTIVE OFFICE OF THE STATE OF KANSAS', 'EXECUTIVE OFFICE OF THE STATE OF NEBRASKA', 'EXECUTIVE OFFICE OF THE STATE OF UTAH', 'EXECUTIVE OFFICE STATE OF OHIO', 'FAIRFAX COUNTY VIRGINIA', 'FINANCE & ADMINISTRATION, MISSISSIPPI DEPT OF', 'FINANCE & ADMINISTRATION, NEW MEXICO DEPARTMENT OF', 'FINANCE AND ADMINISTRATION, ARKANSAS DEPT OF', 'FINANCE AND ADMINISTRATION, TENNESSEE DEPARTMENT OF', 'FINANCE, ALABAMA DEPT OF', 'FINANCIAL SERVICES, FLORIDA DEPARTMENT OF', 'FORT BEND, COUNTY OF', 'FORT WORTH, CITY OF', 'FRANKLIN COUNTY BOARD OF COMMISSIONERS', 'FRESNO, CITY OF', 'FRESNO, COUNTY OF', 'FULTON COUNTY, GEORGIA', 'GOVERNMENT OF GUAM- DEPARTMENT OF ADMINISTRATION', 'GREENVILLE, COUNTY OF', 'GUILFORD, COUNTY OF', 'GWINNETT COUNTY GOVERNMENT', 'HARRIS, COUNTY OF', 'HEMPSTEAD, TOWN OF', 'HENNEPIN COUNTY', 'HILLSBOROUGH, COUNTY OF', 'HOMELAND SECURITY & EMERGENCY PREPAREDNESS, LA GOVERNOR', 'HONOLULU, CITY & COUNTY OF', 'HOUSTON, CITY OF', 'IOWA DEPARTMENT MANAGEMENT', 'JACKSON COUNTY', 'JEFFERSON COUNTY, ALABAMA', 'JEFFERSON, COUNTY OF', 'JOHNSON, COUNTY OF', 'KANE, COUNTY OF', 'KENT COUNTY', 'KENTUCKY, COMMONWEALTH OF', 'KING, COUNTY OF', 'LAKE, COUNTY OF', 'LANCASTER, COUNTY OF', 'LAS VEGAS, CITY OF', 'LEE, COUNTY OF', 'LOS ANGELES, COUNTY OF', 'LOUISVILLE-JEFFERSON COUNTY METRO GOVERNMENT', 'MACOMB, COUNTY OF', 'MAINE, STATE OF', 'MARICOPA, COUNTY OF', 'MARYLAND STATE DEPARTMENT OF EDUCATION', 'MECKLENBURG, COUNTY OF', 'MEMPHIS, CITY OF', 'MESA, CITY OF', 'MIDDLESEX, COUNTY OF (INC)', 'MILWAUKEE COUNTY, WISCONSIN', 'MILWAUKEE, CITY OF', 'MISSOURI, STATE OF', 'MONMOUTH, COUNTY OF', 'MONROE, COUNTY OF', 'MONTGOMERY COUNTY, MARYLAND', 'MONTGOMERY, COUNTY OF', 'MULTNOMAH, COUNTY OF', 'NASHVILLE & DAVIDSON COUNTY, METROPOLITAN GOVERNMENT OF', 'NASSAU, COUNTY OF', 'NEW CASTLE, COUNTY OF', 'NEW JERSEY DEPARTMENT OF TREASURY', 'OAKLAND, COUNTY OF', 'OFFICE OF THE GOVERNOR', 'OKLAHOMA CITY, CITY OF', 'ORANGE, COUNTY OF', 'PALM BEACH, COUNTY OF', 'PASCO, COUNTY OF', 'PERSONNEL AND ADMINISTRATION, COLORADO DEPARTMENT OF', 'PHILADELPHIA, CITY OF', 'PIERCE, COUNTY OF', 'PIMA COUNTY', 'PINELLAS, COUNTY OF', "PLANNING AND BUDGET, GEORGIA GOVERNOR'S OFFICE OF", 'POLK COUNTY', 'PRINCE GEORGES, COUNTY GOVERNMENT', 'PUBLIC SAFETY, ALASKA DEPT OF', 'PUBLIC SAFETY, NEVADA DEPARTMENT OF', 'RAMSEY, COUNTY OF', 'RHODE ISLAND AND PROVIDENCE PLANTATIONS, STATE OF', 'RIVERSIDE, COUNTY OF', 'SACRAMENTO, COUNTY OF', 'SALT LAKE, COUNTY OF', 'SAN ANTONIO, CITY OF', 'SAN BERNARDINO, COUNTY OF', 'SAN DIEGO, CITY OF', 'SAN FRANCISCO, CITY & COUNTY OF', 'SAN JOAQUIN, COUNTY OF', 'SAN JOSE, CITY OF', 'SAN MATEO, COUNTY OF', 'SANTA CLARA, COUNTY OF', 'SEATTLE, CITY OF', 'SHELBY, COUNTY OF', 'SNOHOMISH, COUNTY OF', 'SOUTH CAROLINA OFFICE OF STATE TREASURER', 'SOUTH DAKOTA, STATE OF', 'ST LOUIS, COUNTY OF', 'STANISLAUS, COUNTY OF', 'STATE OF NEW YORK', 'STATE OF WYOMING', 'STATE TREASURER, VERMONT OFFICE OF THE', 'SUFFOLK, COUNTY OF', 'SUMMIT, COUNTY OF', 'TARRANT COUNTY TEXAS (INC)', 'TRAVIS, COUNTY OF', 'TREASURER, OKLAHOMA STATE', 'TREASURY, MICHIGAN DEPARTMENT OF', 'UNION, COUNTY OF', 'UTAH, COUNTY OF', 'WAKE, COUNTY OF', 'WASHINGTON, COUNTY OF', 'WAYNE, COUNTY OF', 'WESTCHESTER, COUNTY OF', 'WILL COUNTY']</code></pre>
      
        <p><strong>Hyp output variables:</strong> percent, __output__ </p>
    
          <p>percent (Series):</p>
          <pre><code>Prime recipient
ABSENTEE SHAWNEE TRIBE OF OKLAHOMA               0.000000
ADAMS, COUNTY OF                                 0.974100
ADMINISTRATION, MONTANA DEPARTMENT OF            0.990706
ADMINISTRATION, WISCONSIN DEPARTMENT OF          0.992420
ADMINISTRATIVE SERVICES, OREGON DEPARTMENT OF    0.914379
                                                   ...   
YOMBA TRIBAL COUNCIL INC                         0.000000
YSLETA DEL SUR PUEBLO                            0.000000
YUPIIT OF ANDREAFSKI                             0.000000
YUROK TRIBE                                      0.000000
ZUNI, PUEBLO OF                                  0.000000
Length: 864, dtype: float64</code></pre>
      
          <p>__output__ (list):</p>
          <pre><code>['ADAMS, COUNTY OF', 'ADMINISTRATION, MONTANA DEPARTMENT OF', 'ADMINISTRATION, WISCONSIN DEPARTMENT OF', 'ALAMEDA, COUNTY OF', 'ALBUQUERQUE, CITY OF', 'ALLEGHENY, COUNTY OF', 'AMERICAN SAMOA GOVERNMENT', 'ANNE ARUNDEL, COUNTY OF', 'ARAPAHOE, COUNTY OF', 'ATLANTA, CITY OF', 'BERGEN, COUNTY OF', 'BERNALILLO, COUNTY OF', 'BEXAR, COUNTY OF', 'BREVARD, COUNTY OF', 'BROWARD, COUNTY OF', 'BUCKS, THE COUNTY OF', 'CAMDEN, COUNTY OF', 'CHARLOTTE, CITY OF', 'CHESTER, COUNTY OF', 'CHICAGO, CITY OF', 'CITY OF INDIANAPOLIS', 'CITY OF LOS ANGELES', 'CITY OF PHOENIX', 'CITY OF TUCSON', 'CLARK, COUNTY OF', 'COLLIN, COUNTY OF', 'COLUMBUS, CITY OF', 'CONTRA COSTA , COUNTY OF', 'COUNTY OF COBB', 'COUNTY OF KERN', 'COUNTY OF PASSAIC GOVERNMENT OFFICE', 'COUNTY OF SAN DIEGO', 'COUNTY OF SPOKANE', 'COUNTY OF TULSA', 'COUNTY OF VENTURA', 'COUNTY OF VOLUSIA', 'CUYAHOGA, COUNTY OF', 'DALLAS, CITY OF', 'DALLAS, COUNTY OF', 'DANE, COUNTY OF', 'DEKALB, COUNTY OF', 'DELAWARE COUNTY, PENNSYLVANIA', 'DENTON, COUNTY OF', 'DENVER, CITY & COUNTY OF', 'DETROIT, CITY OF', 'DOUGLAS COUNTY NEBRASKA', 'DU PAGE, COUNTY OF', 'EL PASO, CITY OF', 'EL PASO, COUNTY OF', 'ERIE, COUNTY OF', 'ESSEX, COUNTY OF', 'EXECUTIVE OFFICE OF THE COMMONWEALTH OF PENNSYLVANIA', 'EXECUTIVE OFFICE OF THE STATE OF HAWAII', 'EXECUTIVE OFFICE OF THE STATE OF IDAHO', 'EXECUTIVE OFFICE OF THE STATE OF KANSAS', 'EXECUTIVE OFFICE OF THE STATE OF NEBRASKA', 'EXECUTIVE OFFICE OF THE STATE OF UTAH', 'EXECUTIVE OFFICE STATE OF OHIO', 'FAIRFAX COUNTY VIRGINIA', 'FINANCE & ADMINISTRATION, MISSISSIPPI DEPT OF', 'FINANCE & ADMINISTRATION, NEW MEXICO DEPARTMENT OF', 'FINANCE AND ADMINISTRATION, ARKANSAS DEPT OF', 'FINANCE AND ADMINISTRATION, TENNESSEE DEPARTMENT OF', 'FINANCE, ALABAMA DEPT OF', 'FINANCIAL SERVICES, FLORIDA DEPARTMENT OF', 'FORT BEND, COUNTY OF', 'FORT WORTH, CITY OF', 'FRANKLIN COUNTY BOARD OF COMMISSIONERS', 'FRESNO, CITY OF', 'FRESNO, COUNTY OF', 'FULTON COUNTY, GEORGIA', 'GOVERNMENT OF GUAM- DEPARTMENT OF ADMINISTRATION', 'GREENVILLE, COUNTY OF', 'GUILFORD, COUNTY OF', 'GWINNETT COUNTY GOVERNMENT', 'HARRIS, COUNTY OF', 'HEMPSTEAD, TOWN OF', 'HENNEPIN COUNTY', 'HILLSBOROUGH, COUNTY OF', 'HOMELAND SECURITY & EMERGENCY PREPAREDNESS, LA GOVERNOR', 'HONOLULU, CITY & COUNTY OF', 'HOUSTON, CITY OF', 'IOWA DEPARTMENT MANAGEMENT', 'JACKSON COUNTY', 'JEFFERSON COUNTY, ALABAMA', 'JEFFERSON, COUNTY OF', 'JOHNSON, COUNTY OF', 'KANE, COUNTY OF', 'KENT COUNTY', 'KENTUCKY, COMMONWEALTH OF', 'KING, COUNTY OF', 'LAKE, COUNTY OF', 'LANCASTER, COUNTY OF', 'LAS VEGAS, CITY OF', 'LEE, COUNTY OF', 'LOS ANGELES, COUNTY OF', 'LOUISVILLE-JEFFERSON COUNTY METRO GOVERNMENT', 'MACOMB, COUNTY OF', 'MAINE, STATE OF', 'MARICOPA, COUNTY OF', 'MARYLAND STATE DEPARTMENT OF EDUCATION', 'MECKLENBURG, COUNTY OF', 'MEMPHIS, CITY OF', 'MESA, CITY OF', 'MIDDLESEX, COUNTY OF (INC)', 'MILWAUKEE COUNTY, WISCONSIN', 'MILWAUKEE, CITY OF', 'MISSOURI, STATE OF', 'MONMOUTH, COUNTY OF', 'MONROE, COUNTY OF', 'MONTGOMERY COUNTY, MARYLAND', 'MONTGOMERY, COUNTY OF', 'MULTNOMAH, COUNTY OF', 'NASHVILLE & DAVIDSON COUNTY, METROPOLITAN GOVERNMENT OF', 'NASSAU, COUNTY OF', 'NEW CASTLE, COUNTY OF', 'NEW JERSEY DEPARTMENT OF TREASURY', 'OAKLAND, COUNTY OF', 'OFFICE OF THE GOVERNOR', 'OKLAHOMA CITY, CITY OF', 'ORANGE, COUNTY OF', 'PALM BEACH, COUNTY OF', 'PASCO, COUNTY OF', 'PERSONNEL AND ADMINISTRATION, COLORADO DEPARTMENT OF', 'PHILADELPHIA, CITY OF', 'PIERCE, COUNTY OF', 'PIMA COUNTY', 'PINELLAS, COUNTY OF', "PLANNING AND BUDGET, GEORGIA GOVERNOR'S OFFICE OF", 'POLK COUNTY', 'PRINCE GEORGES, COUNTY GOVERNMENT', 'PUBLIC SAFETY, ALASKA DEPT OF', 'PUBLIC SAFETY, NEVADA DEPARTMENT OF', 'RAMSEY, COUNTY OF', 'RHODE ISLAND AND PROVIDENCE PLANTATIONS, STATE OF', 'RIVERSIDE, COUNTY OF', 'SACRAMENTO, COUNTY OF', 'SALT LAKE, COUNTY OF', 'SAN ANTONIO, CITY OF', 'SAN BERNARDINO, COUNTY OF', 'SAN DIEGO, CITY OF', 'SAN FRANCISCO, CITY & COUNTY OF', 'SAN JOAQUIN, COUNTY OF', 'SAN JOSE, CITY OF', 'SAN MATEO, COUNTY OF', 'SANTA CLARA, COUNTY OF', 'SEATTLE, CITY OF', 'SHELBY, COUNTY OF', 'SNOHOMISH, COUNTY OF', 'SOUTH CAROLINA OFFICE OF STATE TREASURER', 'SOUTH DAKOTA, STATE OF', 'ST LOUIS, COUNTY OF', 'STANISLAUS, COUNTY OF', 'STATE OF NEW YORK', 'STATE OF WYOMING', 'STATE TREASURER, VERMONT OFFICE OF THE', 'SUFFOLK, COUNTY OF', 'SUMMIT, COUNTY OF', 'TARRANT COUNTY TEXAS (INC)', 'TRAVIS, COUNTY OF', 'TREASURER, OKLAHOMA STATE', 'TREASURY, MICHIGAN DEPARTMENT OF', 'UNION, COUNTY OF', 'UTAH, COUNTY OF', 'WAKE, COUNTY OF', 'WASHINGTON, COUNTY OF', 'WAYNE, COUNTY OF', 'WESTCHESTER, COUNTY OF', 'WILL COUNTY']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> crf-data-full/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of the money spent for each spending category out of the total spent in Denver? Sorted from the highest to the lowest</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>category_groupped=crf[crf['City'].str.lower()=='denver'].groupby('Spending category').sum()
percentage_denver=(category_groupped['Money spent to date']/category_groupped['Money spent to date'].sum()*100).sort_values(ascending=False)
percentage_denver</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>['percentage_denver']</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>category_groupped=crf[crf['City'].str.lower()=='denver'].groupby('Spending category').sum()
percentage_denver=(category_groupped['Money spent to date']/category_groupped['Money spent to date'].sum()*100).sort_values(ascending=False)
percentage_denver</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>category_groupped = crf[crf['City'].str.lower() == 'denver'].groupby(
    'Spending category').sum()
percentage_denver = (category_groupped['Money spent to date'] /
    category_groupped['Money spent to date'].sum() * 100).sort_values(ascending
    =False)
__output__ = percentage_denver
</code></pre>
        <p><span onclick="$('#var_output_f2356418').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f2356418" style="display: none;">
          
        <p><strong>Ref output variables:</strong> percentage_denver </p>
    
          <p>percentage_denver (Series):</p>
          <pre><code>Spending category
COVID-19 Testing and Contact Tracing                                         25.420552
Small Business Assistance                                                    13.360040
Housing Support                                                              10.098596
Budgeted Personnel and Services Diverted to a Substantially Different Use     9.569106
Facilitating Distance Learning                                                8.311198
                                                                               ...    
Items Not Listed Above                                                        1.116640
Administrative Expenses                                                       0.364562
Nursing Home Assistance                                                       0.315677
Unemployment Benefits                                                         0.039284
Select                                                                        0.000000
Name: Money spent to date, Length: 17, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> category_groupped, percentage_denver, __output__ </p>
    
          <p>category_groupped (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Award amount</th>
      <th>Sub-award amount</th>
      <th>Money spent to date</th>
    </tr>
    <tr>
      <th>Spending category</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Administrative Expenses</th>
      <td>2.422308e+10</td>
      <td>1.533937e+08</td>
      <td>1282795.43</td>
    </tr>
    <tr>
      <th>Budgeted Personnel and Services Diverted to a Substantially Different Use</th>
      <td>1.180723e+10</td>
      <td>7.742848e+07</td>
      <td>33671133.19</td>
    </tr>
    <tr>
      <th>COVID-19 Testing and Contact Tracing</th>
      <td>1.916629e+11</td>
      <td>2.248382e+08</td>
      <td>89448144.32</td>
    </tr>
    <tr>
      <th>Economic Support (Other than Small Business, Housing, and Food Assistance)</th>
      <td>3.747801e+10</td>
      <td>4.115227e+07</td>
      <td>23286139.56</td>
    </tr>
    <tr>
      <th>Facilitating Distance Learning</th>
      <td>1.955634e+10</td>
      <td>1.092733e+08</td>
      <td>29244890.80</td>
    </tr>
    <tr>
      <th>Food Programs</th>
      <td>1.135901e+10</td>
      <td>7.997928e+07</td>
      <td>17537630.84</td>
    </tr>
    <tr>
      <th>Housing Support</th>
      <td>8.153240e+10</td>
      <td>6.257633e+07</td>
      <td>35534265.05</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Nursing Home Assistance</th>
      <td>9.544188e+09</td>
      <td>6.615406e+07</td>
      <td>1110781.78</td>
    </tr>
    <tr>
      <th>Payroll for Public Health and Safety Employees</th>
      <td>1.211351e+10</td>
      <td>8.058416e+07</td>
      <td>5680660.40</td>
    </tr>
    <tr>
      <th>Personal Protective Equipment</th>
      <td>4.167123e+10</td>
      <td>1.013187e+08</td>
      <td>15454507.24</td>
    </tr>
    <tr>
      <th>Public Health Expenses</th>
      <td>1.329950e+11</td>
      <td>1.157776e+08</td>
      <td>25489268.92</td>
    </tr>
    <tr>
      <th>Select</th>
      <td>1.153540e+11</td>
      <td>6.120182e+07</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>Small Business Assistance</th>
      <td>1.694194e+10</td>
      <td>9.253834e+07</td>
      <td>47010419.04</td>
    </tr>
    <tr>
      <th>Unemployment Benefits</th>
      <td>3.347699e+09</td>
      <td>6.556858e+07</td>
      <td>138230.41</td>
    </tr>
  </tbody>
</table>
<p>17 rows × 3 columns</p>
      
          <p>percentage_denver (Series):</p>
          <pre><code>Spending category
COVID-19 Testing and Contact Tracing                                         25.420552
Small Business Assistance                                                    13.360040
Housing Support                                                              10.098596
Budgeted Personnel and Services Diverted to a Substantially Different Use     9.569106
Facilitating Distance Learning                                                8.311198
                                                                               ...    
Items Not Listed Above                                                        1.116640
Administrative Expenses                                                       0.364562
Nursing Home Assistance                                                       0.315677
Unemployment Benefits                                                         0.039284
Select                                                                        0.000000
Name: Money spent to date, Length: 17, dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Spending category
COVID-19 Testing and Contact Tracing                                         25.420552
Small Business Assistance                                                    13.360040
Housing Support                                                              10.098596
Budgeted Personnel and Services Diverted to a Substantially Different Use     9.569106
Facilitating Distance Learning                                                8.311198
                                                                               ...    
Items Not Listed Above                                                        1.116640
Administrative Expenses                                                       0.364562
Nursing Home Assistance                                                       0.315677
Unemployment Benefits                                                         0.039284
Select                                                                        0.000000
Name: Money spent to date, Length: 17, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('percentage_denver', 'percentage_denver', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> crf-data-full/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # From these categories, which of them are within the top five spending categories in TX-WILLIAMSON County?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>category_groupped = crf[crf['County']=='TX-WILLIAMSON'].groupby('Spending category').sum()
top_five_cat = (category_groupped['Money spent to date']/category_groupped['Money spent to date'].sum()).sort_values(ascending=False).head(5).index
denv_idx = percentage_denver.index
denv_idx[denv_idx.isin(top_five_cat)].values.tolist()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>category_groupped = crf[crf['County']=='TX-WILLIAMSON'].groupby('Spending category').sum()
top_five_cat = (category_groupped['Money spent to date']/category_groupped['Money spent to date'].sum()).sort_values(ascending=False).head(5).index
denv_idx = percentage_denver.index
denv_idx[denv_idx.isin(top_five_cat)].values.tolist()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>category_groupped = crf[crf['County'] == 'TX-WILLIAMSON'].groupby(
    'Spending category').sum()
top_five_cat = (category_groupped['Money spent to date'] /
    category_groupped['Money spent to date'].sum()).sort_values(ascending=False
    ).head(5).index
denv_idx = percentage_denver.index
__output__ = denv_idx[denv_idx.isin(top_five_cat)].values.tolist()
</code></pre>
        <p><span onclick="$('#var_output_d1b5b842').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d1b5b842" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['COVID-19 Testing and Contact Tracing', 'Public Health Expenses', 'Economic Support (Other than Small Business, Housing, and Food Assistance)', 'Improve Telework Capabilities of Public Employees', 'Items Not Listed Above']</code></pre>
      
        <p><strong>Hyp output variables:</strong> category_groupped, top_five_cat, denv_idx, __output__ </p>
    
          <p>category_groupped (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Award amount</th>
      <th>Sub-award amount</th>
      <th>Money spent to date</th>
    </tr>
    <tr>
      <th>Spending category</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Administrative Expenses</th>
      <td>2.061964e+10</td>
      <td>1.377911e+07</td>
      <td>3158357.36</td>
    </tr>
    <tr>
      <th>COVID-19 Testing and Contact Tracing</th>
      <td>8.078442e+09</td>
      <td>1.855315e+07</td>
      <td>10258106.22</td>
    </tr>
    <tr>
      <th>Economic Support (Other than Small Business, Housing, and Food Assistance)</th>
      <td>7.929523e+09</td>
      <td>1.239322e+07</td>
      <td>6887771.96</td>
    </tr>
    <tr>
      <th>Facilitating Distance Learning</th>
      <td>8.438530e+10</td>
      <td>9.422706e+06</td>
      <td>5928220.99</td>
    </tr>
    <tr>
      <th>Improve Telework Capabilities of Public Employees</th>
      <td>5.458827e+10</td>
      <td>5.539603e+07</td>
      <td>38130321.35</td>
    </tr>
    <tr>
      <th>Items Not Listed Above</th>
      <td>2.638295e+10</td>
      <td>5.067454e+07</td>
      <td>26691089.43</td>
    </tr>
    <tr>
      <th>Personal Protective Equipment</th>
      <td>1.782247e+10</td>
      <td>6.840297e+05</td>
      <td>258944.70</td>
    </tr>
    <tr>
      <th>Public Health Expenses</th>
      <td>2.860941e+10</td>
      <td>1.096016e+07</td>
      <td>10109880.53</td>
    </tr>
    <tr>
      <th>Select</th>
      <td>6.816142e+09</td>
      <td>4.158267e+07</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>Unemployment Benefits</th>
      <td>1.382478e+09</td>
      <td>4.653599e+05</td>
      <td>65642.00</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 3 columns</p>
      
          <p>top_five_cat (Index):</p>
          <pre><code>Index(['Improve Telework Capabilities of Public Employees',
       'Items Not Listed Above', 'COVID-19 Testing and Contact Tracing',
       'Public Health Expenses',
       'Economic Support (Other than Small Business, Housing, and Food Assistance)'],
      dtype='object', name='Spending category')</code></pre>
      
          <p>denv_idx (Index):</p>
          <pre><code>Index(['COVID-19 Testing and Contact Tracing', 'Small Business Assistance',
       'Housing Support',
       'Budgeted Personnel and Services Diverted to a Substantially Different Use',
       'Facilitating Distance Learning', 'Public Health Expenses',
       'Economic Support (Other than Small Business, Housing, and Food Assistance)',
       'Food Programs', 'Personal Protective Equipment',
       'Improve Telework Capabilities of Public Employees', 'Medical Expenses',
       'Payroll for Public Health and Safety Employees',
       'Items Not Listed Above', 'Administrative Expenses',
       'Nursing Home Assistance', 'Unemployment Benefits', 'Select'],
      dtype='object', name='Spending category')</code></pre>
      
          <p>__output__ (list):</p>
          <pre><code>['COVID-19 Testing and Contact Tracing', 'Public Health Expenses', 'Economic Support (Other than Small Business, Housing, and Food Assistance)', 'Improve Telework Capabilities of Public Employees', 'Items Not Listed Above']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.2, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> crf-data-full/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total money spent for each state rounded in millions? (Show the values sorted from the highest to the lowest)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(crf.groupby('State')['Money spent to date'].sum()/1_000_000).round().sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(crf.groupby('State')['Money spent to date'].sum()/1_000_000).round().sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = (crf.groupby('State')['Money spent to date'].sum() / 1000000
    ).round().sort_values(ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_a8f65153').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a8f65153" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>State
CA             15029.0
TX              9372.0
FL              8307.0
NY              7576.0
PA              4923.0
                ...   
100                0.0
IL-Illinois        0.0
EN                 0.0
QC                 0.0
co                 0.0
Name: Money spent to date, Length: 68, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>State
CA             15029.0
TX              9372.0
FL              8307.0
NY              7576.0
PA              4923.0
                ...   
100                0.0
IL-Illinois        0.0
EN                 0.0
QC                 0.0
co                 0.0
Name: Money spent to date, Length: 68, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> crf-data-full/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top five awarded sub-recipients in Colorado state?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>sub_receip=crf[crf['State']=='CO'].groupby('Sub-recipient')['Sub-award amount'].sum().sort_values(ascending=False)
sub_receip.head().index.tolist()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>sub_receip=crf[crf['State']=='CO'].groupby('Sub-recipient')['Sub-award amount'].sum().sort_values(ascending=False)
sub_receip.head().index.tolist()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>sub_receip = crf[crf['State'] == 'CO'].groupby('Sub-recipient')[
    'Sub-award amount'].sum().sort_values(ascending=False)
__output__ = sub_receip.head().index.tolist()
</code></pre>
        <p><span onclick="$('#var_output_5b40ee1c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5b40ee1c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['SCHOOL DISTRICT NO.1 IN THE CITY AND COUNTY OF DENVER', 'MULTIPLE RECIPIENTS', 'DOUGLAS, COUNTY OF', 'AURORA, CITY OF', 'DOUGLAS COUNTY SCHOOL DISTRICT RE1']</code></pre>
      
        <p><strong>Hyp output variables:</strong> sub_receip, __output__ </p>
    
          <p>sub_receip (Series):</p>
          <pre><code>Sub-recipient
SCHOOL DISTRICT NO.1 IN THE CITY AND COUNTY OF DENVER    8.877068e+08
MULTIPLE RECIPIENTS                                      8.108183e+08
DOUGLAS, COUNTY OF                                       4.824891e+08
AURORA, CITY OF                                          4.029037e+08
DOUGLAS COUNTY SCHOOL DISTRICT RE1                       3.886123e+08
                                                             ...     
EAST LARIMER COUNTY WATER DISTRICT                       0.000000e+00
DUCK COMPANY, THE                                        0.000000e+00
RICO FIRE PROTECTION DISTRICT                            0.000000e+00
RESOURCE EXCHANGE INC                                    0.000000e+00
TOWN CENTER METROPOLITAN DIST                            0.000000e+00
Name: Sub-award amount, Length: 1229, dtype: float64</code></pre>
      
          <p>__output__ (list):</p>
          <pre><code>['SCHOOL DISTRICT NO.1 IN THE CITY AND COUNTY OF DENVER', 'MULTIPLE RECIPIENTS', 'DOUGLAS, COUNTY OF', 'AURORA, CITY OF', 'DOUGLAS COUNTY SCHOOL DISTRICT RE1']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> crf-data-full/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of money spent out of the awarded amount for these sub-recipients?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>((crf.groupby('State').get_group('CO').groupby('Sub-recipient')['Money spent to date'].sum().loc[sub_receip.head().index])/sub_receip.head())*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>((crf.groupby('State').get_group('CO').groupby('Sub-recipient')['Money spent to date'].sum().loc[sub_receip.head().index])/sub_receip.head())*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = crf.groupby('State').get_group('CO').groupby('Sub-recipient')[
    'Money spent to date'].sum().loc[sub_receip.head().index
    ] / sub_receip.head() * 100
</code></pre>
        <p><span onclick="$('#var_output_6624ee25').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6624ee25" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Sub-recipient
SCHOOL DISTRICT NO.1 IN THE CITY AND COUNTY OF DENVER     8.564769
MULTIPLE RECIPIENTS                                      99.328115
DOUGLAS, COUNTY OF                                        6.314790
AURORA, CITY OF                                           8.409641
DOUGLAS COUNTY SCHOOL DISTRICT RE1                        7.618773
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Sub-recipient
SCHOOL DISTRICT NO.1 IN THE CITY AND COUNTY OF DENVER     8.564769
MULTIPLE RECIPIENTS                                      99.328115
DOUGLAS, COUNTY OF                                        6.314790
AURORA, CITY OF                                           8.409641
DOUGLAS COUNTY SCHOOL DISTRICT RE1                        7.618773
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> crf-data-full/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which County has the highest total money spent in these sub-recipients?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>top_county=crf[crf['Sub-recipient'].isin(sub_receip.head().index)].groupby('County')['Money spent to date'].sum()
top_county.idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>top_county=crf[crf['Sub-recipient'].isin(sub_receip.head().index)].groupby('County')['Money spent to date'].sum()
top_county.idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>top_county = crf[crf['Sub-recipient'].isin(sub_receip.head().index)].groupby(
    'County')['Money spent to date'].sum()
__output__ = top_county.idxmax()
</code></pre>
        <p><span onclick="$('#var_output_1150f760').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1150f760" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>TX-TRAVIS</code></pre>
      
        <p><strong>Hyp output variables:</strong> top_county, __output__ </p>
    
          <p>top_county (Series):</p>
          <pre><code>County
AK-ANCHORAGE      9.840487e+07
AK-BRISTOL BAY    4.516800e+04
AL-JEFFERSON      4.037145e+07
AL-MONTGOMERY     8.605466e+08
AR-PULASKI        2.022728e+08
                      ...     
WA-THURSTON       3.543428e+08
WI-DANE           6.590236e+08
WI-MILWAUKEE      1.089672e+08
WV-KANAWHA        8.415573e+08
WY-LARAMIE        2.167675e+08
Name: Money spent to date, Length: 176, dtype: float64</code></pre>
      
          <p>__output__ (str):</p>
          <pre><code>TX-TRAVIS</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> crf-data-full/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most used award type in this County?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>crf[crf['County']==top_county.idxmax()].groupby(['Prime recipient','Sub-recipient','Award type']).count().groupby('Award type').count().sort_values('Award amount',ascending=False).index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>crf[crf['County']==top_county.idxmax()].groupby(['Prime recipient','Sub-recipient','Award type']).count().groupby('Award type').count().sort_values('Award amount',ascending=False).index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = crf[crf['County'] == top_county.idxmax()].groupby([
    'Prime recipient', 'Sub-recipient', 'Award type']).count().groupby(
    'Award type').count().sort_values('Award amount', ascending=False).index[0]
</code></pre>
        <p><span onclick="$('#var_output_9a4fa0b3').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9a4fa0b3" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>CONTRACT</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>CONTRACT</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> crf-data-full/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Were Chicago’s amount of awards received higher than that of Phoenix’s?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(crf[crf['City'].str.lower()=='chicago'].groupby('Prime recipient')['Award amount'].mean().sum())>(crf[crf['City'].str.lower()=='phoenix'].groupby('Prime recipient')['Award amount'].mean().sum())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(crf[crf['City'].str.lower()=='chicago'].groupby('Prime recipient')['Award amount'].mean().sum())>(crf[crf['City'].str.lower()=='phoenix'].groupby('Prime recipient')['Award amount'].mean().sum())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = crf[crf['City'].str.lower() == 'chicago'].groupby(
    'Prime recipient')['Award amount'].mean().sum() > crf[crf['City'].str.
    lower() == 'phoenix'].groupby('Prime recipient')['Award amount'].mean(
    ).sum()
</code></pre>
        <p><span onclick="$('#var_output_f888e0ac').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f888e0ac" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (bool_):</p>
          <pre><code>True</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (bool_):</p>
          <pre><code>True</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ev-cars-user-reviews-india/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many new cars have a performance rating of more than 3?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(cars.groupby('Condition').get_group('New')['Performance']>3).value_counts().values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(cars.groupby('Condition').get_group('New')['Performance']>3).value_counts().values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = (cars.groupby('Condition').get_group('New')['Performance'] > 3
    ).value_counts().values[0]
</code></pre>
        <p><span onclick="$('#var_output_5c84b03e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5c84b03e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>55</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>55</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ev-cars-user-reviews-india/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Among the Hyundai Kona reviews, do those with a purchase history have average performance rating better than the ones that have not yet been purchased?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>hyundai=cars[cars['model_name']=='hyundai kona']
hyundai[hyundai['Condition']=='New']['Performance'].mean() > hyundai[hyundai['Condition']=='Not Purchased']['Performance'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>hyundai=cars[cars['model_name']=='hyundai kona']
hyundai[hyundai['Condition']=='New']['Performance'].mean() > hyundai[hyundai['Condition']=='Not Purchased']['Performance'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>hyundai = cars[cars['model_name'] == 'hyundai kona']
__output__ = hyundai[hyundai['Condition'] == 'New']['Performance'].mean(
    ) > hyundai[hyundai['Condition'] == 'Not Purchased']['Performance'].mean()
</code></pre>
        <p><span onclick="$('#var_output_dab09cb0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_dab09cb0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (bool_):</p>
          <pre><code>True</code></pre>
      
        <p><strong>Hyp output variables:</strong> hyundai, __output__ </p>
    
          <p>hyundai (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review</th>
      <th>Exterior</th>
      <th>Comfort</th>
      <th>Performance</th>
      <th>Fuel Economy</th>
      <th>Value for Money</th>
      <th>Condition</th>
      <th>driven</th>
      <th>rating</th>
      <th>model_name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Superb car like as fantastic as petroleum car. Speed is superb. I bought this 2 months ago and it looks premium and fantastic. The car is amazing. This is one of the most number 1 car in the sports car market.</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Few hundred kilometers</td>
      <td>5.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Anti national, worst service, worst customer car, worst dealings to indian customers, over priced, less mileage huge maintenance cost, have better options in India other than Hyundai.</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>New</td>
      <td>Haven't driven it</td>
      <td>0.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Super happy with it. The car is too good</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>New</td>
      <td>Few thousand kilometers</td>
      <td>5.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Pretty good car, smooth as a glider fast car, instant pickup and the range in one charge is also pretty good as well, so we can go more miles, a catchy car grab our eye balls everyone wants to ride this</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Few thousand kilometers</td>
      <td>5.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Price difference between petrol and electronic could not convince customer to buy electronic car. Difference amount can use for Life time use of petrol diesel car. Moreover long ride is big concern for charging. Only useful for fix route of almost 100 km. Price should be reduced and charging pump should be developed more.</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>Not Purchased</td>
      <td>Haven't driven it</td>
      <td>3.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Except for the short legroom in the rear, this is a performance car. I wish they are completely removed the boot as electrics will be only a second or third car in most families. This would have given far more leg room for rear passengers. Brilliant car otherwise.</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>New</td>
      <td>Few thousand kilometers</td>
      <td>5.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Good experience good driving experience all performance good very low maintenance good buying experience and driving experience and good looking wise and good performance etc. Low maintenance</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Did a short drive once</td>
      <td>5.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>27</th>
      <td>It is very good car which help the country from pollution and saves the environment. Its maintenance and servicing cost is also very low as compared to other cars therefore in future we see electric cars between us which is very helpful for our country .if I bought this car then I will be very thankful to that person who had made this car</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Haven't driven it</td>
      <td>5.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>28</th>
      <td>No 1 car in india electric car. Car is so exelent .Speed are so speedy .This cars is no maintance . Performance so very nice .and looks are so beautifull.and very comfartabel car. Engine is so highe perfomance .and good looking designs. And aagad paglchad ne badhi rite jordar car banava ma aavi che .aa car ne game tem chalao moj aavi jay .indias first electirv car so more n more buy this car . So 1 millon s cars sell only 1 months thats perfomance . So good car thankyou so much Hundai</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Few hundred kilometers</td>
      <td>5.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Hyundai Kona Electric is extremely good car but expensive for its size and performance. We should wait for reduction in GST and road tax which is likely to reduce the price by couple of lakh rupees. If or as And when car is available for Rs 20-22 lakh I for sure will buy it. Electric cars indeed would be cheaper to operate.</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>Not Purchased</td>
      <td>Haven't driven it</td>
      <td>3.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>30</th>
      <td>An i20 for 30 lac. Good. That's a car worth buying. 452 mileage arai certified. That's a joke right. Actual will be half than claimed. I'm waiting for maruti to launch it's electric version of wagon R for the price of 12 lac. What if ur warranty runs out and you need battery change then what. Re finance it again.</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>Not Purchased</td>
      <td>Haven't driven it</td>
      <td>2.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Car is amazing car comes with every safety features , but need charging points all over the country and price is higher can't able to buy for middle class people i my opinion they should have base variant in that case price will be affordable for everyone i hope hyndai will launch more basic variant electric cars</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>Not Purchased</td>
      <td>Few hundred kilometers</td>
      <td>4.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>32</th>
      <td>So the future of Indian cars have arrived! Hyundai certainly has heated up the competition in EV segment too now...As currently the Kona Electric is completely build unit that's why the initial cost is looking a bit high because of import tax etc..I hope that it gets upto 20 lakhs after complete manufacturing in India! This is a bang on car and all the best to Hyundai for this!</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>Not Purchased</td>
      <td>Haven't driven it</td>
      <td>5.0</td>
      <td>hyundai kona</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Wow its an awesome car. And a great car for all people. But they are not launched by manual gear. This are the mistakes. If they launched the manual gear its very great. Please fix an manual gear as soon as posible. While iam seeing the Hyundai car all are awesome. So all of u just trust the Hyundai and buy the car.</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Did a short drive once</td>
      <td>5.0</td>
      <td>hyundai kona</td>
    </tr>
  </tbody>
</table>
<p>34 rows × 10 columns</p>
      
          <p>__output__ (bool_):</p>
          <pre><code>True</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ev-cars-user-reviews-india/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new column called "Review's Word Count" and Show the rating of the shortest review</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>cars["Review's Word Count"]=cars['review'].str.split().str.len()
cars.iloc[cars["Review's Word Count"].idxmin()]['rating']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>cars["Review's Word Count"]=cars['review'].str.split().str.len()
cars.iloc[cars["Review's Word Count"].idxmin()]['rating']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>cars["Review's Word Count"] = cars['review'].str.split().str.len()
__output__ = cars.iloc[cars["Review's Word Count"].idxmin()]['rating']
</code></pre>
        <p><span onclick="$('#var_output_bda97d03').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bda97d03" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>5.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> cars, __output__ </p>
    
          <p>cars (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review</th>
      <th>Exterior</th>
      <th>Comfort</th>
      <th>Performance</th>
      <th>Fuel Economy</th>
      <th>Value for Money</th>
      <th>Condition</th>
      <th>driven</th>
      <th>rating</th>
      <th>model_name</th>
      <th>Review's Word Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Superb car like as fantastic as petroleum car. Speed is superb. I bought this 2 months ago and it looks premium and fantastic. The car is amazing. This is one of the most number 1 car in the sports car market.</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Few hundred kilometers</td>
      <td>5.0</td>
      <td>hyundai kona</td>
      <td>41</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Anti national, worst service, worst customer car, worst dealings to indian customers, over priced, less mileage huge maintenance cost, have better options in India other than Hyundai.</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>New</td>
      <td>Haven't driven it</td>
      <td>0.0</td>
      <td>hyundai kona</td>
      <td>27</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Super happy with it. The car is too good</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>New</td>
      <td>Few thousand kilometers</td>
      <td>5.0</td>
      <td>hyundai kona</td>
      <td>9</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Pretty good car, smooth as a glider fast car, instant pickup and the range in one charge is also pretty good as well, so we can go more miles, a catchy car grab our eye balls everyone wants to ride this</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Few thousand kilometers</td>
      <td>5.0</td>
      <td>hyundai kona</td>
      <td>41</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Price difference between petrol and electronic could not convince customer to buy electronic car. Difference amount can use for Life time use of petrol diesel car. Moreover long ride is big concern for charging. Only useful for fix route of almost 100 km. Price should be reduced and charging pump should be developed more.</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>Not Purchased</td>
      <td>Haven't driven it</td>
      <td>3.0</td>
      <td>hyundai kona</td>
      <td>54</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Except for the short legroom in the rear, this is a performance car. I wish they are completely removed the boot as electrics will be only a second or third car in most families. This would have given far more leg room for rear passengers. Brilliant car otherwise.</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>New</td>
      <td>Few thousand kilometers</td>
      <td>5.0</td>
      <td>hyundai kona</td>
      <td>48</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Good experience good driving experience all performance good very low maintenance good buying experience and driving experience and good looking wise and good performance etc. Low maintenance</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Did a short drive once</td>
      <td>5.0</td>
      <td>hyundai kona</td>
      <td>27</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>122</th>
      <td>Riding experience was okay. It still makes a lot of noise that an electric car should not make. Looks good but the wheels are way too small which gives it a donkey like look. The colors are great but service staff was very rude. After the sale has been made the car does make a lot of noises and it is not very fast as an electric should be, and people who thump their chests on the name of Tata being the Indian brand, let me say that all the components are Chinese. Pros: electric, cons: price, performance, range anxiety, charging time. One must wait for under 10 lac EVs (2-3 years wait) or buy Nexon EV if you really have to.</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>New</td>
      <td>Few hundred kilometers</td>
      <td>0.0</td>
      <td>tata tigor ev</td>
      <td>122</td>
    </tr>
    <tr>
      <th>123</th>
      <td>It's great experience to drive this ev car and it is perfectly design sedan car can beat any other sedan .... Like ev cars you can compare budget sedan car to your mileage concern... As per the torque or pick up you get never complain to Tata</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Did a short drive once</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>47</td>
    </tr>
    <tr>
      <th>124</th>
      <td>A good car but overpriced a little. The starting price at 11 L would have been better for customers. Though features and mileage looks good for city drive. What gives us fear is the Tata zconnect app subscription which may be free for only one year. I wish subscription won't burn pockets as that is still in development and not up to mark yet to be charged. And also little worried about Soc drop issues.</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>New</td>
      <td>Did a short drive once</td>
      <td>4.0</td>
      <td>tata tigor ev</td>
      <td>75</td>
    </tr>
    <tr>
      <th>125</th>
      <td>Excellent vehicle driving dynamics and EVs are now at affordable price. This is breakthrough product in market for small car with such aspirational single charge distance and extra ordinary features.</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>Not Purchased</td>
      <td>Did a short drive once</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>30</td>
    </tr>
    <tr>
      <th>126</th>
      <td>After government subsidy it becomes cheaper than diesel car in its segment, so good car for city use as well as for short distance trip. good cabin and boot space, good pick up as 74 bhp and 170 NM torque is almost equal to ddis diesel engine of maruti. Battery and motor warranty of 8 years and 160000 km so complete Peace of mind.</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>Not Purchased</td>
      <td>Did a short drive once</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>64</td>
    </tr>
    <tr>
      <th>127</th>
      <td>Yes I love tata products .. A true Indian company.. But I thought tata Tigor EV price will be 11 lac on road for top end model.. But today company released the model and price. mentioned price not reachable to the even above middle class. And all the states are not giving subsidy.. I belong to AP.. So Tata group please launch Tiago EV @9 lac on road price. With 275 km for single charge.. Thank you TATA group.</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>Not Purchased</td>
      <td>Haven't driven it</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>79</td>
    </tr>
    <tr>
      <th>128</th>
      <td>I am planning to buy. I am driving this car since long and its amazing. Its grey colour is fantastic and a blue line is superb. I don't know about his service Its advantage is its electric vehicle. No use of petrol diesel or gas. Disadvantage is nothing in my way. Tata is a good manufacturer of cars because of its safety, I owned a Nexon Zest, Nano, and Indigo . Zest and Nexon performance is excellent in service cost and fuel economy cost and maintenance cost is in the budget</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>Not Purchased</td>
      <td>Few hundred kilometers</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>91</td>
    </tr>
  </tbody>
</table>
<p>129 rows × 11 columns</p>
      
          <p>__output__ (float64):</p>
          <pre><code>5.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ev-cars-user-reviews-india/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which model has the highest average word count?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>models=cars.groupby('model_name')["Review's Word Count"].mean().idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>['models']</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>models=cars.groupby('model_name')["Review's Word Count"].mean().idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = models = cars.groupby('model_name')["Review's Word Count"].mean(
    ).idxmax()
</code></pre>
        <p><span onclick="$('#var_output_e37afb98').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e37afb98" style="display: none;">
          
        <p><strong>Ref output variables:</strong> models </p>
    
          <p>models (str):</p>
          <pre><code>tata tigor ev</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__, models </p>
    
          <p>__output__ (str):</p>
          <pre><code>tata tigor ev</code></pre>
      
          <p>models (str):</p>
          <pre><code>tata tigor ev</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', 'models', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ev-cars-user-reviews-india/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many reviews are for used cars for this model?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_model=cars.groupby('model_name').get_group(models)
df_model[df_model['Condition']=='Used'].shape[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_model=cars.groupby('model_name').get_group(models)
df_model[df_model['Condition']=='Used'].shape[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_model = cars.groupby('model_name').get_group(models)
__output__ = df_model[df_model['Condition'] == 'Used'].shape[0]
</code></pre>
        <p><span onclick="$('#var_output_27e93a88').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_27e93a88" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>4</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_model, __output__ </p>
    
          <p>df_model (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review</th>
      <th>Exterior</th>
      <th>Comfort</th>
      <th>Performance</th>
      <th>Fuel Economy</th>
      <th>Value for Money</th>
      <th>Condition</th>
      <th>driven</th>
      <th>rating</th>
      <th>model_name</th>
      <th>Review's Word Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>109</th>
      <td>Need to improve body style.It's amazing and drives smoothly.I am happy to share feedback to each one. Very great experience and also come with lot of benefits. Fuel saving car.</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Few thousand kilometers</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>30</td>
    </tr>
    <tr>
      <th>110</th>
      <td>Tata EV has lot of flaws, worst part is service center has no clue about the car and how it works. Car broke down twice mid way and road side assistance took 2-3 hours. Plus no help problem service center. They don't know what's wrong. No help from Tata motors After sales is pathetic Car has lot of problem Cons: 1. Service center has no knowledge about the EV segment 2. Lot of cost cutting even in top models 3. Range is way to less than promised 4. In 2 months only range well drastically 5. Car broke down twice in first 4 months of purchase 6. Road side assistance is useless takes 2-3 hours. 7. Dealership don't help</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>New</td>
      <td>Few thousand kilometers</td>
      <td>0.0</td>
      <td>tata tigor ev</td>
      <td>119</td>
    </tr>
    <tr>
      <th>111</th>
      <td>Very nice car , environmental friendly i like this car , i am very happy to buy this car thank you Mr. Ratan Tata, i suggested to all must purchase this car for all India people.</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Few thousand kilometers</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>36</td>
    </tr>
    <tr>
      <th>112</th>
      <td>Company did not provide slow charging station with my new car, Had to take the car to nearest charging station, one Nexon was also charging next to my Tigor, Nexon went after charging, while after 30 minutes of charging ( FIRST CHARGE) may car stopped completely, Tata towed my car back to their workshop and since last 5 days I am waiting for my car, no reason given. This car is completely un reliable and my suggestion to all users not to buy this car. MH46CE0908. Bought from Fortune Motors Nerul. I am going to consumer forum and take every rupee spent from TATA.</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>New</td>
      <td>Haven't driven it</td>
      <td>0.0</td>
      <td>tata tigor ev</td>
      <td>104</td>
    </tr>
    <tr>
      <th>113</th>
      <td>Servicing and maintenance overall good and good mileage and comfortable driving , look wise ok and smooth driving, no voice and no pollution and Tata motor is also my favourite, service is very good.</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>Not Purchased</td>
      <td>Few hundred kilometers</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>34</td>
    </tr>
    <tr>
      <th>114</th>
      <td>Don't buy &amp; it's a very costly car. Not the best performance car. Tata Nexon ev is the best car among all types. Tigor is a low driving positioned car, not best control, not the best fuel economy.</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>New</td>
      <td>Haven't driven it</td>
      <td>0.0</td>
      <td>tata tigor ev</td>
      <td>38</td>
    </tr>
    <tr>
      <th>115</th>
      <td>Nice car, amazing performance and good smooth performance from Tata good performance by in this price nice car for city ride and highway thanks for Tata car I say this good for future.</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>Used</td>
      <td>Few thousand kilometers</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>33</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>122</th>
      <td>Riding experience was okay. It still makes a lot of noise that an electric car should not make. Looks good but the wheels are way too small which gives it a donkey like look. The colors are great but service staff was very rude. After the sale has been made the car does make a lot of noises and it is not very fast as an electric should be, and people who thump their chests on the name of Tata being the Indian brand, let me say that all the components are Chinese. Pros: electric, cons: price, performance, range anxiety, charging time. One must wait for under 10 lac EVs (2-3 years wait) or buy Nexon EV if you really have to.</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>New</td>
      <td>Few hundred kilometers</td>
      <td>0.0</td>
      <td>tata tigor ev</td>
      <td>122</td>
    </tr>
    <tr>
      <th>123</th>
      <td>It's great experience to drive this ev car and it is perfectly design sedan car can beat any other sedan .... Like ev cars you can compare budget sedan car to your mileage concern... As per the torque or pick up you get never complain to Tata</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>New</td>
      <td>Did a short drive once</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>47</td>
    </tr>
    <tr>
      <th>124</th>
      <td>A good car but overpriced a little. The starting price at 11 L would have been better for customers. Though features and mileage looks good for city drive. What gives us fear is the Tata zconnect app subscription which may be free for only one year. I wish subscription won't burn pockets as that is still in development and not up to mark yet to be charged. And also little worried about Soc drop issues.</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>New</td>
      <td>Did a short drive once</td>
      <td>4.0</td>
      <td>tata tigor ev</td>
      <td>75</td>
    </tr>
    <tr>
      <th>125</th>
      <td>Excellent vehicle driving dynamics and EVs are now at affordable price. This is breakthrough product in market for small car with such aspirational single charge distance and extra ordinary features.</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>Not Purchased</td>
      <td>Did a short drive once</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>30</td>
    </tr>
    <tr>
      <th>126</th>
      <td>After government subsidy it becomes cheaper than diesel car in its segment, so good car for city use as well as for short distance trip. good cabin and boot space, good pick up as 74 bhp and 170 NM torque is almost equal to ddis diesel engine of maruti. Battery and motor warranty of 8 years and 160000 km so complete Peace of mind.</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>Not Purchased</td>
      <td>Did a short drive once</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>64</td>
    </tr>
    <tr>
      <th>127</th>
      <td>Yes I love tata products .. A true Indian company.. But I thought tata Tigor EV price will be 11 lac on road for top end model.. But today company released the model and price. mentioned price not reachable to the even above middle class. And all the states are not giving subsidy.. I belong to AP.. So Tata group please launch Tiago EV @9 lac on road price. With 275 km for single charge.. Thank you TATA group.</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>Not Purchased</td>
      <td>Haven't driven it</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>79</td>
    </tr>
    <tr>
      <th>128</th>
      <td>I am planning to buy. I am driving this car since long and its amazing. Its grey colour is fantastic and a blue line is superb. I don't know about his service Its advantage is its electric vehicle. No use of petrol diesel or gas. Disadvantage is nothing in my way. Tata is a good manufacturer of cars because of its safety, I owned a Nexon Zest, Nano, and Indigo . Zest and Nexon performance is excellent in service cost and fuel economy cost and maintenance cost is in the budget</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>Not Purchased</td>
      <td>Few hundred kilometers</td>
      <td>5.0</td>
      <td>tata tigor ev</td>
      <td>91</td>
    </tr>
  </tbody>
</table>
<p>20 rows × 11 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>4</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ev-cars-user-reviews-india/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top five models with most number of bikes having mileage less than 5000 kilometers</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>bikes_models=bikes[bikes['Ridden for']=='< 5000 kms'].groupby('Model Name').count()['Ridden for'].sort_values(ascending=False).head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>['bikes_models']</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>bikes_models=bikes[bikes['Ridden for']=='< 5000 kms'].groupby('Model Name').count()['Ridden for'].sort_values(ascending=False).head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = bikes_models = bikes[bikes['Ridden for'] == '< 5000 kms'].groupby(
    'Model Name').count()['Ridden for'].sort_values(ascending=False).head(5)
</code></pre>
        <p><span onclick="$('#var_output_a7416f14').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a7416f14" style="display: none;">
          
        <p><strong>Ref output variables:</strong> bikes_models </p>
    
          <p>bikes_models (Series):</p>
          <pre><code>Model Name
Hero Electric Flash     51
Hero Electric Optima    48
Okinawa Praise          46
PURE EV EPluto 7G       33
Ather 450X              22
Name: Ridden for, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__, bikes_models </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Model Name
Hero Electric Flash     51
Hero Electric Optima    48
Okinawa Praise          46
PURE EV EPluto 7G       33
Ather 450X              22
Name: Ridden for, dtype: int64</code></pre>
      
          <p>bikes_models (Series):</p>
          <pre><code>Model Name
Hero Electric Flash     51
Hero Electric Optima    48
Okinawa Praise          46
PURE EV EPluto 7G       33
Ather 450X              22
Name: Ridden for, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', 'bikes_models', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ev-cars-user-reviews-india/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which of these models has the highest comfort score on average?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>model=bikes.groupby('Model Name')['Comfort'].mean().loc[bikes_models.index].idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>['model']</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>model=bikes.groupby('Model Name')['Comfort'].mean().loc[bikes_models.index].idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = model = bikes.groupby('Model Name')['Comfort'].mean().loc[
    bikes_models.index].idxmax()
</code></pre>
        <p><span onclick="$('#var_output_0091b358').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0091b358" style="display: none;">
          
        <p><strong>Ref output variables:</strong> model </p>
    
          <p>model (str):</p>
          <pre><code>Ather 450X</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__, model </p>
    
          <p>__output__ (str):</p>
          <pre><code>Ather 450X</code></pre>
      
          <p>model (str):</p>
          <pre><code>Ather 450X</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', 'model', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ev-cars-user-reviews-india/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are those models mostly used for?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>bikes[(bikes['Model Name']==model)].groupby('Used it for').count()['Model Name'].index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>bikes[(bikes['Model Name']==model)].groupby('Used it for').count()['Model Name'].index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = bikes[bikes['Model Name'] == model].groupby('Used it for').count(
    )['Model Name'].index[0]
</code></pre>
        <p><span onclick="$('#var_output_57a9cd02').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_57a9cd02" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Daily Commute</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Daily Commute</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ev-cars-user-reviews-india/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many times the word scooter was mentioned in the bike's reviews?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(bikes['review'].str.split().explode().str.lower()=='scooter').value_counts()[1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(bikes['review'].str.split().explode().str.lower()=='scooter').value_counts()[1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = (bikes['review'].str.split().explode().str.lower() == 'scooter'
    ).value_counts()[1]
</code></pre>
        <p><span onclick="$('#var_output_83f61cd0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_83f61cd0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>331</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>331</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ev-cars-user-reviews-india/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show a list of words that were mentioned only once in the reviews</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>words=bikes['review'].str.split().explode().value_counts()==1
list(words[words].index)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>words=bikes['review'].str.split().explode().value_counts()==1
list(words[words].index)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>words = bikes['review'].str.split().explode().value_counts() == 1
__output__ = list(words[words].index)
</code></pre>
        <p><span onclick="$('#var_output_1d565449').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1d565449" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['50kmph.', 'even,', 'season.', 'Ask', 'Taken', 'good.Bad', 'soon..', 'say.', 'Felt', 'society.', 'girls', 'economical.', 'destroy', 'first.', 'batteries)', 'term.', 'Screws', 'initially,', 'highway.', 'catchy.', 'fighting', 'blaming', 'customized', 'pockets.', 'Available', 'discounts', 'Expertise', 'ecstatic.', 'acquaintances.', 'professional', 'decisions.', 'Doesn’t', 'hesitant', 'jammed', 'Safety-wise', 'zero-rating.', '1,2,4', 'hs500.', '.Waste', 'wise.', 'Economical', 'agna', 'jp', 'arrival,', '5weeks.', 'Headlights', 'improper', 'Experienced', 'pieces', '5.Pros', 'Environment', 'population.', 'Large', 'trucks', 'flicks', 'little.', 'Cheated', 'lx(hspl)', 'motocrop,', 'company..', 'Fail', 'costed', '3.Details', 'satisfying', '4.Servicing', 'slips', 'easily.Moreover', 'tusha', ',colour', ';its', 'pleasant', '.Little', 'lasting.', 'dilemma,', '!!...Or', 'decent,', '"good', 'old",', 'fossil', 'fueled', 'Outrageous....Keep', 'traders', 'Sitamarhi', 'Bihar.', 'pls', 'Note', 'best,', 'Shockers', 'joking...Serious.', 'minimize', 'everywhere', 'hilly', 'backwards.', 'Etc..', 'proof.', 'lx', 'Bhavya', 'Unfortunately', 'died.', 'news,', 'doctors', 'announcing', 'patient.', 'victim.', '45%', 'st.', 'Thomas', 'agency', 'thrissur', '2018.After', 'down.This', 'good.This', 'emission', 'response,', 'Monopoly', 'seniors', 'immediate', 'melt', 'rs1000', 'tighten', 'its.', 'indicator,', 'manufactures', 'impatiently', 'convert', 'mobility', 'e-mobility.', 'notable', 'disrupting', 'leans', 'bullock', 'cart.', 'presently', 'sustains', 'cycles.', 'Small', "kid's", 'lithium.', 'avon', 'optima.', "dealer's", 'enquiries.', 'pump.', 'sits', 'side)', 'venturing', 'emission.', 'carrying..', 'Moreover', 'levels', '40kms', 'Probably', 'disagreed', "week's", 'serving5.Loding', '100kg,', '32km', 'lover', 'consumption.', 'lockdown.', 'Congratulations', 'developer', 'scout', 'day.This', 'Capacity', 'member', 'solo', 'min', 'Four', 'organization.', 'onboard.', 'slow.The', 'scooter.Servicing', 'priority.', 'At-last', 'steady,', 'mopey', 'Spending', 'tears', 'Good2.Load', '3.Good', 'body4', 'Book', 'even.', 'mismanaged', "toy's", 'counterparts', 'Reasons', 'whats-app.', 'goodwill', 'verdict....', 'youngster,', '2017.', 'automobiles', 'gasoline', 'income.', 'earning!Perks', 'verdict.', 'Everyone', 'global', 'warming.', 'kilometre,', ',worst', 'assurance', 'truth', 'Absolutely!Apart', 'eco-friendly,', 'pockets', 'Plus,', 'beauty', 'used,', 'sometimes,no', 'stiffen', 'optimus', 'interval', 'colour.', 'frequently,on', 'Absolute', 'stops.', '50km.Better', '40km.', 'occasions,', 'precisely', 'smoothie', 'peoples.', 'wreck', '12000/', 'battery.no', '35000.', 'dissatisfied', 'beautiful,eco', 'Reasons.', "what's-app.", 'depreciation', 'p.A.', 'benefits,', 'tax.If', 'Calculate', 'now!!!.', 'Everbody', 'stares', 'capital', 'investment·', 'low-cost', 'maintenance·', 'Furthermore,', 'annual', 'They’re', 'eligible', 'everybody.', 'e-vehicles', '20.', 'reviews.', 'solo.', '1.They', 'e-bikes·', 'cost·', 'bored', 'sometime', '30km/hr', 'avg.4.', '(10000rs', 'approx.)5.', 'problem.If', 'writes', 'cruz', 'owing', 'engine,', 'rto,', 'licence.', 'No,', 'reasonable.2.', 'enough.3.', 'kolhapur', 'separately', 'beginning.', 'careful.', 'although', '250watt', 'telescopic', 'forks', 'Aug', 'undoubtedly', 'Pros.', 'Useful', 'OTA', 'Cons.', 'replacement,', 'goa,', 'upgrade...Thus', 'incentive!', '1,90,000!', 'excellent,', 'wheeler,', 'Introduce', 'rules.', 'Basically', 'retailers', 'year.I', 'it.In', 'issuing', 'separate', 'invoices', '(1,39,000)', 'incentive', 'it.I', 'Electrically', 'chargeable.', "Doesn't", 'licences', "drive,doesn't", 'wear.I', '1/2', 'satisfying.', 'durable', '3-4hours', 'backup.', 'beautiful.', 'instructions', 'instructions.Its', 'petrol-diesel', 'Things', 'b4', 'ecosystem', '1.6L', 'W.', 'bite', 'daughters', 'said.', 'maintenance.I', 'four', 'day.My', 'fulfill', 'thanks.', 'Duke', 'up-to', '80kmph', '40km/hr.', 'Gives', 'goid', 'absorber.', 'most.I', 'much.It', 'designs', 'this.There', 'IQUBE', 'VS', 'ATHER.', 'ATHER', 'rs..no', 'paise', 'clients', 'trustworthy.', 'product....', 'la', 'also.,', 'model.,', 'extra.', 'Proper', 'needed,', 'screw-up', 'wished', 'bog', 'Let', 'fearful', 'over-load', 'damage', 'depressed', 'soon..Much', '1,68,989/-', '1,39,989!', 'vehicle.Buying', 'resolved,', 'constraint', 'mileage.Looks', 'e-scooty', 'suffer', 'collected', 'yesterday!', 'experience...', 'effortless', 'ride..', 'shady', 'billing', 'invoicing', 'manager,', 'dept', 'dark.', 'court.The', '11th', 'Height', 'will.be', 'Connected', 'yesterday', '13th', 'hopefully', 'facility.', 'parents', 'Product', 'measurable.', '>15', 'tilt', 'cornering', 'balance.', 'wet', 'monsoons.', 'structure', 'prolong', 'insured', 'biking', 'absorbers.', 'Extra', 'maps', 'heaviest', '(bearing)', 'higher.', 'noticed', 'referring', 'friends..', 'across.', '1)buying', 'fulfilled', 'Bajaj.', 'Insurance', "EV's", ',over', '1,00,000', '4g,5g,125', 'Ludhiana', 'Chandigarh', 'positively.', 'department,', 'executive.', 'feasible', 'approached', 'judge', 'rims', 'colors,', 'great.Looks', "who's", 'license.', 'Servicing:', 'Bangalore,', 'Price,', '(government', '29k', 'discount)', 'After-sales', 'Long', 'alternative,', 'fiber.', '43000/-', 'learn', 'helping', 'spouse.', 'basis', 'perfectly', 'jam', 'beam.', 'mudguard,', 'mechanics,', 'costumer', 'spear', '(expected).', 'operational', '.Also', 'millage', 'monthly', 'tag.', 'Drum', 'Rainy', 'moist', 'seasons', 'jelly', 'Subscriptions', 'hated', 'described.', 'Previous', '1.2', '1.8', 'liter', 'faster.', '60-62', 'Honestly', 'marvel.', 'Hassle', 'technicians...Replaced', 'ather450x,', 'range....Not', '72ah', 'seamlessly', 'kilometres', '2.4k', 'category', 'maximize', 'volumes', 'grow', 'models,', 'job*****.', 'garage', '..Now', 'e-bike\\car', '*tork*', 'market..', 'brushless', 'fueling', 'sufficient.', 'Trust', 'omr', 'express', 'cautious', 'sync', 'Rather', 'peaceful', 'Public', 'properly,', '15km', '(tested', 'self)', '15%', '10K', 'kickstart', 'two-wheelers', 'fairly', 'fz-s,', "motorcycle's", 'Govt', 'account.', 'absobers', 'vehicles.Option', "i'll", 'x', 'e-motorcycle.', 'worrying,', 'wherever', 'picnic', 'green.', 'Comfort', 'Pricing', 'suggestions', 'ports.', '1.36lakh.', 'market.And', 'vapi-gujarat', 'transporters', 'jan,2019....Again', '2019.....Hope', 'postponed', 'further....I', 'date’s', 'postpnd', 'one......Just', 'good...But', 'north.', 'centres.', 'aspects,', 'gonna', 'relief', '....I', 'year....1st', 'dec,2018,', 'mind,totally', 'presence,', 'tension,', 'tenson,', 'system,just', 'deciding', 'sight.', 'difficulty', 'Ather,', 'complaints,', '100k', 'prototype.', 'converted', '11l', 'points.', 'nvh', 'Those', '450X', 'pick-up', 'reviewing', 'angle.', 'pathetic,', 'pre-booked', 'ad', 'Ride.', 'Unbelievable', 'boing', '737', 'JET.', '4G', 'connectivity...', 'Accuracy', 'research', 'development.', 'thailand', 'click', 'total.', 'aya', 'extreme', 'Superior', 'dates...', 'Few', 'TORK', 'list,', 'commitments', 'consumers,', 'firm', 'struggling', '450is', 'fulfills', 'regeneration', 'coasting.', 'stability', 'arrangement.', 'timeline', '9.', 'impressive.', '105kmph', 'westend', 'aundh', 'sat', '45days.', 'Combi', 'lover.', 'whilst', 'traveling,', 'unhelpful.', 'woman', 'passports', 'generally', 'unpleasant', 'paperwork.', 'information.', 'maintained,', 'rented,', 'prior', 'ended', 'renting', 'confusing', 'receipt', 'attributes.', 'lagging', 'optional', 'indeed', '3.No', '4.Stylish', 'streamline', '5.Abs', 'abs,', 'rivals', 'glamour', 'crazy', 't6', 'super.....', 'X.', 'benchmark', 'agile', 'commuter,', 'smart,', 'ecofriendly', 'cost-effective', 'indian.', 'Weighing', 'kg,', 'Wonderful', 'invest.', 'tad', 'proven', 'commodity', 'kratos-', '-make', 'ridden,', 'fighter', '24.Water', '25.Company', 'ups.', '1.36lakh', '(electric,', 'design,mobile', 'manufacturers,top', 'chaning', '18.Dual', '19.Good', '20.Bike', '21.Mobile', '22.Family', 'suited.23.City', 'street', '12.Helmet', '13.Mobile', '14.Cloud', '15.Cloud', 'detects', 'malfunctioning', '16.No', '17.No', '6.Safety', '7.Tft', 'interface', '8.Tubeless', '9.Easily', 'track', 'records', '11.Good', 'unmatchable.', "brand's", 'wrathful.', 'obviously', 'signals', 'dashboard.', 'grid', 'finished', 'madhapur,', 'Hyderabad...Excellent', 'reception', "apple's", 'perfection', 'core.', 'flaws', 'glitches.', 'choice.Coming', 'tyres,abs', 'good.I', 'not.Because', 'nodes', 'enjoy.', 'conscious', 'walked', 'speed,charging', 'time,water', 'battery)', 'buying.When', 'range(100km)', 'suggests', '0-100', 'stars,if', 'quietly', 'am..', 'Belt', 'priced.', 'rs1.51/-', 'Chennai)', '2500/-', '5000kms', 'desperately', 'win', 'Others', 'oppo,', 'vivo', 'mi.', '|From', 'touring', 'somehow', 'Unexpected', 'unexpected', 'shocked', 'amazed', 'mailed', 'reply.', 'reviewed', '1000kms', 'neutralise', 'Change', 'oil.', 'safe.', 'phone.Very', 'e-moto', 'roads.Last', 'conserve', 'proactive', 'vehicular', 'greenhouse', 'becoming', 'superpower', 'e-mobility', 'AMO', 'two-wheelers.', 'kratos.', 'posture', 'costliest', '1.65', 'emerging', '2022,', 'launched.', 'Seeing', 'field.', 'thief', 'market.For', 'ways', 'kratos,', '•this', 'king', '2400/-', 'annum', 'two,', 'competitors', 'worth.', 'race.', 'kick', '100t', 'extorting', 'fancy', 'order.', 'swadeshi-made', 'vehicle!!!', 'Reverse', 'fine.', '(km/charge)', 'pollachi.', 'removable,', 'be.', 'doubts.', 'shared', 'commuters,', 'world,', 'etc.).', 'pune,', 'already.', 'tamilnadu', 'fore', 'loving', 'officers', 'office.', 's!', 'penetrate', 'felt.', 'Samsung', 'knowledgeable', 'supportive.', 'characteristics', 'r.................', 'Glad', 'assistance,', 'worked.', '50%', 'joke', 'Nexon', 'opinion,', 'investors.', 'schedule', '(203', 'centers,', 'dec,21.', 'members', 'Elderly', 'hype.', 'attends', 'lift.', 'kanpur,', 'lucknow.', 'development', 'ditched', 'coordination', 'commitment', 'exceeding', 'aspect', '"bikewale"', 'wrong,', 'coverage', 'framing', 'cibil', '790,', '1.56', 'lac.', 'occasional', 'lags', 'interface,', "ola's", 'books.', 'necessity', '135-140', 'Perhaps', 'messages', 'march:', 'canceling', 'stating', 'section.', 'turner!', '40%', 'buggy', 'December.', 'happened.', 'Jan.', '(this', 'date).', 'Nevertheless,', 'Feb', 'real-time.', 'doorstep', 'Quality:', '0.', 'Service/maintenance:', 'request,', 'front.', 'agents,', "vehicle...It's", 'ha', 'shape', 'Came', 'stars.', 'cancelled', 'floor,', 'hump.', 'proved', 'too).', 'brainwashed', 'advertisements,', '"', 'this".', 'frustration', 'through.', 'filled', 'Month:', 'Here', 'am,', 'may:', 'Again,', 'prioritizing', 'case".', 'there).', 'regen', 'aggressively', 'juice', 'leisure', 'travels.', "friend's", 'ride!', 'generated.', 'storing', 'regular-sized', 'stand?', 'aftermarket', 'separately.', 'ice', 'height,', 'seats,', 'coordinated', 'nagpur', 'last-minute', 'glitch', 'mix-up', 'impression', 'negative,', 'decade', 'Excellent,', ',Ola', 'nailed', ',speed', 'yes!!', 'Price.', ',range', 'manipulated', 'channels.', 'Placed', 'mega', 'videos', 'circulating', 'advertisement', 'flashy.', 'all..', 'dussera', 'expectation', 'year-end,', 'wishful,', 'tesla', 'usd', 'booking).', 'Anyways', 'encourage', 'Software', 'bugs.', 'input,', 'consistent.', 'temperature', '10-12', 'rights', 'nd', 'inbuilt', 'party', 'anytime', 'hanging', 'friends.', 'view.', 'hate', 'peppy', 'compete', 'By', '/km', 'Emi', 'join', 'electrifying', 'elderly', 'weather,', 'ends', 'season', '-It', 'prompt', 'Until', 'Environment.', 'simplicity,', 'charm', 'metro', 'inconvenience.', 'scenario.', 'appealing', 'Myself', 'hardware', 'cold', 'booking.', 'Bajaj,', 'rely', 'midnight', 'Already', '2005', 'tough.', 'Second', 'payments', 'abide', 'promise.', 'good..', 'web', 'site', 'crashed', 'crashed.', 'systems', 'shift', 'think.', 'ant', 'Overhaul', 'compartment,', 'silent,', 'keyless,', 'Fixed', 'residents', 'building', 'dwellers.', 'sl', 'begin', 'colorful', 'highest.', 'unimpressive', 'J)', 'prominent', 'where.', 'Oct', 'Resident', 'sixty', 'S1pro.', 'commitments,', 'cons-', '70km/h', 'people,', 'A)', 'H)', 'misses', 'I)', 'difference.', '181kms', 'revised', '135/-kms', 'depend', 'display.', '32kms,', 'charges.', 'EV,', 'Twice', 'message', 'supplies.', 'addressing', 'August', '142000+.', 'rs.120000/-.', 'facing.', 'Launched', 'Dec-2021', 'cool,', 'elite', 'awaited', '124', 's1.', 'thinking.', 'jerky', 'EVs', 'eye-catching,', "Can't", 'trails', 'errors', 'resolutions', 'itself..', 'window.', 'Procedural', 'understandable.', 'transporter', 'alright.', 'preinstalled.', '500km', 'tea.', 'capability.', 'looting', 'smoother.', '4.8', 'starings.', 'dropping.', 'emergency)', 'peer-level', 'drained,', 'Due', 'inconveniences', 'salary', 'sleeping', 'grievances', 'cup', 'deducted', 'continue', '135kms', '10%per', 'promised.', 'music', 'glitches', 'stage.', 'alloys', 'brakes..', 'price..', '1,20000', 'INR.', '1-looks', '2-performance', '3-heallty', 'loudspeakers,', '3.Black', 'pretty,', 'horse', '4.Low', 'early.', 'triple', 'touchwood', 'buy!!!', 'remember', 'hard-earned', 'junk,', 'reliability.', 'created', 'lethal', 'disable', 'clerks.', 'Coimbatore', 'beliefs.', 'mail,', 'worse', '560', 'shutdown', 'belief', 'deserve', 'e1', 'communication,', '18th.', '—', 'black.', 'grey', 'hassle,', 'fashionable', 'infinity.', 'EVS', 'trends', 'swappable', 'packs,', 'travelled', 'rock', 'Secondly,', 'tricky.', 'obvious', 'Inline', 'ext.', 'tour', 'family,', 'special.', '4-resonable', '5-boot', '7-and', '1-costly', '2-mono', 'encrypted', 'passcode', 'enables', 'driven,', 'maps.', 'BTW', 'offline', 'speakers,', 'songs', 'utlity', 'knee', 'youngsters', 'kukatpally,ecil,', 'enjoying,', 'colleague', 'ecil', 'workplace.', 'taillamp', 'Coming', 'Pune.', 'June.', 'May.', 'hyderabad,', 'pick-up,', 'front...', 'Bounce', 'rocking.', 'bouncing,', 'tends', '12–15', 'access', 'IDs', 'So-called', 'region,', 'finalize', 'gps,', 'bet', 'rapidly', 'wide.', 'prepping', 'exterior.', 'fabric', 'indicators,', '35%', 'unnecessary,', '92000', 'talk,', 'management,', 'credit', 'innovation,', 'Future', 'trap,', 'deposit', 'reputed', 'amount.', '68000/-', '98000', '/-', 'cancel.', 'OMG,', '110-115', 'sport,', 'hyper.', 'rs.79999/-', 'rs.85000/-', 'rs.87000/-', 'rs.97000/-', 'crack', 'Inform', 'salesman', 'cause.', 'dim', 'aggressive', 'pricing.', 'roading', 'smother', '450x,', 'antitheft', 'comforts', 'e-vehicle', 'exceed', '10electric', 'relatives', 'heads,', 'number.', 'chat', 'feedback.', 'seams', 'link', 'contract', 'starting.', 'headlamp,', 'email.', 'corporate', 'skin,', 'resolution,', 'dummy.', 'Continues', 'Item', 'rs.3/km', '(claimed)', '(info', 'technician,', 'subject', 'increases)', 'Niggles', 'pushed', '6amp', '4.54km/rupee', '0.22/km.', 'comparison,', 'returning', 'km/l', '105/litre', 'equals', 'destroyed', 'enthusiasm,', '400/', 'duke', '250)', 'ass', '750w', '6.5', 'Vary', 'kolkata.', 'instrument', 'cluster,', 'rush.', 'See', 'pricy', 'last,', 'decently', '25km', 'dense', '..But', '..Did', 'b', 'motor..Good', 'autos', 'mayb', 'cuz', 'model(cuz', 'so)', '..They', 'wer', 'patient', '250w', 'use.But', '500rs.', 'Yearly', 'expenses,', 'Kabhi', 'karna', 'timely', 'websites', 'aspects', '.We', 'awesome.Go', 'scooter.Hero', 'splash.', 'buy.But', 'good.Has', 'easy.Although,', 'taller', "(i'm", 'feet).', 'whines', "(it's", 'addictive).', 'bugs', 'beta', 'paise/km', 'free..Just', 'planted', 'corners,', 'mrfs', 'grip.', '790mm', 'padded', 'that(', 'sarcastic)', 'hahaha', '...Looks', 'clearance...Suspension', 'Ridden', '45km', '58.5k', '100cc', '35kmphr', 'breeze', 'vibrations', 'quiet', 'waow', 'squeaking', '..I', '50-70', 'allocate', 'wall', "e's", 'face!', 'parent', 'german', "isn't", 'scooter.I', 'trave', '45000', '53000.', 'cuts', 'saturates', 'drive?', 'Finally,', 'wind,', 'windrider', 'wind', 'lonely', 'road.Looks.', 'asking,', 'thing.Great', 'money.Must', 'os.', '0-40', '0-60', '58nm', '(accelerates', 'arguably', 'dominar', 'surfing', 'happiness', 'Lot', "1'year", 'father.', 'raigad', 'dealers(Trissur).', 'dealers(Trissur,', 'mannuthi)', 'polluted.', 'healthy...', 'kilogram', 'safely', 'education.', 'dismantling', 'assembling', 'accessible', 'chime', '7".', 'runner', '(90s', 'relate?)', 'agile,', '4000-5000', 'atmosphere', 'flat,', 'compensates', '36lt', 'helmets,', 'ls2', 'ece', 'sideways.', 'Turn', '(5000', '5000*3.97', '=', '19850', 'additional)', '89400', 'Effective', '108000', 'km/l.', '9000,', '17000)', 'Fame', '59550', '(15000', '15000*3.97)', '29850', 'freedom', 'situation.', 'role', 'rafter', 'handed', 'diagnose.', 'Rafter', 'expected.', 'nice,and', ',scooty', 'choice,', 'handling,', 'fuel.Good', 'corp.', 'aerodynamics', 'highest', 'Against', 'inexperienced', 'demanded', '1020', 'bike.100', 'actual.', 'account', 'specifications.', ',not', 'receiving', '.Even', 'vouchers', 'redeemed', 'Jindal', 'Khandwa.', 'Elecric', 'Aditya', 'Varanasi', ',up', 'passed', 'renewed', 'basis,', 'Uncomfortable', 'replies', 'sports,', 'Arai', '181', 'Design', 'fan,', "dominar's", 'arise', 'pay,', '197400', '(ex', '163549,', 'card', '200,', 'postal', 'fee', '50,', 'icici', 'lombard', 'respectively.', 'Home', 'mini', 'truck.', 'Idv', '155400', 'rear.', 'invite', 'later.', 'Paid', 'October,', 'window', '15-31.', 'intimation', 'unit.', 'transport.', 'rupees,', 'galaxy', 'pcmc.', "hour's", 'sparingly.', 'Or', 'kilometre.', 'economical.2.', 'women.3.', 'low.4.', 'inserted', 'repair.Pros:', 'weight.Parts', 'weight.Height', 'experience.Ans.', 'Service.', 'In-front', 'battery.So', 'escalation', 'contact.', 'responsible.', 'essential,', 'reserved', '23.', 'later,', 'Hyderabad,', '40.', 'stuff.', 'wiring', 'needed.', 'dep', '7632,', '135km', '/charge', 'launching.', 'household', '3rd,', 'adopters', 'unique.', '500+', 'creasy.', 'fits', '(from', 'remaining)', 'scratches.', 'inspected', 'intrigued', 'astonishing', 'fell', 'stand-by', 'Stay', 'unbeatable', '1/5th', 'Lt', 'peace.', "champ...It's", 'teenagers', 'speeding..The', 'appreciated', 'time..The', "..You'll", 'once...Thanks', 'women.Cons:', 'sightly.Parts', 'strong.Seat', 'man.Tyre', 'necessary.', 'months.When', 'rm', 'secrets', 'now)it', 'According', '130-150', '131', '147', 'online,', 'door', '145', 'ideas', 'expertise', 'conduct/', 'projects', 'useful...', 'bike(lead)', '41,000(maybe', 'costlier', 'aggressive.', 'weaned', 'meaningless', 'consequent', 'inevitable', "'eco-pollutions'...It", 'enhanced.', 'innovative', 'pre', 'Pros-looks,', 'accelerated...', 'immediate!', 'in-town', 'move-abouts.', 'Your', 'ads', 'grips,', 'bag', 'hump),', 'flimsy', '(center', 'possibility', 'design),', 'saree-clad', '27th', '6.45', 'miserably.', 're-brand', 'loyalty', 'Significant', 'capacity,', 'unfirm', 'life..', '30-45', 'km(not', 'me).', 'allowing.Well', 'clean.', 'nonstop.', '6.30', 'price.129999/-', 'lock,', 'Sometime', 'park', 'dedicated', 'chatting', 'chatbot..', 'regretting', '..This', 'free..And', 'useful...And', 'lag', 'over-speeding', 'reversing.', 'followed', 'Bluetooth,', 'lever', 'local.It', 'approx.Very', 'use.Alloy', '.Especially', 'referred', 'parents.I', 'prices.This', 'shop.....', 'shop?', 'take.', 'no...', '10kms', '27km/hr', '55kms/1', 'Brake', 'Off', 'roed', 'bettar', '(ignore', 'news)', 'house', 'Used', 'urgency.', 'students.In', 'trending.Hero', 'packed', 'bent.', 'silence', 'netherland', 'laptop', 'behind.', 'burst', '20-25', 'automatically.', 'pulled', 'pm.', 'unfamiliar.', 'rightfully', 'beneficial', 'Consumes', 'teenagers,', 'hurry.', 'profitable', 'wallet', '&man', 'used.Look', 'scooties', 'navigation,', 'negotiating', 'ambitious', 'balanced', 'patrol', 'inventing', 'Completed', '2800', 'mileage...........Replace', 'average..Its', 'fine..Its', 'money..I', 'dad..Initially', 'police', 'inquiry.', 'Saving', 'Biggest', 'material.', 'Nil', '......', 'flash.', '...Stylish', 'hesitation', 'cost...', 'large.', 'runs.', 'sheer', 'Night', 'lamps', 'ebike', 'gorakhpur.', 'unvalued.', 's/w', 'instructed', '5%', 'produced', 'gases', 'heat.', 'Nowadays,', 'Soundless', 'So...', 'is..', '500.', 'bowled', 'gerua', 'holi,', 'Updates', 'notifications.', 'all.Now', 'putting', 'disconnect', 'reboot', 'supplied', 'industry.', 'cruise.', 'list.', 'indicators.', 'bike.All', 'places....', 'neighbour', 'Specially', 'elder', 'specific', 'passionate', 'activities', 'mom...She', '...Good', 'suits', 'ages....!Capable', 'seater', 'e-', 'ride.Focus', '6)I', 'useless.', 'domestic', '15-18', 'limit.', 'arrange', 'Stunning', 'bike,awesome', 'older', 'canter)', 'guaranteed', 'satisfies', 'Fast', 'width', '3)change', '1400/per', ',because', 'price,,and', 'pollute', 'attractive.Easy', 'reliable.Preferably', 'used,easy', 'wheeler.', 'lightly', 'real-time', 'drop,', 'Before', 'purchasing,', '119', ',,value', 'money.It', 'whenever.I', 'missing,', 'updates.', 'care-', 'actions.', 'serves', 'drain.', 'delivered.', 'a)', 'also.Smooth', 'wonderful.Service', 'cheaper.', 'much.I', 'vasool.', 'company.I', 'malfunctions,', 'overheated,', 'smooth.I', 'elders.', 'stylist', 'certain', 'maintainable', 'fee.', 'bright.', 'Right', ',smoother', 'movement', 'undue', 'hackles', ',just', 'ride.Decent', 'stunning', 'chances', 'i’m', 'wrong.Good', 'pretty.Its', 'encouraging', 'carbon', 'dioxide.', 'brand,because', 'trust-able', 'nice.When', 'links', 'Young', 'rumours', 'reliable.Its', 'environment.Electric', 'trafficking.And', 'box.We', 'excessive', 'storage,', 'luggage,', 'overweight,', 'elderly.And', 'newcomer.', 'safely.', '24kms', 'earning', 'ruined', 'betrayed', 'uncle.', 'stressful', "flash's", 'certainly', 'beautiful.Being', 'flow', 'wings', 'eagle.', 'simplicity.', 'highways.', 'mother', 'exists.', 'started.', 'low.The', 'large.The', 'comfortable.Overall', 'gottigere', 'branch.', 'promote', 'maharana', 'partap.', 'hours..', 'less....', 'ok...', 'Ok', 'flyovers..', 'problem....', 'mix', 'Run', 'Specification', 'Fuel', '300%', '78k...', '80..', 'look...', 'space...', 'heavy...', 'Ather-450x', 'ethics,', 'appeal', 'fair', 'trial', 'manufacturers.', 'entrepreneurs', 'imbibe', 'subsidiary.', 'subsidiary', 'hikes?', 'Chetak,', 'gain', 'slightest', 'adopted', 'strategy,', 'insert', 'Okay', 'components,', '35,000+', '20,000', 'users.', 'compactable', 'pilon', 'heavily,', 'Needs', 'aluminum', 'tire', '155+', 'mm,', 'Feels', 'breaker,', 'Reaches', '60k', '10-15%', 'jump', 'noticeable', 'gradation.', 'Rs.5000/-', 'whopping', 'exposed', 'walls.', 'improved.', 'comfort,', '4.6', 'greeves.', 'released', 'forward.', '-superb', 'maintenance।', 'cons।', 'look?', 'appealing?', '89', 'precise.', 'consoled.', 'Elon', 'Musk,', 'co-founder', 'Tesla', 'Company,', 'sole', 'checked,', 'experience।-', 'ne', 'instantly', 'November.', 'riding.(', 'light)', 'paddle', 'carry.', 'rs.84,000', 'one-second', 'consume', 'Disadvantage:', 'bone.', 'severe', 'r&d', 'handles.', 'hundred', 'intense', 'Getting', '100+', '4.I', 'bill.', 'choice..', 'arises', 'surface.', 'Rs.27000/-', '2021.”Bajaj”', 'exploiting', 'contrary,', 'encashing', 'swallow', 'thumb', 'volume.', 'buyers,', 'theft.', 'goers', 'Since,', 'smaller', 'hats', 'legend', 'confusion', 'concern..Max', '..40', 'speed...', "hours..It's", 'average...Within', 'ones.', 'Enough', 'garages', 'Ampere,', 'nowadays', 'convenience.', '19', 'frond', 'dream...The', "Tyre's", 'quality...', 'Chennai.', '0-100%', '2.2-2.5', '93km', '0.21paise', 'Jalalabad', 'sher', 'singh', 'torque.', 'shifting', 'gears', 'competition,', '@first', '3)one', '4)motor', 'containing', 'illumination', 'Near', 'drainage', 'hole', 'place.', 'stored', 'rain.', 'vip', '100kn', '25km...', 'ac', 'input', 'buildings,', 'stolen.', 'utilized', 'fixing.', 'supportable', 'greatest', '1-month', 'starter', 'damaged..Even', 'low/high', 'range...Plz', '...After', 'unsupported', 'companies.', 'piece.', 'was.', 'breakup', 'good.3.', 'callback,', 'a.', 'withstand', 'extent.', 'Around', 'Women,', 'sr', 'Takes', 'remain,', 'reta.', '6feet', 'rains.', 'waterlogging', 'driven.', 'Loading', 'bridge.', 'option(but', 'ok).', '@75kmph.', 'everyday.', 'sector.', 'sync.', 'Balance', 'longer.', 'Has', 'legroom', 'advertisement...When', '.....Superb', 'chetak....When', 'girlfriend.', 'superb.Full', 'hood', 'urban', 'collection', '600km.', 'rounder', '80k', '3+2', 'environment.So', 'bike.Good', 'bike.....Same', 'chetak.....Humara', '1st-time', 'monoths', '54km.', '84km', 'low-speed', '(mostly', 'high-speed).', 'accommodates', 'Apps', 'ulto', 'Sit', 'fuse.', 'mileage/charge', 'declaration/promo', 'km/', 'broken/damaged,', 'rude.', '7.', '8.', 'ratio', 'frequently.', 'looks.Performance', 'high.We', 'purposes', 'outdoor', 'indoor.', 'backside', 'smartness.', 'Among', 'Mind', 'model!!', 'Saves', 'satisfactory', 'lot,', 'face.Overall', 'term', '(within', '10km/per', 'ride)', 'youths,', 'uncle', '82', 'valuable.', 'futures', 'Wish', 'surat', 'loaded.Looks', 'doing.', '3=Looks', '4=Maintenance', '5=Pros-save', 'Environment,', 'Cons-speed', '51', '100-150rupees', 'knowledge,even', 'motorcycles', 'transportation', 'revealing', 'statistics', 'lifestyle.', 'motorbike', 'youth', '2=Awesome', 'Rider', 'demographics', 'Key', 'geographic', 'markets', 'e-biking', 'Costs', 'cars,', 'workout.Experience', 'working.Battery', '97%', '91', 'time.This', 'E-bike', 'rates', 'variables', 'hai.', 'Showroom,', 'helpless', 'scheduled.', 'washing', 'cleaning', 'Air', 'compressor', "thing.It's", ':Best', 'year.And', 'life2.', 'smooth3.', 'cost5.', 'Pros-light', 'Lajwab', 'separated', 'collision.', 'flow.', 'range.It', 'nature.It', 'salesmen', 'good.They', 'service.And', '.Speed', 'segment.Since', 'negligible.', 'commuter', 'equivalent', 'Eco-friendly', 'voice', 'needed;', '5.The', 'Problems', 'are:1.', "'printed'", 'attachment', 'generate;', 'him,', 'dictate', 'removing.', 'researched', 'scientific.', '3.Braking', '4.The', 'decider', 'unscientific', 'discomfort', 'assured.', 'sackings', 'pushpak.', 'disadvantages.', 'edges', 'Hands', 'injured', 'underwriting', 'best,this', 'shiny', 'like,', 'haves', 'stiff.', 'money5.', 'Cons-some', 'cordial', 'buy.Once', 'teacher', 'rechargeable', 'November', 'Jabalpur', '(MP).', 'heads.', '87', 'Center6.', 'on7.', '(low', 'speed)8.High', 'expensive9.', 'IP', 'replace.', 'electric,i', 'bumper', 'hart', 'crossing', 'long4.', 'Batteries', 'months.....', 'rotate', 'batteries5.', 'use?', 'bike?', 'anything?', 'unlawful', 'least,', 'knowledgeable.', 'damn', 'heavier2.', 'priced,', 'market?', 'baffled', 'end!', 'director', 'koramangala,', 'bangalore,', 'tells', 'bunk.', 'contrast,', 'facts:', 'cover,', 'priced?', 'amounts,', 'force', 'throats', 'grunt', 'adrenaline', 'induced', 'proud.', 'nimble', 'skinny', 'Certainly', 'lavishly', '(around', 'Rs.12)', 'turner', 'Everyday', 'strangers', 'nil.', 'automobile', 'silent;', 'compulsory)', 'invest', '3k', 'Pors', 'bill,', 'made.', 'screw.', 'here.', 'enter', 'arena.', 'mobility.', 'Skyrocketing', 'alternatives', 'indicates', 'photon.', 'kgs.', 'Kudos', 'hero!', 'scooty..', 'port,', 'hinge', 'struck', 'spring,', 'brands,', 'Anyways,', 'proceeded', 'liked.', 'manually', 'in-between', 'otherwise,', 'intimate', 'cribs.', 'refused', '1.49', 'said:', 'chips', '1.51', 'glass', 'tea/coffee.', 'granted.', 'performance:-', 'activa.', 'Servicing:-', 'though,', 'Suitable', '1.38lacs', 'price).', 'date,', 'Indians.', 'Dynamic', 'Monthly', 'rs.800', '3500', 'potholes.', '70kg,', 'below.', "here's", 'ponder', 'misfortune', 'highway,', 'object', 'towns.', 'expense.', 'vegetables', 'hot', 'barrels.', 'fan', 'bike.Right', 'gujrat.', 'grater', 'RV400', 'Features', 'but,', 'Sudden', 'pothole', 'non-use.', 'utterly', 'Hi', 'let’s', 'smoking', 'Me', 'heartily', 'smooth,and', 'round', 'headlight.', 'port.', '150.', '72v', '167cm.', 'men.', 'men,', 'Turning', 'throttle,', 'achieves', 'best.I', 'sharp.', 'erode,', 'trichy', 'li/photon', 'itself.I', 'pin/socket,', 'lift', 'opted', 'apartment/', 'researching', 'choosing', 'e-scooter.', 'drive(especially', 'itself).', 'chennai', '(2', 'dealers),', 'model)', '10/11/2018', 'erode', 'dealership,', 'unavailability.', 'visited,', 'speaks/behaves', 'Lesser', 'v', 'Review', 'hope,I', 'got,', 'updating', 'diff', 'timelines', '(li', 'par', 'top-speed.', 'economics', '100-150', 'Add', 'Remember', 'phones.', 'recall', '3:', 'friction', 'odd,', '40-60', 'individuals', 'habits', 'happily', 'parameters', 'didn’t', 'started,', '2nd.', '2:', 'accelerate,', 'moving.', 'traffic,', 'circumstances.Problem', 'parking,', '(till', 'this)', 'only.Then,', 'hugely.', '1:', 'kms(nearby', 'districts).', 'enough.4)', 't', 'easier.5)', 'noise/vibration', ':my', 'vehicle)6)', 'evs.', 'zip', 'separator', 'separates', 'plastics', 'bit.Pros:', 'bike’s', 'decent.2)', 'spacious,', 'bikes.3)', 'unplugging', 'plugging', 'Adapter', 'alarm/lock', 'll', 'alarm,', 'occupying', 'Quality,', 'generations', 'attention.', 'sound.Apart', 'these,', 'mounted,', 'adapter', 'unplug', 'Upon', 'Ll', '...1...Best', 'relatives,', 'meeting,', 'emergency,', 'so...Very.', 'earth..', 'no..Any', 'removal.', 'vehicle(which', 'got)', 'allowed', 'checks', 'preventive', 'measures', 'cases.', 'aside', '(hoping', 'bike)', 'removal', 'easier.', 'thoroughly', 'mine.', 'fine/manageable', 'Achieves', 'flyovers).', 'counterparts,', 'good.(though', 'change,only', 'slight).', 'flyovers)8)', 'finally,', 'extremity', 'repeated', 'Maintaining', 'downsides', 'statement', '(assume', '20%)', 'degradation', 'electrically', 'occupants.', 'silently.', '50kmpl', 'decline', 'Typical', 'liquid', '2-the', '96,000', 'faulted', 'relay', 'recalcitrant', '55,000..', 'candy', 'delivers', 'powered', 'carbon-dioxide', 'Indians.....', 'earth..Save', 'money...Save', 'life...Save', 'budget...', 'realised', 'beautifully', 'proves', 'Lac,', 'km/Hrs.', 'Km/Hrs.', 'Km./Hrs.', 'Dashing', 'Mesmerizing.', 'yamaha.', 'radically', 'abbe', 'hirakud', 'dam', '75,000', 'breaker.', 'Bounces', 'pit,', 'realistic', 'assumptions.', '1-the', 'tropical', 'india', 'scorching', 'summers', '40+', 'guard,', 'siting', 'belt,', 'mediocre', 'Stated', 'fro', 'staring', 'fetched.', 'Model', 'Delhi.', 'compared.', 'songs.', 'gate', 'dashing.', 'patna', 'Initial', 'consequently', 'counts', 'None', 'loaction', 'thumb.', 'Scam.', 'Ex-show', 'Thus,', '-Good', '-Satisfactory', '55-60)', '-Range-', '-Comfortable', '-Full', 'timing:-', '-Worst', 'Rv400', 'sharing', 'vision', 'tension.Bad', 'experience-', 'merits', '-Front', 'Space', 'assembly.They', '5600', 'Dhanteras,', 'Double', 'Gearless', 'expenses', 'carrying.', 'puck', 'nose', '86500', 'failed.Then', 'twice.The', 'days.The', 'hooter', 'fed', 'year.Now', 'forever', 'chase', 'engineers,', 'expiry', 'delivered...', 'August,', 'revai,', 'heating.Anyway', 'renewable', 'men(boys).', 'kirti', 'overtakes', "EMI's,", 'march,', '(december,', 'repairs/replacement', 'parso', 'aao.', 'Transit', 'mein', 'hai,', 'nahi.', 'Gadi', 'din', 'range(mileage)', 'bastard', 'end...', 'crm', 'months.You', 'deadlock.', 'kal', 'aao', 'bhilai', 'cg.', 'ignores', 'unnecessarily', 'cables,', 'cord,', 'lie', "vehicle's", 'extraordinarily...I', 'refueling....In', 'seen...The', 'defeat', 'videos.', 'repairs/servicing.', 'vidhi', 'jamul,', 'emi,', 'Customize', 'effect.', 'Gps', 'enabled.', 'Bluetooth', 'Robotic', 'Rv', 'pads,', 'ignore', 'bike,but', '.Its', 'others,design', 'revolt.This', 'use,its', 'Stylish', 'bhagabat', 'bhubaneswar', 'puts', 'mixing', '12000kms', '36000/-', 'fake,', 'rotor', 'rakhani', 'padega.', 'Etc', 'lies', '40000kms', '20000kms,', 'shaking,', 'burst.', 'fencing.', 'DRLs', 'key.', 'Although,', 'welcoming', 'stars', 'control.The', 'ans', 'racing)Is', 'man(', '5.9', 'above),now', 'services,', 'Hmmm', 'efficiently', 'sound,', '15kms,', 'customers.Requesting', '150-170', 'km/charge,', '90-110', '7-8hr(5-6', 'electric).', 'superb,(', 'heavier', 'stand.', 'challenges', '2018,mcb', 'failures', 'repeatedly,horn', '20kms', ',travel', 'indicator,front', 'bad,every', 'it,it', 'working.As', 'maximum.', 'slowly', 'riding.Taking', 'impossible.I', 'Usb', 'exterior', 'spoilt', 'rains', 'greenlife', 'baner', 'fronts.', 'Hi,I', 'foreword', 'lithuim', 'friends,', '(Salem)', 'accurately', '35000/-', '45000/-', 'training', 'emi', 'me,Thanks', 'mo', 'nil', 'Con', 'awesome,Look', 'great.All', 'moreover', 'Compromise', 'Plan', 'veil', 'LOAN', 'institution,', '"RattanIndia', 'Finance"', '18%', 'telling).', 'km(', 'it!!!', 'true!!!!)', 'thrissur,', 'over!!!!', 'only!!!!', 'expensive,', 'eco/sort..But', 'km).I', '14-08-2018,', 'also.At', '20-25(', 'km.)i', 'kerala,they', '!!!!', 'wisely', 'scooter.Thank', 'opinions', '(licenced', 'type)', 'originally', 'wrong)', '55-60km', 'response..', 'regional', 'officer', 'theirs..', 'hope..', 'spare,', 'days...', 'same...', "You'll", 'respond,', 'arrogant,', 'meter,', 'shoes', 'torn', 'ordinary.', 'toy-like', 'means…if', 'okinwa', '15000', 'batteries…..(my', 'thoughts', 'changed…', '81000', 'checks.', 'Plan.', 'Down', 'Compulsion', 'loan', 'submission', 'cased', 'controlled,', 'button,', 'tearing', 'coupons', 'sending', 'illegal', 'dangerous.', 'image', 'Mr', "he'll", 'eating', '6000kms', '30k', 'replace,', 'fail', 'over.', 'closed,', 'commission', 'subterfuge.', '2014-15', 'china.', 'Weak', 'see-through', 'sunlight,', 'visibility', 'dark', 'rebrand', 'sigmatel.', 'chinese', 'rebranded', 'indian,', 'internals', 'chinese.', 'lies,', '?Ans', 'superhero', 'mask..', '"pulsar,', 'etc."', '70,000', '90000.', '1,50,000', 'sounds,', 'artificial', 'understandable', 'artificial.Now', 'questions:-1)', '??Ans', 'course..', 'area.2)', 'exquisite', 'performance?', 'nope', 'formerly', 'readily', 'crap,', 'crapped', 'added.9)', 'Tighten', 'sir.', "Here's", 'loser', 'idiot,', 'today?', 'huh?', 'engineering?', '15mm', 'port.17)', 'charge.18)', 'efficient.Cons:-1)', 'abs.2)', '80km/h)3)', '150kg)4)', '19-20kg.', 'elsewhere.', 'allowing', 'malpractice', 'appalling.', 'hilarious.', 'bearings', 'bent', 'rubs', 'lives,', 'bullshit', 'bites', 'outlets.', 'mindset', 'repair,', 'sigmatel,', 'denying', 'bolted.', 'everywhere.', 'craphole', 'abracadabra.', 'await', "else's", 'shorter', 'unlike', 'distributors', 'crazy..', 'mad', 'patel', 'enterprise', 'consumption"', 'anymore,', '100km.', 'weighs', '170kg', 'enfield', 'dangerously', '40kph', 'crap.', 'sigmatel', 'owner.', 'left.', 'boom', "There's", 'overheat', 'drinks', 'un-adjustable', 'extremely', 'sags', '20kg.5)', 'rev', 'acceleration.6)', 'scooter.(personal', 'opinion).7)', 'compact', 'toy.8)', 'exaggerated', 'blot', 'of.', 'intention', 'gujarat', 'gov.', '19000', '75000', 'Else', 'information,', 'further..', 'Returned', 'serviced.', 'answer,', 'opened', 'wasted.', 'khatara,', 'cc/606/2019)', 'wow', 'grievance', 'Unless', 'forum,', 'grievance.', 'disputes', 'redressal', '82000.', 'rob', 'faults,', 'solution.', 'email', 'Tired', 'filed', 'district', 'Okinawa.', 'data.', 'YouTube', 'data,', 'lasted', 'kms-10', '12000', 'old..', 'lawyers', 'matters', 'lurch.', 'speedometer,', 'calculator', '(gel', 'product)', '35k.', 'turncoat', 'bribe', 'politicians', 'hype', 'entice', 'gullible', 'nowhere', 'courts', '2.30', 'lease', 'whatsapp,', 'Whoever', 'lodge', 'faults.', 'judicial', 'accountability', 'high.9)', 'usd(up-side', 'forks).10)', 'projector', 'lamp.11)', 'lamp.15)', '(75%', '2.5hour', 'modes.5)', 'swapping', 'concept.6)', 'lifetime', 'warranty.7)', 'unlimited', 'plan).8)', 'heavily', 'items,', 'seemed', 'together.', '32000.', '32000', 'letter', 'ex-', 'fensing', 'physically', 'mentally', 'suffered', 'badly,', '800meters', '1km,', 'arrogant', 'behavior,', 'month...', 'okinawa...No', 'suggestions...But', 'batteries...It', 'time..', 'drawbacks', 'softer,', 'good,quality', 'praise.Also', 'great.If', '75km/h', '55km/h', 'pollution,no', 'petrol,no', 'money.Its', 'bucks', 'why...', 'yet...5.', 'cons;', 'feelings', '.....And', 'provider.', 'scarring', 'guys.If', '4-4.5', 'hour).16)', 'Little', 'rewari', 'register', 'area........', 'cloudy', '70kmph', 'controlled', 'system)', 'hr', 'strong,', 'horns', 'centres', 'dun', 'falls', '127', '..The', 'Matt', 'likeable', 'gear(like', 'back)', ',EBS', 'abs', 'working.Without', 'ride.And', 'inner', 'it...Well', 'beast..It', 'it...The', 'now.I', 'days..Well', 'super,stylish', 'design,low', 'stability.', 'dicky', 'good.Mileage', 'amazing.My', 'yellow', 'lights.And', 'question', '??', 'together.Pros', '(green).2)', 'plan)', 'scheme.3)', 'compromised', 'revolt.4)', 'long.Company', 'battery.According', 'onroad', '73k.', 'appealing.', 'premium.Although', 'congratulate', 'truth,', '55kmph,', '65khph', 'sec,', 'good.It', '150kms.', '60kms/h,horn', 'direction.Its', 'charge.Looks', 'circles', 'vehicle.It', 'Extremely', '(local)', 'Guys,', '125kms', 'comes,', '170-200kms,', 'km.If', 'cycle.As', '.Battery', 'lid', 'only.Lid', '.Who', 'yearly', 'rs30000/..Dear', '...I', 'planing', 'also.Please', '.When', 'newly', '300~400', 'traveled', '6020', 'shoppings', 'service.I', '2018.', 'direct', '50~55', '.New', 'rs=25000.So', '.Worst', 'high-tech', 'apps', 'disclose', 'gone.If', 'worth-able,', 'multipurpose', 'coaching,', 'school,', 'terribly', '170kg+', 'tiers', "policy.India's", 'Supper', 'built-in', 'city..Future', 'grab', '100-120', 'kms.2.', '52-53km/h..3.', 'posture.5.', 'Useless', 'distance..', 'Hard', 'night.6.', 'good.Low', 'life.Is', '.If', 'beneficial.Riding', 'specified', 'inviting', '76500,', 'problems...1.', 'blog', 'internet', 'company.Please', '..Max', 'rodding.', 'Lighting', '.In', 'runs.All', 'described', 'Pros:1.Visually', 'awesome.2.Stunning', 'looking.3.Lower', 'comparatively.', '4.Full', 'km.5.Economically', 'good.6.3', 'beneficial.Company', 'worthy.', '75km.', '175', 'Distance', 'lengthy', 'ie', '20kms.', 'it...', 'worst.I', 'purchase.Battery', 'inventory.Avoid', 'it.Chassis', 'shocking.So', 'run.One', 'life.Not', 'beauty..Will', '2020.Both', 'features.For', 'option.Further', 'different.Great', 'vibrates', 'breakers.I', "scooter...I'll", 'dhalapathar,khurda,odisha.', 'straight', 'rs76000', 'experience:To', 'awkward', 'disc.3.', 'performance:I', 'glossy', 'blinker', 'worst.Suspension', 'bicycle.', 'Loss', 'experience.Look', 'praise.1.', 'experience:I', 'sai', 'design.Cons.1', 'infrastructure', 'date.2.', 'risk', 'camel.175', 'road.Sitting', 'arrangement', 'Adaptation', '60/70', 'km.Run.7.', 'good.8.Boot', 'good.Helmet', 'space.9.', 'hide', 'protects', 'raining.10.Good', 'scam', 'directed', 'cancellation-', 'of,', 'bookings', 'references', 'environment,not', 'free,easy', 'that.Look', 'good.Only', 'rs10', 'metre.', 'person.However', 'poor.Cons:', 'transfer.', 'urge', 'adjustments.Maintenance', 'cost.5.', 'cons:Pros:', 'rs100', 'rs36000', 'amazing.In', '140kms', '.Zero', 'purpule', 'amazingly', 'catching.Charging', '140kms.', '150kms', 'version.4.', 'Haha', 'availed', '70-', 'shipped', 'trolley', 'snap', 'shots', 'this.5)', 'ex:', 'trapping', 'year.The', 'one..4)', 'broke-in', 'spokes', 'pivot', 'tire.This', 'Virtually', 'Roughly', '150-200', 'Thats', 'treadmillIn', '80-100', '*(initially', 'tested).', 'Depends', 'Guarantee', 'say.2)handle', 'shake', 'fully.3)', '(power', 'motor)', 'switches.', 'adapt', 'matter.4)major', 'indefinitely', 'delayed.', 'andheri', 'live.Revolt', 'financing.', 'telephone', 'off.Mumbai', 'pursue', '170-200', 'km/per', 'milage', '120km/per', '10hrs', 'agents', 'admitted', 'Mumbai,', '(maintenance).3)eco', 'friendly.4)', 'and.', 'Attractive', 'Good:-', 'person)', '300.', 'Bad:-', '-356)', 'rarely', 'mechanism.', '7)parts', 'loosely', 'coupled,', 'bike.8)', 'Pros:There', 'submitted', 'condition...?', 'secondary', 'policy,', 'primary', '1.Bought', '87k', '3.Look', 'kutch', 'satara.', 'one-month', 'policy.', 'sensors,', 'month?', 'happening', 'April,', 'issue.Need', '(72v', '48ah)', 'exhausted', 'recharge.Looking', 'provider', 'outlet', 'gandhidham', 'bike.However,', 'issued', 'unsolvable', 'irresponsible,', 'attend', '&maintenance', 'issues.Bike', 'yrs(5600km).No', 'bothered.', 'jan', 'dabba,', 'patiently', 'requirement', 'promised,', '140km', 'mode..120', "same..Yes'day", 'authorized', 'screeching', 'arising.', 'intermittently', 'shooting.', 'z', 'dombivli,', 'proper...', 'promoting', 'batteries..', '26', 'aug.', 'rs.31000/-', 'bar..', 'quested', 'medium.', 'odometer.', '4.Not', 'required,', '(includes', 'condition)', '5.Saving', 'trips', 'replied', 'answers', 'solutions.', 'advances', 'slots.', 'december', 'march-April', 'redirected', 'connecting', 'escalated,', 'you(', 'months).', 'Whatsapp', 'pits', 'stop.', 'Mails', 'gradually', 'decreases..', 'recommend..', 'improvements..', 'think..For', 'bike..We', 'years..', '10min.', 'km..', 'now..', 'thing,', 'drop.', 'itself,', 'scooters..', 'perspective..First', 'comfortable..After', 'record', '25800km', 'now..But', 'here..No', 'this..No', '.......', 'joys', 'happiness.', 'I-praise', '52km/h', '800meter', '1km', 'shows,', '8to', '9hours,27julay2021', 'purchase.I', 'rubbish', 'sock', 'pillion.', 'absorbers..', '(no', 'puncture).', 'Maybe', 'drum.', 'passed,', '34', 'distance,', '80-90', 'beware', 'breaks.', 'conclusions.', 'season,', 'this...', 'approved', 'bribe.', 'God', 'Spent', 'deal,', '2.99kw,', 'bridges', 'RSA,', '15k.', 'fooled', 'fraudulent', 'bone', 'stupid,', 'engineering,', '1*.', 'eng.', 'system..Problem..This', 'cost??', '103500', 'carefully.', 'Dec', 'stiff,', 'dead.', 'vise', 'worthless.', 'Pune', '21,', '20k', 'amount,', 'Feb-mar', '22.', '"please', 'that."', 'Dwarka', 'wrongly', 'again,', 'days..."', '4g', '2g', 'added.', '89000.', 'following.', 'explain', 'varied', 'dealer?', 'adaptation', '73000/-', 'Aura', 'Fun', 'quick.', 'harder', 'observers', 'riding...', '(side', '3000)', 'raw', 'size.', 'lamp.', 'upgraded', 'versions.', 'fused', "center's", 'khatara', 'fast-changing,', 'budget,', 'quit,', 'jurk', 'centres,', 'display,', 'disk.', 'encouragement', "'Vespa'.", 'Vespa', 'accelerated.', 'sunny', 'placed.', 'placement.', 'scratched.', 'locating', 'manufacturer,', 'Professionalism', 'dealings', 'authorities', 'behave', 'delivered!', 'quiet.', 'economy,', 'app,', '92500/-?', 'detailed', 'break-up', 'summarize', 'proceed', 'product?', 'via', 'bosch', '1-mirrors', 'welding.', '80-150', '45-85', 'rated', '814', 'mm', 'coolly', 'nicely.', '55km/hr', '(130kg).', '90km.', 'faraway', 'create', 'Thane', '60..parts', 'market..my', 'dealers.', 'mood', 'jerking', 'maintainance', '0/10', 'seperately', 'sorry', 'aura...', 'riding.(key', 'failure).Lock', 'glow.', '..it', '110000.scooter', '60..company', 'like.', 'Smooth,', 'Absolutely', 'query', 'months?', 'sarcastic', 'accumulate', 'crores', '1.Speed', 'calculation.', '(high', 'Back', 'ktm.', 'harm', 'eyes', 'kinds', 'hard.', 'athlete', 'whatsapp.', 'USB', 'tail', '4060', '84000', '4500', 'Mar.', '22)', 'chasing', 'handover', '(saying', 'days).', '(what', 'charger).', '25-30k', 'guyz!!', 'insurance).', 'upgraded...', 'effort.', 'somewhere', 'else...', 'bike,feels', '(100%', '82000).', 'onwards.', 'volt', 'kharadi', 'wagholi', 'access.', 'lac', 'shortage.', 'e-bike.', 'flyover', '80k.', 'jupiter.', 'pending', 'Permanent', '02/07/2020', 'requests.', 'stadium.', 'stadium', 'Ex-showroom', '.On', '(include', 'warranty)', 'Booking', 'stands.', 'Because,', 'tend', 'irritating', 'rainfalls', 'misty', 'climate,', 'blurred', 'Certain', ':1)', 'turns,', 'waves', 'desired', 'angle', 'course,', 'punched', 'Shri', 'balaji', 'e-motors', 'Markapur', '(a.p)', '8th', 'dealer’s', 'likes.', 'energetic,', 'dream:', 'silencer', 'bike.Best', 'Energy', 'Mother', 'food', 'Ampere.', 'understand.', 'beforehand.', 'adult', 'adjust', 'service....', 'ago!!!!', 'company....', 'times...', 'jumbling', 'Good,', 'Amo', 'rapidly.', 'Contribute', 'revolution', 'tomorrow.', 'parking.', 'cheers', '70s', '160kg.', '57kmph', '20paise/km', 'unusable', '1)charging', 'hr.', 'efficiency.', 'blame', '(totally', 'multi', 'colored)', 'hit.', 'lucky', 'Magnus.', 'irritating,', 'downs', 'Support', '150cc', 'gearing', 'brother', 'thumbs', 'lovers', 'Material', 'breakable.', 'Whereas', '1/1.5', 'plot', 'stamped', 'forgotten.', 'come,', '86000.', 'purchased.Some', '(dikki)', 'shockupser', 'quarter', 'Maintenance-', 'Low-quality', '6/7', 'response....', '15,000', 'real.', 'honest,', 'weigh', '170-175', '150kg.', '76000', 'element', 'grabs', 'attention', 'plenty', "ev's", 'nation.', 'governments', 'encouraging,', 'hyderabad)', 'standard.', "Dealer's", 'complaining.', 'manages', 'unskilled', 'hyderabad', 'importantly', 'wiil', 'associated', 'terrible.', 'inferior', 'focused', '(Gaura', 'automotive', 'kondapur,', '400.Its', 'neighbor', 'blinking', 'Richmond', 'od', '5500km', '10inch', '12inch', "We'll,", 'interests', 'Indians,', 'factors,', 'excluding', 'combined', 'performing', 'Ergonomics', '(r)Regenerative', 'yesDisplay', 'ledRim', 'alloyed', 'reflector', 'Blinkers', 'Tamulpur', 'Assam.', 'metallicCells', 'nmc', '18650', '3c', '50aCharger', '10aExternal', 'yesBrake', '(f)', 'peaking', '(even', 'future),', 'adapted', 'rides.Motor', 'nominal', 'vector', 'looped', 'Indicator,', 'ordered', '8600kms', 'Travelled', 'hearable', 'buy!!', 'Wanna', 'fraudsters', 'compliants', 'showrooms,', 'finish...', 'screws', 'pathetic..', 'absorbers,', 'Switches', 'problem...', 'henceforth', 'refueling.', 'Gradeability', 'lockLadies', 'phenomenal.', 'Break,', 'algorithm', 'implemented', 'prioritized', 'makers.', '3.at', 'km./hrs.', '.My', 'swap', 'gray', 'color.', '85-90', '80-85', '95-100', 'Speed:', '60-65', 'Comfortable:', 'shouting', 'contacting', 'completed:', '2/5', 'problem:', '1.There', '60km.Every', '2.Top', 'pulsar,', 'true?', 'date:', '(inc.Taxes):', '93000', 'Kilometer', 'driven:', '1675', '2021)', 'No.', 'besides', "i've", 'exceptionally', 'Chhattisgarh', 'brack,', '3months.', 'engines', 'extract', 'improve,', 'rider!', 'cum', 'anantapur', 'aides', 'owns', '2012,', 'manageability,', '*worst*', 'habsiguda', 'connected.', 'late.I', 'February', 'Digital', 'kilometers..', '8%', 'chat.', 'compliant', 'whatsapp', 'Request/advice:', 'blind', 'too,.', 'milege,', 'newest', 'happening,', 'government,', 'practice,', 'cracked.', 'rider)', 'support:', 'satisfied.', 'toll-free', 'Creech', 'observed', 'beginning', 'competitive', '4–5', "day's", 'geo-fencing', 'cooler', '1.Attitude', 'Yelahanka', 'appreciable', 'Gracious', 'designed,', 'ages', 'genders', 'Minuet', 'Yamuna', 'Nagar', 'ambala', 'cantt', '65km', 'there)', 'construction', 'completion', 'absorbing,', 'ruff', 'tuff', 'Each', 'aspects.', 'corona', 'partner', 'jam,', 'corrected', 'politely.', 'this,.', 'room..', 'whom', 'call.', 'rebadged', '0–40kmph', 'requests', "scooter's", 'Hopefully', 'placement', 'redesigned.', '59k', 'mph', 'reacted', 'Bengaluru.', 'lowest', 'myth', 'basement', 'exit.', 'anxiety.', 'oriented', 'satisfaction.', 'acceptability', 'alone.', 'acceptance', 'feedback,', "relation's", 'clarified', 'questions.', 'processed', 'old,', 'cell', 'survey', 'accept', 'it!', 'savings!', 'asap!!', 'A.', 'degenerative', 'super,', 'no1', 'tight.', 'Purchase', '350', '2025.', '7g,', 'sensor.', 'rs.250', 'mat,', 'slips.', 'swing', 'arm', 'cranking', 'schooter,125', '4.2', 'kgs', '1.15', 'Thankfully', 'deteriorated', 'Acceleration', 'sometimes.', 'rs.200', '11)', '12)', 'graduates', '13)', 'competing', '(bounce', 'infinity,', 'hours,', 'outer', 'layer', 'peels', 'catches', '10)', 'women,', 'ladies,', 'impossible)', 'excel', 'blade', 'logo', '"pure', '7g"', 'pasted', 'tape,', 'shaking', 'B.', 'premature', 'discussed', '7g.', 'turns', 'agent,', 'sire', 'handmade', '54k', '105-108', 'well-equipped', '14/04/2022', '98', 'happened?', '40days', 'superb,', 'guaranty', 'Dirty', 'blink', 'features..', 'higher,', 'bottom', 'suit', '2.3', 'staff,', 'warrant', 'react', 'king.', 'expert', 'tight', 'the,', 'rush', 'setup', 'ramurthinagar,', 'optima,', 'ex)', 'mistakes', 'acceptable.', 'treat', 'Illiterate', 'sale.', '"on",', 'drl,', 'louder', '100%,', 'replaceable', 'reserve', 'watch,', 'penny.', 'nightmare.', 'downgrade', 'breaker', 'standards', 'bumps', 'image(i', 'value).', 'risk.', 'humble', 'supplier.', 'Suggest', 'k', 'iQube.', 'gaura', 'Kondapur', 'purchases', 'brank', 'facing,', 'upgrade,', 'kml', 'difficulties.', '*', 'Rs.9000/-.', 'unorganized,', 'assembly,', 'fulfil', 'business,', 'seating.', 'complete.', 'process.', 'Coimbatore.', 'leakage,', 'promising', 'circuit', 'IC', "travel's", 'tyre.', "women's", 'terrific,', 'etc..................', '15years', 'banglore', 'Simply', 'circle', '(shreekrishna', 'bandup', 'mumbai)', 'improvements', '!!', '950', '100-105', '12km.', 'catcher', 'showrooms.', 'rs3000', '32%', 'respectively,', '71.9', 'empty', '7km', '78.9', '%,', 'reports', 'shattering', 'network.', 'darling', 'alone', 'kid', 'true.With', '35.', '68%', "Scooter's", 'lodged', 'it.Since', 'october', 'communications,', 'lajpat', 'nagar,', 'fine.Thank', 'erode.', 'okay.', 'doubted', ',incase', 'hills', 'areas.', 'boon', 'ecology', 'backache.', 'gearbox', 'intelligent', 'eight', 'ten', 'frequently', 'disappointment!', '(with', 'curb', 'facility', 'low/', 'agers', 'works,', 'Upto', 'riders,', 'rupee.', 'bicycle', 'fie.', 'practically', 'experience.It', 'praiseworthy', 'comments', 'relatives.Yearly', 'dealer.As', 'Unnecessarily', 'negative.Even', 'overcrowded', "you'll", "child's", 'blessing.', 'geared', 'she', 'aftercare', 'knew', 'argue', 'competitor', 'margin', '84', '52', 'kmh.', 'up)', 'tuesday', 'thursday.', 'thursday', 'friday.', '(friday)', 'arrived.', 'saturday.', 'pitch', 'pedal', 'continuously', 'wheeling.', 'forthcoming', 'probably', 'wheel,', 'organized', 'met.)', 'together', 'supplied.', 'concerns', 'congealed', 'substance', 'problems)', '4km', 'jealous', 'car,', 'disturbance.', 'Beat', 'rate.', 'rate,', 'heavy-duty,', 'very,', 'months…', 'massive', 'handling…', 'costs…', 'experience…', 'it..', 'Worthwhile', 'vegetables…very', 'ampire', 'Locks', '950.', 'Condenser', 'focusing', 'amperes', 'experience..', 'Went', '70%,', 'yrs.', '22-24', 'head-office,', 'dealer,4000', 'keen', 'clueless.', 'search', '10rs', 'clock', 'headache.', 'Chennai', '115580/-', 'cable.', 'Rs.8260', 'Rs.2000/-', 'Mileage=', '1/speed', 'km/charge.', 'Drive', 'shopkeeper', 'needs,', '3hrs', 'morning.', 'onsite', 'Low-cost', 'models.', 'above.', 'Avg', 'Wty:', 'Trust:', '(hero)', 'Overload', 'must,', 'good...For', 'Unbeatable', 'technology...Very', 'cochin', '(aban', 'motors).', 'Multiple', '1000km', '120-150', 'reality,', 'mira', '70kms.', 'tied', 'spoiled.', 'point,', 'riding.Dealer', 'utilization.Company', 'srinivasa', 'trustworthy', 'prepared', 'yourself', 'insulted', 'nut', 'bolts', 'tool', 'allows', 'ground.3.', 'slots', 'secure', 'liars', 'Rs.3000/-.', 'refresh', 'limitation', 'dealers,', 'good.The', 'preference.', 'style,', 'good.Cons:', 'nice...', 'concept', 'Awful', 'considered', 'player.', 'Otherwise,', 'footnote', 'revolution.', 'release,', "company's.", 'favor', 'government.', 'vehicle..', '(okinawa', 'i-praise)I', 'India...', 'adventure', 'subtle', 'combo...', 'recommend.', 'Tell', 'one!!', 'roading.', 'i-praise', 'addition', 'family..', 'ecstatic', 'comfortable..Chic..Handy..And', 'one-time', 'investment.', 'wild', 'structured', 'Center', 'spring', '50-51', '50%.Battery', 'broke.', 'stuff', '45.', '20+', 'funny,', 'tiny,', 'catch', 'man,', 'garage.', 'fraud,', 'Thin', 'humps,', 'time...', 'overpriced.', 'wise,', '.low', 'MCB', 'sheets', 'aches,', 'pain.', '1400', 'dead,', 'prn', 'superb...', 'speed....', 'Eco,', 'turbo....', 'seven%', 'mat.', 'reliability', 'anxiety', 'aside,', 'knocked', 'bricked', '(keep', 'handy).', 'lol.', 'research.', 'findings', '88000', '(on-road)', 'included-charger,', 'mirrors,', 'footrest,', '.Ground', '60km/h', '48-49km/h', 'gmaps.', 'show12.8', "commitment....Don't", 'company....Price', 'ather450', '61', "5'", "5'6", 'freely.', 'loves', 'decreases', '-53', 'decreases.', '2.Sufficient', ':p', 'Low/no', 'fills', 'Pillion', 'Inferior', "could've", '0%', '(dealer', 'day)', 'calipers', 'refinement', 'refined', 'acceleration.)', 'satisfactory.', '1.Good', 'startup,', 'like;', 'switches,', 'high/low', 'toggle', 'zero.', 'persists.', 'tripped.', 'interaction', 'serviceability', '4hrs', '(0-100%)', 'Range:', '(mixed', 'pillions', 'time)', 'mom', 'Apply', 'nitrogen', 'apt', 'etrance', 'handling.', 'Beautiful', 'planned', '95km', 'Tires', 'Size', 'uncomfortable.', '5\'6"', 'Above', 'fat', 'mom,', 'cooperate.', 'Rear', 'Changed', '105+', '96', 'Improvement-', '1)Instrument', '1)Good', 'restart', 'Zippy,', 'responsive.', 'Performance:', 'ghat', 'vendor', 'vendor.', 'RTO', 'edition', 'youths', '150kg', 'load.', 'enters', 'on/off', '(anything', '1km)', 'nice..', '12"', 'ample..', 'commuters', '(45km/h)', '105km', '90kg).', '(60km/h),', 'finally....', 'Hearing', 'firstly', '90km', 'charge...', 'viewers', 'green....', 'better..', 'outskirts', 'extending', 'millage,', 'styled', 'interesting.', 'dilemma', 'weather', 'launch...', 'Siren', 'more(just', ').', 'day...', 'free.Now', 'perplexed', 'random', '"close', 'Comfortable.', 'bikewale.Com', 'shared.', 'Desirable,', 'city.Unable', 'good.But', 'lackey.', 'favorite', 'term(more', 'yrs).', 'cheap,', 'shockers', '20-30k', 'better-built', 'Luxury', 'Healthy', 'Anything', 'recorded', 'often.', 'Important', 'suggestion:', 'recently,', 'raided', 'Compact', '49', 'reading,', '39', 'cheating.', 'Hence,', 'claim,', 'ridge+', 'feb', 'players', 'raipur,', 'Starting', 'tier', 'ride.Om', 'hiking.', 'Step', 'june.', 'pro:-1)', 'price.2)', 'engine.3)', '0/km', 'operation', 'Cons:-1)', '30000)3)', 'responded', 'warning"', 'calibration', 'problem-free', 'garages.', 'mercy', 'ensured', 'deliberate.', 'compatible', 'adults', 'me:', "son's", 'bumping', 'everytime', 'footrest.', 'Effectively,', 'dirty', 'backpacks', 'it.3)', 'hook', 'interference', 'lunch', 'bags.4)', 'store', 'helmet.5)', '(in', 'traffic)', 'fake).', 'two:', 'haul', 'school.Here', 'feedback:1)', 'manage.2)', '(4600km,', '3500km', '),', '(so', '31', '40km/h', '(when', 'full),', '73', 'dont', 'ships', 'chose', 'to.', 'pays', 'gimmick.', 'earthing', 'children,daily', 'uses.', 'Performance-wise', 'Had', 'speedometer/distance', 'provided.', '48km.', 'invalid', 'commute...', 'experience....', 'battery...', 'boon.', 'Far', 'detwin-50', 'peck', 'turnings,', 'pants', 'kids.Many', 'alternate', 'Changing', 'drivetrain', 'convenience', 'middle-class', 'consumer.', 'series:', 'electricals,', 'lights,', '75kmph', 'quality.Cons:', 'overloads', 'stresses', 'split', 'giants', 'ather,', 'sites', 'possible.Personally', 'benelli,', 'chennai.', 'Reviews', 'brands:', 'speed,km', 'readings', 'twenty', 'readings.', 'Personal', ':I', '23', 'risked', 'takes.', 'onus', 'complaint,', '58', 'chinese,', ',totally', '89000', 'scooters.They', '(Indian', 'chinese)', 'name(like', 'benle)', 'u.', 'odd', 'amazon)4.', 'reo:Pros:', 'feared', '(but', 'heavy)', 'stock.', '(suits', 'too)', 'long.3.', 'Benelli:', 'matching', 'rivals.Pros:', '(have', 'reverse),', 'usual', 'bikes.Cons:', 'drew', 'dint', 'extra,', 'plain', 'yamaha', 'longer).', '(better', 'ather)', 'battery.2.', 'ridge+:', 'coimbatore', 'acquired', '75km/charge', 'kpmh', '>90', '>50.', 'lamp,', '(it', 'looks),', 'avearge', 'quality.7.', 'zeal:Reason', 'words,', 'waiting.', 'specs.', '>50', ',belt', 'long.Cons:', 'bugged', 'buzzing', 'electrc:', 'effective,', 'brand,', '(very', '(cheap),', 'performance.Cons:', '40kmph,', 'quality.5.', '450', '400:', "(haven't", 'driven)', '51There', 'July', 'vibrations.', 'either.', '..Plastic', 'Gaps', 'fob', 'prime', 'floating', 'water.', 'echo', '50km/hr.', 'dried.', '20/09/20,', 'running...It', '55-58km', 'good)Who', 'donate', 'speed+', 'performance+', 'fort', 'it.Note:', 'yamaha,', 'watt', 'newbie', 'body),', 'harness', '(my', 'changed)', 'options,', '(fast', 'reduces', '(12', 'kgs)', 'warehouse.', 'Planning', 'shortly.', ':-)', 'chosen', 'enthusiastic', 'shares', '160.', '1700', '4500.', 'slowing', 'outdated', 'Jupiter', 'while.', 'part,', 'structure,', 'supermarket', 'recommendation', 'porter', 'rajajinagar,', 'Found', 'cotton', 'flashiness', 'identified', 'rectified.', 'Experience,', 'trash', 'know,', 'Three', 'spleen', 'amp', 'sockets', 'kms),', 'god', 'moving)', 'tightened', 'stalled', 'replying', 'Nearby', 'centers.', 'noiseless', 'Post', 'boys', 'established', 'bang', '54km', 'wagon', 'Electronic', 'scratching', 'finalized', 'Brand', '(indian)', 'Practical', 'goods', 'ton', 'performs', '....100%', 'Crossed', '11500', 'zeal.', 'stretch', '76km', 'often,', 'hopeful', 'shell', 'Nearly', 'breaking,', 'grip,', 'built,', 'availability,', 'rattling', 'indicator.', '(else', 'giant', 'hand)', 'Recurring', 'rush,', 'q', 'years/30k', 'km)', 'ample', 'agencies.', 'Keyless', '(controllable', 'car)', 'Minus:-', 'patience.', 'Apart', 'Plus:', 'Budget', '(all', 'incl.', 'pune)', '(3', 'mere', 'coil', 'burnt', 'fought', 'debut', 'sadly', 'motherly', 'treatment', 'properly.4,', 'newly,4,', 'newly.', 'greenway', 'keezhapaloor.', '63-67', 'indicator,tail', 'particular', 'component', '67500', 'Stopped', 'Matte', 'seen,', 'Lite', 'burned.2.', 'pressing.3.', 'lightning.', 'dealing', 'Tyres', 'bulged', '2020.Since', 'accelerating.', '8months', '4dys.', 'Who', 'basis.', 'especially,', '8000', 'awesome!!!', 'singles', "lite's", 'Approached', 'immediate,', 'vehicle-', 'same,', 'properly-', '700km,', 'mistake(', 'issue),', 'defect.', 'praise.3.', 'Par', 'excellence', 'features.4.', 'new..', 'cons..', 'amazing..', 'coming,', '7k', 'assembly', 'removed.', 'Allover', 'pollution-less', 'mcp(middle', 'Awesome;', 'lite,', 'Sound', 'unbearable', '200.', 'sunday', 'hours.3.', 'braked', 'signal,', 'releasing', 'Dl', '9sb', 'v7147)', 'dwarka', 'both.1.', 'connector.', 'day.2.', 'saturday', 'bad.When', 'dinzy.', "'ls", 'superb..The', 'more.The', 'sharp.The', 'e-5', '(registration', 'cycles,', 'everyday!!!!', 'duff,', 'charged,', 'start.', '45kms', 'employees.So', 'better..In', 'smooth...', 'fuel...', 'scooter...', 'reasonable...', 'perfect...', "Heart's", 'consult', 'owners.', 'battery5.', '6.The', '7.And', 'sincere', 'z,', 'After-sale', 'dry', 'scooter/motor', 'badly.', 'shocker,', 'shocker', 'road.6.', 'mileage(', 'charge)', '3.Worst', '4.No', 'Fortunately', 'workshop,', 'engineers', 'month.4.', 'tight,', '–', 'suddenly.', 'hurt', 'town.', 'lights.', 'study', 'imports', 'china,', 'evident', 'lacks', '50km.', 'toys.', 'Anyone', '61,000', '8km', '20km.', 'left)', '50-55.', '0-100%.', 'cheetah,', 'smoothy,', 'memorable', 'inhabitant', 'switch,', "breaker's", 'touched.', 'recently.', 'touching...', 'services...', 'On-time', 'good...', 'scooter...This', 'mah', 'r30', 'faster', 'cost,', 'cry', ',thanks', 'best!', 'level!', 'one!', ':)', 'Hey', 'diseases.', "month...Don't", 'guys...!', ',every', 'formality', 'converter', '30000.', 'Moreover,', 'basically', 'torquey', 'availably', 'Road', 'ridded', 'bikes...', 'Yo', 'drift...!!', 'setback', 'advise', 'packing', 'tubes', 'heated.', '41', '10-20', 'kilometers.', 'ability', '.storage', 'lazy', 'quote', '35kms', 'escalation.', 'attends.', 'BMS', 'whit', 'commits', 'buying,', '1.9', '(r)regenerative', 'led,', 'alloyed,', 'reflector,', ',2021)', 'crosses', 'century,', 'km/full', '(7hrs', '-9hrs)', 'executives', 'explains', 'sujan', 'roy', 'coochbehar', 'yo', 'drift', 'dx', 'nine', '(August', 'embarrassed', '8)I', '33', '0.19', 'cylinder', '150kms,which', '9000', 'clueless', '1)no', '2)no', '4)battery', '5)charger', '6)even', 'call,', '7)people', 'experimenting', 'footboard', 'fit,', 'hence,', 'Super-smart', 'hindrance.', 'patches', 'loosing', 'life,', 'waterproof', 'Seems', 'third', 'jobs', 'draining', 'fast,', 'cracked,', 'out,', '90-100km', 'change.', '5-6', 'provides.', 'complain', 'tracked.', 'Techo', 'Electra', 'nontechnical', 'repairs', 'breakdown', 'Continuously', 'ether', 'money.Sent', 'experiments', 'handled', 'super-bike', 'short-ride', 'rs,10', 'rs.60', 'sip.', '2000kms', '.Mcb', 'burning,', 'specifically', 'idea.', 'disappointed.', 'Nobody', '180kg', ',price', 'unavoidable.', 'air,', 'backrest', 'surfaces', 'locally', 'soothing', 'white', 'affordable.', 'propose', 'charge).', 'Gets', '4km.', 'covering', 'Value,', 'zomato', 'Third', 'toy.', 'garage,', 'electra.', '55,000-60,000/-.', 'clocked', '6,100', '27,000/-.', 'Poor.', 'perfect!', 'L', 'service.Spare', 'that.Now', 'mails.', 'supportive..', "pune...Doesn't", 'premium...Have', 'Plus.', 'model...Or', 'genuine', 'thowlichowki', 'on)', 'Compare', 'tips', 'Bottle', 'rack', 'plus,', 'all-purpose.', 'Wasted', 'license,', 'rc', 'challenge', '62000', 'Up', 'moving,', 'improve.', 'worthiness.', 'Models', 'elegant', 'genex', 'inquired', 'enquired', 'safe,', 'drives.', "it'", 'Disappointed', 'ebike.', '(15+).', 'functions', 'appreciable.', '(generally).']</code></pre>
      
        <p><strong>Hyp output variables:</strong> words, __output__ </p>
    
          <p>words (Series):</p>
          <pre><code>is              False
the             False
and             False
to              False
in              False
                ...  
ebike.           True
(15+).           True
functions        True
appreciable.     True
(generally).     True
Name: review, Length: 9153, dtype: bool</code></pre>
      
          <p>__output__ (list):</p>
          <pre><code>['50kmph.', 'even,', 'season.', 'Ask', 'Taken', 'good.Bad', 'soon..', 'say.', 'Felt', 'society.', 'girls', 'economical.', 'destroy', 'first.', 'batteries)', 'term.', 'Screws', 'initially,', 'highway.', 'catchy.', 'fighting', 'blaming', 'customized', 'pockets.', 'Available', 'discounts', 'Expertise', 'ecstatic.', 'acquaintances.', 'professional', 'decisions.', 'Doesn’t', 'hesitant', 'jammed', 'Safety-wise', 'zero-rating.', '1,2,4', 'hs500.', '.Waste', 'wise.', 'Economical', 'agna', 'jp', 'arrival,', '5weeks.', 'Headlights', 'improper', 'Experienced', 'pieces', '5.Pros', 'Environment', 'population.', 'Large', 'trucks', 'flicks', 'little.', 'Cheated', 'lx(hspl)', 'motocrop,', 'company..', 'Fail', 'costed', '3.Details', 'satisfying', '4.Servicing', 'slips', 'easily.Moreover', 'tusha', ',colour', ';its', 'pleasant', '.Little', 'lasting.', 'dilemma,', '!!...Or', 'decent,', '"good', 'old",', 'fossil', 'fueled', 'Outrageous....Keep', 'traders', 'Sitamarhi', 'Bihar.', 'pls', 'Note', 'best,', 'Shockers', 'joking...Serious.', 'minimize', 'everywhere', 'hilly', 'backwards.', 'Etc..', 'proof.', 'lx', 'Bhavya', 'Unfortunately', 'died.', 'news,', 'doctors', 'announcing', 'patient.', 'victim.', '45%', 'st.', 'Thomas', 'agency', 'thrissur', '2018.After', 'down.This', 'good.This', 'emission', 'response,', 'Monopoly', 'seniors', 'immediate', 'melt', 'rs1000', 'tighten', 'its.', 'indicator,', 'manufactures', 'impatiently', 'convert', 'mobility', 'e-mobility.', 'notable', 'disrupting', 'leans', 'bullock', 'cart.', 'presently', 'sustains', 'cycles.', 'Small', "kid's", 'lithium.', 'avon', 'optima.', "dealer's", 'enquiries.', 'pump.', 'sits', 'side)', 'venturing', 'emission.', 'carrying..', 'Moreover', 'levels', '40kms', 'Probably', 'disagreed', "week's", 'serving5.Loding', '100kg,', '32km', 'lover', 'consumption.', 'lockdown.', 'Congratulations', 'developer', 'scout', 'day.This', 'Capacity', 'member', 'solo', 'min', 'Four', 'organization.', 'onboard.', 'slow.The', 'scooter.Servicing', 'priority.', 'At-last', 'steady,', 'mopey', 'Spending', 'tears', 'Good2.Load', '3.Good', 'body4', 'Book', 'even.', 'mismanaged', "toy's", 'counterparts', 'Reasons', 'whats-app.', 'goodwill', 'verdict....', 'youngster,', '2017.', 'automobiles', 'gasoline', 'income.', 'earning!Perks', 'verdict.', 'Everyone', 'global', 'warming.', 'kilometre,', ',worst', 'assurance', 'truth', 'Absolutely!Apart', 'eco-friendly,', 'pockets', 'Plus,', 'beauty', 'used,', 'sometimes,no', 'stiffen', 'optimus', 'interval', 'colour.', 'frequently,on', 'Absolute', 'stops.', '50km.Better', '40km.', 'occasions,', 'precisely', 'smoothie', 'peoples.', 'wreck', '12000/', 'battery.no', '35000.', 'dissatisfied', 'beautiful,eco', 'Reasons.', "what's-app.", 'depreciation', 'p.A.', 'benefits,', 'tax.If', 'Calculate', 'now!!!.', 'Everbody', 'stares', 'capital', 'investment·', 'low-cost', 'maintenance·', 'Furthermore,', 'annual', 'They’re', 'eligible', 'everybody.', 'e-vehicles', '20.', 'reviews.', 'solo.', '1.They', 'e-bikes·', 'cost·', 'bored', 'sometime', '30km/hr', 'avg.4.', '(10000rs', 'approx.)5.', 'problem.If', 'writes', 'cruz', 'owing', 'engine,', 'rto,', 'licence.', 'No,', 'reasonable.2.', 'enough.3.', 'kolhapur', 'separately', 'beginning.', 'careful.', 'although', '250watt', 'telescopic', 'forks', 'Aug', 'undoubtedly', 'Pros.', 'Useful', 'OTA', 'Cons.', 'replacement,', 'goa,', 'upgrade...Thus', 'incentive!', '1,90,000!', 'excellent,', 'wheeler,', 'Introduce', 'rules.', 'Basically', 'retailers', 'year.I', 'it.In', 'issuing', 'separate', 'invoices', '(1,39,000)', 'incentive', 'it.I', 'Electrically', 'chargeable.', "Doesn't", 'licences', "drive,doesn't", 'wear.I', '1/2', 'satisfying.', 'durable', '3-4hours', 'backup.', 'beautiful.', 'instructions', 'instructions.Its', 'petrol-diesel', 'Things', 'b4', 'ecosystem', '1.6L', 'W.', 'bite', 'daughters', 'said.', 'maintenance.I', 'four', 'day.My', 'fulfill', 'thanks.', 'Duke', 'up-to', '80kmph', '40km/hr.', 'Gives', 'goid', 'absorber.', 'most.I', 'much.It', 'designs', 'this.There', 'IQUBE', 'VS', 'ATHER.', 'ATHER', 'rs..no', 'paise', 'clients', 'trustworthy.', 'product....', 'la', 'also.,', 'model.,', 'extra.', 'Proper', 'needed,', 'screw-up', 'wished', 'bog', 'Let', 'fearful', 'over-load', 'damage', 'depressed', 'soon..Much', '1,68,989/-', '1,39,989!', 'vehicle.Buying', 'resolved,', 'constraint', 'mileage.Looks', 'e-scooty', 'suffer', 'collected', 'yesterday!', 'experience...', 'effortless', 'ride..', 'shady', 'billing', 'invoicing', 'manager,', 'dept', 'dark.', 'court.The', '11th', 'Height', 'will.be', 'Connected', 'yesterday', '13th', 'hopefully', 'facility.', 'parents', 'Product', 'measurable.', '>15', 'tilt', 'cornering', 'balance.', 'wet', 'monsoons.', 'structure', 'prolong', 'insured', 'biking', 'absorbers.', 'Extra', 'maps', 'heaviest', '(bearing)', 'higher.', 'noticed', 'referring', 'friends..', 'across.', '1)buying', 'fulfilled', 'Bajaj.', 'Insurance', "EV's", ',over', '1,00,000', '4g,5g,125', 'Ludhiana', 'Chandigarh', 'positively.', 'department,', 'executive.', 'feasible', 'approached', 'judge', 'rims', 'colors,', 'great.Looks', "who's", 'license.', 'Servicing:', 'Bangalore,', 'Price,', '(government', '29k', 'discount)', 'After-sales', 'Long', 'alternative,', 'fiber.', '43000/-', 'learn', 'helping', 'spouse.', 'basis', 'perfectly', 'jam', 'beam.', 'mudguard,', 'mechanics,', 'costumer', 'spear', '(expected).', 'operational', '.Also', 'millage', 'monthly', 'tag.', 'Drum', 'Rainy', 'moist', 'seasons', 'jelly', 'Subscriptions', 'hated', 'described.', 'Previous', '1.2', '1.8', 'liter', 'faster.', '60-62', 'Honestly', 'marvel.', 'Hassle', 'technicians...Replaced', 'ather450x,', 'range....Not', '72ah', 'seamlessly', 'kilometres', '2.4k', 'category', 'maximize', 'volumes', 'grow', 'models,', 'job*****.', 'garage', '..Now', 'e-bike\\car', '*tork*', 'market..', 'brushless', 'fueling', 'sufficient.', 'Trust', 'omr', 'express', 'cautious', 'sync', 'Rather', 'peaceful', 'Public', 'properly,', '15km', '(tested', 'self)', '15%', '10K', 'kickstart', 'two-wheelers', 'fairly', 'fz-s,', "motorcycle's", 'Govt', 'account.', 'absobers', 'vehicles.Option', "i'll", 'x', 'e-motorcycle.', 'worrying,', 'wherever', 'picnic', 'green.', 'Comfort', 'Pricing', 'suggestions', 'ports.', '1.36lakh.', 'market.And', 'vapi-gujarat', 'transporters', 'jan,2019....Again', '2019.....Hope', 'postponed', 'further....I', 'date’s', 'postpnd', 'one......Just', 'good...But', 'north.', 'centres.', 'aspects,', 'gonna', 'relief', '....I', 'year....1st', 'dec,2018,', 'mind,totally', 'presence,', 'tension,', 'tenson,', 'system,just', 'deciding', 'sight.', 'difficulty', 'Ather,', 'complaints,', '100k', 'prototype.', 'converted', '11l', 'points.', 'nvh', 'Those', '450X', 'pick-up', 'reviewing', 'angle.', 'pathetic,', 'pre-booked', 'ad', 'Ride.', 'Unbelievable', 'boing', '737', 'JET.', '4G', 'connectivity...', 'Accuracy', 'research', 'development.', 'thailand', 'click', 'total.', 'aya', 'extreme', 'Superior', 'dates...', 'Few', 'TORK', 'list,', 'commitments', 'consumers,', 'firm', 'struggling', '450is', 'fulfills', 'regeneration', 'coasting.', 'stability', 'arrangement.', 'timeline', '9.', 'impressive.', '105kmph', 'westend', 'aundh', 'sat', '45days.', 'Combi', 'lover.', 'whilst', 'traveling,', 'unhelpful.', 'woman', 'passports', 'generally', 'unpleasant', 'paperwork.', 'information.', 'maintained,', 'rented,', 'prior', 'ended', 'renting', 'confusing', 'receipt', 'attributes.', 'lagging', 'optional', 'indeed', '3.No', '4.Stylish', 'streamline', '5.Abs', 'abs,', 'rivals', 'glamour', 'crazy', 't6', 'super.....', 'X.', 'benchmark', 'agile', 'commuter,', 'smart,', 'ecofriendly', 'cost-effective', 'indian.', 'Weighing', 'kg,', 'Wonderful', 'invest.', 'tad', 'proven', 'commodity', 'kratos-', '-make', 'ridden,', 'fighter', '24.Water', '25.Company', 'ups.', '1.36lakh', '(electric,', 'design,mobile', 'manufacturers,top', 'chaning', '18.Dual', '19.Good', '20.Bike', '21.Mobile', '22.Family', 'suited.23.City', 'street', '12.Helmet', '13.Mobile', '14.Cloud', '15.Cloud', 'detects', 'malfunctioning', '16.No', '17.No', '6.Safety', '7.Tft', 'interface', '8.Tubeless', '9.Easily', 'track', 'records', '11.Good', 'unmatchable.', "brand's", 'wrathful.', 'obviously', 'signals', 'dashboard.', 'grid', 'finished', 'madhapur,', 'Hyderabad...Excellent', 'reception', "apple's", 'perfection', 'core.', 'flaws', 'glitches.', 'choice.Coming', 'tyres,abs', 'good.I', 'not.Because', 'nodes', 'enjoy.', 'conscious', 'walked', 'speed,charging', 'time,water', 'battery)', 'buying.When', 'range(100km)', 'suggests', '0-100', 'stars,if', 'quietly', 'am..', 'Belt', 'priced.', 'rs1.51/-', 'Chennai)', '2500/-', '5000kms', 'desperately', 'win', 'Others', 'oppo,', 'vivo', 'mi.', '|From', 'touring', 'somehow', 'Unexpected', 'unexpected', 'shocked', 'amazed', 'mailed', 'reply.', 'reviewed', '1000kms', 'neutralise', 'Change', 'oil.', 'safe.', 'phone.Very', 'e-moto', 'roads.Last', 'conserve', 'proactive', 'vehicular', 'greenhouse', 'becoming', 'superpower', 'e-mobility', 'AMO', 'two-wheelers.', 'kratos.', 'posture', 'costliest', '1.65', 'emerging', '2022,', 'launched.', 'Seeing', 'field.', 'thief', 'market.For', 'ways', 'kratos,', '•this', 'king', '2400/-', 'annum', 'two,', 'competitors', 'worth.', 'race.', 'kick', '100t', 'extorting', 'fancy', 'order.', 'swadeshi-made', 'vehicle!!!', 'Reverse', 'fine.', '(km/charge)', 'pollachi.', 'removable,', 'be.', 'doubts.', 'shared', 'commuters,', 'world,', 'etc.).', 'pune,', 'already.', 'tamilnadu', 'fore', 'loving', 'officers', 'office.', 's!', 'penetrate', 'felt.', 'Samsung', 'knowledgeable', 'supportive.', 'characteristics', 'r.................', 'Glad', 'assistance,', 'worked.', '50%', 'joke', 'Nexon', 'opinion,', 'investors.', 'schedule', '(203', 'centers,', 'dec,21.', 'members', 'Elderly', 'hype.', 'attends', 'lift.', 'kanpur,', 'lucknow.', 'development', 'ditched', 'coordination', 'commitment', 'exceeding', 'aspect', '"bikewale"', 'wrong,', 'coverage', 'framing', 'cibil', '790,', '1.56', 'lac.', 'occasional', 'lags', 'interface,', "ola's", 'books.', 'necessity', '135-140', 'Perhaps', 'messages', 'march:', 'canceling', 'stating', 'section.', 'turner!', '40%', 'buggy', 'December.', 'happened.', 'Jan.', '(this', 'date).', 'Nevertheless,', 'Feb', 'real-time.', 'doorstep', 'Quality:', '0.', 'Service/maintenance:', 'request,', 'front.', 'agents,', "vehicle...It's", 'ha', 'shape', 'Came', 'stars.', 'cancelled', 'floor,', 'hump.', 'proved', 'too).', 'brainwashed', 'advertisements,', '"', 'this".', 'frustration', 'through.', 'filled', 'Month:', 'Here', 'am,', 'may:', 'Again,', 'prioritizing', 'case".', 'there).', 'regen', 'aggressively', 'juice', 'leisure', 'travels.', "friend's", 'ride!', 'generated.', 'storing', 'regular-sized', 'stand?', 'aftermarket', 'separately.', 'ice', 'height,', 'seats,', 'coordinated', 'nagpur', 'last-minute', 'glitch', 'mix-up', 'impression', 'negative,', 'decade', 'Excellent,', ',Ola', 'nailed', ',speed', 'yes!!', 'Price.', ',range', 'manipulated', 'channels.', 'Placed', 'mega', 'videos', 'circulating', 'advertisement', 'flashy.', 'all..', 'dussera', 'expectation', 'year-end,', 'wishful,', 'tesla', 'usd', 'booking).', 'Anyways', 'encourage', 'Software', 'bugs.', 'input,', 'consistent.', 'temperature', '10-12', 'rights', 'nd', 'inbuilt', 'party', 'anytime', 'hanging', 'friends.', 'view.', 'hate', 'peppy', 'compete', 'By', '/km', 'Emi', 'join', 'electrifying', 'elderly', 'weather,', 'ends', 'season', '-It', 'prompt', 'Until', 'Environment.', 'simplicity,', 'charm', 'metro', 'inconvenience.', 'scenario.', 'appealing', 'Myself', 'hardware', 'cold', 'booking.', 'Bajaj,', 'rely', 'midnight', 'Already', '2005', 'tough.', 'Second', 'payments', 'abide', 'promise.', 'good..', 'web', 'site', 'crashed', 'crashed.', 'systems', 'shift', 'think.', 'ant', 'Overhaul', 'compartment,', 'silent,', 'keyless,', 'Fixed', 'residents', 'building', 'dwellers.', 'sl', 'begin', 'colorful', 'highest.', 'unimpressive', 'J)', 'prominent', 'where.', 'Oct', 'Resident', 'sixty', 'S1pro.', 'commitments,', 'cons-', '70km/h', 'people,', 'A)', 'H)', 'misses', 'I)', 'difference.', '181kms', 'revised', '135/-kms', 'depend', 'display.', '32kms,', 'charges.', 'EV,', 'Twice', 'message', 'supplies.', 'addressing', 'August', '142000+.', 'rs.120000/-.', 'facing.', 'Launched', 'Dec-2021', 'cool,', 'elite', 'awaited', '124', 's1.', 'thinking.', 'jerky', 'EVs', 'eye-catching,', "Can't", 'trails', 'errors', 'resolutions', 'itself..', 'window.', 'Procedural', 'understandable.', 'transporter', 'alright.', 'preinstalled.', '500km', 'tea.', 'capability.', 'looting', 'smoother.', '4.8', 'starings.', 'dropping.', 'emergency)', 'peer-level', 'drained,', 'Due', 'inconveniences', 'salary', 'sleeping', 'grievances', 'cup', 'deducted', 'continue', '135kms', '10%per', 'promised.', 'music', 'glitches', 'stage.', 'alloys', 'brakes..', 'price..', '1,20000', 'INR.', '1-looks', '2-performance', '3-heallty', 'loudspeakers,', '3.Black', 'pretty,', 'horse', '4.Low', 'early.', 'triple', 'touchwood', 'buy!!!', 'remember', 'hard-earned', 'junk,', 'reliability.', 'created', 'lethal', 'disable', 'clerks.', 'Coimbatore', 'beliefs.', 'mail,', 'worse', '560', 'shutdown', 'belief', 'deserve', 'e1', 'communication,', '18th.', '—', 'black.', 'grey', 'hassle,', 'fashionable', 'infinity.', 'EVS', 'trends', 'swappable', 'packs,', 'travelled', 'rock', 'Secondly,', 'tricky.', 'obvious', 'Inline', 'ext.', 'tour', 'family,', 'special.', '4-resonable', '5-boot', '7-and', '1-costly', '2-mono', 'encrypted', 'passcode', 'enables', 'driven,', 'maps.', 'BTW', 'offline', 'speakers,', 'songs', 'utlity', 'knee', 'youngsters', 'kukatpally,ecil,', 'enjoying,', 'colleague', 'ecil', 'workplace.', 'taillamp', 'Coming', 'Pune.', 'June.', 'May.', 'hyderabad,', 'pick-up,', 'front...', 'Bounce', 'rocking.', 'bouncing,', 'tends', '12–15', 'access', 'IDs', 'So-called', 'region,', 'finalize', 'gps,', 'bet', 'rapidly', 'wide.', 'prepping', 'exterior.', 'fabric', 'indicators,', '35%', 'unnecessary,', '92000', 'talk,', 'management,', 'credit', 'innovation,', 'Future', 'trap,', 'deposit', 'reputed', 'amount.', '68000/-', '98000', '/-', 'cancel.', 'OMG,', '110-115', 'sport,', 'hyper.', 'rs.79999/-', 'rs.85000/-', 'rs.87000/-', 'rs.97000/-', 'crack', 'Inform', 'salesman', 'cause.', 'dim', 'aggressive', 'pricing.', 'roading', 'smother', '450x,', 'antitheft', 'comforts', 'e-vehicle', 'exceed', '10electric', 'relatives', 'heads,', 'number.', 'chat', 'feedback.', 'seams', 'link', 'contract', 'starting.', 'headlamp,', 'email.', 'corporate', 'skin,', 'resolution,', 'dummy.', 'Continues', 'Item', 'rs.3/km', '(claimed)', '(info', 'technician,', 'subject', 'increases)', 'Niggles', 'pushed', '6amp', '4.54km/rupee', '0.22/km.', 'comparison,', 'returning', 'km/l', '105/litre', 'equals', 'destroyed', 'enthusiasm,', '400/', 'duke', '250)', 'ass', '750w', '6.5', 'Vary', 'kolkata.', 'instrument', 'cluster,', 'rush.', 'See', 'pricy', 'last,', 'decently', '25km', 'dense', '..But', '..Did', 'b', 'motor..Good', 'autos', 'mayb', 'cuz', 'model(cuz', 'so)', '..They', 'wer', 'patient', '250w', 'use.But', '500rs.', 'Yearly', 'expenses,', 'Kabhi', 'karna', 'timely', 'websites', 'aspects', '.We', 'awesome.Go', 'scooter.Hero', 'splash.', 'buy.But', 'good.Has', 'easy.Although,', 'taller', "(i'm", 'feet).', 'whines', "(it's", 'addictive).', 'bugs', 'beta', 'paise/km', 'free..Just', 'planted', 'corners,', 'mrfs', 'grip.', '790mm', 'padded', 'that(', 'sarcastic)', 'hahaha', '...Looks', 'clearance...Suspension', 'Ridden', '45km', '58.5k', '100cc', '35kmphr', 'breeze', 'vibrations', 'quiet', 'waow', 'squeaking', '..I', '50-70', 'allocate', 'wall', "e's", 'face!', 'parent', 'german', "isn't", 'scooter.I', 'trave', '45000', '53000.', 'cuts', 'saturates', 'drive?', 'Finally,', 'wind,', 'windrider', 'wind', 'lonely', 'road.Looks.', 'asking,', 'thing.Great', 'money.Must', 'os.', '0-40', '0-60', '58nm', '(accelerates', 'arguably', 'dominar', 'surfing', 'happiness', 'Lot', "1'year", 'father.', 'raigad', 'dealers(Trissur).', 'dealers(Trissur,', 'mannuthi)', 'polluted.', 'healthy...', 'kilogram', 'safely', 'education.', 'dismantling', 'assembling', 'accessible', 'chime', '7".', 'runner', '(90s', 'relate?)', 'agile,', '4000-5000', 'atmosphere', 'flat,', 'compensates', '36lt', 'helmets,', 'ls2', 'ece', 'sideways.', 'Turn', '(5000', '5000*3.97', '=', '19850', 'additional)', '89400', 'Effective', '108000', 'km/l.', '9000,', '17000)', 'Fame', '59550', '(15000', '15000*3.97)', '29850', 'freedom', 'situation.', 'role', 'rafter', 'handed', 'diagnose.', 'Rafter', 'expected.', 'nice,and', ',scooty', 'choice,', 'handling,', 'fuel.Good', 'corp.', 'aerodynamics', 'highest', 'Against', 'inexperienced', 'demanded', '1020', 'bike.100', 'actual.', 'account', 'specifications.', ',not', 'receiving', '.Even', 'vouchers', 'redeemed', 'Jindal', 'Khandwa.', 'Elecric', 'Aditya', 'Varanasi', ',up', 'passed', 'renewed', 'basis,', 'Uncomfortable', 'replies', 'sports,', 'Arai', '181', 'Design', 'fan,', "dominar's", 'arise', 'pay,', '197400', '(ex', '163549,', 'card', '200,', 'postal', 'fee', '50,', 'icici', 'lombard', 'respectively.', 'Home', 'mini', 'truck.', 'Idv', '155400', 'rear.', 'invite', 'later.', 'Paid', 'October,', 'window', '15-31.', 'intimation', 'unit.', 'transport.', 'rupees,', 'galaxy', 'pcmc.', "hour's", 'sparingly.', 'Or', 'kilometre.', 'economical.2.', 'women.3.', 'low.4.', 'inserted', 'repair.Pros:', 'weight.Parts', 'weight.Height', 'experience.Ans.', 'Service.', 'In-front', 'battery.So', 'escalation', 'contact.', 'responsible.', 'essential,', 'reserved', '23.', 'later,', 'Hyderabad,', '40.', 'stuff.', 'wiring', 'needed.', 'dep', '7632,', '135km', '/charge', 'launching.', 'household', '3rd,', 'adopters', 'unique.', '500+', 'creasy.', 'fits', '(from', 'remaining)', 'scratches.', 'inspected', 'intrigued', 'astonishing', 'fell', 'stand-by', 'Stay', 'unbeatable', '1/5th', 'Lt', 'peace.', "champ...It's", 'teenagers', 'speeding..The', 'appreciated', 'time..The', "..You'll", 'once...Thanks', 'women.Cons:', 'sightly.Parts', 'strong.Seat', 'man.Tyre', 'necessary.', 'months.When', 'rm', 'secrets', 'now)it', 'According', '130-150', '131', '147', 'online,', 'door', '145', 'ideas', 'expertise', 'conduct/', 'projects', 'useful...', 'bike(lead)', '41,000(maybe', 'costlier', 'aggressive.', 'weaned', 'meaningless', 'consequent', 'inevitable', "'eco-pollutions'...It", 'enhanced.', 'innovative', 'pre', 'Pros-looks,', 'accelerated...', 'immediate!', 'in-town', 'move-abouts.', 'Your', 'ads', 'grips,', 'bag', 'hump),', 'flimsy', '(center', 'possibility', 'design),', 'saree-clad', '27th', '6.45', 'miserably.', 're-brand', 'loyalty', 'Significant', 'capacity,', 'unfirm', 'life..', '30-45', 'km(not', 'me).', 'allowing.Well', 'clean.', 'nonstop.', '6.30', 'price.129999/-', 'lock,', 'Sometime', 'park', 'dedicated', 'chatting', 'chatbot..', 'regretting', '..This', 'free..And', 'useful...And', 'lag', 'over-speeding', 'reversing.', 'followed', 'Bluetooth,', 'lever', 'local.It', 'approx.Very', 'use.Alloy', '.Especially', 'referred', 'parents.I', 'prices.This', 'shop.....', 'shop?', 'take.', 'no...', '10kms', '27km/hr', '55kms/1', 'Brake', 'Off', 'roed', 'bettar', '(ignore', 'news)', 'house', 'Used', 'urgency.', 'students.In', 'trending.Hero', 'packed', 'bent.', 'silence', 'netherland', 'laptop', 'behind.', 'burst', '20-25', 'automatically.', 'pulled', 'pm.', 'unfamiliar.', 'rightfully', 'beneficial', 'Consumes', 'teenagers,', 'hurry.', 'profitable', 'wallet', '&man', 'used.Look', 'scooties', 'navigation,', 'negotiating', 'ambitious', 'balanced', 'patrol', 'inventing', 'Completed', '2800', 'mileage...........Replace', 'average..Its', 'fine..Its', 'money..I', 'dad..Initially', 'police', 'inquiry.', 'Saving', 'Biggest', 'material.', 'Nil', '......', 'flash.', '...Stylish', 'hesitation', 'cost...', 'large.', 'runs.', 'sheer', 'Night', 'lamps', 'ebike', 'gorakhpur.', 'unvalued.', 's/w', 'instructed', '5%', 'produced', 'gases', 'heat.', 'Nowadays,', 'Soundless', 'So...', 'is..', '500.', 'bowled', 'gerua', 'holi,', 'Updates', 'notifications.', 'all.Now', 'putting', 'disconnect', 'reboot', 'supplied', 'industry.', 'cruise.', 'list.', 'indicators.', 'bike.All', 'places....', 'neighbour', 'Specially', 'elder', 'specific', 'passionate', 'activities', 'mom...She', '...Good', 'suits', 'ages....!Capable', 'seater', 'e-', 'ride.Focus', '6)I', 'useless.', 'domestic', '15-18', 'limit.', 'arrange', 'Stunning', 'bike,awesome', 'older', 'canter)', 'guaranteed', 'satisfies', 'Fast', 'width', '3)change', '1400/per', ',because', 'price,,and', 'pollute', 'attractive.Easy', 'reliable.Preferably', 'used,easy', 'wheeler.', 'lightly', 'real-time', 'drop,', 'Before', 'purchasing,', '119', ',,value', 'money.It', 'whenever.I', 'missing,', 'updates.', 'care-', 'actions.', 'serves', 'drain.', 'delivered.', 'a)', 'also.Smooth', 'wonderful.Service', 'cheaper.', 'much.I', 'vasool.', 'company.I', 'malfunctions,', 'overheated,', 'smooth.I', 'elders.', 'stylist', 'certain', 'maintainable', 'fee.', 'bright.', 'Right', ',smoother', 'movement', 'undue', 'hackles', ',just', 'ride.Decent', 'stunning', 'chances', 'i’m', 'wrong.Good', 'pretty.Its', 'encouraging', 'carbon', 'dioxide.', 'brand,because', 'trust-able', 'nice.When', 'links', 'Young', 'rumours', 'reliable.Its', 'environment.Electric', 'trafficking.And', 'box.We', 'excessive', 'storage,', 'luggage,', 'overweight,', 'elderly.And', 'newcomer.', 'safely.', '24kms', 'earning', 'ruined', 'betrayed', 'uncle.', 'stressful', "flash's", 'certainly', 'beautiful.Being', 'flow', 'wings', 'eagle.', 'simplicity.', 'highways.', 'mother', 'exists.', 'started.', 'low.The', 'large.The', 'comfortable.Overall', 'gottigere', 'branch.', 'promote', 'maharana', 'partap.', 'hours..', 'less....', 'ok...', 'Ok', 'flyovers..', 'problem....', 'mix', 'Run', 'Specification', 'Fuel', '300%', '78k...', '80..', 'look...', 'space...', 'heavy...', 'Ather-450x', 'ethics,', 'appeal', 'fair', 'trial', 'manufacturers.', 'entrepreneurs', 'imbibe', 'subsidiary.', 'subsidiary', 'hikes?', 'Chetak,', 'gain', 'slightest', 'adopted', 'strategy,', 'insert', 'Okay', 'components,', '35,000+', '20,000', 'users.', 'compactable', 'pilon', 'heavily,', 'Needs', 'aluminum', 'tire', '155+', 'mm,', 'Feels', 'breaker,', 'Reaches', '60k', '10-15%', 'jump', 'noticeable', 'gradation.', 'Rs.5000/-', 'whopping', 'exposed', 'walls.', 'improved.', 'comfort,', '4.6', 'greeves.', 'released', 'forward.', '-superb', 'maintenance।', 'cons।', 'look?', 'appealing?', '89', 'precise.', 'consoled.', 'Elon', 'Musk,', 'co-founder', 'Tesla', 'Company,', 'sole', 'checked,', 'experience।-', 'ne', 'instantly', 'November.', 'riding.(', 'light)', 'paddle', 'carry.', 'rs.84,000', 'one-second', 'consume', 'Disadvantage:', 'bone.', 'severe', 'r&d', 'handles.', 'hundred', 'intense', 'Getting', '100+', '4.I', 'bill.', 'choice..', 'arises', 'surface.', 'Rs.27000/-', '2021.”Bajaj”', 'exploiting', 'contrary,', 'encashing', 'swallow', 'thumb', 'volume.', 'buyers,', 'theft.', 'goers', 'Since,', 'smaller', 'hats', 'legend', 'confusion', 'concern..Max', '..40', 'speed...', "hours..It's", 'average...Within', 'ones.', 'Enough', 'garages', 'Ampere,', 'nowadays', 'convenience.', '19', 'frond', 'dream...The', "Tyre's", 'quality...', 'Chennai.', '0-100%', '2.2-2.5', '93km', '0.21paise', 'Jalalabad', 'sher', 'singh', 'torque.', 'shifting', 'gears', 'competition,', '@first', '3)one', '4)motor', 'containing', 'illumination', 'Near', 'drainage', 'hole', 'place.', 'stored', 'rain.', 'vip', '100kn', '25km...', 'ac', 'input', 'buildings,', 'stolen.', 'utilized', 'fixing.', 'supportable', 'greatest', '1-month', 'starter', 'damaged..Even', 'low/high', 'range...Plz', '...After', 'unsupported', 'companies.', 'piece.', 'was.', 'breakup', 'good.3.', 'callback,', 'a.', 'withstand', 'extent.', 'Around', 'Women,', 'sr', 'Takes', 'remain,', 'reta.', '6feet', 'rains.', 'waterlogging', 'driven.', 'Loading', 'bridge.', 'option(but', 'ok).', '@75kmph.', 'everyday.', 'sector.', 'sync.', 'Balance', 'longer.', 'Has', 'legroom', 'advertisement...When', '.....Superb', 'chetak....When', 'girlfriend.', 'superb.Full', 'hood', 'urban', 'collection', '600km.', 'rounder', '80k', '3+2', 'environment.So', 'bike.Good', 'bike.....Same', 'chetak.....Humara', '1st-time', 'monoths', '54km.', '84km', 'low-speed', '(mostly', 'high-speed).', 'accommodates', 'Apps', 'ulto', 'Sit', 'fuse.', 'mileage/charge', 'declaration/promo', 'km/', 'broken/damaged,', 'rude.', '7.', '8.', 'ratio', 'frequently.', 'looks.Performance', 'high.We', 'purposes', 'outdoor', 'indoor.', 'backside', 'smartness.', 'Among', 'Mind', 'model!!', 'Saves', 'satisfactory', 'lot,', 'face.Overall', 'term', '(within', '10km/per', 'ride)', 'youths,', 'uncle', '82', 'valuable.', 'futures', 'Wish', 'surat', 'loaded.Looks', 'doing.', '3=Looks', '4=Maintenance', '5=Pros-save', 'Environment,', 'Cons-speed', '51', '100-150rupees', 'knowledge,even', 'motorcycles', 'transportation', 'revealing', 'statistics', 'lifestyle.', 'motorbike', 'youth', '2=Awesome', 'Rider', 'demographics', 'Key', 'geographic', 'markets', 'e-biking', 'Costs', 'cars,', 'workout.Experience', 'working.Battery', '97%', '91', 'time.This', 'E-bike', 'rates', 'variables', 'hai.', 'Showroom,', 'helpless', 'scheduled.', 'washing', 'cleaning', 'Air', 'compressor', "thing.It's", ':Best', 'year.And', 'life2.', 'smooth3.', 'cost5.', 'Pros-light', 'Lajwab', 'separated', 'collision.', 'flow.', 'range.It', 'nature.It', 'salesmen', 'good.They', 'service.And', '.Speed', 'segment.Since', 'negligible.', 'commuter', 'equivalent', 'Eco-friendly', 'voice', 'needed;', '5.The', 'Problems', 'are:1.', "'printed'", 'attachment', 'generate;', 'him,', 'dictate', 'removing.', 'researched', 'scientific.', '3.Braking', '4.The', 'decider', 'unscientific', 'discomfort', 'assured.', 'sackings', 'pushpak.', 'disadvantages.', 'edges', 'Hands', 'injured', 'underwriting', 'best,this', 'shiny', 'like,', 'haves', 'stiff.', 'money5.', 'Cons-some', 'cordial', 'buy.Once', 'teacher', 'rechargeable', 'November', 'Jabalpur', '(MP).', 'heads.', '87', 'Center6.', 'on7.', '(low', 'speed)8.High', 'expensive9.', 'IP', 'replace.', 'electric,i', 'bumper', 'hart', 'crossing', 'long4.', 'Batteries', 'months.....', 'rotate', 'batteries5.', 'use?', 'bike?', 'anything?', 'unlawful', 'least,', 'knowledgeable.', 'damn', 'heavier2.', 'priced,', 'market?', 'baffled', 'end!', 'director', 'koramangala,', 'bangalore,', 'tells', 'bunk.', 'contrast,', 'facts:', 'cover,', 'priced?', 'amounts,', 'force', 'throats', 'grunt', 'adrenaline', 'induced', 'proud.', 'nimble', 'skinny', 'Certainly', 'lavishly', '(around', 'Rs.12)', 'turner', 'Everyday', 'strangers', 'nil.', 'automobile', 'silent;', 'compulsory)', 'invest', '3k', 'Pors', 'bill,', 'made.', 'screw.', 'here.', 'enter', 'arena.', 'mobility.', 'Skyrocketing', 'alternatives', 'indicates', 'photon.', 'kgs.', 'Kudos', 'hero!', 'scooty..', 'port,', 'hinge', 'struck', 'spring,', 'brands,', 'Anyways,', 'proceeded', 'liked.', 'manually', 'in-between', 'otherwise,', 'intimate', 'cribs.', 'refused', '1.49', 'said:', 'chips', '1.51', 'glass', 'tea/coffee.', 'granted.', 'performance:-', 'activa.', 'Servicing:-', 'though,', 'Suitable', '1.38lacs', 'price).', 'date,', 'Indians.', 'Dynamic', 'Monthly', 'rs.800', '3500', 'potholes.', '70kg,', 'below.', "here's", 'ponder', 'misfortune', 'highway,', 'object', 'towns.', 'expense.', 'vegetables', 'hot', 'barrels.', 'fan', 'bike.Right', 'gujrat.', 'grater', 'RV400', 'Features', 'but,', 'Sudden', 'pothole', 'non-use.', 'utterly', 'Hi', 'let’s', 'smoking', 'Me', 'heartily', 'smooth,and', 'round', 'headlight.', 'port.', '150.', '72v', '167cm.', 'men.', 'men,', 'Turning', 'throttle,', 'achieves', 'best.I', 'sharp.', 'erode,', 'trichy', 'li/photon', 'itself.I', 'pin/socket,', 'lift', 'opted', 'apartment/', 'researching', 'choosing', 'e-scooter.', 'drive(especially', 'itself).', 'chennai', '(2', 'dealers),', 'model)', '10/11/2018', 'erode', 'dealership,', 'unavailability.', 'visited,', 'speaks/behaves', 'Lesser', 'v', 'Review', 'hope,I', 'got,', 'updating', 'diff', 'timelines', '(li', 'par', 'top-speed.', 'economics', '100-150', 'Add', 'Remember', 'phones.', 'recall', '3:', 'friction', 'odd,', '40-60', 'individuals', 'habits', 'happily', 'parameters', 'didn’t', 'started,', '2nd.', '2:', 'accelerate,', 'moving.', 'traffic,', 'circumstances.Problem', 'parking,', '(till', 'this)', 'only.Then,', 'hugely.', '1:', 'kms(nearby', 'districts).', 'enough.4)', 't', 'easier.5)', 'noise/vibration', ':my', 'vehicle)6)', 'evs.', 'zip', 'separator', 'separates', 'plastics', 'bit.Pros:', 'bike’s', 'decent.2)', 'spacious,', 'bikes.3)', 'unplugging', 'plugging', 'Adapter', 'alarm/lock', 'll', 'alarm,', 'occupying', 'Quality,', 'generations', 'attention.', 'sound.Apart', 'these,', 'mounted,', 'adapter', 'unplug', 'Upon', 'Ll', '...1...Best', 'relatives,', 'meeting,', 'emergency,', 'so...Very.', 'earth..', 'no..Any', 'removal.', 'vehicle(which', 'got)', 'allowed', 'checks', 'preventive', 'measures', 'cases.', 'aside', '(hoping', 'bike)', 'removal', 'easier.', 'thoroughly', 'mine.', 'fine/manageable', 'Achieves', 'flyovers).', 'counterparts,', 'good.(though', 'change,only', 'slight).', 'flyovers)8)', 'finally,', 'extremity', 'repeated', 'Maintaining', 'downsides', 'statement', '(assume', '20%)', 'degradation', 'electrically', 'occupants.', 'silently.', '50kmpl', 'decline', 'Typical', 'liquid', '2-the', '96,000', 'faulted', 'relay', 'recalcitrant', '55,000..', 'candy', 'delivers', 'powered', 'carbon-dioxide', 'Indians.....', 'earth..Save', 'money...Save', 'life...Save', 'budget...', 'realised', 'beautifully', 'proves', 'Lac,', 'km/Hrs.', 'Km/Hrs.', 'Km./Hrs.', 'Dashing', 'Mesmerizing.', 'yamaha.', 'radically', 'abbe', 'hirakud', 'dam', '75,000', 'breaker.', 'Bounces', 'pit,', 'realistic', 'assumptions.', '1-the', 'tropical', 'india', 'scorching', 'summers', '40+', 'guard,', 'siting', 'belt,', 'mediocre', 'Stated', 'fro', 'staring', 'fetched.', 'Model', 'Delhi.', 'compared.', 'songs.', 'gate', 'dashing.', 'patna', 'Initial', 'consequently', 'counts', 'None', 'loaction', 'thumb.', 'Scam.', 'Ex-show', 'Thus,', '-Good', '-Satisfactory', '55-60)', '-Range-', '-Comfortable', '-Full', 'timing:-', '-Worst', 'Rv400', 'sharing', 'vision', 'tension.Bad', 'experience-', 'merits', '-Front', 'Space', 'assembly.They', '5600', 'Dhanteras,', 'Double', 'Gearless', 'expenses', 'carrying.', 'puck', 'nose', '86500', 'failed.Then', 'twice.The', 'days.The', 'hooter', 'fed', 'year.Now', 'forever', 'chase', 'engineers,', 'expiry', 'delivered...', 'August,', 'revai,', 'heating.Anyway', 'renewable', 'men(boys).', 'kirti', 'overtakes', "EMI's,", 'march,', '(december,', 'repairs/replacement', 'parso', 'aao.', 'Transit', 'mein', 'hai,', 'nahi.', 'Gadi', 'din', 'range(mileage)', 'bastard', 'end...', 'crm', 'months.You', 'deadlock.', 'kal', 'aao', 'bhilai', 'cg.', 'ignores', 'unnecessarily', 'cables,', 'cord,', 'lie', "vehicle's", 'extraordinarily...I', 'refueling....In', 'seen...The', 'defeat', 'videos.', 'repairs/servicing.', 'vidhi', 'jamul,', 'emi,', 'Customize', 'effect.', 'Gps', 'enabled.', 'Bluetooth', 'Robotic', 'Rv', 'pads,', 'ignore', 'bike,but', '.Its', 'others,design', 'revolt.This', 'use,its', 'Stylish', 'bhagabat', 'bhubaneswar', 'puts', 'mixing', '12000kms', '36000/-', 'fake,', 'rotor', 'rakhani', 'padega.', 'Etc', 'lies', '40000kms', '20000kms,', 'shaking,', 'burst.', 'fencing.', 'DRLs', 'key.', 'Although,', 'welcoming', 'stars', 'control.The', 'ans', 'racing)Is', 'man(', '5.9', 'above),now', 'services,', 'Hmmm', 'efficiently', 'sound,', '15kms,', 'customers.Requesting', '150-170', 'km/charge,', '90-110', '7-8hr(5-6', 'electric).', 'superb,(', 'heavier', 'stand.', 'challenges', '2018,mcb', 'failures', 'repeatedly,horn', '20kms', ',travel', 'indicator,front', 'bad,every', 'it,it', 'working.As', 'maximum.', 'slowly', 'riding.Taking', 'impossible.I', 'Usb', 'exterior', 'spoilt', 'rains', 'greenlife', 'baner', 'fronts.', 'Hi,I', 'foreword', 'lithuim', 'friends,', '(Salem)', 'accurately', '35000/-', '45000/-', 'training', 'emi', 'me,Thanks', 'mo', 'nil', 'Con', 'awesome,Look', 'great.All', 'moreover', 'Compromise', 'Plan', 'veil', 'LOAN', 'institution,', '"RattanIndia', 'Finance"', '18%', 'telling).', 'km(', 'it!!!', 'true!!!!)', 'thrissur,', 'over!!!!', 'only!!!!', 'expensive,', 'eco/sort..But', 'km).I', '14-08-2018,', 'also.At', '20-25(', 'km.)i', 'kerala,they', '!!!!', 'wisely', 'scooter.Thank', 'opinions', '(licenced', 'type)', 'originally', 'wrong)', '55-60km', 'response..', 'regional', 'officer', 'theirs..', 'hope..', 'spare,', 'days...', 'same...', "You'll", 'respond,', 'arrogant,', 'meter,', 'shoes', 'torn', 'ordinary.', 'toy-like', 'means…if', 'okinwa', '15000', 'batteries…..(my', 'thoughts', 'changed…', '81000', 'checks.', 'Plan.', 'Down', 'Compulsion', 'loan', 'submission', 'cased', 'controlled,', 'button,', 'tearing', 'coupons', 'sending', 'illegal', 'dangerous.', 'image', 'Mr', "he'll", 'eating', '6000kms', '30k', 'replace,', 'fail', 'over.', 'closed,', 'commission', 'subterfuge.', '2014-15', 'china.', 'Weak', 'see-through', 'sunlight,', 'visibility', 'dark', 'rebrand', 'sigmatel.', 'chinese', 'rebranded', 'indian,', 'internals', 'chinese.', 'lies,', '?Ans', 'superhero', 'mask..', '"pulsar,', 'etc."', '70,000', '90000.', '1,50,000', 'sounds,', 'artificial', 'understandable', 'artificial.Now', 'questions:-1)', '??Ans', 'course..', 'area.2)', 'exquisite', 'performance?', 'nope', 'formerly', 'readily', 'crap,', 'crapped', 'added.9)', 'Tighten', 'sir.', "Here's", 'loser', 'idiot,', 'today?', 'huh?', 'engineering?', '15mm', 'port.17)', 'charge.18)', 'efficient.Cons:-1)', 'abs.2)', '80km/h)3)', '150kg)4)', '19-20kg.', 'elsewhere.', 'allowing', 'malpractice', 'appalling.', 'hilarious.', 'bearings', 'bent', 'rubs', 'lives,', 'bullshit', 'bites', 'outlets.', 'mindset', 'repair,', 'sigmatel,', 'denying', 'bolted.', 'everywhere.', 'craphole', 'abracadabra.', 'await', "else's", 'shorter', 'unlike', 'distributors', 'crazy..', 'mad', 'patel', 'enterprise', 'consumption"', 'anymore,', '100km.', 'weighs', '170kg', 'enfield', 'dangerously', '40kph', 'crap.', 'sigmatel', 'owner.', 'left.', 'boom', "There's", 'overheat', 'drinks', 'un-adjustable', 'extremely', 'sags', '20kg.5)', 'rev', 'acceleration.6)', 'scooter.(personal', 'opinion).7)', 'compact', 'toy.8)', 'exaggerated', 'blot', 'of.', 'intention', 'gujarat', 'gov.', '19000', '75000', 'Else', 'information,', 'further..', 'Returned', 'serviced.', 'answer,', 'opened', 'wasted.', 'khatara,', 'cc/606/2019)', 'wow', 'grievance', 'Unless', 'forum,', 'grievance.', 'disputes', 'redressal', '82000.', 'rob', 'faults,', 'solution.', 'email', 'Tired', 'filed', 'district', 'Okinawa.', 'data.', 'YouTube', 'data,', 'lasted', 'kms-10', '12000', 'old..', 'lawyers', 'matters', 'lurch.', 'speedometer,', 'calculator', '(gel', 'product)', '35k.', 'turncoat', 'bribe', 'politicians', 'hype', 'entice', 'gullible', 'nowhere', 'courts', '2.30', 'lease', 'whatsapp,', 'Whoever', 'lodge', 'faults.', 'judicial', 'accountability', 'high.9)', 'usd(up-side', 'forks).10)', 'projector', 'lamp.11)', 'lamp.15)', '(75%', '2.5hour', 'modes.5)', 'swapping', 'concept.6)', 'lifetime', 'warranty.7)', 'unlimited', 'plan).8)', 'heavily', 'items,', 'seemed', 'together.', '32000.', '32000', 'letter', 'ex-', 'fensing', 'physically', 'mentally', 'suffered', 'badly,', '800meters', '1km,', 'arrogant', 'behavior,', 'month...', 'okinawa...No', 'suggestions...But', 'batteries...It', 'time..', 'drawbacks', 'softer,', 'good,quality', 'praise.Also', 'great.If', '75km/h', '55km/h', 'pollution,no', 'petrol,no', 'money.Its', 'bucks', 'why...', 'yet...5.', 'cons;', 'feelings', '.....And', 'provider.', 'scarring', 'guys.If', '4-4.5', 'hour).16)', 'Little', 'rewari', 'register', 'area........', 'cloudy', '70kmph', 'controlled', 'system)', 'hr', 'strong,', 'horns', 'centres', 'dun', 'falls', '127', '..The', 'Matt', 'likeable', 'gear(like', 'back)', ',EBS', 'abs', 'working.Without', 'ride.And', 'inner', 'it...Well', 'beast..It', 'it...The', 'now.I', 'days..Well', 'super,stylish', 'design,low', 'stability.', 'dicky', 'good.Mileage', 'amazing.My', 'yellow', 'lights.And', 'question', '??', 'together.Pros', '(green).2)', 'plan)', 'scheme.3)', 'compromised', 'revolt.4)', 'long.Company', 'battery.According', 'onroad', '73k.', 'appealing.', 'premium.Although', 'congratulate', 'truth,', '55kmph,', '65khph', 'sec,', 'good.It', '150kms.', '60kms/h,horn', 'direction.Its', 'charge.Looks', 'circles', 'vehicle.It', 'Extremely', '(local)', 'Guys,', '125kms', 'comes,', '170-200kms,', 'km.If', 'cycle.As', '.Battery', 'lid', 'only.Lid', '.Who', 'yearly', 'rs30000/..Dear', '...I', 'planing', 'also.Please', '.When', 'newly', '300~400', 'traveled', '6020', 'shoppings', 'service.I', '2018.', 'direct', '50~55', '.New', 'rs=25000.So', '.Worst', 'high-tech', 'apps', 'disclose', 'gone.If', 'worth-able,', 'multipurpose', 'coaching,', 'school,', 'terribly', '170kg+', 'tiers', "policy.India's", 'Supper', 'built-in', 'city..Future', 'grab', '100-120', 'kms.2.', '52-53km/h..3.', 'posture.5.', 'Useless', 'distance..', 'Hard', 'night.6.', 'good.Low', 'life.Is', '.If', 'beneficial.Riding', 'specified', 'inviting', '76500,', 'problems...1.', 'blog', 'internet', 'company.Please', '..Max', 'rodding.', 'Lighting', '.In', 'runs.All', 'described', 'Pros:1.Visually', 'awesome.2.Stunning', 'looking.3.Lower', 'comparatively.', '4.Full', 'km.5.Economically', 'good.6.3', 'beneficial.Company', 'worthy.', '75km.', '175', 'Distance', 'lengthy', 'ie', '20kms.', 'it...', 'worst.I', 'purchase.Battery', 'inventory.Avoid', 'it.Chassis', 'shocking.So', 'run.One', 'life.Not', 'beauty..Will', '2020.Both', 'features.For', 'option.Further', 'different.Great', 'vibrates', 'breakers.I', "scooter...I'll", 'dhalapathar,khurda,odisha.', 'straight', 'rs76000', 'experience:To', 'awkward', 'disc.3.', 'performance:I', 'glossy', 'blinker', 'worst.Suspension', 'bicycle.', 'Loss', 'experience.Look', 'praise.1.', 'experience:I', 'sai', 'design.Cons.1', 'infrastructure', 'date.2.', 'risk', 'camel.175', 'road.Sitting', 'arrangement', 'Adaptation', '60/70', 'km.Run.7.', 'good.8.Boot', 'good.Helmet', 'space.9.', 'hide', 'protects', 'raining.10.Good', 'scam', 'directed', 'cancellation-', 'of,', 'bookings', 'references', 'environment,not', 'free,easy', 'that.Look', 'good.Only', 'rs10', 'metre.', 'person.However', 'poor.Cons:', 'transfer.', 'urge', 'adjustments.Maintenance', 'cost.5.', 'cons:Pros:', 'rs100', 'rs36000', 'amazing.In', '140kms', '.Zero', 'purpule', 'amazingly', 'catching.Charging', '140kms.', '150kms', 'version.4.', 'Haha', 'availed', '70-', 'shipped', 'trolley', 'snap', 'shots', 'this.5)', 'ex:', 'trapping', 'year.The', 'one..4)', 'broke-in', 'spokes', 'pivot', 'tire.This', 'Virtually', 'Roughly', '150-200', 'Thats', 'treadmillIn', '80-100', '*(initially', 'tested).', 'Depends', 'Guarantee', 'say.2)handle', 'shake', 'fully.3)', '(power', 'motor)', 'switches.', 'adapt', 'matter.4)major', 'indefinitely', 'delayed.', 'andheri', 'live.Revolt', 'financing.', 'telephone', 'off.Mumbai', 'pursue', '170-200', 'km/per', 'milage', '120km/per', '10hrs', 'agents', 'admitted', 'Mumbai,', '(maintenance).3)eco', 'friendly.4)', 'and.', 'Attractive', 'Good:-', 'person)', '300.', 'Bad:-', '-356)', 'rarely', 'mechanism.', '7)parts', 'loosely', 'coupled,', 'bike.8)', 'Pros:There', 'submitted', 'condition...?', 'secondary', 'policy,', 'primary', '1.Bought', '87k', '3.Look', 'kutch', 'satara.', 'one-month', 'policy.', 'sensors,', 'month?', 'happening', 'April,', 'issue.Need', '(72v', '48ah)', 'exhausted', 'recharge.Looking', 'provider', 'outlet', 'gandhidham', 'bike.However,', 'issued', 'unsolvable', 'irresponsible,', 'attend', '&maintenance', 'issues.Bike', 'yrs(5600km).No', 'bothered.', 'jan', 'dabba,', 'patiently', 'requirement', 'promised,', '140km', 'mode..120', "same..Yes'day", 'authorized', 'screeching', 'arising.', 'intermittently', 'shooting.', 'z', 'dombivli,', 'proper...', 'promoting', 'batteries..', '26', 'aug.', 'rs.31000/-', 'bar..', 'quested', 'medium.', 'odometer.', '4.Not', 'required,', '(includes', 'condition)', '5.Saving', 'trips', 'replied', 'answers', 'solutions.', 'advances', 'slots.', 'december', 'march-April', 'redirected', 'connecting', 'escalated,', 'you(', 'months).', 'Whatsapp', 'pits', 'stop.', 'Mails', 'gradually', 'decreases..', 'recommend..', 'improvements..', 'think..For', 'bike..We', 'years..', '10min.', 'km..', 'now..', 'thing,', 'drop.', 'itself,', 'scooters..', 'perspective..First', 'comfortable..After', 'record', '25800km', 'now..But', 'here..No', 'this..No', '.......', 'joys', 'happiness.', 'I-praise', '52km/h', '800meter', '1km', 'shows,', '8to', '9hours,27julay2021', 'purchase.I', 'rubbish', 'sock', 'pillion.', 'absorbers..', '(no', 'puncture).', 'Maybe', 'drum.', 'passed,', '34', 'distance,', '80-90', 'beware', 'breaks.', 'conclusions.', 'season,', 'this...', 'approved', 'bribe.', 'God', 'Spent', 'deal,', '2.99kw,', 'bridges', 'RSA,', '15k.', 'fooled', 'fraudulent', 'bone', 'stupid,', 'engineering,', '1*.', 'eng.', 'system..Problem..This', 'cost??', '103500', 'carefully.', 'Dec', 'stiff,', 'dead.', 'vise', 'worthless.', 'Pune', '21,', '20k', 'amount,', 'Feb-mar', '22.', '"please', 'that."', 'Dwarka', 'wrongly', 'again,', 'days..."', '4g', '2g', 'added.', '89000.', 'following.', 'explain', 'varied', 'dealer?', 'adaptation', '73000/-', 'Aura', 'Fun', 'quick.', 'harder', 'observers', 'riding...', '(side', '3000)', 'raw', 'size.', 'lamp.', 'upgraded', 'versions.', 'fused', "center's", 'khatara', 'fast-changing,', 'budget,', 'quit,', 'jurk', 'centres,', 'display,', 'disk.', 'encouragement', "'Vespa'.", 'Vespa', 'accelerated.', 'sunny', 'placed.', 'placement.', 'scratched.', 'locating', 'manufacturer,', 'Professionalism', 'dealings', 'authorities', 'behave', 'delivered!', 'quiet.', 'economy,', 'app,', '92500/-?', 'detailed', 'break-up', 'summarize', 'proceed', 'product?', 'via', 'bosch', '1-mirrors', 'welding.', '80-150', '45-85', 'rated', '814', 'mm', 'coolly', 'nicely.', '55km/hr', '(130kg).', '90km.', 'faraway', 'create', 'Thane', '60..parts', 'market..my', 'dealers.', 'mood', 'jerking', 'maintainance', '0/10', 'seperately', 'sorry', 'aura...', 'riding.(key', 'failure).Lock', 'glow.', '..it', '110000.scooter', '60..company', 'like.', 'Smooth,', 'Absolutely', 'query', 'months?', 'sarcastic', 'accumulate', 'crores', '1.Speed', 'calculation.', '(high', 'Back', 'ktm.', 'harm', 'eyes', 'kinds', 'hard.', 'athlete', 'whatsapp.', 'USB', 'tail', '4060', '84000', '4500', 'Mar.', '22)', 'chasing', 'handover', '(saying', 'days).', '(what', 'charger).', '25-30k', 'guyz!!', 'insurance).', 'upgraded...', 'effort.', 'somewhere', 'else...', 'bike,feels', '(100%', '82000).', 'onwards.', 'volt', 'kharadi', 'wagholi', 'access.', 'lac', 'shortage.', 'e-bike.', 'flyover', '80k.', 'jupiter.', 'pending', 'Permanent', '02/07/2020', 'requests.', 'stadium.', 'stadium', 'Ex-showroom', '.On', '(include', 'warranty)', 'Booking', 'stands.', 'Because,', 'tend', 'irritating', 'rainfalls', 'misty', 'climate,', 'blurred', 'Certain', ':1)', 'turns,', 'waves', 'desired', 'angle', 'course,', 'punched', 'Shri', 'balaji', 'e-motors', 'Markapur', '(a.p)', '8th', 'dealer’s', 'likes.', 'energetic,', 'dream:', 'silencer', 'bike.Best', 'Energy', 'Mother', 'food', 'Ampere.', 'understand.', 'beforehand.', 'adult', 'adjust', 'service....', 'ago!!!!', 'company....', 'times...', 'jumbling', 'Good,', 'Amo', 'rapidly.', 'Contribute', 'revolution', 'tomorrow.', 'parking.', 'cheers', '70s', '160kg.', '57kmph', '20paise/km', 'unusable', '1)charging', 'hr.', 'efficiency.', 'blame', '(totally', 'multi', 'colored)', 'hit.', 'lucky', 'Magnus.', 'irritating,', 'downs', 'Support', '150cc', 'gearing', 'brother', 'thumbs', 'lovers', 'Material', 'breakable.', 'Whereas', '1/1.5', 'plot', 'stamped', 'forgotten.', 'come,', '86000.', 'purchased.Some', '(dikki)', 'shockupser', 'quarter', 'Maintenance-', 'Low-quality', '6/7', 'response....', '15,000', 'real.', 'honest,', 'weigh', '170-175', '150kg.', '76000', 'element', 'grabs', 'attention', 'plenty', "ev's", 'nation.', 'governments', 'encouraging,', 'hyderabad)', 'standard.', "Dealer's", 'complaining.', 'manages', 'unskilled', 'hyderabad', 'importantly', 'wiil', 'associated', 'terrible.', 'inferior', 'focused', '(Gaura', 'automotive', 'kondapur,', '400.Its', 'neighbor', 'blinking', 'Richmond', 'od', '5500km', '10inch', '12inch', "We'll,", 'interests', 'Indians,', 'factors,', 'excluding', 'combined', 'performing', 'Ergonomics', '(r)Regenerative', 'yesDisplay', 'ledRim', 'alloyed', 'reflector', 'Blinkers', 'Tamulpur', 'Assam.', 'metallicCells', 'nmc', '18650', '3c', '50aCharger', '10aExternal', 'yesBrake', '(f)', 'peaking', '(even', 'future),', 'adapted', 'rides.Motor', 'nominal', 'vector', 'looped', 'Indicator,', 'ordered', '8600kms', 'Travelled', 'hearable', 'buy!!', 'Wanna', 'fraudsters', 'compliants', 'showrooms,', 'finish...', 'screws', 'pathetic..', 'absorbers,', 'Switches', 'problem...', 'henceforth', 'refueling.', 'Gradeability', 'lockLadies', 'phenomenal.', 'Break,', 'algorithm', 'implemented', 'prioritized', 'makers.', '3.at', 'km./hrs.', '.My', 'swap', 'gray', 'color.', '85-90', '80-85', '95-100', 'Speed:', '60-65', 'Comfortable:', 'shouting', 'contacting', 'completed:', '2/5', 'problem:', '1.There', '60km.Every', '2.Top', 'pulsar,', 'true?', 'date:', '(inc.Taxes):', '93000', 'Kilometer', 'driven:', '1675', '2021)', 'No.', 'besides', "i've", 'exceptionally', 'Chhattisgarh', 'brack,', '3months.', 'engines', 'extract', 'improve,', 'rider!', 'cum', 'anantapur', 'aides', 'owns', '2012,', 'manageability,', '*worst*', 'habsiguda', 'connected.', 'late.I', 'February', 'Digital', 'kilometers..', '8%', 'chat.', 'compliant', 'whatsapp', 'Request/advice:', 'blind', 'too,.', 'milege,', 'newest', 'happening,', 'government,', 'practice,', 'cracked.', 'rider)', 'support:', 'satisfied.', 'toll-free', 'Creech', 'observed', 'beginning', 'competitive', '4–5', "day's", 'geo-fencing', 'cooler', '1.Attitude', 'Yelahanka', 'appreciable', 'Gracious', 'designed,', 'ages', 'genders', 'Minuet', 'Yamuna', 'Nagar', 'ambala', 'cantt', '65km', 'there)', 'construction', 'completion', 'absorbing,', 'ruff', 'tuff', 'Each', 'aspects.', 'corona', 'partner', 'jam,', 'corrected', 'politely.', 'this,.', 'room..', 'whom', 'call.', 'rebadged', '0–40kmph', 'requests', "scooter's", 'Hopefully', 'placement', 'redesigned.', '59k', 'mph', 'reacted', 'Bengaluru.', 'lowest', 'myth', 'basement', 'exit.', 'anxiety.', 'oriented', 'satisfaction.', 'acceptability', 'alone.', 'acceptance', 'feedback,', "relation's", 'clarified', 'questions.', 'processed', 'old,', 'cell', 'survey', 'accept', 'it!', 'savings!', 'asap!!', 'A.', 'degenerative', 'super,', 'no1', 'tight.', 'Purchase', '350', '2025.', '7g,', 'sensor.', 'rs.250', 'mat,', 'slips.', 'swing', 'arm', 'cranking', 'schooter,125', '4.2', 'kgs', '1.15', 'Thankfully', 'deteriorated', 'Acceleration', 'sometimes.', 'rs.200', '11)', '12)', 'graduates', '13)', 'competing', '(bounce', 'infinity,', 'hours,', 'outer', 'layer', 'peels', 'catches', '10)', 'women,', 'ladies,', 'impossible)', 'excel', 'blade', 'logo', '"pure', '7g"', 'pasted', 'tape,', 'shaking', 'B.', 'premature', 'discussed', '7g.', 'turns', 'agent,', 'sire', 'handmade', '54k', '105-108', 'well-equipped', '14/04/2022', '98', 'happened?', '40days', 'superb,', 'guaranty', 'Dirty', 'blink', 'features..', 'higher,', 'bottom', 'suit', '2.3', 'staff,', 'warrant', 'react', 'king.', 'expert', 'tight', 'the,', 'rush', 'setup', 'ramurthinagar,', 'optima,', 'ex)', 'mistakes', 'acceptable.', 'treat', 'Illiterate', 'sale.', '"on",', 'drl,', 'louder', '100%,', 'replaceable', 'reserve', 'watch,', 'penny.', 'nightmare.', 'downgrade', 'breaker', 'standards', 'bumps', 'image(i', 'value).', 'risk.', 'humble', 'supplier.', 'Suggest', 'k', 'iQube.', 'gaura', 'Kondapur', 'purchases', 'brank', 'facing,', 'upgrade,', 'kml', 'difficulties.', '*', 'Rs.9000/-.', 'unorganized,', 'assembly,', 'fulfil', 'business,', 'seating.', 'complete.', 'process.', 'Coimbatore.', 'leakage,', 'promising', 'circuit', 'IC', "travel's", 'tyre.', "women's", 'terrific,', 'etc..................', '15years', 'banglore', 'Simply', 'circle', '(shreekrishna', 'bandup', 'mumbai)', 'improvements', '!!', '950', '100-105', '12km.', 'catcher', 'showrooms.', 'rs3000', '32%', 'respectively,', '71.9', 'empty', '7km', '78.9', '%,', 'reports', 'shattering', 'network.', 'darling', 'alone', 'kid', 'true.With', '35.', '68%', "Scooter's", 'lodged', 'it.Since', 'october', 'communications,', 'lajpat', 'nagar,', 'fine.Thank', 'erode.', 'okay.', 'doubted', ',incase', 'hills', 'areas.', 'boon', 'ecology', 'backache.', 'gearbox', 'intelligent', 'eight', 'ten', 'frequently', 'disappointment!', '(with', 'curb', 'facility', 'low/', 'agers', 'works,', 'Upto', 'riders,', 'rupee.', 'bicycle', 'fie.', 'practically', 'experience.It', 'praiseworthy', 'comments', 'relatives.Yearly', 'dealer.As', 'Unnecessarily', 'negative.Even', 'overcrowded', "you'll", "child's", 'blessing.', 'geared', 'she', 'aftercare', 'knew', 'argue', 'competitor', 'margin', '84', '52', 'kmh.', 'up)', 'tuesday', 'thursday.', 'thursday', 'friday.', '(friday)', 'arrived.', 'saturday.', 'pitch', 'pedal', 'continuously', 'wheeling.', 'forthcoming', 'probably', 'wheel,', 'organized', 'met.)', 'together', 'supplied.', 'concerns', 'congealed', 'substance', 'problems)', '4km', 'jealous', 'car,', 'disturbance.', 'Beat', 'rate.', 'rate,', 'heavy-duty,', 'very,', 'months…', 'massive', 'handling…', 'costs…', 'experience…', 'it..', 'Worthwhile', 'vegetables…very', 'ampire', 'Locks', '950.', 'Condenser', 'focusing', 'amperes', 'experience..', 'Went', '70%,', 'yrs.', '22-24', 'head-office,', 'dealer,4000', 'keen', 'clueless.', 'search', '10rs', 'clock', 'headache.', 'Chennai', '115580/-', 'cable.', 'Rs.8260', 'Rs.2000/-', 'Mileage=', '1/speed', 'km/charge.', 'Drive', 'shopkeeper', 'needs,', '3hrs', 'morning.', 'onsite', 'Low-cost', 'models.', 'above.', 'Avg', 'Wty:', 'Trust:', '(hero)', 'Overload', 'must,', 'good...For', 'Unbeatable', 'technology...Very', 'cochin', '(aban', 'motors).', 'Multiple', '1000km', '120-150', 'reality,', 'mira', '70kms.', 'tied', 'spoiled.', 'point,', 'riding.Dealer', 'utilization.Company', 'srinivasa', 'trustworthy', 'prepared', 'yourself', 'insulted', 'nut', 'bolts', 'tool', 'allows', 'ground.3.', 'slots', 'secure', 'liars', 'Rs.3000/-.', 'refresh', 'limitation', 'dealers,', 'good.The', 'preference.', 'style,', 'good.Cons:', 'nice...', 'concept', 'Awful', 'considered', 'player.', 'Otherwise,', 'footnote', 'revolution.', 'release,', "company's.", 'favor', 'government.', 'vehicle..', '(okinawa', 'i-praise)I', 'India...', 'adventure', 'subtle', 'combo...', 'recommend.', 'Tell', 'one!!', 'roading.', 'i-praise', 'addition', 'family..', 'ecstatic', 'comfortable..Chic..Handy..And', 'one-time', 'investment.', 'wild', 'structured', 'Center', 'spring', '50-51', '50%.Battery', 'broke.', 'stuff', '45.', '20+', 'funny,', 'tiny,', 'catch', 'man,', 'garage.', 'fraud,', 'Thin', 'humps,', 'time...', 'overpriced.', 'wise,', '.low', 'MCB', 'sheets', 'aches,', 'pain.', '1400', 'dead,', 'prn', 'superb...', 'speed....', 'Eco,', 'turbo....', 'seven%', 'mat.', 'reliability', 'anxiety', 'aside,', 'knocked', 'bricked', '(keep', 'handy).', 'lol.', 'research.', 'findings', '88000', '(on-road)', 'included-charger,', 'mirrors,', 'footrest,', '.Ground', '60km/h', '48-49km/h', 'gmaps.', 'show12.8', "commitment....Don't", 'company....Price', 'ather450', '61', "5'", "5'6", 'freely.', 'loves', 'decreases', '-53', 'decreases.', '2.Sufficient', ':p', 'Low/no', 'fills', 'Pillion', 'Inferior', "could've", '0%', '(dealer', 'day)', 'calipers', 'refinement', 'refined', 'acceleration.)', 'satisfactory.', '1.Good', 'startup,', 'like;', 'switches,', 'high/low', 'toggle', 'zero.', 'persists.', 'tripped.', 'interaction', 'serviceability', '4hrs', '(0-100%)', 'Range:', '(mixed', 'pillions', 'time)', 'mom', 'Apply', 'nitrogen', 'apt', 'etrance', 'handling.', 'Beautiful', 'planned', '95km', 'Tires', 'Size', 'uncomfortable.', '5\'6"', 'Above', 'fat', 'mom,', 'cooperate.', 'Rear', 'Changed', '105+', '96', 'Improvement-', '1)Instrument', '1)Good', 'restart', 'Zippy,', 'responsive.', 'Performance:', 'ghat', 'vendor', 'vendor.', 'RTO', 'edition', 'youths', '150kg', 'load.', 'enters', 'on/off', '(anything', '1km)', 'nice..', '12"', 'ample..', 'commuters', '(45km/h)', '105km', '90kg).', '(60km/h),', 'finally....', 'Hearing', 'firstly', '90km', 'charge...', 'viewers', 'green....', 'better..', 'outskirts', 'extending', 'millage,', 'styled', 'interesting.', 'dilemma', 'weather', 'launch...', 'Siren', 'more(just', ').', 'day...', 'free.Now', 'perplexed', 'random', '"close', 'Comfortable.', 'bikewale.Com', 'shared.', 'Desirable,', 'city.Unable', 'good.But', 'lackey.', 'favorite', 'term(more', 'yrs).', 'cheap,', 'shockers', '20-30k', 'better-built', 'Luxury', 'Healthy', 'Anything', 'recorded', 'often.', 'Important', 'suggestion:', 'recently,', 'raided', 'Compact', '49', 'reading,', '39', 'cheating.', 'Hence,', 'claim,', 'ridge+', 'feb', 'players', 'raipur,', 'Starting', 'tier', 'ride.Om', 'hiking.', 'Step', 'june.', 'pro:-1)', 'price.2)', 'engine.3)', '0/km', 'operation', 'Cons:-1)', '30000)3)', 'responded', 'warning"', 'calibration', 'problem-free', 'garages.', 'mercy', 'ensured', 'deliberate.', 'compatible', 'adults', 'me:', "son's", 'bumping', 'everytime', 'footrest.', 'Effectively,', 'dirty', 'backpacks', 'it.3)', 'hook', 'interference', 'lunch', 'bags.4)', 'store', 'helmet.5)', '(in', 'traffic)', 'fake).', 'two:', 'haul', 'school.Here', 'feedback:1)', 'manage.2)', '(4600km,', '3500km', '),', '(so', '31', '40km/h', '(when', 'full),', '73', 'dont', 'ships', 'chose', 'to.', 'pays', 'gimmick.', 'earthing', 'children,daily', 'uses.', 'Performance-wise', 'Had', 'speedometer/distance', 'provided.', '48km.', 'invalid', 'commute...', 'experience....', 'battery...', 'boon.', 'Far', 'detwin-50', 'peck', 'turnings,', 'pants', 'kids.Many', 'alternate', 'Changing', 'drivetrain', 'convenience', 'middle-class', 'consumer.', 'series:', 'electricals,', 'lights,', '75kmph', 'quality.Cons:', 'overloads', 'stresses', 'split', 'giants', 'ather,', 'sites', 'possible.Personally', 'benelli,', 'chennai.', 'Reviews', 'brands:', 'speed,km', 'readings', 'twenty', 'readings.', 'Personal', ':I', '23', 'risked', 'takes.', 'onus', 'complaint,', '58', 'chinese,', ',totally', '89000', 'scooters.They', '(Indian', 'chinese)', 'name(like', 'benle)', 'u.', 'odd', 'amazon)4.', 'reo:Pros:', 'feared', '(but', 'heavy)', 'stock.', '(suits', 'too)', 'long.3.', 'Benelli:', 'matching', 'rivals.Pros:', '(have', 'reverse),', 'usual', 'bikes.Cons:', 'drew', 'dint', 'extra,', 'plain', 'yamaha', 'longer).', '(better', 'ather)', 'battery.2.', 'ridge+:', 'coimbatore', 'acquired', '75km/charge', 'kpmh', '>90', '>50.', 'lamp,', '(it', 'looks),', 'avearge', 'quality.7.', 'zeal:Reason', 'words,', 'waiting.', 'specs.', '>50', ',belt', 'long.Cons:', 'bugged', 'buzzing', 'electrc:', 'effective,', 'brand,', '(very', '(cheap),', 'performance.Cons:', '40kmph,', 'quality.5.', '450', '400:', "(haven't", 'driven)', '51There', 'July', 'vibrations.', 'either.', '..Plastic', 'Gaps', 'fob', 'prime', 'floating', 'water.', 'echo', '50km/hr.', 'dried.', '20/09/20,', 'running...It', '55-58km', 'good)Who', 'donate', 'speed+', 'performance+', 'fort', 'it.Note:', 'yamaha,', 'watt', 'newbie', 'body),', 'harness', '(my', 'changed)', 'options,', '(fast', 'reduces', '(12', 'kgs)', 'warehouse.', 'Planning', 'shortly.', ':-)', 'chosen', 'enthusiastic', 'shares', '160.', '1700', '4500.', 'slowing', 'outdated', 'Jupiter', 'while.', 'part,', 'structure,', 'supermarket', 'recommendation', 'porter', 'rajajinagar,', 'Found', 'cotton', 'flashiness', 'identified', 'rectified.', 'Experience,', 'trash', 'know,', 'Three', 'spleen', 'amp', 'sockets', 'kms),', 'god', 'moving)', 'tightened', 'stalled', 'replying', 'Nearby', 'centers.', 'noiseless', 'Post', 'boys', 'established', 'bang', '54km', 'wagon', 'Electronic', 'scratching', 'finalized', 'Brand', '(indian)', 'Practical', 'goods', 'ton', 'performs', '....100%', 'Crossed', '11500', 'zeal.', 'stretch', '76km', 'often,', 'hopeful', 'shell', 'Nearly', 'breaking,', 'grip,', 'built,', 'availability,', 'rattling', 'indicator.', '(else', 'giant', 'hand)', 'Recurring', 'rush,', 'q', 'years/30k', 'km)', 'ample', 'agencies.', 'Keyless', '(controllable', 'car)', 'Minus:-', 'patience.', 'Apart', 'Plus:', 'Budget', '(all', 'incl.', 'pune)', '(3', 'mere', 'coil', 'burnt', 'fought', 'debut', 'sadly', 'motherly', 'treatment', 'properly.4,', 'newly,4,', 'newly.', 'greenway', 'keezhapaloor.', '63-67', 'indicator,tail', 'particular', 'component', '67500', 'Stopped', 'Matte', 'seen,', 'Lite', 'burned.2.', 'pressing.3.', 'lightning.', 'dealing', 'Tyres', 'bulged', '2020.Since', 'accelerating.', '8months', '4dys.', 'Who', 'basis.', 'especially,', '8000', 'awesome!!!', 'singles', "lite's", 'Approached', 'immediate,', 'vehicle-', 'same,', 'properly-', '700km,', 'mistake(', 'issue),', 'defect.', 'praise.3.', 'Par', 'excellence', 'features.4.', 'new..', 'cons..', 'amazing..', 'coming,', '7k', 'assembly', 'removed.', 'Allover', 'pollution-less', 'mcp(middle', 'Awesome;', 'lite,', 'Sound', 'unbearable', '200.', 'sunday', 'hours.3.', 'braked', 'signal,', 'releasing', 'Dl', '9sb', 'v7147)', 'dwarka', 'both.1.', 'connector.', 'day.2.', 'saturday', 'bad.When', 'dinzy.', "'ls", 'superb..The', 'more.The', 'sharp.The', 'e-5', '(registration', 'cycles,', 'everyday!!!!', 'duff,', 'charged,', 'start.', '45kms', 'employees.So', 'better..In', 'smooth...', 'fuel...', 'scooter...', 'reasonable...', 'perfect...', "Heart's", 'consult', 'owners.', 'battery5.', '6.The', '7.And', 'sincere', 'z,', 'After-sale', 'dry', 'scooter/motor', 'badly.', 'shocker,', 'shocker', 'road.6.', 'mileage(', 'charge)', '3.Worst', '4.No', 'Fortunately', 'workshop,', 'engineers', 'month.4.', 'tight,', '–', 'suddenly.', 'hurt', 'town.', 'lights.', 'study', 'imports', 'china,', 'evident', 'lacks', '50km.', 'toys.', 'Anyone', '61,000', '8km', '20km.', 'left)', '50-55.', '0-100%.', 'cheetah,', 'smoothy,', 'memorable', 'inhabitant', 'switch,', "breaker's", 'touched.', 'recently.', 'touching...', 'services...', 'On-time', 'good...', 'scooter...This', 'mah', 'r30', 'faster', 'cost,', 'cry', ',thanks', 'best!', 'level!', 'one!', ':)', 'Hey', 'diseases.', "month...Don't", 'guys...!', ',every', 'formality', 'converter', '30000.', 'Moreover,', 'basically', 'torquey', 'availably', 'Road', 'ridded', 'bikes...', 'Yo', 'drift...!!', 'setback', 'advise', 'packing', 'tubes', 'heated.', '41', '10-20', 'kilometers.', 'ability', '.storage', 'lazy', 'quote', '35kms', 'escalation.', 'attends.', 'BMS', 'whit', 'commits', 'buying,', '1.9', '(r)regenerative', 'led,', 'alloyed,', 'reflector,', ',2021)', 'crosses', 'century,', 'km/full', '(7hrs', '-9hrs)', 'executives', 'explains', 'sujan', 'roy', 'coochbehar', 'yo', 'drift', 'dx', 'nine', '(August', 'embarrassed', '8)I', '33', '0.19', 'cylinder', '150kms,which', '9000', 'clueless', '1)no', '2)no', '4)battery', '5)charger', '6)even', 'call,', '7)people', 'experimenting', 'footboard', 'fit,', 'hence,', 'Super-smart', 'hindrance.', 'patches', 'loosing', 'life,', 'waterproof', 'Seems', 'third', 'jobs', 'draining', 'fast,', 'cracked,', 'out,', '90-100km', 'change.', '5-6', 'provides.', 'complain', 'tracked.', 'Techo', 'Electra', 'nontechnical', 'repairs', 'breakdown', 'Continuously', 'ether', 'money.Sent', 'experiments', 'handled', 'super-bike', 'short-ride', 'rs,10', 'rs.60', 'sip.', '2000kms', '.Mcb', 'burning,', 'specifically', 'idea.', 'disappointed.', 'Nobody', '180kg', ',price', 'unavoidable.', 'air,', 'backrest', 'surfaces', 'locally', 'soothing', 'white', 'affordable.', 'propose', 'charge).', 'Gets', '4km.', 'covering', 'Value,', 'zomato', 'Third', 'toy.', 'garage,', 'electra.', '55,000-60,000/-.', 'clocked', '6,100', '27,000/-.', 'Poor.', 'perfect!', 'L', 'service.Spare', 'that.Now', 'mails.', 'supportive..', "pune...Doesn't", 'premium...Have', 'Plus.', 'model...Or', 'genuine', 'thowlichowki', 'on)', 'Compare', 'tips', 'Bottle', 'rack', 'plus,', 'all-purpose.', 'Wasted', 'license,', 'rc', 'challenge', '62000', 'Up', 'moving,', 'improve.', 'worthiness.', 'Models', 'elegant', 'genex', 'inquired', 'enquired', 'safe,', 'drives.', "it'", 'Disappointed', 'ebike.', '(15+).', 'functions', 'appreciable.', '(generally).']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> xbox-game-pass-games-library/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Extract min and max (if applicable) hours as two columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def get_avg(x):
      try:
            return float(x[0]) , float(x[1])
      except:
        return 0,0
df['min'],df['max']=zip(*df['TIME'].str.replace(" hours",'').str.strip('+').str.split("-").apply(get_avg))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>['df']</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def get_avg(x):
      try:
            return float(x[0]) , float(x[1])
      except:
        return 0,0
df['min'],df['max']=zip(*df['TIME'].str.replace(" hours",'').str.strip('+').str.split("-").apply(get_avg))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def get_avg(x):
    try:
        return float(x[0]), float(x[1])
    except:
        return 0, 0


__output__ = df['min'], df['max'] = zip(*df['TIME'].str.replace(' hours',
    '').str.strip('+').str.split('-').apply(get_avg))
</code></pre>
        <p><span onclick="$('#var_output_e39c802e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e39c802e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> df </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GAME</th>
      <th>RATIO</th>
      <th>GAMERS</th>
      <th>COMP %</th>
      <th>TIME</th>
      <th>RATING</th>
      <th>ADDED</th>
      <th>True_Achievement</th>
      <th>Game_Score</th>
      <th>min</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mass Effect Legendary Edition</td>
      <td>1.87</td>
      <td>84,143</td>
      <td>4.1</td>
      <td>100-120 hours</td>
      <td>4.8</td>
      <td>2022-01-06</td>
      <td>5442</td>
      <td>2915</td>
      <td>100.0</td>
      <td>120.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The Elder Scrolls V: Skyrim Special Edition</td>
      <td>1.97</td>
      <td>213,257</td>
      <td>8.0</td>
      <td>80-100 hours</td>
      <td>4.7</td>
      <td>2020-12-15</td>
      <td>3055</td>
      <td>1550</td>
      <td>80.0</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Mass Effect 2</td>
      <td>1.34</td>
      <td>221,178</td>
      <td>9.6</td>
      <td>50-60 hours</td>
      <td>4.7</td>
      <td>2020-11-09</td>
      <td>1819</td>
      <td>1355</td>
      <td>50.0</td>
      <td>60.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Stardew Valley</td>
      <td>3.04</td>
      <td>51,530</td>
      <td>1.0</td>
      <td>150-200 hours</td>
      <td>4.7</td>
      <td>2021-12-02</td>
      <td>3036</td>
      <td>1000</td>
      <td>150.0</td>
      <td>200.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>It Takes Two</td>
      <td>1.68</td>
      <td>71,981</td>
      <td>15.6</td>
      <td>12-15 hours</td>
      <td>4.7</td>
      <td>2021-11-03</td>
      <td>1678</td>
      <td>1000</td>
      <td>12.0</td>
      <td>15.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Hades</td>
      <td>2.40</td>
      <td>83,710</td>
      <td>6.1</td>
      <td>60-80 hours</td>
      <td>4.6</td>
      <td>2021-06-18</td>
      <td>2404</td>
      <td>1000</td>
      <td>60.0</td>
      <td>80.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Resident Evil 7: Biohazard Grotesque Ver.</td>
      <td>1.58</td>
      <td>777</td>
      <td>9.8</td>
      <td>15-20 hours</td>
      <td>4.6</td>
      <td>2020-09-17</td>
      <td>2560</td>
      <td>1620</td>
      <td>15.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>448</th>
      <td>The Catch: Carp Coarse Fishing</td>
      <td>11.70</td>
      <td>8,084</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>2.7</td>
      <td>2021-05-18</td>
      <td>13455</td>
      <td>1150</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>449</th>
      <td>Atomicrops</td>
      <td>2.90</td>
      <td>1,853</td>
      <td>1.9</td>
      <td>NaN</td>
      <td>4.5</td>
      <td>2021-07-22</td>
      <td>5374</td>
      <td>1850</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>450</th>
      <td>Lethal League Blaze</td>
      <td>3.91</td>
      <td>4,509</td>
      <td>1.6</td>
      <td>15-20 hours</td>
      <td>3.6</td>
      <td>2021-07-29</td>
      <td>3905</td>
      <td>1000</td>
      <td>15.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>451</th>
      <td>The Evil Within (JP)</td>
      <td>1.61</td>
      <td>388</td>
      <td>12.1</td>
      <td>NaN</td>
      <td>3.8</td>
      <td>2021-08-16</td>
      <td>2787</td>
      <td>1735</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>452</th>
      <td>Shadowrun Returns</td>
      <td>-</td>
      <td>0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2022-04-20</td>
      <td>1000</td>
      <td>1000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>453</th>
      <td>Shadowrun: Hong Kong - Extended Edition</td>
      <td>-</td>
      <td>0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2022-04-20</td>
      <td>1000</td>
      <td>1000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>454</th>
      <td>Shadowrun: Dragonfall - Director's Cut</td>
      <td>-</td>
      <td>0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2022-04-20</td>
      <td>1000</td>
      <td>1000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>453 rows × 11 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GAME</th>
      <th>RATIO</th>
      <th>GAMERS</th>
      <th>COMP %</th>
      <th>TIME</th>
      <th>RATING</th>
      <th>ADDED</th>
      <th>True_Achievement</th>
      <th>Game_Score</th>
      <th>min</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mass Effect Legendary Edition</td>
      <td>1.87</td>
      <td>84,143</td>
      <td>4.1</td>
      <td>100-120 hours</td>
      <td>4.8</td>
      <td>2022-01-06</td>
      <td>5442</td>
      <td>2915</td>
      <td>100.0</td>
      <td>120.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The Elder Scrolls V: Skyrim Special Edition</td>
      <td>1.97</td>
      <td>213,257</td>
      <td>8.0</td>
      <td>80-100 hours</td>
      <td>4.7</td>
      <td>2020-12-15</td>
      <td>3055</td>
      <td>1550</td>
      <td>80.0</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Mass Effect 2</td>
      <td>1.34</td>
      <td>221,178</td>
      <td>9.6</td>
      <td>50-60 hours</td>
      <td>4.7</td>
      <td>2020-11-09</td>
      <td>1819</td>
      <td>1355</td>
      <td>50.0</td>
      <td>60.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Stardew Valley</td>
      <td>3.04</td>
      <td>51,530</td>
      <td>1.0</td>
      <td>150-200 hours</td>
      <td>4.7</td>
      <td>2021-12-02</td>
      <td>3036</td>
      <td>1000</td>
      <td>150.0</td>
      <td>200.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>It Takes Two</td>
      <td>1.68</td>
      <td>71,981</td>
      <td>15.6</td>
      <td>12-15 hours</td>
      <td>4.7</td>
      <td>2021-11-03</td>
      <td>1678</td>
      <td>1000</td>
      <td>12.0</td>
      <td>15.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Hades</td>
      <td>2.40</td>
      <td>83,710</td>
      <td>6.1</td>
      <td>60-80 hours</td>
      <td>4.6</td>
      <td>2021-06-18</td>
      <td>2404</td>
      <td>1000</td>
      <td>60.0</td>
      <td>80.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Resident Evil 7: Biohazard Grotesque Ver.</td>
      <td>1.58</td>
      <td>777</td>
      <td>9.8</td>
      <td>15-20 hours</td>
      <td>4.6</td>
      <td>2020-09-17</td>
      <td>2560</td>
      <td>1620</td>
      <td>15.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>448</th>
      <td>The Catch: Carp Coarse Fishing</td>
      <td>11.70</td>
      <td>8,084</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>2.7</td>
      <td>2021-05-18</td>
      <td>13455</td>
      <td>1150</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>449</th>
      <td>Atomicrops</td>
      <td>2.90</td>
      <td>1,853</td>
      <td>1.9</td>
      <td>NaN</td>
      <td>4.5</td>
      <td>2021-07-22</td>
      <td>5374</td>
      <td>1850</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>450</th>
      <td>Lethal League Blaze</td>
      <td>3.91</td>
      <td>4,509</td>
      <td>1.6</td>
      <td>15-20 hours</td>
      <td>3.6</td>
      <td>2021-07-29</td>
      <td>3905</td>
      <td>1000</td>
      <td>15.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>451</th>
      <td>The Evil Within (JP)</td>
      <td>1.61</td>
      <td>388</td>
      <td>12.1</td>
      <td>NaN</td>
      <td>3.8</td>
      <td>2021-08-16</td>
      <td>2787</td>
      <td>1735</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>452</th>
      <td>Shadowrun Returns</td>
      <td>-</td>
      <td>0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2022-04-20</td>
      <td>1000</td>
      <td>1000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>453</th>
      <td>Shadowrun: Hong Kong - Extended Edition</td>
      <td>-</td>
      <td>0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2022-04-20</td>
      <td>1000</td>
      <td>1000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>454</th>
      <td>Shadowrun: Dragonfall - Director's Cut</td>
      <td>-</td>
      <td>0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2022-04-20</td>
      <td>1000</td>
      <td>1000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>453 rows × 11 columns</p>
      
          <p>__output__ (zip):</p>
          <pre><code><zip object at 0x7f552a5f9f40></code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('df', 'df', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> xbox-game-pass-games-library/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert Gamers column from string to integer and find in which year were the most played game was added</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['GAMERS']=df['GAMERS'].str.replace(",","").astype(int)
added_date=df.iloc[df['GAMERS'].idxmax()]['ADDED']
added_date.year</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['GAMERS']=df['GAMERS'].str.replace(",","").astype(int)
added_date=df.iloc[df['GAMERS'].idxmax()]['ADDED']
added_date.year</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['GAMERS'] = df['GAMERS'].str.replace(',', '').astype(int)
added_date = df.iloc[df['GAMERS'].idxmax()]['ADDED']
__output__ = added_date.year
</code></pre>
        <p><span onclick="$('#var_output_e748acde').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e748acde" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>2020</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GAME</th>
      <th>RATIO</th>
      <th>GAMERS</th>
      <th>COMP %</th>
      <th>TIME</th>
      <th>RATING</th>
      <th>ADDED</th>
      <th>True_Achievement</th>
      <th>Game_Score</th>
      <th>min</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mass Effect Legendary Edition</td>
      <td>1.87</td>
      <td>84143</td>
      <td>4.1</td>
      <td>100-120 hours</td>
      <td>4.8</td>
      <td>2022-01-06</td>
      <td>5442</td>
      <td>2915</td>
      <td>100.0</td>
      <td>120.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The Elder Scrolls V: Skyrim Special Edition</td>
      <td>1.97</td>
      <td>213257</td>
      <td>8.0</td>
      <td>80-100 hours</td>
      <td>4.7</td>
      <td>2020-12-15</td>
      <td>3055</td>
      <td>1550</td>
      <td>80.0</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Mass Effect 2</td>
      <td>1.34</td>
      <td>221178</td>
      <td>9.6</td>
      <td>50-60 hours</td>
      <td>4.7</td>
      <td>2020-11-09</td>
      <td>1819</td>
      <td>1355</td>
      <td>50.0</td>
      <td>60.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Stardew Valley</td>
      <td>3.04</td>
      <td>51530</td>
      <td>1.0</td>
      <td>150-200 hours</td>
      <td>4.7</td>
      <td>2021-12-02</td>
      <td>3036</td>
      <td>1000</td>
      <td>150.0</td>
      <td>200.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>It Takes Two</td>
      <td>1.68</td>
      <td>71981</td>
      <td>15.6</td>
      <td>12-15 hours</td>
      <td>4.7</td>
      <td>2021-11-03</td>
      <td>1678</td>
      <td>1000</td>
      <td>12.0</td>
      <td>15.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Hades</td>
      <td>2.40</td>
      <td>83710</td>
      <td>6.1</td>
      <td>60-80 hours</td>
      <td>4.6</td>
      <td>2021-06-18</td>
      <td>2404</td>
      <td>1000</td>
      <td>60.0</td>
      <td>80.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Resident Evil 7: Biohazard Grotesque Ver.</td>
      <td>1.58</td>
      <td>777</td>
      <td>9.8</td>
      <td>15-20 hours</td>
      <td>4.6</td>
      <td>2020-09-17</td>
      <td>2560</td>
      <td>1620</td>
      <td>15.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>448</th>
      <td>The Catch: Carp Coarse Fishing</td>
      <td>11.70</td>
      <td>8084</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>2.7</td>
      <td>2021-05-18</td>
      <td>13455</td>
      <td>1150</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>449</th>
      <td>Atomicrops</td>
      <td>2.90</td>
      <td>1853</td>
      <td>1.9</td>
      <td>NaN</td>
      <td>4.5</td>
      <td>2021-07-22</td>
      <td>5374</td>
      <td>1850</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>450</th>
      <td>Lethal League Blaze</td>
      <td>3.91</td>
      <td>4509</td>
      <td>1.6</td>
      <td>15-20 hours</td>
      <td>3.6</td>
      <td>2021-07-29</td>
      <td>3905</td>
      <td>1000</td>
      <td>15.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>451</th>
      <td>The Evil Within (JP)</td>
      <td>1.61</td>
      <td>388</td>
      <td>12.1</td>
      <td>NaN</td>
      <td>3.8</td>
      <td>2021-08-16</td>
      <td>2787</td>
      <td>1735</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>452</th>
      <td>Shadowrun Returns</td>
      <td>-</td>
      <td>0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2022-04-20</td>
      <td>1000</td>
      <td>1000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>453</th>
      <td>Shadowrun: Hong Kong - Extended Edition</td>
      <td>-</td>
      <td>0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2022-04-20</td>
      <td>1000</td>
      <td>1000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>454</th>
      <td>Shadowrun: Dragonfall - Director's Cut</td>
      <td>-</td>
      <td>0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2022-04-20</td>
      <td>1000</td>
      <td>1000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>453 rows × 11 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>2020</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> xbox-game-pass-games-library/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For each month in that year, how many games that has a rating of more than four?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['ADDED'].dt.year== added_date.year) & (df['RATING']>4)].groupby(df["ADDED"].dt.month)['GAME'].count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['ADDED'].dt.year== added_date.year) & (df['RATING']>4)].groupby(df["ADDED"].dt.month)['GAME'].count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['ADDED'].dt.year == added_date.year) & (df['RATING'] > 4)
    ].groupby(df['ADDED'].dt.month)['GAME'].count()
</code></pre>
        <p><span onclick="$('#var_output_dc9ed0be').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_dc9ed0be" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>ADDED
1.0      3
3.0      1
4.0      3
8.0      1
9.0      1
10.0     5
11.0    18
12.0     4
Name: GAME, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>ADDED
1.0      3
3.0      1
4.0      3
8.0      1
9.0      1
10.0     5
11.0    18
12.0     4
Name: GAME, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> xbox-game-pass-games-library/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average ratings of games that were added in 2022 and have a minimum completion time of more than or equal to eighty hours?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['ADDED'].dt.year==2022) & (df['min']>=80)]['RATING'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['ADDED'].dt.year==2022) & (df['min']>=80)]['RATING'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['ADDED'].dt.year == 2022) & (df['min'] >= 80)]['RATING'
    ].mean()
</code></pre>
        <p><span onclick="$('#var_output_5e080cda').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5e080cda" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>3.899999999999999</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>3.899999999999999</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> xbox-game-pass-games-library/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the number of games which were completed by more than ten thousand players in each year?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[((df['GAMERS']*(df['COMP %']/100))>10000)].groupby(df['ADDED'].dt.year).count()['GAME']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[((df['GAMERS']*(df['COMP %']/100))>10000)].groupby(df['ADDED'].dt.year).count()['GAME']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['GAMERS'] * (df['COMP %'] / 100) > 10000].groupby(df[
    'ADDED'].dt.year).count()['GAME']
</code></pre>
        <p><span onclick="$('#var_output_319642c8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_319642c8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>ADDED
2018.0     1
2019.0    14
2020.0    14
2021.0    17
2022.0     3
Name: GAME, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>ADDED
2018.0     1
2019.0    14
2020.0    14
2021.0    17
2022.0     3
Name: GAME, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> xbox-game-pass-games-library/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of the players who completed Mass Effect games out of all Mass Effect gamers?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>mass_effect=df[df['GAME'].str.contains("Mass Effect")]
((mass_effect['GAMERS'] * mass_effect['COMP %']/100).sum()/mass_effect['GAMERS'].sum())*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>mass_effect=df[df['GAME'].str.contains("Mass Effect")]
((mass_effect['GAMERS'] * mass_effect['COMP %']/100).sum()/mass_effect['GAMERS'].sum())*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>mass_effect = df[df['GAME'].str.contains('Mass Effect')]
__output__ = (mass_effect['GAMERS'] * mass_effect['COMP %'] / 100).sum(
    ) / mass_effect['GAMERS'].sum() * 100
</code></pre>
        <p><span onclick="$('#var_output_31a66ba9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_31a66ba9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>6.101162313272597</code></pre>
      
        <p><strong>Hyp output variables:</strong> mass_effect, __output__ </p>
    
          <p>mass_effect (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GAME</th>
      <th>RATIO</th>
      <th>GAMERS</th>
      <th>COMP %</th>
      <th>TIME</th>
      <th>RATING</th>
      <th>ADDED</th>
      <th>True_Achievement</th>
      <th>Game_Score</th>
      <th>min</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mass Effect Legendary Edition</td>
      <td>1.87</td>
      <td>84143</td>
      <td>4.1</td>
      <td>100-120 hours</td>
      <td>4.8</td>
      <td>2022-01-06</td>
      <td>5442</td>
      <td>2915</td>
      <td>100.0</td>
      <td>120.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Mass Effect 2</td>
      <td>1.34</td>
      <td>221178</td>
      <td>9.6</td>
      <td>50-60 hours</td>
      <td>4.7</td>
      <td>2020-11-09</td>
      <td>1819</td>
      <td>1355</td>
      <td>50.0</td>
      <td>60.0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Mass Effect 3</td>
      <td>1.52</td>
      <td>197006</td>
      <td>5.8</td>
      <td>50-60 hours</td>
      <td>4.5</td>
      <td>2020-11-09</td>
      <td>2357</td>
      <td>1550</td>
      <td>50.0</td>
      <td>60.0</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Mass Effect</td>
      <td>1.83</td>
      <td>273105</td>
      <td>6.4</td>
      <td>60-80 hours</td>
      <td>4.4</td>
      <td>2019-12-16</td>
      <td>2196</td>
      <td>1200</td>
      <td>60.0</td>
      <td>80.0</td>
    </tr>
    <tr>
      <th>178</th>
      <td>Mass Effect: Andromeda</td>
      <td>2.20</td>
      <td>179302</td>
      <td>2.6</td>
      <td>80-100 hours</td>
      <td>3.9</td>
      <td>2020-11-09</td>
      <td>2205</td>
      <td>1000</td>
      <td>80.0</td>
      <td>100.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 11 columns</p>
      
          <p>__output__ (float64):</p>
          <pre><code>6.101162313272597</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> xbox-game-pass-games-library/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average maximum completion time for all fallout games added in 2021?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>fallout=df[df['GAME'].str.contains('Fallout')]
fallout.groupby(fallout['ADDED'].dt.year).get_group(2021)['max'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>fallout=df[df['GAME'].str.contains('Fallout')]
fallout.groupby(fallout['ADDED'].dt.year).get_group(2021)['max'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>fallout = df[df['GAME'].str.contains('Fallout')]
__output__ = fallout.groupby(fallout['ADDED'].dt.year).get_group(2021)['max'
    ].mean()
</code></pre>
        <p><span onclick="$('#var_output_76e5d047').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_76e5d047" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>90.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> fallout, __output__ </p>
    
          <p>fallout (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GAME</th>
      <th>RATIO</th>
      <th>GAMERS</th>
      <th>COMP %</th>
      <th>TIME</th>
      <th>RATING</th>
      <th>ADDED</th>
      <th>True_Achievement</th>
      <th>Game_Score</th>
      <th>min</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>16</th>
      <td>Fallout 4</td>
      <td>1.78</td>
      <td>365955</td>
      <td>3.6</td>
      <td>80-100 hours</td>
      <td>4.5</td>
      <td>2021-03-12</td>
      <td>2856</td>
      <td>1600</td>
      <td>80.0</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Fallout 3</td>
      <td>1.58</td>
      <td>358627</td>
      <td>9.9</td>
      <td>60-80 hours</td>
      <td>4.5</td>
      <td>2021-06-13</td>
      <td>2447</td>
      <td>1550</td>
      <td>60.0</td>
      <td>80.0</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Fallout: New Vegas</td>
      <td>1.83</td>
      <td>256198</td>
      <td>5.9</td>
      <td>60-80 hours</td>
      <td>4.4</td>
      <td>2019-12-16</td>
      <td>3023</td>
      <td>1655</td>
      <td>60.0</td>
      <td>80.0</td>
    </tr>
    <tr>
      <th>355</th>
      <td>Fallout 76</td>
      <td>2.79</td>
      <td>179272</td>
      <td>0.7</td>
      <td>80-100 hours</td>
      <td>3.2</td>
      <td>2020-07-09</td>
      <td>3659</td>
      <td>1310</td>
      <td>80.0</td>
      <td>100.0</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 11 columns</p>
      
          <p>__output__ (float64):</p>
          <pre><code>90.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> xbox-game-pass-games-library/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the amount of games added in each year for each month? (show a table with index as years, columns as months and fill null values with 0)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pd.pivot_table(df,index=df['ADDED'].dt.year,columns=df['ADDED'].dt.month,values='ADDED',aggfunc=np.count_nonzero,fill_value='0').rename_axis(index='Year',columns='Month')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pd.pivot_table(df,index=df['ADDED'].dt.year,columns=df['ADDED'].dt.month,values='ADDED',aggfunc=np.count_nonzero,fill_value='0').rename_axis(index='Year',columns='Month')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = pd.pivot_table(df, index=df['ADDED'].dt.year, columns=df[
    'ADDED'].dt.month, values='ADDED', aggfunc=np.count_nonzero, fill_value='0'
    ).rename_axis(index='Year', columns='Month')
</code></pre>
        <p><span onclick="$('#var_output_cd5150a2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_cd5150a2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Month</th>
      <th>1.0</th>
      <th>2.0</th>
      <th>3.0</th>
      <th>4.0</th>
      <th>5.0</th>
      <th>6.0</th>
      <th>7.0</th>
      <th>8.0</th>
      <th>9.0</th>
      <th>10.0</th>
      <th>11.0</th>
      <th>12.0</th>
    </tr>
    <tr>
      <th>Year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2019.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>71.0</td>
    </tr>
    <tr>
      <th>2020.0</th>
      <td>3.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>18.0</td>
      <td>68.0</td>
      <td>12.0</td>
    </tr>
    <tr>
      <th>2021.0</th>
      <td>5.0</td>
      <td>5.0</td>
      <td>21.0</td>
      <td>4.0</td>
      <td>12.0</td>
      <td>14.0</td>
      <td>15.0</td>
      <td>19.0</td>
      <td>29.0</td>
      <td>17.0</td>
      <td>18.0</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>2022.0</th>
      <td>17.0</td>
      <td>10.0</td>
      <td>21.0</td>
      <td>14.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 12 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Month</th>
      <th>1.0</th>
      <th>2.0</th>
      <th>3.0</th>
      <th>4.0</th>
      <th>5.0</th>
      <th>6.0</th>
      <th>7.0</th>
      <th>8.0</th>
      <th>9.0</th>
      <th>10.0</th>
      <th>11.0</th>
      <th>12.0</th>
    </tr>
    <tr>
      <th>Year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2019.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>71.0</td>
    </tr>
    <tr>
      <th>2020.0</th>
      <td>3.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>18.0</td>
      <td>68.0</td>
      <td>12.0</td>
    </tr>
    <tr>
      <th>2021.0</th>
      <td>5.0</td>
      <td>5.0</td>
      <td>21.0</td>
      <td>4.0</td>
      <td>12.0</td>
      <td>14.0</td>
      <td>15.0</td>
      <td>19.0</td>
      <td>29.0</td>
      <td>17.0</td>
      <td>18.0</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>2022.0</th>
      <td>17.0</td>
      <td>10.0</td>
      <td>21.0</td>
      <td>14.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 12 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> xbox-game-pass-games-library/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What month has the highest number of games added?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>month=df.groupby(df['ADDED'].dt.month)['GAME'].count()
month.idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>month=df.groupby(df['ADDED'].dt.month)['GAME'].count()
month.idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>month = df.groupby(df['ADDED'].dt.month)['GAME'].count()
__output__ = month.idxmax()
</code></pre>
        <p><span onclick="$('#var_output_09bf6f85').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_09bf6f85" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>12.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> month, __output__ </p>
    
          <p>month (Series):</p>
          <pre><code>ADDED
1.0      25
2.0      18
3.0      46
4.0      23
5.0      14
6.0      18
7.0      19
8.0      24
9.0      33
10.0     35
11.0     86
12.0    110
Name: GAME, dtype: int64</code></pre>
      
          <p>__output__ (float64):</p>
          <pre><code>12.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> xbox-game-pass-games-library/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which game has the highest number of players added that month?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['ADDED'].dt.month==month.idxmax()].sort_values('GAMERS',ascending=False)['GAME'].iloc[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['ADDED'].dt.month==month.idxmax()].sort_values('GAMERS',ascending=False)['GAME'].iloc[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['ADDED'].dt.month == month.idxmax()].sort_values('GAMERS',
    ascending=False)['GAME'].iloc[0]
</code></pre>
        <p><span onclick="$('#var_output_349b4e96').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_349b4e96" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Gears of War</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Gears of War</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> credit-score-classification/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Make a new column 'Credit_Hist_yr' contains 'Credit_History_Age' in years unit and replace nulls with their median</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Credit_Hist_yr', 'Credit_Hist_mnt']]=df['Credit_History_Age'].str.split(pat=' and ', expand=True)

df['Credit_Hist_yr']=df['Credit_Hist_yr'].str.rstrip(' Years').astype('float')
df['Credit_Hist_mnt']=df['Credit_Hist_mnt'].str.rstrip(' Months').astype('float')

df['Credit_Hist_yr'] = df['Credit_Hist_yr'] + (df['Credit_Hist_mnt']/12)

df.drop(['Credit_History_Age','Credit_Hist_mnt'], axis=1, inplace=True)

df['Credit_Hist_yr']=df['Credit_Hist_yr'].fillna(df['Credit_Hist_yr'].median())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Credit_Hist_yr', 'Credit_Hist_mnt']]=df['Credit_History_Age'].str.split(pat=' and ', expand=True)

df['Credit_Hist_yr']=df['Credit_Hist_yr'].str.rstrip(' Years').astype('float')
df['Credit_Hist_mnt']=df['Credit_Hist_mnt'].str.rstrip(' Months').astype('float')

df['Credit_Hist_yr'] = df['Credit_Hist_yr'] + (df['Credit_Hist_mnt']/12)

df.drop(['Credit_History_Age','Credit_Hist_mnt'], axis=1, inplace=True)

df['Credit_Hist_yr']=df['Credit_Hist_yr'].fillna(df['Credit_Hist_yr'].median())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df[['Credit_Hist_yr', 'Credit_Hist_mnt']] = df['Credit_History_Age'].str.split(
    pat=' and ', expand=True)
df['Credit_Hist_yr'] = df['Credit_Hist_yr'].str.rstrip(' Years').astype('float'
    )
df['Credit_Hist_mnt'] = df['Credit_Hist_mnt'].str.rstrip(' Months').astype(
    'float')
df['Credit_Hist_yr'] = df['Credit_Hist_yr'] + df['Credit_Hist_mnt'] / 12
__tmp_4 = df.drop(['Credit_History_Age', 'Credit_Hist_mnt'], axis=1,
    inplace=True)
__output__ = df['Credit_Hist_yr'] = df['Credit_Hist_yr'].fillna(df[
    'Credit_Hist_yr'].median())
</code></pre>
        <p><span onclick="$('#var_output_4e2c89df').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4e2c89df" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0        22.083333
1        18.250000
2        22.250000
3        22.333333
4        22.416667
           ...    
99995    31.500000
99996    31.583333
99997    31.666667
99998    31.750000
99999    31.833333
Name: Credit_Hist_yr, Length: 100000, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Customer_ID</th>
      <th>Month</th>
      <th>Name</th>
      <th>Age</th>
      <th>SSN</th>
      <th>Occupation</th>
      <th>...</th>
      <th>Payment_of_Min_Amount</th>
      <th>Total_EMI_per_month</th>
      <th>Amount_invested_monthly</th>
      <th>Payment_Behaviour</th>
      <th>Monthly_Balance</th>
      <th>Credit_Score</th>
      <th>Credit_Hist_yr</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0x1602</td>
      <td>CUS_0xd40</td>
      <td>January</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>80.41529543900253</td>
      <td>High_spent_Small_value_payments</td>
      <td>312.49408867943663</td>
      <td>Good</td>
      <td>22.083333</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0x1603</td>
      <td>CUS_0xd40</td>
      <td>February</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>118.28022162236736</td>
      <td>Low_spent_Large_value_payments</td>
      <td>284.62916249607184</td>
      <td>Good</td>
      <td>18.250000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0x1604</td>
      <td>CUS_0xd40</td>
      <td>March</td>
      <td>Aaron Maashoh</td>
      <td>-500</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>81.699521264648</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>331.2098628537912</td>
      <td>Good</td>
      <td>22.250000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0x1605</td>
      <td>CUS_0xd40</td>
      <td>April</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>199.4580743910713</td>
      <td>Low_spent_Small_value_payments</td>
      <td>223.45130972736786</td>
      <td>Good</td>
      <td>22.333333</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0x1606</td>
      <td>CUS_0xd40</td>
      <td>May</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>41.420153086217326</td>
      <td>High_spent_Medium_value_payments</td>
      <td>341.48923103222177</td>
      <td>Good</td>
      <td>22.416667</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0x1607</td>
      <td>CUS_0xd40</td>
      <td>June</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>62.430172331195294</td>
      <td>!@9#%8</td>
      <td>340.4792117872438</td>
      <td>Good</td>
      <td>22.500000</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0x1608</td>
      <td>CUS_0xd40</td>
      <td>July</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>178.3440674122349</td>
      <td>Low_spent_Small_value_payments</td>
      <td>244.5653167062043</td>
      <td>Good</td>
      <td>22.583333</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99993</th>
      <td>0x25fe7</td>
      <td>CUS_0x942c</td>
      <td>February</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>58638.000000</td>
      <td>180.7330951944497</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>400.104466</td>
      <td>Standard</td>
      <td>31.333333</td>
    </tr>
    <tr>
      <th>99994</th>
      <td>0x25fe8</td>
      <td>CUS_0x942c</td>
      <td>March</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>140.58140274528395</td>
      <td>High_spent_Medium_value_payments</td>
      <td>410.256158</td>
      <td>Poor</td>
      <td>31.416667</td>
    </tr>
    <tr>
      <th>99995</th>
      <td>0x25fe9</td>
      <td>CUS_0x942c</td>
      <td>April</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>60.97133255718485</td>
      <td>High_spent_Large_value_payments</td>
      <td>479.866228</td>
      <td>Poor</td>
      <td>31.500000</td>
    </tr>
    <tr>
      <th>99996</th>
      <td>0x25fea</td>
      <td>CUS_0x942c</td>
      <td>May</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>54.18595028760385</td>
      <td>High_spent_Medium_value_payments</td>
      <td>496.65161</td>
      <td>Poor</td>
      <td>31.583333</td>
    </tr>
    <tr>
      <th>99997</th>
      <td>0x25feb</td>
      <td>CUS_0x942c</td>
      <td>June</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>24.02847744864441</td>
      <td>High_spent_Large_value_payments</td>
      <td>516.809083</td>
      <td>Poor</td>
      <td>31.666667</td>
    </tr>
    <tr>
      <th>99998</th>
      <td>0x25fec</td>
      <td>CUS_0x942c</td>
      <td>July</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>251.67258219721603</td>
      <td>Low_spent_Large_value_payments</td>
      <td>319.164979</td>
      <td>Standard</td>
      <td>31.750000</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>0x25fed</td>
      <td>CUS_0x942c</td>
      <td>August</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>167.1638651610451</td>
      <td>!@9#%8</td>
      <td>393.673696</td>
      <td>Poor</td>
      <td>31.833333</td>
    </tr>
  </tbody>
</table>
<p>100000 rows × 28 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0        22.083333
1        18.250000
2        22.250000
3        22.333333
4        22.416667
           ...    
99995    31.500000
99996    31.583333
99997    31.666667
99998    31.750000
99999    31.833333
Name: Credit_Hist_yr, Length: 100000, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> credit-score-classification/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many Lawyers called Ricko?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>len(df[(df['Occupation']=='Lawyer') & (df['Name']=='Ricko')].Customer_ID.unique())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>len(df[(df['Occupation']=='Lawyer') & (df['Name']=='Ricko')].Customer_ID.unique())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = len(df[(df['Occupation'] == 'Lawyer') & (df['Name'] == 'Ricko'
    )].Customer_ID.unique())
</code></pre>
        <p><span onclick="$('#var_output_05d10c91').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_05d10c91" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>2</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>2</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> credit-score-classification/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Remove _ and " from strings, also replace any string has empty string, 'nan', '!@9#%8', '#F%$D@*&8' with null</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df=df.applymap(lambda x: x if x is np.NaN or not isinstance(x, str) else str(x).strip('_ ,"')).replace(['', 'nan', '!@9#%8', '#F%$D@*&8'], np.NaN)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df=df.applymap(lambda x: x if x is np.NaN or not isinstance(x, str) else str(x).strip('_ ,"')).replace(['', 'nan', '!@9#%8', '#F%$D@*&8'], np.NaN)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df = df.applymap(lambda x: x if x is np.NaN or not isinstance(
    x, str) else str(x).strip('_ ,"')).replace(['', 'nan', '!@9#%8',
    '#F%$D@*&8'], np.NaN)
</code></pre>
        <p><span onclick="$('#var_output_0c0c9577').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0c0c9577" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Customer_ID</th>
      <th>Month</th>
      <th>Name</th>
      <th>Age</th>
      <th>SSN</th>
      <th>Occupation</th>
      <th>...</th>
      <th>Payment_of_Min_Amount</th>
      <th>Total_EMI_per_month</th>
      <th>Amount_invested_monthly</th>
      <th>Payment_Behaviour</th>
      <th>Monthly_Balance</th>
      <th>Credit_Score</th>
      <th>Credit_Hist_yr</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0x1602</td>
      <td>CUS_0xd40</td>
      <td>January</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>80.41529543900253</td>
      <td>High_spent_Small_value_payments</td>
      <td>312.49408867943663</td>
      <td>Good</td>
      <td>22.083333</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0x1603</td>
      <td>CUS_0xd40</td>
      <td>February</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>118.28022162236736</td>
      <td>Low_spent_Large_value_payments</td>
      <td>284.62916249607184</td>
      <td>Good</td>
      <td>18.250000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0x1604</td>
      <td>CUS_0xd40</td>
      <td>March</td>
      <td>Aaron Maashoh</td>
      <td>-500</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>81.699521264648</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>331.2098628537912</td>
      <td>Good</td>
      <td>22.250000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0x1605</td>
      <td>CUS_0xd40</td>
      <td>April</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>199.4580743910713</td>
      <td>Low_spent_Small_value_payments</td>
      <td>223.45130972736786</td>
      <td>Good</td>
      <td>22.333333</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0x1606</td>
      <td>CUS_0xd40</td>
      <td>May</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>41.420153086217326</td>
      <td>High_spent_Medium_value_payments</td>
      <td>341.48923103222177</td>
      <td>Good</td>
      <td>22.416667</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0x1607</td>
      <td>CUS_0xd40</td>
      <td>June</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>62.430172331195294</td>
      <td>NaN</td>
      <td>340.4792117872438</td>
      <td>Good</td>
      <td>22.500000</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0x1608</td>
      <td>CUS_0xd40</td>
      <td>July</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>178.3440674122349</td>
      <td>Low_spent_Small_value_payments</td>
      <td>244.5653167062043</td>
      <td>Good</td>
      <td>22.583333</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99993</th>
      <td>0x25fe7</td>
      <td>CUS_0x942c</td>
      <td>February</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>58638.000000</td>
      <td>180.7330951944497</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>400.104466</td>
      <td>Standard</td>
      <td>31.333333</td>
    </tr>
    <tr>
      <th>99994</th>
      <td>0x25fe8</td>
      <td>CUS_0x942c</td>
      <td>March</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>140.58140274528395</td>
      <td>High_spent_Medium_value_payments</td>
      <td>410.256158</td>
      <td>Poor</td>
      <td>31.416667</td>
    </tr>
    <tr>
      <th>99995</th>
      <td>0x25fe9</td>
      <td>CUS_0x942c</td>
      <td>April</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>60.97133255718485</td>
      <td>High_spent_Large_value_payments</td>
      <td>479.866228</td>
      <td>Poor</td>
      <td>31.500000</td>
    </tr>
    <tr>
      <th>99996</th>
      <td>0x25fea</td>
      <td>CUS_0x942c</td>
      <td>May</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>54.18595028760385</td>
      <td>High_spent_Medium_value_payments</td>
      <td>496.65161</td>
      <td>Poor</td>
      <td>31.583333</td>
    </tr>
    <tr>
      <th>99997</th>
      <td>0x25feb</td>
      <td>CUS_0x942c</td>
      <td>June</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>24.02847744864441</td>
      <td>High_spent_Large_value_payments</td>
      <td>516.809083</td>
      <td>Poor</td>
      <td>31.666667</td>
    </tr>
    <tr>
      <th>99998</th>
      <td>0x25fec</td>
      <td>CUS_0x942c</td>
      <td>July</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>251.67258219721603</td>
      <td>Low_spent_Large_value_payments</td>
      <td>319.164979</td>
      <td>Standard</td>
      <td>31.750000</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>0x25fed</td>
      <td>CUS_0x942c</td>
      <td>August</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>167.1638651610451</td>
      <td>NaN</td>
      <td>393.673696</td>
      <td>Poor</td>
      <td>31.833333</td>
    </tr>
  </tbody>
</table>
<p>100000 rows × 28 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Customer_ID</th>
      <th>Month</th>
      <th>Name</th>
      <th>Age</th>
      <th>SSN</th>
      <th>Occupation</th>
      <th>...</th>
      <th>Payment_of_Min_Amount</th>
      <th>Total_EMI_per_month</th>
      <th>Amount_invested_monthly</th>
      <th>Payment_Behaviour</th>
      <th>Monthly_Balance</th>
      <th>Credit_Score</th>
      <th>Credit_Hist_yr</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0x1602</td>
      <td>CUS_0xd40</td>
      <td>January</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>80.41529543900253</td>
      <td>High_spent_Small_value_payments</td>
      <td>312.49408867943663</td>
      <td>Good</td>
      <td>22.083333</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0x1603</td>
      <td>CUS_0xd40</td>
      <td>February</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>118.28022162236736</td>
      <td>Low_spent_Large_value_payments</td>
      <td>284.62916249607184</td>
      <td>Good</td>
      <td>18.250000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0x1604</td>
      <td>CUS_0xd40</td>
      <td>March</td>
      <td>Aaron Maashoh</td>
      <td>-500</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>81.699521264648</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>331.2098628537912</td>
      <td>Good</td>
      <td>22.250000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0x1605</td>
      <td>CUS_0xd40</td>
      <td>April</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>199.4580743910713</td>
      <td>Low_spent_Small_value_payments</td>
      <td>223.45130972736786</td>
      <td>Good</td>
      <td>22.333333</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0x1606</td>
      <td>CUS_0xd40</td>
      <td>May</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>41.420153086217326</td>
      <td>High_spent_Medium_value_payments</td>
      <td>341.48923103222177</td>
      <td>Good</td>
      <td>22.416667</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0x1607</td>
      <td>CUS_0xd40</td>
      <td>June</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>62.430172331195294</td>
      <td>NaN</td>
      <td>340.4792117872438</td>
      <td>Good</td>
      <td>22.500000</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0x1608</td>
      <td>CUS_0xd40</td>
      <td>July</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>178.3440674122349</td>
      <td>Low_spent_Small_value_payments</td>
      <td>244.5653167062043</td>
      <td>Good</td>
      <td>22.583333</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99993</th>
      <td>0x25fe7</td>
      <td>CUS_0x942c</td>
      <td>February</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>58638.000000</td>
      <td>180.7330951944497</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>400.104466</td>
      <td>Standard</td>
      <td>31.333333</td>
    </tr>
    <tr>
      <th>99994</th>
      <td>0x25fe8</td>
      <td>CUS_0x942c</td>
      <td>March</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>140.58140274528395</td>
      <td>High_spent_Medium_value_payments</td>
      <td>410.256158</td>
      <td>Poor</td>
      <td>31.416667</td>
    </tr>
    <tr>
      <th>99995</th>
      <td>0x25fe9</td>
      <td>CUS_0x942c</td>
      <td>April</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>60.97133255718485</td>
      <td>High_spent_Large_value_payments</td>
      <td>479.866228</td>
      <td>Poor</td>
      <td>31.500000</td>
    </tr>
    <tr>
      <th>99996</th>
      <td>0x25fea</td>
      <td>CUS_0x942c</td>
      <td>May</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>54.18595028760385</td>
      <td>High_spent_Medium_value_payments</td>
      <td>496.65161</td>
      <td>Poor</td>
      <td>31.583333</td>
    </tr>
    <tr>
      <th>99997</th>
      <td>0x25feb</td>
      <td>CUS_0x942c</td>
      <td>June</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>24.02847744864441</td>
      <td>High_spent_Large_value_payments</td>
      <td>516.809083</td>
      <td>Poor</td>
      <td>31.666667</td>
    </tr>
    <tr>
      <th>99998</th>
      <td>0x25fec</td>
      <td>CUS_0x942c</td>
      <td>July</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>251.67258219721603</td>
      <td>Low_spent_Large_value_payments</td>
      <td>319.164979</td>
      <td>Standard</td>
      <td>31.750000</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>0x25fed</td>
      <td>CUS_0x942c</td>
      <td>August</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>167.1638651610451</td>
      <td>NaN</td>
      <td>393.673696</td>
      <td>Poor</td>
      <td>31.833333</td>
    </tr>
  </tbody>
</table>
<p>100000 rows × 28 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Customer_ID</th>
      <th>Month</th>
      <th>Name</th>
      <th>Age</th>
      <th>SSN</th>
      <th>Occupation</th>
      <th>...</th>
      <th>Payment_of_Min_Amount</th>
      <th>Total_EMI_per_month</th>
      <th>Amount_invested_monthly</th>
      <th>Payment_Behaviour</th>
      <th>Monthly_Balance</th>
      <th>Credit_Score</th>
      <th>Credit_Hist_yr</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0x1602</td>
      <td>CUS_0xd40</td>
      <td>January</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>80.41529543900253</td>
      <td>High_spent_Small_value_payments</td>
      <td>312.49408867943663</td>
      <td>Good</td>
      <td>22.083333</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0x1603</td>
      <td>CUS_0xd40</td>
      <td>February</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>118.28022162236736</td>
      <td>Low_spent_Large_value_payments</td>
      <td>284.62916249607184</td>
      <td>Good</td>
      <td>18.250000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0x1604</td>
      <td>CUS_0xd40</td>
      <td>March</td>
      <td>Aaron Maashoh</td>
      <td>-500</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>81.699521264648</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>331.2098628537912</td>
      <td>Good</td>
      <td>22.250000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0x1605</td>
      <td>CUS_0xd40</td>
      <td>April</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>199.4580743910713</td>
      <td>Low_spent_Small_value_payments</td>
      <td>223.45130972736786</td>
      <td>Good</td>
      <td>22.333333</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0x1606</td>
      <td>CUS_0xd40</td>
      <td>May</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>41.420153086217326</td>
      <td>High_spent_Medium_value_payments</td>
      <td>341.48923103222177</td>
      <td>Good</td>
      <td>22.416667</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0x1607</td>
      <td>CUS_0xd40</td>
      <td>June</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>62.430172331195294</td>
      <td>NaN</td>
      <td>340.4792117872438</td>
      <td>Good</td>
      <td>22.500000</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0x1608</td>
      <td>CUS_0xd40</td>
      <td>July</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>No</td>
      <td>49.574949</td>
      <td>178.3440674122349</td>
      <td>Low_spent_Small_value_payments</td>
      <td>244.5653167062043</td>
      <td>Good</td>
      <td>22.583333</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99993</th>
      <td>0x25fe7</td>
      <td>CUS_0x942c</td>
      <td>February</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>58638.000000</td>
      <td>180.7330951944497</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>400.104466</td>
      <td>Standard</td>
      <td>31.333333</td>
    </tr>
    <tr>
      <th>99994</th>
      <td>0x25fe8</td>
      <td>CUS_0x942c</td>
      <td>March</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>140.58140274528395</td>
      <td>High_spent_Medium_value_payments</td>
      <td>410.256158</td>
      <td>Poor</td>
      <td>31.416667</td>
    </tr>
    <tr>
      <th>99995</th>
      <td>0x25fe9</td>
      <td>CUS_0x942c</td>
      <td>April</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>60.97133255718485</td>
      <td>High_spent_Large_value_payments</td>
      <td>479.866228</td>
      <td>Poor</td>
      <td>31.500000</td>
    </tr>
    <tr>
      <th>99996</th>
      <td>0x25fea</td>
      <td>CUS_0x942c</td>
      <td>May</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>54.18595028760385</td>
      <td>High_spent_Medium_value_payments</td>
      <td>496.65161</td>
      <td>Poor</td>
      <td>31.583333</td>
    </tr>
    <tr>
      <th>99997</th>
      <td>0x25feb</td>
      <td>CUS_0x942c</td>
      <td>June</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>24.02847744864441</td>
      <td>High_spent_Large_value_payments</td>
      <td>516.809083</td>
      <td>Poor</td>
      <td>31.666667</td>
    </tr>
    <tr>
      <th>99998</th>
      <td>0x25fec</td>
      <td>CUS_0x942c</td>
      <td>July</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>251.67258219721603</td>
      <td>Low_spent_Large_value_payments</td>
      <td>319.164979</td>
      <td>Standard</td>
      <td>31.750000</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>0x25fed</td>
      <td>CUS_0x942c</td>
      <td>August</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>No</td>
      <td>35.104023</td>
      <td>167.1638651610451</td>
      <td>NaN</td>
      <td>393.673696</td>
      <td>Poor</td>
      <td>31.833333</td>
    </tr>
  </tbody>
</table>
<p>100000 rows × 28 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> credit-score-classification/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Split Payment Behaviour's column into Spent and Payment columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def spent(x):
  if x is np.NaN:
    return x
  else: 
    x_split=x.split('_')
    return str(x_split[0])

def payment(x):
  if x is np.NaN:
    return x
  else: 
    x_split=x.split('_')
    return str(x_split[2])

df['Spent']=df.Payment_Behaviour.apply(spent)
df['Payment']=df.Payment_Behaviour.apply(payment)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>['df']</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def spent(x):
  if x is np.NaN:
    return x
  else: 
    x_split=x.split('_')
    return str(x_split[0])

def payment(x):
  if x is np.NaN:
    return x
  else: 
    x_split=x.split('_')
    return str(x_split[2])

df['Spent']=df.Payment_Behaviour.apply(spent)
df['Payment']=df.Payment_Behaviour.apply(payment)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def spent(x):
    if x is np.NaN:
        return x
    else:
        x_split = x.split('_')
        return str(x_split[0])


def payment(x):
    if x is np.NaN:
        return x
    else:
        x_split = x.split('_')
        return str(x_split[2])


df['Spent'] = df.Payment_Behaviour.apply(spent)
__output__ = df['Payment'] = df.Payment_Behaviour.apply(payment)
</code></pre>
        <p><span onclick="$('#var_output_0386f0d6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0386f0d6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> df </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Customer_ID</th>
      <th>Month</th>
      <th>Name</th>
      <th>Age</th>
      <th>SSN</th>
      <th>Occupation</th>
      <th>...</th>
      <th>Amount_invested_monthly</th>
      <th>Payment_Behaviour</th>
      <th>Monthly_Balance</th>
      <th>Credit_Score</th>
      <th>Credit_Hist_yr</th>
      <th>Spent</th>
      <th>Payment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0x1602</td>
      <td>CUS_0xd40</td>
      <td>January</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>80.41529543900253</td>
      <td>High_spent_Small_value_payments</td>
      <td>312.49408867943663</td>
      <td>Good</td>
      <td>22.083333</td>
      <td>High</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0x1603</td>
      <td>CUS_0xd40</td>
      <td>February</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>118.28022162236736</td>
      <td>Low_spent_Large_value_payments</td>
      <td>284.62916249607184</td>
      <td>Good</td>
      <td>18.250000</td>
      <td>Low</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0x1604</td>
      <td>CUS_0xd40</td>
      <td>March</td>
      <td>Aaron Maashoh</td>
      <td>-500</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>81.699521264648</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>331.2098628537912</td>
      <td>Good</td>
      <td>22.250000</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0x1605</td>
      <td>CUS_0xd40</td>
      <td>April</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>199.4580743910713</td>
      <td>Low_spent_Small_value_payments</td>
      <td>223.45130972736786</td>
      <td>Good</td>
      <td>22.333333</td>
      <td>Low</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0x1606</td>
      <td>CUS_0xd40</td>
      <td>May</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>41.420153086217326</td>
      <td>High_spent_Medium_value_payments</td>
      <td>341.48923103222177</td>
      <td>Good</td>
      <td>22.416667</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0x1607</td>
      <td>CUS_0xd40</td>
      <td>June</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>62.430172331195294</td>
      <td>NaN</td>
      <td>340.4792117872438</td>
      <td>Good</td>
      <td>22.500000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0x1608</td>
      <td>CUS_0xd40</td>
      <td>July</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>178.3440674122349</td>
      <td>Low_spent_Small_value_payments</td>
      <td>244.5653167062043</td>
      <td>Good</td>
      <td>22.583333</td>
      <td>Low</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99993</th>
      <td>0x25fe7</td>
      <td>CUS_0x942c</td>
      <td>February</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>180.7330951944497</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>400.104466</td>
      <td>Standard</td>
      <td>31.333333</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99994</th>
      <td>0x25fe8</td>
      <td>CUS_0x942c</td>
      <td>March</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>140.58140274528395</td>
      <td>High_spent_Medium_value_payments</td>
      <td>410.256158</td>
      <td>Poor</td>
      <td>31.416667</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99995</th>
      <td>0x25fe9</td>
      <td>CUS_0x942c</td>
      <td>April</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>60.97133255718485</td>
      <td>High_spent_Large_value_payments</td>
      <td>479.866228</td>
      <td>Poor</td>
      <td>31.500000</td>
      <td>High</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99996</th>
      <td>0x25fea</td>
      <td>CUS_0x942c</td>
      <td>May</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>54.18595028760385</td>
      <td>High_spent_Medium_value_payments</td>
      <td>496.65161</td>
      <td>Poor</td>
      <td>31.583333</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99997</th>
      <td>0x25feb</td>
      <td>CUS_0x942c</td>
      <td>June</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>24.02847744864441</td>
      <td>High_spent_Large_value_payments</td>
      <td>516.809083</td>
      <td>Poor</td>
      <td>31.666667</td>
      <td>High</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99998</th>
      <td>0x25fec</td>
      <td>CUS_0x942c</td>
      <td>July</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>251.67258219721603</td>
      <td>Low_spent_Large_value_payments</td>
      <td>319.164979</td>
      <td>Standard</td>
      <td>31.750000</td>
      <td>Low</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>0x25fed</td>
      <td>CUS_0x942c</td>
      <td>August</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>167.1638651610451</td>
      <td>NaN</td>
      <td>393.673696</td>
      <td>Poor</td>
      <td>31.833333</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>100000 rows × 30 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Customer_ID</th>
      <th>Month</th>
      <th>Name</th>
      <th>Age</th>
      <th>SSN</th>
      <th>Occupation</th>
      <th>...</th>
      <th>Amount_invested_monthly</th>
      <th>Payment_Behaviour</th>
      <th>Monthly_Balance</th>
      <th>Credit_Score</th>
      <th>Credit_Hist_yr</th>
      <th>Spent</th>
      <th>Payment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0x1602</td>
      <td>CUS_0xd40</td>
      <td>January</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>80.41529543900253</td>
      <td>High_spent_Small_value_payments</td>
      <td>312.49408867943663</td>
      <td>Good</td>
      <td>22.083333</td>
      <td>High</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0x1603</td>
      <td>CUS_0xd40</td>
      <td>February</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>118.28022162236736</td>
      <td>Low_spent_Large_value_payments</td>
      <td>284.62916249607184</td>
      <td>Good</td>
      <td>18.250000</td>
      <td>Low</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0x1604</td>
      <td>CUS_0xd40</td>
      <td>March</td>
      <td>Aaron Maashoh</td>
      <td>-500</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>81.699521264648</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>331.2098628537912</td>
      <td>Good</td>
      <td>22.250000</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0x1605</td>
      <td>CUS_0xd40</td>
      <td>April</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>199.4580743910713</td>
      <td>Low_spent_Small_value_payments</td>
      <td>223.45130972736786</td>
      <td>Good</td>
      <td>22.333333</td>
      <td>Low</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0x1606</td>
      <td>CUS_0xd40</td>
      <td>May</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>41.420153086217326</td>
      <td>High_spent_Medium_value_payments</td>
      <td>341.48923103222177</td>
      <td>Good</td>
      <td>22.416667</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0x1607</td>
      <td>CUS_0xd40</td>
      <td>June</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>62.430172331195294</td>
      <td>NaN</td>
      <td>340.4792117872438</td>
      <td>Good</td>
      <td>22.500000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0x1608</td>
      <td>CUS_0xd40</td>
      <td>July</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>178.3440674122349</td>
      <td>Low_spent_Small_value_payments</td>
      <td>244.5653167062043</td>
      <td>Good</td>
      <td>22.583333</td>
      <td>Low</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99993</th>
      <td>0x25fe7</td>
      <td>CUS_0x942c</td>
      <td>February</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>180.7330951944497</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>400.104466</td>
      <td>Standard</td>
      <td>31.333333</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99994</th>
      <td>0x25fe8</td>
      <td>CUS_0x942c</td>
      <td>March</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>140.58140274528395</td>
      <td>High_spent_Medium_value_payments</td>
      <td>410.256158</td>
      <td>Poor</td>
      <td>31.416667</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99995</th>
      <td>0x25fe9</td>
      <td>CUS_0x942c</td>
      <td>April</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>60.97133255718485</td>
      <td>High_spent_Large_value_payments</td>
      <td>479.866228</td>
      <td>Poor</td>
      <td>31.500000</td>
      <td>High</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99996</th>
      <td>0x25fea</td>
      <td>CUS_0x942c</td>
      <td>May</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>54.18595028760385</td>
      <td>High_spent_Medium_value_payments</td>
      <td>496.65161</td>
      <td>Poor</td>
      <td>31.583333</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99997</th>
      <td>0x25feb</td>
      <td>CUS_0x942c</td>
      <td>June</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>24.02847744864441</td>
      <td>High_spent_Large_value_payments</td>
      <td>516.809083</td>
      <td>Poor</td>
      <td>31.666667</td>
      <td>High</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99998</th>
      <td>0x25fec</td>
      <td>CUS_0x942c</td>
      <td>July</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>251.67258219721603</td>
      <td>Low_spent_Large_value_payments</td>
      <td>319.164979</td>
      <td>Standard</td>
      <td>31.750000</td>
      <td>Low</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>0x25fed</td>
      <td>CUS_0x942c</td>
      <td>August</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>167.1638651610451</td>
      <td>NaN</td>
      <td>393.673696</td>
      <td>Poor</td>
      <td>31.833333</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>100000 rows × 30 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0         Small
1         Large
2        Medium
3         Small
4        Medium
          ...  
99995     Large
99996    Medium
99997     Large
99998     Large
99999       NaN
Name: Payment_Behaviour, Length: 100000, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('df', 'df', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> credit-score-classification/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many customers have poor credit scores yet have less numbers of loans than the average amount of loans taken out by customers with good credit score?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['Num_of_Loan']=df['Num_of_Loan'].astype(float)
loan_good=df.groupby('Credit_Score').mean()['Num_of_Loan']['Good']
len(df[(df['Num_of_Loan']<loan_good) & (df['Credit_Score']=='Poor')])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['Num_of_Loan']=df['Num_of_Loan'].astype(float)
loan_good=df.groupby('Credit_Score').mean()['Num_of_Loan']['Good']
len(df[(df['Num_of_Loan']<loan_good) & (df['Credit_Score']=='Poor')])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['Num_of_Loan'] = df['Num_of_Loan'].astype(float)
loan_good = df.groupby('Credit_Score').mean()['Num_of_Loan']['Good']
__output__ = len(df[(df['Num_of_Loan'] < loan_good) & (df['Credit_Score'] ==
    'Poor')])
</code></pre>
        <p><span onclick="$('#var_output_429c0dc2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_429c0dc2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>3580</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, loan_good, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Customer_ID</th>
      <th>Month</th>
      <th>Name</th>
      <th>Age</th>
      <th>SSN</th>
      <th>Occupation</th>
      <th>...</th>
      <th>Amount_invested_monthly</th>
      <th>Payment_Behaviour</th>
      <th>Monthly_Balance</th>
      <th>Credit_Score</th>
      <th>Credit_Hist_yr</th>
      <th>Spent</th>
      <th>Payment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0x1602</td>
      <td>CUS_0xd40</td>
      <td>January</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>80.41529543900253</td>
      <td>High_spent_Small_value_payments</td>
      <td>312.49408867943663</td>
      <td>Good</td>
      <td>22.083333</td>
      <td>High</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0x1603</td>
      <td>CUS_0xd40</td>
      <td>February</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>118.28022162236736</td>
      <td>Low_spent_Large_value_payments</td>
      <td>284.62916249607184</td>
      <td>Good</td>
      <td>18.250000</td>
      <td>Low</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0x1604</td>
      <td>CUS_0xd40</td>
      <td>March</td>
      <td>Aaron Maashoh</td>
      <td>-500</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>81.699521264648</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>331.2098628537912</td>
      <td>Good</td>
      <td>22.250000</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0x1605</td>
      <td>CUS_0xd40</td>
      <td>April</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>199.4580743910713</td>
      <td>Low_spent_Small_value_payments</td>
      <td>223.45130972736786</td>
      <td>Good</td>
      <td>22.333333</td>
      <td>Low</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0x1606</td>
      <td>CUS_0xd40</td>
      <td>May</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>41.420153086217326</td>
      <td>High_spent_Medium_value_payments</td>
      <td>341.48923103222177</td>
      <td>Good</td>
      <td>22.416667</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0x1607</td>
      <td>CUS_0xd40</td>
      <td>June</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>62.430172331195294</td>
      <td>NaN</td>
      <td>340.4792117872438</td>
      <td>Good</td>
      <td>22.500000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0x1608</td>
      <td>CUS_0xd40</td>
      <td>July</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>178.3440674122349</td>
      <td>Low_spent_Small_value_payments</td>
      <td>244.5653167062043</td>
      <td>Good</td>
      <td>22.583333</td>
      <td>Low</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99993</th>
      <td>0x25fe7</td>
      <td>CUS_0x942c</td>
      <td>February</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>180.7330951944497</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>400.104466</td>
      <td>Standard</td>
      <td>31.333333</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99994</th>
      <td>0x25fe8</td>
      <td>CUS_0x942c</td>
      <td>March</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>140.58140274528395</td>
      <td>High_spent_Medium_value_payments</td>
      <td>410.256158</td>
      <td>Poor</td>
      <td>31.416667</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99995</th>
      <td>0x25fe9</td>
      <td>CUS_0x942c</td>
      <td>April</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>60.97133255718485</td>
      <td>High_spent_Large_value_payments</td>
      <td>479.866228</td>
      <td>Poor</td>
      <td>31.500000</td>
      <td>High</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99996</th>
      <td>0x25fea</td>
      <td>CUS_0x942c</td>
      <td>May</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>54.18595028760385</td>
      <td>High_spent_Medium_value_payments</td>
      <td>496.65161</td>
      <td>Poor</td>
      <td>31.583333</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99997</th>
      <td>0x25feb</td>
      <td>CUS_0x942c</td>
      <td>June</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>24.02847744864441</td>
      <td>High_spent_Large_value_payments</td>
      <td>516.809083</td>
      <td>Poor</td>
      <td>31.666667</td>
      <td>High</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99998</th>
      <td>0x25fec</td>
      <td>CUS_0x942c</td>
      <td>July</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>251.67258219721603</td>
      <td>Low_spent_Large_value_payments</td>
      <td>319.164979</td>
      <td>Standard</td>
      <td>31.750000</td>
      <td>Low</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>0x25fed</td>
      <td>CUS_0x942c</td>
      <td>August</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>167.1638651610451</td>
      <td>NaN</td>
      <td>393.673696</td>
      <td>Poor</td>
      <td>31.833333</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>100000 rows × 30 columns</p>
      
          <p>loan_good (float64):</p>
          <pre><code>1.7926295714606237</code></pre>
      
          <p>__output__ (int):</p>
          <pre><code>3580</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> credit-score-classification/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert Customers IDs into integer</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['Customer_ID'] = df.Customer_ID.apply(lambda x: int(x[4:], 16))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['Customer_ID'] = df.Customer_ID.apply(lambda x: int(x[4:], 16))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df['Customer_ID'] = df.Customer_ID.apply(lambda x: int(x[4:], 16))
</code></pre>
        <p><span onclick="$('#var_output_bf507390').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bf507390" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0         3392
1         3392
2         3392
3         3392
4         3392
         ...  
99995    37932
99996    37932
99997    37932
99998    37932
99999    37932
Name: Customer_ID, Length: 100000, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Customer_ID</th>
      <th>Month</th>
      <th>Name</th>
      <th>Age</th>
      <th>SSN</th>
      <th>Occupation</th>
      <th>...</th>
      <th>Amount_invested_monthly</th>
      <th>Payment_Behaviour</th>
      <th>Monthly_Balance</th>
      <th>Credit_Score</th>
      <th>Credit_Hist_yr</th>
      <th>Spent</th>
      <th>Payment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0x1602</td>
      <td>3392</td>
      <td>January</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>80.41529543900253</td>
      <td>High_spent_Small_value_payments</td>
      <td>312.49408867943663</td>
      <td>Good</td>
      <td>22.083333</td>
      <td>High</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0x1603</td>
      <td>3392</td>
      <td>February</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>118.28022162236736</td>
      <td>Low_spent_Large_value_payments</td>
      <td>284.62916249607184</td>
      <td>Good</td>
      <td>18.250000</td>
      <td>Low</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0x1604</td>
      <td>3392</td>
      <td>March</td>
      <td>Aaron Maashoh</td>
      <td>-500</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>81.699521264648</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>331.2098628537912</td>
      <td>Good</td>
      <td>22.250000</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0x1605</td>
      <td>3392</td>
      <td>April</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>199.4580743910713</td>
      <td>Low_spent_Small_value_payments</td>
      <td>223.45130972736786</td>
      <td>Good</td>
      <td>22.333333</td>
      <td>Low</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0x1606</td>
      <td>3392</td>
      <td>May</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>41.420153086217326</td>
      <td>High_spent_Medium_value_payments</td>
      <td>341.48923103222177</td>
      <td>Good</td>
      <td>22.416667</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0x1607</td>
      <td>3392</td>
      <td>June</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>62.430172331195294</td>
      <td>NaN</td>
      <td>340.4792117872438</td>
      <td>Good</td>
      <td>22.500000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0x1608</td>
      <td>3392</td>
      <td>July</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821-00-0265</td>
      <td>Scientist</td>
      <td>...</td>
      <td>178.3440674122349</td>
      <td>Low_spent_Small_value_payments</td>
      <td>244.5653167062043</td>
      <td>Good</td>
      <td>22.583333</td>
      <td>Low</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99993</th>
      <td>0x25fe7</td>
      <td>37932</td>
      <td>February</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>180.7330951944497</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>400.104466</td>
      <td>Standard</td>
      <td>31.333333</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99994</th>
      <td>0x25fe8</td>
      <td>37932</td>
      <td>March</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>140.58140274528395</td>
      <td>High_spent_Medium_value_payments</td>
      <td>410.256158</td>
      <td>Poor</td>
      <td>31.416667</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99995</th>
      <td>0x25fe9</td>
      <td>37932</td>
      <td>April</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>60.97133255718485</td>
      <td>High_spent_Large_value_payments</td>
      <td>479.866228</td>
      <td>Poor</td>
      <td>31.500000</td>
      <td>High</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99996</th>
      <td>0x25fea</td>
      <td>37932</td>
      <td>May</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>54.18595028760385</td>
      <td>High_spent_Medium_value_payments</td>
      <td>496.65161</td>
      <td>Poor</td>
      <td>31.583333</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99997</th>
      <td>0x25feb</td>
      <td>37932</td>
      <td>June</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>24.02847744864441</td>
      <td>High_spent_Large_value_payments</td>
      <td>516.809083</td>
      <td>Poor</td>
      <td>31.666667</td>
      <td>High</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99998</th>
      <td>0x25fec</td>
      <td>37932</td>
      <td>July</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>251.67258219721603</td>
      <td>Low_spent_Large_value_payments</td>
      <td>319.164979</td>
      <td>Standard</td>
      <td>31.750000</td>
      <td>Low</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>0x25fed</td>
      <td>37932</td>
      <td>August</td>
      <td>Nicks</td>
      <td>25</td>
      <td>078-73-5990</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>167.1638651610451</td>
      <td>NaN</td>
      <td>393.673696</td>
      <td>Poor</td>
      <td>31.833333</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>100000 rows × 30 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0         3392
1         3392
2         3392
3         3392
4         3392
         ...  
99995    37932
99996    37932
99997    37932
99998    37932
99999    37932
Name: Customer_ID, Length: 100000, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> credit-score-classification/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert Social Security Numbers into float</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['SSN'] = df.SSN.apply(lambda x: x if x is np.NaN else int(str(x).replace('-', ''))).astype(float)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['SSN'] = df.SSN.apply(lambda x: x if x is np.NaN else int(str(x).replace('-', ''))).astype(float)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df['SSN'] = df.SSN.apply(lambda x: x if x is np.NaN else int(
    str(x).replace('-', ''))).astype(float)
</code></pre>
        <p><span onclick="$('#var_output_94e5c017').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_94e5c017" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0        821000265.0
1        821000265.0
2        821000265.0
3        821000265.0
4        821000265.0
            ...     
99995     78735990.0
99996     78735990.0
99997     78735990.0
99998     78735990.0
99999     78735990.0
Name: SSN, Length: 100000, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Customer_ID</th>
      <th>Month</th>
      <th>Name</th>
      <th>Age</th>
      <th>SSN</th>
      <th>Occupation</th>
      <th>...</th>
      <th>Amount_invested_monthly</th>
      <th>Payment_Behaviour</th>
      <th>Monthly_Balance</th>
      <th>Credit_Score</th>
      <th>Credit_Hist_yr</th>
      <th>Spent</th>
      <th>Payment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0x1602</td>
      <td>3392</td>
      <td>January</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821000265.0</td>
      <td>Scientist</td>
      <td>...</td>
      <td>80.41529543900253</td>
      <td>High_spent_Small_value_payments</td>
      <td>312.49408867943663</td>
      <td>Good</td>
      <td>22.083333</td>
      <td>High</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0x1603</td>
      <td>3392</td>
      <td>February</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821000265.0</td>
      <td>Scientist</td>
      <td>...</td>
      <td>118.28022162236736</td>
      <td>Low_spent_Large_value_payments</td>
      <td>284.62916249607184</td>
      <td>Good</td>
      <td>18.250000</td>
      <td>Low</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0x1604</td>
      <td>3392</td>
      <td>March</td>
      <td>Aaron Maashoh</td>
      <td>-500</td>
      <td>821000265.0</td>
      <td>Scientist</td>
      <td>...</td>
      <td>81.699521264648</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>331.2098628537912</td>
      <td>Good</td>
      <td>22.250000</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0x1605</td>
      <td>3392</td>
      <td>April</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821000265.0</td>
      <td>Scientist</td>
      <td>...</td>
      <td>199.4580743910713</td>
      <td>Low_spent_Small_value_payments</td>
      <td>223.45130972736786</td>
      <td>Good</td>
      <td>22.333333</td>
      <td>Low</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0x1606</td>
      <td>3392</td>
      <td>May</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821000265.0</td>
      <td>Scientist</td>
      <td>...</td>
      <td>41.420153086217326</td>
      <td>High_spent_Medium_value_payments</td>
      <td>341.48923103222177</td>
      <td>Good</td>
      <td>22.416667</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0x1607</td>
      <td>3392</td>
      <td>June</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821000265.0</td>
      <td>Scientist</td>
      <td>...</td>
      <td>62.430172331195294</td>
      <td>NaN</td>
      <td>340.4792117872438</td>
      <td>Good</td>
      <td>22.500000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0x1608</td>
      <td>3392</td>
      <td>July</td>
      <td>Aaron Maashoh</td>
      <td>23</td>
      <td>821000265.0</td>
      <td>Scientist</td>
      <td>...</td>
      <td>178.3440674122349</td>
      <td>Low_spent_Small_value_payments</td>
      <td>244.5653167062043</td>
      <td>Good</td>
      <td>22.583333</td>
      <td>Low</td>
      <td>Small</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99993</th>
      <td>0x25fe7</td>
      <td>37932</td>
      <td>February</td>
      <td>Nicks</td>
      <td>25</td>
      <td>78735990.0</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>180.7330951944497</td>
      <td>Low_spent_Medium_value_payments</td>
      <td>400.104466</td>
      <td>Standard</td>
      <td>31.333333</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99994</th>
      <td>0x25fe8</td>
      <td>37932</td>
      <td>March</td>
      <td>Nicks</td>
      <td>25</td>
      <td>78735990.0</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>140.58140274528395</td>
      <td>High_spent_Medium_value_payments</td>
      <td>410.256158</td>
      <td>Poor</td>
      <td>31.416667</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99995</th>
      <td>0x25fe9</td>
      <td>37932</td>
      <td>April</td>
      <td>Nicks</td>
      <td>25</td>
      <td>78735990.0</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>60.97133255718485</td>
      <td>High_spent_Large_value_payments</td>
      <td>479.866228</td>
      <td>Poor</td>
      <td>31.500000</td>
      <td>High</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99996</th>
      <td>0x25fea</td>
      <td>37932</td>
      <td>May</td>
      <td>Nicks</td>
      <td>25</td>
      <td>78735990.0</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>54.18595028760385</td>
      <td>High_spent_Medium_value_payments</td>
      <td>496.65161</td>
      <td>Poor</td>
      <td>31.583333</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <th>99997</th>
      <td>0x25feb</td>
      <td>37932</td>
      <td>June</td>
      <td>Nicks</td>
      <td>25</td>
      <td>78735990.0</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>24.02847744864441</td>
      <td>High_spent_Large_value_payments</td>
      <td>516.809083</td>
      <td>Poor</td>
      <td>31.666667</td>
      <td>High</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99998</th>
      <td>0x25fec</td>
      <td>37932</td>
      <td>July</td>
      <td>Nicks</td>
      <td>25</td>
      <td>78735990.0</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>251.67258219721603</td>
      <td>Low_spent_Large_value_payments</td>
      <td>319.164979</td>
      <td>Standard</td>
      <td>31.750000</td>
      <td>Low</td>
      <td>Large</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>0x25fed</td>
      <td>37932</td>
      <td>August</td>
      <td>Nicks</td>
      <td>25</td>
      <td>78735990.0</td>
      <td>Mechanic</td>
      <td>...</td>
      <td>167.1638651610451</td>
      <td>NaN</td>
      <td>393.673696</td>
      <td>Poor</td>
      <td>31.833333</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>100000 rows × 30 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0        821000265.0
1        821000265.0
2        821000265.0
3        821000265.0
4        821000265.0
            ...     
99995     78735990.0
99996     78735990.0
99997     78735990.0
99998     78735990.0
99999     78735990.0
Name: SSN, Length: 100000, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> credit-score-classification/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average monthly balance for each occupation with every payment category?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pd.pivot_table(df,values='Monthly_Balance',index=['Occupation'],columns=['Payment'],aggfunc=np.mean)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pd.pivot_table(df,values='Monthly_Balance',index=['Occupation'],columns=['Payment'],aggfunc=np.mean)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = pd.pivot_table(df, values='Monthly_Balance', index=[
    'Occupation'], columns=['Payment'], aggfunc=np.mean)
</code></pre>
        <p><span onclick="$('#var_output_7df50f4f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7df50f4f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Payment</th>
      <th>Large</th>
      <th>Medium</th>
      <th>Small</th>
    </tr>
    <tr>
      <th>Occupation</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accountant</th>
      <td>5.054358e+02</td>
      <td>4.292943e+02</td>
      <td>3.133373e+02</td>
    </tr>
    <tr>
      <th>Architect</th>
      <td>5.093903e+02</td>
      <td>4.385775e+02</td>
      <td>3.157913e+02</td>
    </tr>
    <tr>
      <th>Developer</th>
      <td>5.060844e+02</td>
      <td>-1.722653e+23</td>
      <td>3.155779e+02</td>
    </tr>
    <tr>
      <th>Doctor</th>
      <td>4.979596e+02</td>
      <td>-1.774938e+23</td>
      <td>-1.535391e+23</td>
    </tr>
    <tr>
      <th>Engineer</th>
      <td>-2.210433e+23</td>
      <td>4.296500e+02</td>
      <td>3.126870e+02</td>
    </tr>
    <tr>
      <th>Entrepreneur</th>
      <td>4.905842e+02</td>
      <td>4.232120e+02</td>
      <td>3.083081e+02</td>
    </tr>
    <tr>
      <th>Journalist</th>
      <td>-2.389486e+23</td>
      <td>4.225795e+02</td>
      <td>-1.467782e+23</td>
    </tr>
    <tr>
      <th>Lawyer</th>
      <td>5.103436e+02</td>
      <td>4.247946e+02</td>
      <td>-1.388889e+23</td>
    </tr>
    <tr>
      <th>Manager</th>
      <td>5.081227e+02</td>
      <td>4.346736e+02</td>
      <td>3.134689e+02</td>
    </tr>
    <tr>
      <th>Mechanic</th>
      <td>4.923165e+02</td>
      <td>4.292734e+02</td>
      <td>-1.467782e+23</td>
    </tr>
    <tr>
      <th>Media_Manager</th>
      <td>5.174371e+02</td>
      <td>4.265737e+02</td>
      <td>3.139619e+02</td>
    </tr>
    <tr>
      <th>Musician</th>
      <td>5.238696e+02</td>
      <td>4.231338e+02</td>
      <td>3.143197e+02</td>
    </tr>
    <tr>
      <th>Scientist</th>
      <td>5.058089e+02</td>
      <td>4.268840e+02</td>
      <td>3.138108e+02</td>
    </tr>
    <tr>
      <th>Teacher</th>
      <td>5.055487e+02</td>
      <td>4.303200e+02</td>
      <td>3.096823e+02</td>
    </tr>
    <tr>
      <th>Writer</th>
      <td>4.953018e+02</td>
      <td>4.212715e+02</td>
      <td>3.116133e+02</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Payment</th>
      <th>Large</th>
      <th>Medium</th>
      <th>Small</th>
    </tr>
    <tr>
      <th>Occupation</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accountant</th>
      <td>5.054358e+02</td>
      <td>4.292943e+02</td>
      <td>3.133373e+02</td>
    </tr>
    <tr>
      <th>Architect</th>
      <td>5.093903e+02</td>
      <td>4.385775e+02</td>
      <td>3.157913e+02</td>
    </tr>
    <tr>
      <th>Developer</th>
      <td>5.060844e+02</td>
      <td>-1.722653e+23</td>
      <td>3.155779e+02</td>
    </tr>
    <tr>
      <th>Doctor</th>
      <td>4.979596e+02</td>
      <td>-1.774938e+23</td>
      <td>-1.535391e+23</td>
    </tr>
    <tr>
      <th>Engineer</th>
      <td>-2.210433e+23</td>
      <td>4.296500e+02</td>
      <td>3.126870e+02</td>
    </tr>
    <tr>
      <th>Entrepreneur</th>
      <td>4.905842e+02</td>
      <td>4.232120e+02</td>
      <td>3.083081e+02</td>
    </tr>
    <tr>
      <th>Journalist</th>
      <td>-2.389486e+23</td>
      <td>4.225795e+02</td>
      <td>-1.467782e+23</td>
    </tr>
    <tr>
      <th>Lawyer</th>
      <td>5.103436e+02</td>
      <td>4.247946e+02</td>
      <td>-1.388889e+23</td>
    </tr>
    <tr>
      <th>Manager</th>
      <td>5.081227e+02</td>
      <td>4.346736e+02</td>
      <td>3.134689e+02</td>
    </tr>
    <tr>
      <th>Mechanic</th>
      <td>4.923165e+02</td>
      <td>4.292734e+02</td>
      <td>-1.467782e+23</td>
    </tr>
    <tr>
      <th>Media_Manager</th>
      <td>5.174371e+02</td>
      <td>4.265737e+02</td>
      <td>3.139619e+02</td>
    </tr>
    <tr>
      <th>Musician</th>
      <td>5.238696e+02</td>
      <td>4.231338e+02</td>
      <td>3.143197e+02</td>
    </tr>
    <tr>
      <th>Scientist</th>
      <td>5.058089e+02</td>
      <td>4.268840e+02</td>
      <td>3.138108e+02</td>
    </tr>
    <tr>
      <th>Teacher</th>
      <td>5.055487e+02</td>
      <td>4.303200e+02</td>
      <td>3.096823e+02</td>
    </tr>
    <tr>
      <th>Writer</th>
      <td>4.953018e+02</td>
      <td>4.212715e+02</td>
      <td>3.116133e+02</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> credit-score-classification/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 5 occupations that have the highest annual income? Show the occupations and their mean annual income</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.duplicated('Customer_ID')==False].groupby('Occupation').mean()['Annual_Income'].sort_values(ascending=False).head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.duplicated('Customer_ID')==False].groupby('Occupation').mean()['Annual_Income'].sort_values(ascending=False).head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.duplicated('Customer_ID') == False].groupby('Occupation'
    ).mean()['Annual_Income'].sort_values(ascending=False).head(5)
</code></pre>
        <p><span onclick="$('#var_output_b70dc650').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b70dc650" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Occupation
Manager          261858.303062
Media_Manager    255074.680216
Entrepreneur     251400.654191
Engineer         234621.163914
Teacher          219628.628361
Name: Annual_Income, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Occupation
Manager          261858.303062
Media_Manager    255074.680216
Entrepreneur     251400.654191
Engineer         234621.163914
Teacher          219628.628361
Name: Annual_Income, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> credit-score-classification/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of amounts invested by each customer from their annual incomes? Show the customer IDs and their percentage</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(df.groupby('Customer_ID').sum()['Amount_invested_monthly'] /df.groupby('Customer_ID').sum()['Annual_Income']) *100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(df.groupby('Customer_ID').sum()['Amount_invested_monthly'] /df.groupby('Customer_ID').sum()['Annual_Income']) *100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('Customer_ID').sum()['Amount_invested_monthly'
    ] / df.groupby('Customer_ID').sum()['Annual_Income'] * 100
</code></pre>
        <p><span onclick="$('#var_output_19acaa40').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_19acaa40" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Customer_ID
1006     0.394279
1007     6.165860
1008     0.435914
1009     0.268952
1011     0.221973
           ...   
50984    0.564484
50990    0.290948
50992    0.440116
50996    0.257815
50999    0.336091
Length: 12500, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Customer_ID
1006     0.394279
1007     6.165860
1008     0.435914
1009     0.268952
1011     0.221973
           ...   
50984    0.564484
50990    0.290948
50992    0.440116
50996    0.257815
50999    0.336091
Length: 12500, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> data-science-job-salaries/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of people who work full time in companies located in the US? (rounded to 2 decimal places)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>employment_type_no=df[df['company_location']=='US'].groupby('employment_type').count().iloc[:,0]
(employment_type_no['FT']/employment_type_no.sum()*100).round(2)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>employment_type_no=df[df['company_location']=='US'].groupby('employment_type').count().iloc[:,0]
(employment_type_no['FT']/employment_type_no.sum()*100).round(2)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>employment_type_no = df[df['company_location'] == 'US'].groupby(
    'employment_type').count().iloc[:, 0]
__output__ = (employment_type_no['FT'] / employment_type_no.sum() * 100).round(
    2)
</code></pre>
        <p><span onclick="$('#var_output_7bfc6af1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7bfc6af1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>97.46</code></pre>
      
        <p><strong>Hyp output variables:</strong> employment_type_no, __output__ </p>
    
          <p>employment_type_no (Series):</p>
          <pre><code>employment_type
CT      4
FL      3
FT    346
PT      2
Name: work_year, dtype: int64</code></pre>
      
          <p>__output__ (float64):</p>
          <pre><code>97.46</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> data-science-job-salaries/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 10 salaries for Senior Data Scientists?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['job_title']=='Data Scientist') & (df['experience_level']=='SE')].sort_values('salary_in_usd',ascending=False)['salary_in_usd'].head(10).values</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['job_title']=='Data Scientist') & (df['experience_level']=='SE')].sort_values('salary_in_usd',ascending=False)['salary_in_usd'].head(10).values</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['job_title'] == 'Data Scientist') & (df[
    'experience_level'] == 'SE')].sort_values('salary_in_usd', ascending=False
    )['salary_in_usd'].head(10).values
</code></pre>
        <p><span onclick="$('#var_output_45250e13').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_45250e13" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>[412000 260000 230000 230000 220000 215300 215300 211500 210000 210000]</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>[412000 260000 230000 230000 220000 215300 215300 211500 210000 210000]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> data-science-job-salaries/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average salary for each position in every company size?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pd.pivot_table(df, values='salary_in_usd', index=['company_size'],
                columns=['job_title'], aggfunc=np.mean).fillna(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pd.pivot_table(df, values='salary_in_usd', index=['company_size'],
                columns=['job_title'], aggfunc=np.mean).fillna(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = pd.pivot_table(df, values='salary_in_usd', index=[
    'company_size'], columns=['job_title'], aggfunc=np.mean).fillna(0)
</code></pre>
        <p><span onclick="$('#var_output_1e2c27e6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1e2c27e6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>job_title</th>
      <th>3D Computer Vision Researcher</th>
      <th>AI Scientist</th>
      <th>Analytics Engineer</th>
      <th>Applied Data Scientist</th>
      <th>Applied Machine Learning Scientist</th>
      <th>BI Data Analyst</th>
      <th>Big Data Architect</th>
      <th>...</th>
      <th>NLP Engineer</th>
      <th>Principal Data Analyst</th>
      <th>Principal Data Engineer</th>
      <th>Principal Data Scientist</th>
      <th>Product Data Analyst</th>
      <th>Research Scientist</th>
      <th>Staff Data Scientist</th>
    </tr>
    <tr>
      <th>company_size</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>L</th>
      <td>0.0</td>
      <td>127500.000000</td>
      <td>0.0</td>
      <td>175655.0</td>
      <td>249000.0</td>
      <td>93129.5</td>
      <td>0.0</td>
      <td>...</td>
      <td>37236.0</td>
      <td>0.0</td>
      <td>392500.0</td>
      <td>202000.000000</td>
      <td>6072.0</td>
      <td>96465.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>M</th>
      <td>5409.0</td>
      <td>66000.000000</td>
      <td>175000.0</td>
      <td>0.0</td>
      <td>35137.5</td>
      <td>99000.0</td>
      <td>99703.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>170000.0</td>
      <td>200000.0</td>
      <td>161565.666667</td>
      <td>0.0</td>
      <td>192153.0</td>
      <td>105000.0</td>
    </tr>
    <tr>
      <th>S</th>
      <td>0.0</td>
      <td>25316.333333</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>32136.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>75000.0</td>
      <td>0.0</td>
      <td>416000.000000</td>
      <td>20000.0</td>
      <td>53369.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 50 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>job_title</th>
      <th>3D Computer Vision Researcher</th>
      <th>AI Scientist</th>
      <th>Analytics Engineer</th>
      <th>Applied Data Scientist</th>
      <th>Applied Machine Learning Scientist</th>
      <th>BI Data Analyst</th>
      <th>Big Data Architect</th>
      <th>...</th>
      <th>NLP Engineer</th>
      <th>Principal Data Analyst</th>
      <th>Principal Data Engineer</th>
      <th>Principal Data Scientist</th>
      <th>Product Data Analyst</th>
      <th>Research Scientist</th>
      <th>Staff Data Scientist</th>
    </tr>
    <tr>
      <th>company_size</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>L</th>
      <td>0.0</td>
      <td>127500.000000</td>
      <td>0.0</td>
      <td>175655.0</td>
      <td>249000.0</td>
      <td>93129.5</td>
      <td>0.0</td>
      <td>...</td>
      <td>37236.0</td>
      <td>0.0</td>
      <td>392500.0</td>
      <td>202000.000000</td>
      <td>6072.0</td>
      <td>96465.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>M</th>
      <td>5409.0</td>
      <td>66000.000000</td>
      <td>175000.0</td>
      <td>0.0</td>
      <td>35137.5</td>
      <td>99000.0</td>
      <td>99703.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>170000.0</td>
      <td>200000.0</td>
      <td>161565.666667</td>
      <td>0.0</td>
      <td>192153.0</td>
      <td>105000.0</td>
    </tr>
    <tr>
      <th>S</th>
      <td>0.0</td>
      <td>25316.333333</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>32136.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>75000.0</td>
      <td>0.0</td>
      <td>416000.000000</td>
      <td>20000.0</td>
      <td>53369.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 50 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> data-science-job-salaries/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many research scientists are paid above 80% percentile?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_data=df[df['job_title']=='Research Scientist']
max_value=df_data.salary_in_usd.quantile(0.8)
len(df_data[df_data.salary_in_usd>max_value])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_data=df[df['job_title']=='Research Scientist']
max_value=df_data.salary_in_usd.quantile(0.8)
len(df_data[df_data.salary_in_usd>max_value])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_data = df[df['job_title'] == 'Research Scientist']
max_value = df_data.salary_in_usd.quantile(0.8)
__output__ = len(df_data[df_data.salary_in_usd > max_value])
</code></pre>
        <p><span onclick="$('#var_output_e63087d8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e63087d8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>3</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_data, max_value, __output__ </p>
    
          <p>df_data (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>work_year</th>
      <th>experience_level</th>
      <th>employment_type</th>
      <th>job_title</th>
      <th>salary</th>
      <th>salary_currency</th>
      <th>salary_in_usd</th>
      <th>employee_residence</th>
      <th>remote_ratio</th>
      <th>company_location</th>
      <th>company_size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26</th>
      <td>2020</td>
      <td>EN</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>42000</td>
      <td>USD</td>
      <td>42000</td>
      <td>NL</td>
      <td>50</td>
      <td>NL</td>
      <td>L</td>
    </tr>
    <tr>
      <th>33</th>
      <td>2020</td>
      <td>MI</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>450000</td>
      <td>USD</td>
      <td>450000</td>
      <td>US</td>
      <td>0</td>
      <td>US</td>
      <td>M</td>
    </tr>
    <tr>
      <th>72</th>
      <td>2021</td>
      <td>EN</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>60000</td>
      <td>GBP</td>
      <td>82528</td>
      <td>GB</td>
      <td>50</td>
      <td>GB</td>
      <td>L</td>
    </tr>
    <tr>
      <th>106</th>
      <td>2021</td>
      <td>MI</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>235000</td>
      <td>CAD</td>
      <td>187442</td>
      <td>CA</td>
      <td>100</td>
      <td>CA</td>
      <td>L</td>
    </tr>
    <tr>
      <th>146</th>
      <td>2021</td>
      <td>MI</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>53000</td>
      <td>EUR</td>
      <td>62649</td>
      <td>FR</td>
      <td>50</td>
      <td>FR</td>
      <td>M</td>
    </tr>
    <tr>
      <th>174</th>
      <td>2021</td>
      <td>SE</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>51400</td>
      <td>EUR</td>
      <td>60757</td>
      <td>PT</td>
      <td>50</td>
      <td>PT</td>
      <td>L</td>
    </tr>
    <tr>
      <th>194</th>
      <td>2021</td>
      <td>SE</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>120500</td>
      <td>CAD</td>
      <td>96113</td>
      <td>CA</td>
      <td>50</td>
      <td>CA</td>
      <td>L</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>236</th>
      <td>2021</td>
      <td>MI</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>80000</td>
      <td>CAD</td>
      <td>63810</td>
      <td>CA</td>
      <td>100</td>
      <td>CA</td>
      <td>M</td>
    </tr>
    <tr>
      <th>281</th>
      <td>2021</td>
      <td>EN</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>100000</td>
      <td>USD</td>
      <td>100000</td>
      <td>JE</td>
      <td>0</td>
      <td>CN</td>
      <td>L</td>
    </tr>
    <tr>
      <th>284</th>
      <td>2021</td>
      <td>MI</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>69999</td>
      <td>USD</td>
      <td>69999</td>
      <td>CZ</td>
      <td>50</td>
      <td>CZ</td>
      <td>L</td>
    </tr>
    <tr>
      <th>466</th>
      <td>2022</td>
      <td>SE</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>144000</td>
      <td>USD</td>
      <td>144000</td>
      <td>US</td>
      <td>50</td>
      <td>US</td>
      <td>L</td>
    </tr>
    <tr>
      <th>498</th>
      <td>2022</td>
      <td>SE</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>85000</td>
      <td>EUR</td>
      <td>93427</td>
      <td>FR</td>
      <td>50</td>
      <td>FR</td>
      <td>L</td>
    </tr>
    <tr>
      <th>507</th>
      <td>2022</td>
      <td>MI</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>59000</td>
      <td>EUR</td>
      <td>64849</td>
      <td>AT</td>
      <td>0</td>
      <td>AT</td>
      <td>L</td>
    </tr>
    <tr>
      <th>508</th>
      <td>2022</td>
      <td>EN</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>120000</td>
      <td>USD</td>
      <td>120000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>L</td>
    </tr>
  </tbody>
</table>
<p>16 rows × 11 columns</p>
      
          <p>max_value (float64):</p>
          <pre><code>120000.0</code></pre>
      
          <p>__output__ (int):</p>
          <pre><code>3</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> data-science-job-salaries/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the percetages of each remote ratio for every year? (rounded to 2 decimal places)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_combined=pd.pivot_table(df, values='salary_in_usd', index=['remote_ratio'],
                columns=['work_year'], aggfunc=np.count_nonzero).fillna(0).sort_index()
sumation=df.work_year.value_counts().sort_index()
(df_combined/sumation*100).round(2)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_combined=pd.pivot_table(df, values='salary_in_usd', index=['remote_ratio'],
                columns=['work_year'], aggfunc=np.count_nonzero).fillna(0).sort_index()
sumation=df.work_year.value_counts().sort_index()
(df_combined/sumation*100).round(2)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_combined = pd.pivot_table(df, values='salary_in_usd', index=[
    'remote_ratio'], columns=['work_year'], aggfunc=np.count_nonzero).fillna(0
    ).sort_index()
sumation = df.work_year.value_counts().sort_index()
__output__ = (df_combined / sumation * 100).round(2)
</code></pre>
        <p><span onclick="$('#var_output_43464951').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_43464951" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>work_year</th>
      <th>2020</th>
      <th>2021</th>
      <th>2022</th>
    </tr>
    <tr>
      <th>remote_ratio</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>20.83</td>
      <td>15.67</td>
      <td>24.53</td>
    </tr>
    <tr>
      <th>50</th>
      <td>29.17</td>
      <td>30.41</td>
      <td>3.77</td>
    </tr>
    <tr>
      <th>100</th>
      <td>50.00</td>
      <td>53.92</td>
      <td>71.70</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_combined, sumation, __output__ </p>
    
          <p>df_combined (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>work_year</th>
      <th>2020</th>
      <th>2021</th>
      <th>2022</th>
    </tr>
    <tr>
      <th>remote_ratio</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>15</td>
      <td>34</td>
      <td>78</td>
    </tr>
    <tr>
      <th>50</th>
      <td>21</td>
      <td>66</td>
      <td>12</td>
    </tr>
    <tr>
      <th>100</th>
      <td>36</td>
      <td>117</td>
      <td>228</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
          <p>sumation (Series):</p>
          <pre><code>2020     72
2021    217
2022    318
Name: work_year, dtype: int64</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>work_year</th>
      <th>2020</th>
      <th>2021</th>
      <th>2022</th>
    </tr>
    <tr>
      <th>remote_ratio</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>20.83</td>
      <td>15.67</td>
      <td>24.53</td>
    </tr>
    <tr>
      <th>50</th>
      <td>29.17</td>
      <td>30.41</td>
      <td>3.77</td>
    </tr>
    <tr>
      <th>100</th>
      <td>50.00</td>
      <td>53.92</td>
      <td>71.70</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> data-science-job-salaries/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many job titles has Scientist in it?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>len(df['job_title'].value_counts().index.str.contains('Scientist', regex=False)==True)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>len(df['job_title'].value_counts().index.str.contains('Scientist', regex=False)==True)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = len(df['job_title'].value_counts().index.str.contains(
    'Scientist', regex=False) == True)
</code></pre>
        <p><span onclick="$('#var_output_e0877fa7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e0877fa7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>50</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>50</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> data-science-job-salaries/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new column 'Salary_Cat' contains the salaries in catagories ( Low: <=65000, Average: 65000-150000, high: >=150000)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def salary_cat(salary):
  if salary <= 65000:
    return 'Low'
  elif salary < 150000:
    return 'Average'
  else:
    return 'High'

df['Salary_Cat']=df.salary_in_usd.apply(salary_cat)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def salary_cat(salary):
  if salary <= 65000:
    return 'Low'
  elif salary < 150000:
    return 'Average'
  else:
    return 'High'

df['Salary_Cat']=df.salary_in_usd.apply(salary_cat)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def salary_cat(salary):
    if salary <= 65000:
        return 'Low'
    elif salary < 150000:
        return 'Average'
    else:
        return 'High'


__output__ = df['Salary_Cat'] = df.salary_in_usd.apply(salary_cat)
</code></pre>
        <p><span onclick="$('#var_output_2298448b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2298448b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      Average
1         High
2      Average
3          Low
4         High
        ...   
602       High
603    Average
604    Average
605       High
606       High
Name: salary_in_usd, Length: 607, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>work_year</th>
      <th>experience_level</th>
      <th>employment_type</th>
      <th>job_title</th>
      <th>salary</th>
      <th>salary_currency</th>
      <th>salary_in_usd</th>
      <th>employee_residence</th>
      <th>remote_ratio</th>
      <th>company_location</th>
      <th>company_size</th>
      <th>Salary_Cat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2020</td>
      <td>MI</td>
      <td>FT</td>
      <td>Data Scientist</td>
      <td>70000</td>
      <td>EUR</td>
      <td>79833</td>
      <td>DE</td>
      <td>0</td>
      <td>DE</td>
      <td>L</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2020</td>
      <td>SE</td>
      <td>FT</td>
      <td>Machine Learning Scientist</td>
      <td>260000</td>
      <td>USD</td>
      <td>260000</td>
      <td>JP</td>
      <td>0</td>
      <td>JP</td>
      <td>S</td>
      <td>High</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2020</td>
      <td>SE</td>
      <td>FT</td>
      <td>Big Data Engineer</td>
      <td>85000</td>
      <td>GBP</td>
      <td>109024</td>
      <td>GB</td>
      <td>50</td>
      <td>GB</td>
      <td>M</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2020</td>
      <td>MI</td>
      <td>FT</td>
      <td>Product Data Analyst</td>
      <td>20000</td>
      <td>USD</td>
      <td>20000</td>
      <td>HN</td>
      <td>0</td>
      <td>HN</td>
      <td>S</td>
      <td>Low</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2020</td>
      <td>SE</td>
      <td>FT</td>
      <td>Machine Learning Engineer</td>
      <td>150000</td>
      <td>USD</td>
      <td>150000</td>
      <td>US</td>
      <td>50</td>
      <td>US</td>
      <td>L</td>
      <td>High</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2020</td>
      <td>EN</td>
      <td>FT</td>
      <td>Data Analyst</td>
      <td>72000</td>
      <td>USD</td>
      <td>72000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>L</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2020</td>
      <td>SE</td>
      <td>FT</td>
      <td>Lead Data Scientist</td>
      <td>190000</td>
      <td>USD</td>
      <td>190000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>S</td>
      <td>High</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>600</th>
      <td>2022</td>
      <td>EN</td>
      <td>FT</td>
      <td>Data Analyst</td>
      <td>67000</td>
      <td>USD</td>
      <td>67000</td>
      <td>CA</td>
      <td>0</td>
      <td>CA</td>
      <td>M</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>601</th>
      <td>2022</td>
      <td>EN</td>
      <td>FT</td>
      <td>Data Analyst</td>
      <td>52000</td>
      <td>USD</td>
      <td>52000</td>
      <td>CA</td>
      <td>0</td>
      <td>CA</td>
      <td>M</td>
      <td>Low</td>
    </tr>
    <tr>
      <th>602</th>
      <td>2022</td>
      <td>SE</td>
      <td>FT</td>
      <td>Data Engineer</td>
      <td>154000</td>
      <td>USD</td>
      <td>154000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>M</td>
      <td>High</td>
    </tr>
    <tr>
      <th>603</th>
      <td>2022</td>
      <td>SE</td>
      <td>FT</td>
      <td>Data Engineer</td>
      <td>126000</td>
      <td>USD</td>
      <td>126000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>M</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>604</th>
      <td>2022</td>
      <td>SE</td>
      <td>FT</td>
      <td>Data Analyst</td>
      <td>129000</td>
      <td>USD</td>
      <td>129000</td>
      <td>US</td>
      <td>0</td>
      <td>US</td>
      <td>M</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>605</th>
      <td>2022</td>
      <td>SE</td>
      <td>FT</td>
      <td>Data Analyst</td>
      <td>150000</td>
      <td>USD</td>
      <td>150000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>M</td>
      <td>High</td>
    </tr>
    <tr>
      <th>606</th>
      <td>2022</td>
      <td>MI</td>
      <td>FT</td>
      <td>AI Scientist</td>
      <td>200000</td>
      <td>USD</td>
      <td>200000</td>
      <td>IN</td>
      <td>100</td>
      <td>US</td>
      <td>L</td>
      <td>High</td>
    </tr>
  </tbody>
</table>
<p>607 rows × 12 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      Average
1         High
2      Average
3          Low
4         High
        ...   
602       High
603    Average
604    Average
605       High
606       High
Name: salary_in_usd, Length: 607, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> data-science-job-salaries/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Calculate the number of unique values in each column, show the column names and unique counts</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>dict = {}
for col in df.columns:
    dict[col] = df[col].value_counts().shape[0]

pd.DataFrame(dict, index=['unique counts']).transpose()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>dict = {}
for col in df.columns:
    dict[col] = df[col].value_counts().shape[0]

pd.DataFrame(dict, index=['unique counts']).transpose()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>dict = {}
for col in df.columns:
    dict[col] = df[col].value_counts().shape[0]
__output__ = pd.DataFrame(dict, index=['unique counts']).transpose()
</code></pre>
        <p><span onclick="$('#var_output_8f9a97a5').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8f9a97a5" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>unique counts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>work_year</th>
      <td>3</td>
    </tr>
    <tr>
      <th>experience_level</th>
      <td>4</td>
    </tr>
    <tr>
      <th>employment_type</th>
      <td>4</td>
    </tr>
    <tr>
      <th>job_title</th>
      <td>50</td>
    </tr>
    <tr>
      <th>salary</th>
      <td>272</td>
    </tr>
    <tr>
      <th>salary_currency</th>
      <td>17</td>
    </tr>
    <tr>
      <th>salary_in_usd</th>
      <td>369</td>
    </tr>
    <tr>
      <th>employee_residence</th>
      <td>57</td>
    </tr>
    <tr>
      <th>remote_ratio</th>
      <td>3</td>
    </tr>
    <tr>
      <th>company_location</th>
      <td>50</td>
    </tr>
    <tr>
      <th>company_size</th>
      <td>3</td>
    </tr>
    <tr>
      <th>Salary_Cat</th>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> col, __output__ </p>
    
          <p>col (str):</p>
          <pre><code>Salary_Cat</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>unique counts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>work_year</th>
      <td>3</td>
    </tr>
    <tr>
      <th>experience_level</th>
      <td>4</td>
    </tr>
    <tr>
      <th>employment_type</th>
      <td>4</td>
    </tr>
    <tr>
      <th>job_title</th>
      <td>50</td>
    </tr>
    <tr>
      <th>salary</th>
      <td>272</td>
    </tr>
    <tr>
      <th>salary_currency</th>
      <td>17</td>
    </tr>
    <tr>
      <th>salary_in_usd</th>
      <td>369</td>
    </tr>
    <tr>
      <th>employee_residence</th>
      <td>57</td>
    </tr>
    <tr>
      <th>remote_ratio</th>
      <td>3</td>
    </tr>
    <tr>
      <th>company_location</th>
      <td>50</td>
    </tr>
    <tr>
      <th>company_size</th>
      <td>3</td>
    </tr>
    <tr>
      <th>Salary_Cat</th>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> data-science-job-salaries/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 5 positions for working remotely with entry level experience? Show the job title with the mean salary</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>remotely_filtered = df[(df['remote_ratio'] == 100) & (df['experience_level'] == 'EN')]
remotely_filtered.groupby('job_title')['salary_in_usd'].mean().sort_values(ascending = False)[:5]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>remotely_filtered = df[(df['remote_ratio'] == 100) & (df['experience_level'] == 'EN')]
remotely_filtered.groupby('job_title')['salary_in_usd'].mean().sort_values(ascending = False)[:5]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>remotely_filtered = df[(df['remote_ratio'] == 100) & (df['experience_level'
    ] == 'EN')]
__output__ = remotely_filtered.groupby('job_title')['salary_in_usd'].mean(
    ).sort_values(ascending=False)[:5]
</code></pre>
        <p><span onclick="$('#var_output_4ef13f14').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4ef13f14" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>job_title
Machine Learning Scientist           225000.0
Research Scientist                   120000.0
Computer Vision Software Engineer    110000.0
Data Science Consultant               83416.5
Machine Learning Engineer             81060.0
Name: salary_in_usd, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> remotely_filtered, __output__ </p>
    
          <p>remotely_filtered (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>work_year</th>
      <th>experience_level</th>
      <th>employment_type</th>
      <th>job_title</th>
      <th>salary</th>
      <th>salary_currency</th>
      <th>salary_in_usd</th>
      <th>employee_residence</th>
      <th>remote_ratio</th>
      <th>company_location</th>
      <th>company_size</th>
      <th>Salary_Cat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>2020</td>
      <td>EN</td>
      <td>FT</td>
      <td>Data Analyst</td>
      <td>72000</td>
      <td>USD</td>
      <td>72000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>L</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>16</th>
      <td>2020</td>
      <td>EN</td>
      <td>FT</td>
      <td>Data Engineer</td>
      <td>4450000</td>
      <td>JPY</td>
      <td>41689</td>
      <td>JP</td>
      <td>100</td>
      <td>JP</td>
      <td>S</td>
      <td>Low</td>
    </tr>
    <tr>
      <th>28</th>
      <td>2020</td>
      <td>EN</td>
      <td>CT</td>
      <td>Business Data Analyst</td>
      <td>100000</td>
      <td>USD</td>
      <td>100000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>L</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>31</th>
      <td>2020</td>
      <td>EN</td>
      <td>FT</td>
      <td>Big Data Engineer</td>
      <td>70000</td>
      <td>USD</td>
      <td>70000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>L</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>38</th>
      <td>2020</td>
      <td>EN</td>
      <td>FT</td>
      <td>Data Analyst</td>
      <td>10000</td>
      <td>USD</td>
      <td>10000</td>
      <td>NG</td>
      <td>100</td>
      <td>NG</td>
      <td>S</td>
      <td>Low</td>
    </tr>
    <tr>
      <th>39</th>
      <td>2020</td>
      <td>EN</td>
      <td>FT</td>
      <td>Machine Learning Engineer</td>
      <td>138000</td>
      <td>USD</td>
      <td>138000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>S</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>45</th>
      <td>2020</td>
      <td>EN</td>
      <td>PT</td>
      <td>ML Engineer</td>
      <td>14000</td>
      <td>EUR</td>
      <td>15966</td>
      <td>DE</td>
      <td>100</td>
      <td>DE</td>
      <td>S</td>
      <td>Low</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>496</th>
      <td>2022</td>
      <td>EN</td>
      <td>FT</td>
      <td>Data Engineer</td>
      <td>52800</td>
      <td>EUR</td>
      <td>58035</td>
      <td>PK</td>
      <td>100</td>
      <td>DE</td>
      <td>M</td>
      <td>Low</td>
    </tr>
    <tr>
      <th>499</th>
      <td>2022</td>
      <td>EN</td>
      <td>FT</td>
      <td>Data Scientist</td>
      <td>66500</td>
      <td>CAD</td>
      <td>52396</td>
      <td>CA</td>
      <td>100</td>
      <td>CA</td>
      <td>L</td>
      <td>Low</td>
    </tr>
    <tr>
      <th>502</th>
      <td>2022</td>
      <td>EN</td>
      <td>FT</td>
      <td>Data Scientist</td>
      <td>40000</td>
      <td>USD</td>
      <td>40000</td>
      <td>JP</td>
      <td>100</td>
      <td>MY</td>
      <td>L</td>
      <td>Low</td>
    </tr>
    <tr>
      <th>508</th>
      <td>2022</td>
      <td>EN</td>
      <td>FT</td>
      <td>Research Scientist</td>
      <td>120000</td>
      <td>USD</td>
      <td>120000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>L</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>510</th>
      <td>2022</td>
      <td>EN</td>
      <td>FT</td>
      <td>Computer Vision Software Engineer</td>
      <td>150000</td>
      <td>USD</td>
      <td>150000</td>
      <td>AU</td>
      <td>100</td>
      <td>AU</td>
      <td>S</td>
      <td>High</td>
    </tr>
    <tr>
      <th>512</th>
      <td>2022</td>
      <td>EN</td>
      <td>FT</td>
      <td>Data Engineer</td>
      <td>65000</td>
      <td>USD</td>
      <td>65000</td>
      <td>US</td>
      <td>100</td>
      <td>US</td>
      <td>S</td>
      <td>Low</td>
    </tr>
    <tr>
      <th>521</th>
      <td>2022</td>
      <td>EN</td>
      <td>FT</td>
      <td>Computer Vision Engineer</td>
      <td>10000</td>
      <td>USD</td>
      <td>10000</td>
      <td>PT</td>
      <td>100</td>
      <td>LU</td>
      <td>M</td>
      <td>Low</td>
    </tr>
  </tbody>
</table>
<p>49 rows × 12 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>job_title
Machine Learning Scientist           225000.0
Research Scientist                   120000.0
Computer Vision Software Engineer    110000.0
Data Science Consultant               83416.5
Machine Learning Engineer             81060.0
Name: salary_in_usd, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> data-science-job-salaries/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which are the top 10 highest paying countries? Show the comapny location, mean salary and count of jobs</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby("company_location").agg(mean_salary=('salary_in_usd', 'mean'), count_jobs=('company_location', 'count')).sort_values('mean_salary',ascending = False)[:10]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby("company_location").agg(mean_salary=('salary_in_usd', 'mean'), count_jobs=('company_location', 'count')).sort_values('mean_salary',ascending = False)[:10]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('company_location').agg(mean_salary=(
    'salary_in_usd', 'mean'), count_jobs=('company_location', 'count')
    ).sort_values('mean_salary', ascending=False)[:10]
</code></pre>
        <p><span onclick="$('#var_output_f5f8ad2f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f5f8ad2f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean_salary</th>
      <th>count_jobs</th>
    </tr>
    <tr>
      <th>company_location</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>RU</th>
      <td>157500.000000</td>
      <td>2</td>
    </tr>
    <tr>
      <th>US</th>
      <td>144055.261972</td>
      <td>355</td>
    </tr>
    <tr>
      <th>NZ</th>
      <td>125000.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>IL</th>
      <td>119059.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>JP</th>
      <td>114127.333333</td>
      <td>6</td>
    </tr>
    <tr>
      <th>AU</th>
      <td>108042.666667</td>
      <td>3</td>
    </tr>
    <tr>
      <th>DZ</th>
      <td>100000.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>AE</th>
      <td>100000.000000</td>
      <td>3</td>
    </tr>
    <tr>
      <th>IQ</th>
      <td>100000.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>CA</th>
      <td>99823.733333</td>
      <td>30</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean_salary</th>
      <th>count_jobs</th>
    </tr>
    <tr>
      <th>company_location</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>RU</th>
      <td>157500.000000</td>
      <td>2</td>
    </tr>
    <tr>
      <th>US</th>
      <td>144055.261972</td>
      <td>355</td>
    </tr>
    <tr>
      <th>NZ</th>
      <td>125000.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>IL</th>
      <td>119059.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>JP</th>
      <td>114127.333333</td>
      <td>6</td>
    </tr>
    <tr>
      <th>AU</th>
      <td>108042.666667</td>
      <td>3</td>
    </tr>
    <tr>
      <th>DZ</th>
      <td>100000.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>AE</th>
      <td>100000.000000</td>
      <td>3</td>
    </tr>
    <tr>
      <th>IQ</th>
      <td>100000.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>CA</th>
      <td>99823.733333</td>
      <td>30</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> television-dataset-2022/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Reassign values contains 'Hz' in the picture quality and speaker columns to frequency also replace the incorrect values in these columns with nulls</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def clean(col_1,col_2, key): 
    t = df[[col_1,col_2]]
    t = t[t[col_1].str.contains(pat=key)]
    df.loc[t.index, [col_2]] = t[col_1]
    df.loc[t.index, [col_1]] = np.NaN

clean('Picture_qualtiy', 'Frequency', 'Hz')
clean('Speaker', 'Frequency', 'Hz')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def clean(col_1,col_2, key): 
    t = df[[col_1,col_2]]
    t = t[t[col_1].str.contains(pat=key)]
    df.loc[t.index, [col_2]] = t[col_1]
    df.loc[t.index, [col_1]] = np.NaN

clean('Picture_qualtiy', 'Frequency', 'Hz')
clean('Speaker', 'Frequency', 'Hz')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def clean(col_1, col_2, key):
    t = df[[col_1, col_2]]
    t = t[t[col_1].str.contains(pat=key)]
    df.loc[t.index, [col_2]] = t[col_1]
    df.loc[t.index, [col_1]] = np.NaN


__tmp_1 = clean('Picture_qualtiy', 'Frequency', 'Hz')
__output__ = clean('Speaker', 'Frequency', 'Hz')
</code></pre>
        <p><span onclick="$('#var_output_895f5199').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_895f5199" style="display: none;">
          
        <p><strong>Ref output variables:</strong> df </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Product_Name</th>
      <th>Stars</th>
      <th>Ratings</th>
      <th>Reviews</th>
      <th>current_price</th>
      <th>MRP</th>
      <th>channel</th>
      <th>Operating_system</th>
      <th>Picture_qualtiy</th>
      <th>Speaker</th>
      <th>Frequency</th>
      <th>Image_url</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Croma</td>
      <td>4.2</td>
      <td>1773</td>
      <td>217</td>
      <td>₹7990</td>
      <td>₹20000</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/ku1k4280/television/p/f/6/crel7369-croma-original-imag7969pxhrwp2k.jpeg?q=70</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Adsun</td>
      <td>3.8</td>
      <td>6742</td>
      <td>930</td>
      <td>₹8699</td>
      <td>₹21999</td>
      <td>Netflix|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android Based</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/krntoy80/television/u/d/y/a-3200s-adsun-original-imag5edguuyn54fh.jpeg?q=70</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LG</td>
      <td>4.4</td>
      <td>38870</td>
      <td>3443</td>
      <td>₹16499</td>
      <td>₹21990</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: WebOS</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>10 W Speaker Output</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0fm07k0/television/7/x/9/-original-imagc8fnpx39evgc.jpeg?q=70</td>
    </tr>
    <tr>
      <th>3</th>
      <td>OnePlus</td>
      <td>4.3</td>
      <td>101256</td>
      <td>9189</td>
      <td>₹16499</td>
      <td>₹21999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzfvzww0/television/e/b/b/32hd2a00-32-y1s-oneplus-original-imagbgcewfqywgk7.jpeg?q=70</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Xiaomi</td>
      <td>4.3</td>
      <td>3120</td>
      <td>305</td>
      <td>₹15499</td>
      <td>₹24999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l2ghgnk0/television/u/a/c/l32m7-5ain-mi-original-imagdsdwqf6bkmkz.jpeg?q=70</td>
    </tr>
    <tr>
      <th>5</th>
      <td>SAMSUNG</td>
      <td>4.4</td>
      <td>53639</td>
      <td>4811</td>
      <td>₹15999</td>
      <td>₹22900</td>
      <td>Netflix|Disney+Hotstar|Youtube</td>
      <td>Operating System: Tizen</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kbs9k7k0/television/c/j/3/samsung-ua32t4340akxxl-original-imaft25qdysfsq7k.jpeg?q=70</td>
    </tr>
    <tr>
      <th>6</th>
      <td>OnePlus</td>
      <td>4.3</td>
      <td>101256</td>
      <td>9189</td>
      <td>₹15499</td>
      <td>₹19999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kqidx8w0/television/m/1/v/32ha0a00-oneplus-original-imag4gy8yezxdhen.jpeg?q=70</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>875</th>
      <td>SONY</td>
      <td>4.6</td>
      <td>0</td>
      <td>0</td>
      <td>₹59999</td>
      <td>₹94900</td>
      <td>Ultra HD (4K) 3840 x 2160 pixels Pixels</td>
      <td>NO Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 1 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kfvfwy80/television/b/h/y/sony-kd-55x7500h-original-imafw8d6dmqtdw8h.jpeg?q=70</td>
    </tr>
    <tr>
      <th>876</th>
      <td>Adsun</td>
      <td>3.8</td>
      <td>6742</td>
      <td>930</td>
      <td>₹8999</td>
      <td>₹29999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android Based</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzn17680/television/o/q/p/a-3210s-f-adsun-original-imagbhqzhafpzhyz.jpeg?q=70</td>
    </tr>
    <tr>
      <th>877</th>
      <td>SONY</td>
      <td>4.5</td>
      <td>6056</td>
      <td>1082</td>
      <td>₹34184</td>
      <td>₹68400</td>
      <td>Netflix|Prime Video|Youtube</td>
      <td>Operating System: Linux based</td>
      <td>Ultra HD (4K) 3840 x 2160 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kbqu4cw0/television/b/h/t/sony-kd-43x7002g-kd-43x7002g-original-imaftyujugrkzct2.jpeg?q=70</td>
    </tr>
    <tr>
      <th>878</th>
      <td>Croma</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>₹9194</td>
      <td>₹20000</td>
      <td>HD Ready 1366 x 786 Pixels</td>
      <td>20 Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/ku8pbbk0/television/d/i/p/crel7369-3yr-croma-original-imag7escqzvf4g5e.jpeg?q=70</td>
    </tr>
    <tr>
      <th>879</th>
      <td>T-Series</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>₹26999</td>
      <td>₹33990</td>
      <td>Netflix|Prime Video|Apple TV|Disney+Hotstar|Youtube</td>
      <td>Full HD 1920 x 1080 Pixels</td>
      <td>16 Speaker Output</td>
      <td>NaN</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kz4gh3k0/television/p/v/8/t-series-smart-43-movie-plus-bezel-less-43-inch-109-cm-full-hd-original-imagb7e74mgzweb3.jpeg?q=70</td>
    </tr>
    <tr>
      <th>880</th>
      <td>Adsun</td>
      <td>3.8</td>
      <td>6742</td>
      <td>930</td>
      <td>₹6199</td>
      <td>₹12999</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>NaN</td>
      <td>1 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/krntoy80/television/h/i/m/a-2400n-adsun-original-imag5ecpqjfzews3.jpeg?q=70</td>
    </tr>
    <tr>
      <th>881</th>
      <td>SONY</td>
      <td>4.4</td>
      <td>0</td>
      <td>0</td>
      <td>₹52949</td>
      <td>₹72990</td>
      <td>Ultra HD (4K) 3840 x 2160 pixels Pixels</td>
      <td>10W + 10W Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kfvfwy80/television/g/m/7/sony-kd-43x8000h-original-imafw8d6evas4yxh.jpeg?q=70</td>
    </tr>
  </tbody>
</table>
<p>882 rows × 12 columns</p>
      
        <p><strong>Hyp output variables:</strong> df </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Product_Name</th>
      <th>Stars</th>
      <th>Ratings</th>
      <th>Reviews</th>
      <th>current_price</th>
      <th>MRP</th>
      <th>channel</th>
      <th>Operating_system</th>
      <th>Picture_qualtiy</th>
      <th>Speaker</th>
      <th>Frequency</th>
      <th>Image_url</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Croma</td>
      <td>4.2</td>
      <td>1773</td>
      <td>217</td>
      <td>₹7990</td>
      <td>₹20000</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/ku1k4280/television/p/f/6/crel7369-croma-original-imag7969pxhrwp2k.jpeg?q=70</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Adsun</td>
      <td>3.8</td>
      <td>6742</td>
      <td>930</td>
      <td>₹8699</td>
      <td>₹21999</td>
      <td>Netflix|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android Based</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/krntoy80/television/u/d/y/a-3200s-adsun-original-imag5edguuyn54fh.jpeg?q=70</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LG</td>
      <td>4.4</td>
      <td>38870</td>
      <td>3443</td>
      <td>₹16499</td>
      <td>₹21990</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: WebOS</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>10 W Speaker Output</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0fm07k0/television/7/x/9/-original-imagc8fnpx39evgc.jpeg?q=70</td>
    </tr>
    <tr>
      <th>3</th>
      <td>OnePlus</td>
      <td>4.3</td>
      <td>101256</td>
      <td>9189</td>
      <td>₹16499</td>
      <td>₹21999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzfvzww0/television/e/b/b/32hd2a00-32-y1s-oneplus-original-imagbgcewfqywgk7.jpeg?q=70</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Xiaomi</td>
      <td>4.3</td>
      <td>3120</td>
      <td>305</td>
      <td>₹15499</td>
      <td>₹24999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l2ghgnk0/television/u/a/c/l32m7-5ain-mi-original-imagdsdwqf6bkmkz.jpeg?q=70</td>
    </tr>
    <tr>
      <th>5</th>
      <td>SAMSUNG</td>
      <td>4.4</td>
      <td>53639</td>
      <td>4811</td>
      <td>₹15999</td>
      <td>₹22900</td>
      <td>Netflix|Disney+Hotstar|Youtube</td>
      <td>Operating System: Tizen</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kbs9k7k0/television/c/j/3/samsung-ua32t4340akxxl-original-imaft25qdysfsq7k.jpeg?q=70</td>
    </tr>
    <tr>
      <th>6</th>
      <td>OnePlus</td>
      <td>4.3</td>
      <td>101256</td>
      <td>9189</td>
      <td>₹15499</td>
      <td>₹19999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kqidx8w0/television/m/1/v/32ha0a00-oneplus-original-imag4gy8yezxdhen.jpeg?q=70</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>875</th>
      <td>SONY</td>
      <td>4.6</td>
      <td>0</td>
      <td>0</td>
      <td>₹59999</td>
      <td>₹94900</td>
      <td>Ultra HD (4K) 3840 x 2160 pixels Pixels</td>
      <td>NO Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 1 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kfvfwy80/television/b/h/y/sony-kd-55x7500h-original-imafw8d6dmqtdw8h.jpeg?q=70</td>
    </tr>
    <tr>
      <th>876</th>
      <td>Adsun</td>
      <td>3.8</td>
      <td>6742</td>
      <td>930</td>
      <td>₹8999</td>
      <td>₹29999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android Based</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzn17680/television/o/q/p/a-3210s-f-adsun-original-imagbhqzhafpzhyz.jpeg?q=70</td>
    </tr>
    <tr>
      <th>877</th>
      <td>SONY</td>
      <td>4.5</td>
      <td>6056</td>
      <td>1082</td>
      <td>₹34184</td>
      <td>₹68400</td>
      <td>Netflix|Prime Video|Youtube</td>
      <td>Operating System: Linux based</td>
      <td>Ultra HD (4K) 3840 x 2160 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kbqu4cw0/television/b/h/t/sony-kd-43x7002g-kd-43x7002g-original-imaftyujugrkzct2.jpeg?q=70</td>
    </tr>
    <tr>
      <th>878</th>
      <td>Croma</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>₹9194</td>
      <td>₹20000</td>
      <td>HD Ready 1366 x 786 Pixels</td>
      <td>20 Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/ku8pbbk0/television/d/i/p/crel7369-3yr-croma-original-imag7escqzvf4g5e.jpeg?q=70</td>
    </tr>
    <tr>
      <th>879</th>
      <td>T-Series</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>₹26999</td>
      <td>₹33990</td>
      <td>Netflix|Prime Video|Apple TV|Disney+Hotstar|Youtube</td>
      <td>Full HD 1920 x 1080 Pixels</td>
      <td>16 Speaker Output</td>
      <td>NaN</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kz4gh3k0/television/p/v/8/t-series-smart-43-movie-plus-bezel-less-43-inch-109-cm-full-hd-original-imagb7e74mgzweb3.jpeg?q=70</td>
    </tr>
    <tr>
      <th>880</th>
      <td>Adsun</td>
      <td>3.8</td>
      <td>6742</td>
      <td>930</td>
      <td>₹6199</td>
      <td>₹12999</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>NaN</td>
      <td>1 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/krntoy80/television/h/i/m/a-2400n-adsun-original-imag5ecpqjfzews3.jpeg?q=70</td>
    </tr>
    <tr>
      <th>881</th>
      <td>SONY</td>
      <td>4.4</td>
      <td>0</td>
      <td>0</td>
      <td>₹52949</td>
      <td>₹72990</td>
      <td>Ultra HD (4K) 3840 x 2160 pixels Pixels</td>
      <td>10W + 10W Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kfvfwy80/television/g/m/7/sony-kd-43x8000h-original-imafw8d6evas4yxh.jpeg?q=70</td>
    </tr>
  </tbody>
</table>
<p>882 rows × 12 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('df', 'df', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> television-dataset-2022/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Remove ₹ from the current price and the original manufacturer's price, also change their type to integer</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.current_price,df.MRP = df['current_price'].str.replace('₹','').astype(int),df['MRP'].str.replace('₹','').astype(int)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.current_price,df.MRP = df['current_price'].str.replace('₹','').astype(int),df['MRP'].str.replace('₹','').astype(int)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.current_price, df.MRP = df['current_price'].str.replace('₹', ''
    ).astype(int), df['MRP'].str.replace('₹', '').astype(int)
</code></pre>
        <p><span onclick="$('#var_output_ec489b7b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ec489b7b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (tuple):</p>
          <pre><code>(0       7990
1       8699
2      16499
3      16499
4      15499
       ...  
877    34184
878     9194
879    26999
880     6199
881    52949
Name: current_price, Length: 882, dtype: int64, 0      20000
1      21999
2      21990
3      21999
4      24999
       ...  
877    68400
878    20000
879    33990
880    12999
881    72990
Name: MRP, Length: 882, dtype: int64)</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Product_Name</th>
      <th>Stars</th>
      <th>Ratings</th>
      <th>Reviews</th>
      <th>current_price</th>
      <th>MRP</th>
      <th>channel</th>
      <th>Operating_system</th>
      <th>Picture_qualtiy</th>
      <th>Speaker</th>
      <th>Frequency</th>
      <th>Image_url</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Croma</td>
      <td>4.2</td>
      <td>1773</td>
      <td>217</td>
      <td>7990</td>
      <td>20000</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/ku1k4280/television/p/f/6/crel7369-croma-original-imag7969pxhrwp2k.jpeg?q=70</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Adsun</td>
      <td>3.8</td>
      <td>6742</td>
      <td>930</td>
      <td>8699</td>
      <td>21999</td>
      <td>Netflix|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android Based</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/krntoy80/television/u/d/y/a-3200s-adsun-original-imag5edguuyn54fh.jpeg?q=70</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LG</td>
      <td>4.4</td>
      <td>38870</td>
      <td>3443</td>
      <td>16499</td>
      <td>21990</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: WebOS</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>10 W Speaker Output</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0fm07k0/television/7/x/9/-original-imagc8fnpx39evgc.jpeg?q=70</td>
    </tr>
    <tr>
      <th>3</th>
      <td>OnePlus</td>
      <td>4.3</td>
      <td>101256</td>
      <td>9189</td>
      <td>16499</td>
      <td>21999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzfvzww0/television/e/b/b/32hd2a00-32-y1s-oneplus-original-imagbgcewfqywgk7.jpeg?q=70</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Xiaomi</td>
      <td>4.3</td>
      <td>3120</td>
      <td>305</td>
      <td>15499</td>
      <td>24999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l2ghgnk0/television/u/a/c/l32m7-5ain-mi-original-imagdsdwqf6bkmkz.jpeg?q=70</td>
    </tr>
    <tr>
      <th>5</th>
      <td>SAMSUNG</td>
      <td>4.4</td>
      <td>53639</td>
      <td>4811</td>
      <td>15999</td>
      <td>22900</td>
      <td>Netflix|Disney+Hotstar|Youtube</td>
      <td>Operating System: Tizen</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kbs9k7k0/television/c/j/3/samsung-ua32t4340akxxl-original-imaft25qdysfsq7k.jpeg?q=70</td>
    </tr>
    <tr>
      <th>6</th>
      <td>OnePlus</td>
      <td>4.3</td>
      <td>101256</td>
      <td>9189</td>
      <td>15499</td>
      <td>19999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kqidx8w0/television/m/1/v/32ha0a00-oneplus-original-imag4gy8yezxdhen.jpeg?q=70</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>875</th>
      <td>SONY</td>
      <td>4.6</td>
      <td>0</td>
      <td>0</td>
      <td>59999</td>
      <td>94900</td>
      <td>Ultra HD (4K) 3840 x 2160 pixels Pixels</td>
      <td>NO Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 1 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kfvfwy80/television/b/h/y/sony-kd-55x7500h-original-imafw8d6dmqtdw8h.jpeg?q=70</td>
    </tr>
    <tr>
      <th>876</th>
      <td>Adsun</td>
      <td>3.8</td>
      <td>6742</td>
      <td>930</td>
      <td>8999</td>
      <td>29999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android Based</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzn17680/television/o/q/p/a-3210s-f-adsun-original-imagbhqzhafpzhyz.jpeg?q=70</td>
    </tr>
    <tr>
      <th>877</th>
      <td>SONY</td>
      <td>4.5</td>
      <td>6056</td>
      <td>1082</td>
      <td>34184</td>
      <td>68400</td>
      <td>Netflix|Prime Video|Youtube</td>
      <td>Operating System: Linux based</td>
      <td>Ultra HD (4K) 3840 x 2160 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kbqu4cw0/television/b/h/t/sony-kd-43x7002g-kd-43x7002g-original-imaftyujugrkzct2.jpeg?q=70</td>
    </tr>
    <tr>
      <th>878</th>
      <td>Croma</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>9194</td>
      <td>20000</td>
      <td>HD Ready 1366 x 786 Pixels</td>
      <td>20 Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/ku8pbbk0/television/d/i/p/crel7369-3yr-croma-original-imag7escqzvf4g5e.jpeg?q=70</td>
    </tr>
    <tr>
      <th>879</th>
      <td>T-Series</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>26999</td>
      <td>33990</td>
      <td>Netflix|Prime Video|Apple TV|Disney+Hotstar|Youtube</td>
      <td>Full HD 1920 x 1080 Pixels</td>
      <td>16 Speaker Output</td>
      <td>NaN</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kz4gh3k0/television/p/v/8/t-series-smart-43-movie-plus-bezel-less-43-inch-109-cm-full-hd-original-imagb7e74mgzweb3.jpeg?q=70</td>
    </tr>
    <tr>
      <th>880</th>
      <td>Adsun</td>
      <td>3.8</td>
      <td>6742</td>
      <td>930</td>
      <td>6199</td>
      <td>12999</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>NaN</td>
      <td>1 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/krntoy80/television/h/i/m/a-2400n-adsun-original-imag5ecpqjfzews3.jpeg?q=70</td>
    </tr>
    <tr>
      <th>881</th>
      <td>SONY</td>
      <td>4.4</td>
      <td>0</td>
      <td>0</td>
      <td>52949</td>
      <td>72990</td>
      <td>Ultra HD (4K) 3840 x 2160 pixels Pixels</td>
      <td>10W + 10W Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kfvfwy80/television/g/m/7/sony-kd-43x8000h-original-imafw8d6evas4yxh.jpeg?q=70</td>
    </tr>
  </tbody>
</table>
<p>882 rows × 12 columns</p>
      
          <p>__output__ (tuple):</p>
          <pre><code>(0       7990
1       8699
2      16499
3      16499
4      15499
       ...  
877    34184
878     9194
879    26999
880     6199
881    52949
Name: current_price, Length: 882, dtype: int64, 0      20000
1      21999
2      21990
3      21999
4      24999
       ...  
877    68400
878    20000
879    33990
880    12999
881    72990
Name: MRP, Length: 882, dtype: int64)</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', {'functionally_equivalent': True, 'reason': 'compare_lists'})]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> television-dataset-2022/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Are televisions with higher ratings more expensive? Compare between the average original prices above the ratings mean and below it.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>rating_mean=df.Ratings.mean()
high = df[df['Ratings'] >= rating_mean]['MRP'].mean()
low = df[df['Ratings'] < rating_mean]['MRP'].mean()
high>low</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>rating_mean=df.Ratings.mean()
high = df[df['Ratings'] >= rating_mean]['MRP'].mean()
low = df[df['Ratings'] < rating_mean]['MRP'].mean()
high>low</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>rating_mean = df.Ratings.mean()
high = df[df['Ratings'] >= rating_mean]['MRP'].mean()
low = df[df['Ratings'] < rating_mean]['MRP'].mean()
__output__ = high > low
</code></pre>
        <p><span onclick="$('#var_output_d76b4764').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d76b4764" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (bool_):</p>
          <pre><code>False</code></pre>
      
        <p><strong>Hyp output variables:</strong> rating_mean, high, low, __output__ </p>
    
          <p>rating_mean (float64):</p>
          <pre><code>5675.442176870748</code></pre>
      
          <p>high (float64):</p>
          <pre><code>36179.86016949153</code></pre>
      
          <p>low (float64):</p>
          <pre><code>68845.82972136223</code></pre>
      
          <p>__output__ (bool_):</p>
          <pre><code>False</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> television-dataset-2022/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How expensive each product's average current price from it's average orginal price? Sort values from the highest to the lowest</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(df.groupby('Product_Name').mean()['current_price']-df.groupby('Product_Name').mean()['MRP']).sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(df.groupby('Product_Name').mean()['current_price']-df.groupby('Product_Name').mean()['MRP']).sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = (df.groupby('Product_Name').mean()['current_price'] - df.
    groupby('Product_Name').mean()['MRP']).sort_values(ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_0ccdf728').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0ccdf728" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Product_Name
SAMSUNG     25352.764151
Sansui      12700.923077
Micromax    11669.000000
Infinix      6166.333333
Mi            580.142857
                ...     
PHILIPS    -35807.555556
Compaq     -40698.200000
SONY       -45508.375000
iFFALCON   -50235.750000
TCL        -55914.518519
Length: 56, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Product_Name
SAMSUNG     25352.764151
Sansui      12700.923077
Micromax    11669.000000
Infinix      6166.333333
Mi            580.142857
                ...     
PHILIPS    -35807.555556
Compaq     -40698.200000
SONY       -45508.375000
iFFALCON   -50235.750000
TCL        -55914.518519
Length: 56, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> television-dataset-2022/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 5 most selling television frequencies? Show the frequencies with their counts</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def freq(x):
    split=x.split(' ')
    return (" ").join(split[:2])
df.Frequency.apply(freq).value_counts()[:5]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def freq(x):
    split=x.split(' ')
    return (" ").join(split[:2])
df.Frequency.apply(freq).value_counts()[:5]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def freq(x):
    split = x.split(' ')
    return ' '.join(split[:2])


__output__ = df.Frequency.apply(freq).value_counts()[:5]
</code></pre>
        <p><span onclick="$('#var_output_550ce9c0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_550ce9c0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>60 Hz     717
50 Hz      76
100 Hz     32
120 Hz     30
200 Hz     19
Name: Frequency, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>60 Hz     717
50 Hz      76
100 Hz     32
120 Hz     30
200 Hz     19
Name: Frequency, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> television-dataset-2022/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which companies have 0 ratings and 0 reviews?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>grouped_sum=df.groupby('Product_Name').sum()
list(grouped_sum[(grouped_sum['Ratings']==0) & (grouped_sum['Reviews']==0)].index)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>grouped_sum=df.groupby('Product_Name').sum()
list(grouped_sum[(grouped_sum['Ratings']==0) & (grouped_sum['Reviews']==0)].index)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>grouped_sum = df.groupby('Product_Name').sum()
__output__ = list(grouped_sum[(grouped_sum['Ratings'] == 0) & (grouped_sum[
    'Reviews'] == 0)].index)
</code></pre>
        <p><span onclick="$('#var_output_dd86de54').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_dd86de54" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Akai', 'BPL', 'Bush', 'CORNEA', 'Candes', 'Compaq', 'DETEL', 'Dyanora', 'Haier', 'Hyundai', 'IGO', 'IMPEX', 'InnoQ', 'Lloyd', 'LumX', 'Maser', 'Nacson', 'Onix', 'Oxygen', 'PHILIPS', 'T-Series', 'TCL', 'VG', 'Yuwa', 'iMEE', 'kinger']</code></pre>
      
        <p><strong>Hyp output variables:</strong> grouped_sum, __output__ </p>
    
          <p>grouped_sum (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Stars</th>
      <th>Ratings</th>
      <th>Reviews</th>
      <th>current_price</th>
      <th>MRP</th>
    </tr>
    <tr>
      <th>Product_Name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adsun</th>
      <td>429.4</td>
      <td>760853</td>
      <td>104971</td>
      <td>1189584</td>
      <td>3101884</td>
    </tr>
    <tr>
      <th>Akai</th>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>74925</td>
      <td>131970</td>
    </tr>
    <tr>
      <th>BPL</th>
      <td>4.3</td>
      <td>0</td>
      <td>0</td>
      <td>76479</td>
      <td>122999</td>
    </tr>
    <tr>
      <th>Blaupunkt</th>
      <td>31.6</td>
      <td>34452</td>
      <td>8516</td>
      <td>210493</td>
      <td>294493</td>
    </tr>
    <tr>
      <th>Bush</th>
      <td>4.1</td>
      <td>0</td>
      <td>0</td>
      <td>29497</td>
      <td>37997</td>
    </tr>
    <tr>
      <th>CORNEA</th>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>331996</td>
      <td>444996</td>
    </tr>
    <tr>
      <th>Candes</th>
      <td>20.1</td>
      <td>0</td>
      <td>0</td>
      <td>58995</td>
      <td>133650</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Xiaomi</th>
      <td>17.6</td>
      <td>9360</td>
      <td>915</td>
      <td>154496</td>
      <td>290996</td>
    </tr>
    <tr>
      <th>Yuwa</th>
      <td>12.8</td>
      <td>0</td>
      <td>0</td>
      <td>107142</td>
      <td>211908</td>
    </tr>
    <tr>
      <th>acer</th>
      <td>30.8</td>
      <td>30685</td>
      <td>5015</td>
      <td>166993</td>
      <td>239930</td>
    </tr>
    <tr>
      <th>iFFALCON</th>
      <td>52.6</td>
      <td>96514</td>
      <td>13644</td>
      <td>616970</td>
      <td>1219799</td>
    </tr>
    <tr>
      <th>iMEE</th>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>121291</td>
      <td>206991</td>
    </tr>
    <tr>
      <th>kinger</th>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>480963</td>
      <td>832130</td>
    </tr>
    <tr>
      <th>realme</th>
      <td>34.3</td>
      <td>676784</td>
      <td>77471</td>
      <td>214992</td>
      <td>277992</td>
    </tr>
  </tbody>
</table>
<p>56 rows × 5 columns</p>
      
          <p>__output__ (list):</p>
          <pre><code>['Akai', 'BPL', 'Bush', 'CORNEA', 'Candes', 'Compaq', 'DETEL', 'Dyanora', 'Haier', 'Hyundai', 'IGO', 'IMPEX', 'InnoQ', 'Lloyd', 'LumX', 'Maser', 'Nacson', 'Onix', 'Oxygen', 'PHILIPS', 'T-Series', 'TCL', 'VG', 'Yuwa', 'iMEE', 'kinger']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> television-dataset-2022/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 5 operating systems used in televisions?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def OS(x):
    splitted=x.split(':')
    if len(splitted)>=2:
        splitted=splitted[1].split(' ')
        return splitted[1].lower()
    else:
        return np.NaN

list(df.Operating_system.apply(OS).value_counts()[:5].index)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def OS(x):
    splitted=x.split(':')
    if len(splitted)>=2:
        splitted=splitted[1].split(' ')
        return splitted[1].lower()
    else:
        return np.NaN

list(df.Operating_system.apply(OS).value_counts()[:5].index)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def OS(x):
    splitted = x.split(':')
    if len(splitted) >= 2:
        splitted = splitted[1].split(' ')
        return splitted[1].lower()
    else:
        return np.NaN


__output__ = list(df.Operating_system.apply(OS).value_counts()[:5].index)
</code></pre>
        <p><span onclick="$('#var_output_d0fc8db2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d0fc8db2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['android', 'tizen', 'webos', 'linux', 'google']</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['android', 'tizen', 'webos', 'linux', 'google']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> television-dataset-2022/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which companies have more than 4 stars but 0 reviews? Show company name, stars and reviews</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>grouped_df=df.groupby('Product_Name').mean()
summed=df.groupby('Product_Name').sum()
grouped_df[(grouped_df['Stars']>4) & (summed['Reviews']==0)][['Stars','Reviews']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>grouped_df=df.groupby('Product_Name').mean()
summed=df.groupby('Product_Name').sum()
grouped_df[(grouped_df['Stars']>4) & (summed['Reviews']==0)][['Stars','Reviews']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>grouped_df = df.groupby('Product_Name').mean()
summed = df.groupby('Product_Name').sum()
__output__ = grouped_df[(grouped_df['Stars'] > 4) & (summed['Reviews'] == 0)][[
    'Stars', 'Reviews']]
</code></pre>
        <p><span onclick="$('#var_output_4ee73823').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4ee73823" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Stars</th>
      <th>Reviews</th>
    </tr>
    <tr>
      <th>Product_Name</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Candes</th>
      <td>4.020000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Compaq</th>
      <td>4.300000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>DETEL</th>
      <td>4.100000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>IGO</th>
      <td>4.100000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>InnoQ</th>
      <td>4.100000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>LumX</th>
      <td>4.133333</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Nacson</th>
      <td>4.033333</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> grouped_df, summed, __output__ </p>
    
          <p>grouped_df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Stars</th>
      <th>Ratings</th>
      <th>Reviews</th>
      <th>current_price</th>
      <th>MRP</th>
    </tr>
    <tr>
      <th>Product_Name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adsun</th>
      <td>3.701724</td>
      <td>6559.077586</td>
      <td>904.922414</td>
      <td>10255.034483</td>
      <td>26740.379310</td>
    </tr>
    <tr>
      <th>Akai</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>24975.000000</td>
      <td>43990.000000</td>
    </tr>
    <tr>
      <th>BPL</th>
      <td>1.433333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>25493.000000</td>
      <td>40999.666667</td>
    </tr>
    <tr>
      <th>Blaupunkt</th>
      <td>4.514286</td>
      <td>4921.714286</td>
      <td>1216.571429</td>
      <td>30070.428571</td>
      <td>42070.428571</td>
    </tr>
    <tr>
      <th>Bush</th>
      <td>1.366667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>9832.333333</td>
      <td>12665.666667</td>
    </tr>
    <tr>
      <th>CORNEA</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>82999.000000</td>
      <td>111249.000000</td>
    </tr>
    <tr>
      <th>Candes</th>
      <td>4.020000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>11799.000000</td>
      <td>26730.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Xiaomi</th>
      <td>4.400000</td>
      <td>2340.000000</td>
      <td>228.750000</td>
      <td>38624.000000</td>
      <td>72749.000000</td>
    </tr>
    <tr>
      <th>Yuwa</th>
      <td>1.600000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>13392.750000</td>
      <td>26488.500000</td>
    </tr>
    <tr>
      <th>acer</th>
      <td>4.400000</td>
      <td>4383.571429</td>
      <td>716.428571</td>
      <td>23856.142857</td>
      <td>34275.714286</td>
    </tr>
    <tr>
      <th>iFFALCON</th>
      <td>4.383333</td>
      <td>8042.833333</td>
      <td>1137.000000</td>
      <td>51414.166667</td>
      <td>101649.916667</td>
    </tr>
    <tr>
      <th>iMEE</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>13476.777778</td>
      <td>22999.000000</td>
    </tr>
    <tr>
      <th>kinger</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>12999.000000</td>
      <td>22490.000000</td>
    </tr>
    <tr>
      <th>realme</th>
      <td>4.287500</td>
      <td>84598.000000</td>
      <td>9683.875000</td>
      <td>26874.000000</td>
      <td>34749.000000</td>
    </tr>
  </tbody>
</table>
<p>56 rows × 5 columns</p>
      
          <p>summed (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Stars</th>
      <th>Ratings</th>
      <th>Reviews</th>
      <th>current_price</th>
      <th>MRP</th>
    </tr>
    <tr>
      <th>Product_Name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adsun</th>
      <td>429.4</td>
      <td>760853</td>
      <td>104971</td>
      <td>1189584</td>
      <td>3101884</td>
    </tr>
    <tr>
      <th>Akai</th>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>74925</td>
      <td>131970</td>
    </tr>
    <tr>
      <th>BPL</th>
      <td>4.3</td>
      <td>0</td>
      <td>0</td>
      <td>76479</td>
      <td>122999</td>
    </tr>
    <tr>
      <th>Blaupunkt</th>
      <td>31.6</td>
      <td>34452</td>
      <td>8516</td>
      <td>210493</td>
      <td>294493</td>
    </tr>
    <tr>
      <th>Bush</th>
      <td>4.1</td>
      <td>0</td>
      <td>0</td>
      <td>29497</td>
      <td>37997</td>
    </tr>
    <tr>
      <th>CORNEA</th>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>331996</td>
      <td>444996</td>
    </tr>
    <tr>
      <th>Candes</th>
      <td>20.1</td>
      <td>0</td>
      <td>0</td>
      <td>58995</td>
      <td>133650</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Xiaomi</th>
      <td>17.6</td>
      <td>9360</td>
      <td>915</td>
      <td>154496</td>
      <td>290996</td>
    </tr>
    <tr>
      <th>Yuwa</th>
      <td>12.8</td>
      <td>0</td>
      <td>0</td>
      <td>107142</td>
      <td>211908</td>
    </tr>
    <tr>
      <th>acer</th>
      <td>30.8</td>
      <td>30685</td>
      <td>5015</td>
      <td>166993</td>
      <td>239930</td>
    </tr>
    <tr>
      <th>iFFALCON</th>
      <td>52.6</td>
      <td>96514</td>
      <td>13644</td>
      <td>616970</td>
      <td>1219799</td>
    </tr>
    <tr>
      <th>iMEE</th>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>121291</td>
      <td>206991</td>
    </tr>
    <tr>
      <th>kinger</th>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>480963</td>
      <td>832130</td>
    </tr>
    <tr>
      <th>realme</th>
      <td>34.3</td>
      <td>676784</td>
      <td>77471</td>
      <td>214992</td>
      <td>277992</td>
    </tr>
  </tbody>
</table>
<p>56 rows × 5 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Stars</th>
      <th>Reviews</th>
    </tr>
    <tr>
      <th>Product_Name</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Candes</th>
      <td>4.020000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Compaq</th>
      <td>4.300000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>DETEL</th>
      <td>4.100000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>IGO</th>
      <td>4.100000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>InnoQ</th>
      <td>4.100000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>LumX</th>
      <td>4.133333</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Nacson</th>
      <td>4.033333</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> television-dataset-2022/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Change the stars column to catagories ( Bad: <=2, Average: 4-2, Good: >=4)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def star_cat(x):
    if x>=4:
        return 'Good'
    elif x<2:
        return 'Average'
    else:
        return 'Bad'
df['Stars']=df.Stars.apply(star_cat)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def star_cat(x):
    if x>=4:
        return 'Good'
    elif x<2:
        return 'Average'
    else:
        return 'Bad'
df['Stars']=df.Stars.apply(star_cat)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def star_cat(x):
    if x >= 4:
        return 'Good'
    elif x < 2:
        return 'Average'
    else:
        return 'Bad'


__output__ = df['Stars'] = df.Stars.apply(star_cat)
</code></pre>
        <p><span onclick="$('#var_output_3e97f225').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3e97f225" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0         Good
1          Bad
2         Good
3         Good
4         Good
        ...   
877       Good
878    Average
879    Average
880        Bad
881       Good
Name: Stars, Length: 882, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Product_Name</th>
      <th>Stars</th>
      <th>Ratings</th>
      <th>Reviews</th>
      <th>current_price</th>
      <th>MRP</th>
      <th>channel</th>
      <th>Operating_system</th>
      <th>Picture_qualtiy</th>
      <th>Speaker</th>
      <th>Frequency</th>
      <th>Image_url</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Croma</td>
      <td>Good</td>
      <td>1773</td>
      <td>217</td>
      <td>7990</td>
      <td>20000</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/ku1k4280/television/p/f/6/crel7369-croma-original-imag7969pxhrwp2k.jpeg?q=70</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Adsun</td>
      <td>Bad</td>
      <td>6742</td>
      <td>930</td>
      <td>8699</td>
      <td>21999</td>
      <td>Netflix|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android Based</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/krntoy80/television/u/d/y/a-3200s-adsun-original-imag5edguuyn54fh.jpeg?q=70</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LG</td>
      <td>Good</td>
      <td>38870</td>
      <td>3443</td>
      <td>16499</td>
      <td>21990</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: WebOS</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>10 W Speaker Output</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l0fm07k0/television/7/x/9/-original-imagc8fnpx39evgc.jpeg?q=70</td>
    </tr>
    <tr>
      <th>3</th>
      <td>OnePlus</td>
      <td>Good</td>
      <td>101256</td>
      <td>9189</td>
      <td>16499</td>
      <td>21999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzfvzww0/television/e/b/b/32hd2a00-32-y1s-oneplus-original-imagbgcewfqywgk7.jpeg?q=70</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Xiaomi</td>
      <td>Good</td>
      <td>3120</td>
      <td>305</td>
      <td>15499</td>
      <td>24999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/l2ghgnk0/television/u/a/c/l32m7-5ain-mi-original-imagdsdwqf6bkmkz.jpeg?q=70</td>
    </tr>
    <tr>
      <th>5</th>
      <td>SAMSUNG</td>
      <td>Good</td>
      <td>53639</td>
      <td>4811</td>
      <td>15999</td>
      <td>22900</td>
      <td>Netflix|Disney+Hotstar|Youtube</td>
      <td>Operating System: Tizen</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kbs9k7k0/television/c/j/3/samsung-ua32t4340akxxl-original-imaft25qdysfsq7k.jpeg?q=70</td>
    </tr>
    <tr>
      <th>6</th>
      <td>OnePlus</td>
      <td>Good</td>
      <td>101256</td>
      <td>9189</td>
      <td>15499</td>
      <td>19999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kqidx8w0/television/m/1/v/32ha0a00-oneplus-original-imag4gy8yezxdhen.jpeg?q=70</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>875</th>
      <td>SONY</td>
      <td>Good</td>
      <td>0</td>
      <td>0</td>
      <td>59999</td>
      <td>94900</td>
      <td>Ultra HD (4K) 3840 x 2160 pixels Pixels</td>
      <td>NO Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 1 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kfvfwy80/television/b/h/y/sony-kd-55x7500h-original-imafw8d6dmqtdw8h.jpeg?q=70</td>
    </tr>
    <tr>
      <th>876</th>
      <td>Adsun</td>
      <td>Bad</td>
      <td>6742</td>
      <td>930</td>
      <td>8999</td>
      <td>29999</td>
      <td>Netflix|Prime Video|Disney+Hotstar|Youtube</td>
      <td>Operating System: Android Based</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kzn17680/television/o/q/p/a-3210s-f-adsun-original-imagbhqzhafpzhyz.jpeg?q=70</td>
    </tr>
    <tr>
      <th>877</th>
      <td>SONY</td>
      <td>Good</td>
      <td>6056</td>
      <td>1082</td>
      <td>34184</td>
      <td>68400</td>
      <td>Netflix|Prime Video|Youtube</td>
      <td>Operating System: Linux based</td>
      <td>Ultra HD (4K) 3840 x 2160 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kbqu4cw0/television/b/h/t/sony-kd-43x7002g-kd-43x7002g-original-imaftyujugrkzct2.jpeg?q=70</td>
    </tr>
    <tr>
      <th>878</th>
      <td>Croma</td>
      <td>Average</td>
      <td>0</td>
      <td>0</td>
      <td>9194</td>
      <td>20000</td>
      <td>HD Ready 1366 x 786 Pixels</td>
      <td>20 Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/ku8pbbk0/television/d/i/p/crel7369-3yr-croma-original-imag7escqzvf4g5e.jpeg?q=70</td>
    </tr>
    <tr>
      <th>879</th>
      <td>T-Series</td>
      <td>Average</td>
      <td>0</td>
      <td>0</td>
      <td>26999</td>
      <td>33990</td>
      <td>Netflix|Prime Video|Apple TV|Disney+Hotstar|Youtube</td>
      <td>Full HD 1920 x 1080 Pixels</td>
      <td>16 Speaker Output</td>
      <td>NaN</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kz4gh3k0/television/p/v/8/t-series-smart-43-movie-plus-bezel-less-43-inch-109-cm-full-hd-original-imagb7e74mgzweb3.jpeg?q=70</td>
    </tr>
    <tr>
      <th>880</th>
      <td>Adsun</td>
      <td>Bad</td>
      <td>6742</td>
      <td>930</td>
      <td>6199</td>
      <td>12999</td>
      <td>HD Ready 1366 x 768 Pixels</td>
      <td>20 W Speaker Output</td>
      <td>NaN</td>
      <td>1 x HDMI | 2 x USB</td>
      <td>60 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/krntoy80/television/h/i/m/a-2400n-adsun-original-imag5ecpqjfzews3.jpeg?q=70</td>
    </tr>
    <tr>
      <th>881</th>
      <td>SONY</td>
      <td>Good</td>
      <td>0</td>
      <td>0</td>
      <td>52949</td>
      <td>72990</td>
      <td>Ultra HD (4K) 3840 x 2160 pixels Pixels</td>
      <td>10W + 10W Speaker Output</td>
      <td>NaN</td>
      <td>2 x HDMI | 2 x USB</td>
      <td>50 Hz Refresh Rate</td>
      <td>https://rukminim1.flixcart.com/image/312/312/kfvfwy80/television/g/m/7/sony-kd-43x8000h-original-imafw8d6evas4yxh.jpeg?q=70</td>
    </tr>
  </tbody>
</table>
<p>882 rows × 12 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0         Good
1          Bad
2         Good
3         Good
4         Good
        ...   
877       Good
878    Average
879    Average
880        Bad
881       Good
Name: Stars, Length: 882, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> television-dataset-2022/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the mean selling price of each company for every star category? Show a table with companies names as index, star categories as columns and the mean selling prices as values and rounded to 2 decimal places.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pd.pivot_table(df, values='current_price', index=['Product_Name'],
                columns=['Stars'], aggfunc=np.mean).fillna(0).sort_index().round(2)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pd.pivot_table(df, values='current_price', index=['Product_Name'],
                columns=['Stars'], aggfunc=np.mean).fillna(0).sort_index().round(2)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = pd.pivot_table(df, values='current_price', index=[
    'Product_Name'], columns=['Stars'], aggfunc=np.mean).fillna(0).sort_index(
    ).round(2)
</code></pre>
        <p><span onclick="$('#var_output_61d6bb4e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_61d6bb4e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Stars</th>
      <th>Average</th>
      <th>Bad</th>
      <th>Good</th>
    </tr>
    <tr>
      <th>Product_Name</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adsun</th>
      <td>14399.00</td>
      <td>10145.02</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>Akai</th>
      <td>24975.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>BPL</th>
      <td>30494.50</td>
      <td>0.00</td>
      <td>15490.00</td>
    </tr>
    <tr>
      <th>Blaupunkt</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>30070.43</td>
    </tr>
    <tr>
      <th>Bush</th>
      <td>11499.00</td>
      <td>0.00</td>
      <td>6499.00</td>
    </tr>
    <tr>
      <th>CORNEA</th>
      <td>82999.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>Candes</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>11799.00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Xiaomi</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>38624.00</td>
    </tr>
    <tr>
      <th>Yuwa</th>
      <td>16039.00</td>
      <td>8982.33</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>acer</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>23856.14</td>
    </tr>
    <tr>
      <th>iFFALCON</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>51414.17</td>
    </tr>
    <tr>
      <th>iMEE</th>
      <td>13476.78</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>kinger</th>
      <td>12999.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>realme</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>26874.00</td>
    </tr>
  </tbody>
</table>
<p>56 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Stars</th>
      <th>Average</th>
      <th>Bad</th>
      <th>Good</th>
    </tr>
    <tr>
      <th>Product_Name</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adsun</th>
      <td>14399.00</td>
      <td>10145.02</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>Akai</th>
      <td>24975.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>BPL</th>
      <td>30494.50</td>
      <td>0.00</td>
      <td>15490.00</td>
    </tr>
    <tr>
      <th>Blaupunkt</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>30070.43</td>
    </tr>
    <tr>
      <th>Bush</th>
      <td>11499.00</td>
      <td>0.00</td>
      <td>6499.00</td>
    </tr>
    <tr>
      <th>CORNEA</th>
      <td>82999.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>Candes</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>11799.00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Xiaomi</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>38624.00</td>
    </tr>
    <tr>
      <th>Yuwa</th>
      <td>16039.00</td>
      <td>8982.33</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>acer</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>23856.14</td>
    </tr>
    <tr>
      <th>iFFALCON</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>51414.17</td>
    </tr>
    <tr>
      <th>iMEE</th>
      <td>13476.78</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>kinger</th>
      <td>12999.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>realme</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>26874.00</td>
    </tr>
  </tbody>
</table>
<p>56 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-and-taluk-court-cases/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total number of delayed cases in 2021? Show column name as index and the sum as value</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>names=df.columns[df.columns.str.lower().str.contains('delayed')]
df[names].iloc[df[df['Year']==2021].index].sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>names=df.columns[df.columns.str.lower().str.contains('delayed')]
df[names].iloc[df[df['Year']==2021].index].sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>names = df.columns[df.columns.str.lower().str.contains('delayed')]
__output__ = df[names].iloc[df[df['Year'] == 2021].index].sum()
</code></pre>
        <p><span onclick="$('#var_output_eefe7fb5').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_eefe7fb5" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Cases delayed in disposal    31276546
dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> names, __output__ </p>
    
          <p>names (Index):</p>
          <pre><code>Index(['Cases delayed in disposal'], dtype='object')</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Cases delayed in disposal    31276546
dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> district-and-taluk-court-cases/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which state has the most civil cases filed by women?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pd.pivot_table(df,values='Cases filed by women',index='srcStateName',columns='District and Taluk Court Case type',aggfunc=np.sum)['Civil'].sort_values(ascending=False).index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pd.pivot_table(df,values='Cases filed by women',index='srcStateName',columns='District and Taluk Court Case type',aggfunc=np.sum)['Civil'].sort_values(ascending=False).index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = pd.pivot_table(df, values='Cases filed by women', index=
    'srcStateName', columns='District and Taluk Court Case type', aggfunc=
    np.sum)['Civil'].sort_values(ascending=False).index[0]
</code></pre>
        <p><span onclick="$('#var_output_8469818a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8469818a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Uttar Pradesh</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Uttar Pradesh</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> simulated-customer-data/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # In what city is the highest spending customer located in?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.iloc[df['Spent'].idxmax()]['city']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.iloc[df['Spent'].idxmax()]['city']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.iloc[df['Spent'].idxmax()]['city']
</code></pre>
        <p><span onclick="$('#var_output_840a2579').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_840a2579" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Notaplace</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Notaplace</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> simulated-customer-data/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the mean age of customers located in Simsinnati with children? Show the value as integer</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>int(df[df['city']=='Simsinnati'].groupby('children').mean()['age'][1])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>int(df[df['city']=='Simsinnati'].groupby('children').mean()['age'][1])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = int(df[df['city'] == 'Simsinnati'].groupby('children').mean()[
    'age'][1])
</code></pre>
        <p><span onclick="$('#var_output_aa0094f6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_aa0094f6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>40</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>40</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> simulated-customer-data/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Where are the top 10 customers receiving the highest incomes located?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>list(df.sort_values('income',ascending=False)[:10]['city'].unique())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>list(df.sort_values('income',ascending=False)[:10]['city'].unique())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = list(df.sort_values('income', ascending=False)[:10]['city'].
    unique())
</code></pre>
        <p><span onclick="$('#var_output_5a489ccb').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5a489ccb" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Notaplace', 'Simsinnati', 'Doesnotexist']</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Notaplace', 'Simsinnati', 'Doesnotexist']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> simulated-customer-data/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many male customers have made a review on their previous purchase?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def string_to_int(x):
    try:
        x=int(x)
        return x
    except:
        return np.nan
df[df['gender']=='M']['review'].apply(string_to_int).value_counts().sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def string_to_int(x):
    try:
        x=int(x)
        return x
    except:
        return np.nan
df[df['gender']=='M']['review'].apply(string_to_int).value_counts().sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def string_to_int(x):
    try:
        x = int(x)
        return x
    except:
        return np.nan


__output__ = df[df['gender'] == 'M']['review'].apply(string_to_int
    ).value_counts().sum()
</code></pre>
        <p><span onclick="$('#var_output_afde0bff').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_afde0bff" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>30056</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>30056</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> simulated-customer-data/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the mean income for customers who have master's degree? (Rounded to 2 decimal points)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>round(df[df['degree']=='Master']['income'].mean(), 2)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>round(df[df['degree']=='Master']['income'].mean(), 2)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = round(df[df['degree'] == 'Master']['income'].mean(), 2)
</code></pre>
        <p><span onclick="$('#var_output_658be2ae').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_658be2ae" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>6665.92</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>6665.92</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> simulated-customer-data/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many customers receive an income of more than 95 percentile?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>qu_95=df['income'].quantile(0.95)
len(df[df['income']>qu_95])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>qu_95=df['income'].quantile(0.95)
len(df[df['income']>qu_95])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>qu_95 = df['income'].quantile(0.95)
__output__ = len(df[df['income'] > qu_95])
</code></pre>
        <p><span onclick="$('#var_output_f56ddbe6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f56ddbe6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>11675</code></pre>
      
        <p><strong>Hyp output variables:</strong> qu_95, __output__ </p>
    
          <p>qu_95 (float64):</p>
          <pre><code>12340.885499999986</code></pre>
      
          <p>__output__ (int):</p>
          <pre><code>11675</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> simulated-customer-data/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many women was her first time to purchase?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['gender']=='W']['review'].str.lower().str.contains("no prior").value_counts()[1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['gender']=='W']['review'].str.lower().str.contains("no prior").value_counts()[1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['gender'] == 'W']['review'].str.lower().str.contains(
    'no prior').value_counts()[1]
</code></pre>
        <p><span onclick="$('#var_output_1c017a68').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1c017a68" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>21438</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>21438</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-performance-gce-al-exam-2020-sri-lanka/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Change birth_day column to integer, replace values above 30, below 1 and non-integer values with the column's median</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def to_num(x):
    try:
        x=int(x)
        if x>30 or x<1:
            return np.nan
        else:
            return x
    except:
        return np.nan
df['birth_day']=df['birth_day'].apply(to_num)
df['birth_day'].fillna(df['birth_day'].median(),inplace=True)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def to_num(x):
    try:
        x=int(x)
        if x>30 or x<1:
            return np.nan
        else:
            return x
    except:
        return np.nan
df['birth_day']=df['birth_day'].apply(to_num)
df['birth_day'].fillna(df['birth_day'].median(),inplace=True)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def to_num(x):
    try:
        x = int(x)
        if x > 30 or x < 1:
            return np.nan
        else:
            return x
    except:
        return np.nan


df['birth_day'] = df['birth_day'].apply(to_num)
__output__ = df['birth_day'].fillna(df['birth_day'].median(), inplace=True)
</code></pre>
        <p><span onclick="$('#var_output_ef974be6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ef974be6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> df </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>stream</th>
      <th>Zscore</th>
      <th>district_rank</th>
      <th>island_rank</th>
      <th>al_year</th>
      <th>sub1</th>
      <th>...</th>
      <th>cgt_r</th>
      <th>ge_r</th>
      <th>syllabus</th>
      <th>birth_day</th>
      <th>birth_month</th>
      <th>birth_year</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>ARTS</td>
      <td>-.3550</td>
      <td>4336 (NEW)</td>
      <td>64994 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>056</td>
      <td>S</td>
      <td>new</td>
      <td>15.0</td>
      <td>May</td>
      <td>2001</td>
      <td>female</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>ARTS</td>
      <td>-.2648</td>
      <td>4154 (NEW)</td>
      <td>62338 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>032</td>
      <td>C</td>
      <td>new</td>
      <td>13.0</td>
      <td>January</td>
      <td>2002</td>
      <td>female</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>COMMERCE</td>
      <td>-.4760</td>
      <td>6910 (NEW)</td>
      <td>37307 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>050</td>
      <td>S</td>
      <td>new</td>
      <td>16.0</td>
      <td>August</td>
      <td>2001</td>
      <td>female</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>COMMERCE</td>
      <td>-.1012</td>
      <td>5678 (NEW)</td>
      <td>30449 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>034</td>
      <td>S</td>
      <td>new</td>
      <td>16.0</td>
      <td>August</td>
      <td>2001</td>
      <td>female</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>COMMERCE</td>
      <td>.6014</td>
      <td>3269 (NEW)</td>
      <td>17010 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>036</td>
      <td>S</td>
      <td>new</td>
      <td>7.0</td>
      <td>August</td>
      <td>2000</td>
      <td>female</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>ARTS</td>
      <td>-.5061</td>
      <td>4602 (NEW)</td>
      <td>68521 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>022</td>
      <td>S</td>
      <td>new</td>
      <td>9.0</td>
      <td>January</td>
      <td>2002</td>
      <td>female</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
      <td>ARTS</td>
      <td>.0177</td>
      <td>3419 (NEW)</td>
      <td>52426 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>028</td>
      <td>F</td>
      <td>new</td>
      <td>15.0</td>
      <td>December</td>
      <td>2001</td>
      <td>female</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>337546</th>
      <td>337546</td>
      <td>BIOLOGICAL SCIENCE</td>
      <td>-.0393</td>
      <td>74 (OLD)</td>
      <td>4417 (OLD)</td>
      <td>2020</td>
      <td>PHYSICS</td>
      <td>...</td>
      <td>058</td>
      <td>F</td>
      <td>old</td>
      <td>21.0</td>
      <td>September</td>
      <td>1999</td>
      <td>male</td>
    </tr>
    <tr>
      <th>337547</th>
      <td>337547</td>
      <td>ARTS</td>
      <td>-.0586</td>
      <td>140 (OLD)</td>
      <td>4438 (OLD)</td>
      <td>2020</td>
      <td>AGRICULTURAL SCIENCE</td>
      <td>...</td>
      <td>043</td>
      <td>C</td>
      <td>old</td>
      <td>22.0</td>
      <td>August</td>
      <td>1995</td>
      <td>male</td>
    </tr>
    <tr>
      <th>337548</th>
      <td>337548</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>2020</td>
      <td>MATHEMATICS</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>28.0</td>
      <td>October</td>
      <td>1996</td>
      <td>male</td>
    </tr>
    <tr>
      <th>337549</th>
      <td>337549</td>
      <td>ARTS</td>
      <td>-.3467</td>
      <td>184 (OLD)</td>
      <td>5184 (OLD)</td>
      <td>2020</td>
      <td>HOME ECONOMICS</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>25.0</td>
      <td>March</td>
      <td>1997</td>
      <td>female</td>
    </tr>
    <tr>
      <th>337550</th>
      <td>337550</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>2020</td>
      <td>INFORMATION &amp; COMMUNICATION TECHNOLOGY</td>
      <td>...</td>
      <td>055</td>
      <td>B</td>
      <td>old</td>
      <td>11.0</td>
      <td>July</td>
      <td>1999</td>
      <td>male</td>
    </tr>
    <tr>
      <th>337551</th>
      <td>337551</td>
      <td>BIOSYSTEMS TECHNOLOGY</td>
      <td>.0509</td>
      <td>24 (OLD)</td>
      <td>366 (OLD)</td>
      <td>2020</td>
      <td>AGRICULTURAL SCIENCE</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>3.0</td>
      <td>September</td>
      <td>1996</td>
      <td>female</td>
    </tr>
    <tr>
      <th>337552</th>
      <td>337552</td>
      <td>ARTS</td>
      <td>-.1560</td>
      <td>152 (OLD)</td>
      <td>4693 (OLD)</td>
      <td>2020</td>
      <td>HOME ECONOMICS</td>
      <td>...</td>
      <td>030</td>
      <td>Absent</td>
      <td>old</td>
      <td>27.0</td>
      <td>April</td>
      <td>1994</td>
      <td>male</td>
    </tr>
  </tbody>
</table>
<p>337553 rows × 19 columns</p>
      
        <p><strong>Hyp output variables:</strong> df </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>stream</th>
      <th>Zscore</th>
      <th>district_rank</th>
      <th>island_rank</th>
      <th>al_year</th>
      <th>sub1</th>
      <th>...</th>
      <th>cgt_r</th>
      <th>ge_r</th>
      <th>syllabus</th>
      <th>birth_day</th>
      <th>birth_month</th>
      <th>birth_year</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>ARTS</td>
      <td>-.3550</td>
      <td>4336 (NEW)</td>
      <td>64994 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>056</td>
      <td>S</td>
      <td>new</td>
      <td>15.0</td>
      <td>May</td>
      <td>2001</td>
      <td>female</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>ARTS</td>
      <td>-.2648</td>
      <td>4154 (NEW)</td>
      <td>62338 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>032</td>
      <td>C</td>
      <td>new</td>
      <td>13.0</td>
      <td>January</td>
      <td>2002</td>
      <td>female</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>COMMERCE</td>
      <td>-.4760</td>
      <td>6910 (NEW)</td>
      <td>37307 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>050</td>
      <td>S</td>
      <td>new</td>
      <td>16.0</td>
      <td>August</td>
      <td>2001</td>
      <td>female</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>COMMERCE</td>
      <td>-.1012</td>
      <td>5678 (NEW)</td>
      <td>30449 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>034</td>
      <td>S</td>
      <td>new</td>
      <td>16.0</td>
      <td>August</td>
      <td>2001</td>
      <td>female</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>COMMERCE</td>
      <td>.6014</td>
      <td>3269 (NEW)</td>
      <td>17010 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>036</td>
      <td>S</td>
      <td>new</td>
      <td>7.0</td>
      <td>August</td>
      <td>2000</td>
      <td>female</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>ARTS</td>
      <td>-.5061</td>
      <td>4602 (NEW)</td>
      <td>68521 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>022</td>
      <td>S</td>
      <td>new</td>
      <td>9.0</td>
      <td>January</td>
      <td>2002</td>
      <td>female</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
      <td>ARTS</td>
      <td>.0177</td>
      <td>3419 (NEW)</td>
      <td>52426 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>028</td>
      <td>F</td>
      <td>new</td>
      <td>15.0</td>
      <td>December</td>
      <td>2001</td>
      <td>female</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>337546</th>
      <td>337546</td>
      <td>BIOLOGICAL SCIENCE</td>
      <td>-.0393</td>
      <td>74 (OLD)</td>
      <td>4417 (OLD)</td>
      <td>2020</td>
      <td>PHYSICS</td>
      <td>...</td>
      <td>058</td>
      <td>F</td>
      <td>old</td>
      <td>21.0</td>
      <td>September</td>
      <td>1999</td>
      <td>male</td>
    </tr>
    <tr>
      <th>337547</th>
      <td>337547</td>
      <td>ARTS</td>
      <td>-.0586</td>
      <td>140 (OLD)</td>
      <td>4438 (OLD)</td>
      <td>2020</td>
      <td>AGRICULTURAL SCIENCE</td>
      <td>...</td>
      <td>043</td>
      <td>C</td>
      <td>old</td>
      <td>22.0</td>
      <td>August</td>
      <td>1995</td>
      <td>male</td>
    </tr>
    <tr>
      <th>337548</th>
      <td>337548</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>2020</td>
      <td>MATHEMATICS</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>28.0</td>
      <td>October</td>
      <td>1996</td>
      <td>male</td>
    </tr>
    <tr>
      <th>337549</th>
      <td>337549</td>
      <td>ARTS</td>
      <td>-.3467</td>
      <td>184 (OLD)</td>
      <td>5184 (OLD)</td>
      <td>2020</td>
      <td>HOME ECONOMICS</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>25.0</td>
      <td>March</td>
      <td>1997</td>
      <td>female</td>
    </tr>
    <tr>
      <th>337550</th>
      <td>337550</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>2020</td>
      <td>INFORMATION &amp; COMMUNICATION TECHNOLOGY</td>
      <td>...</td>
      <td>055</td>
      <td>B</td>
      <td>old</td>
      <td>11.0</td>
      <td>July</td>
      <td>1999</td>
      <td>male</td>
    </tr>
    <tr>
      <th>337551</th>
      <td>337551</td>
      <td>BIOSYSTEMS TECHNOLOGY</td>
      <td>.0509</td>
      <td>24 (OLD)</td>
      <td>366 (OLD)</td>
      <td>2020</td>
      <td>AGRICULTURAL SCIENCE</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>3.0</td>
      <td>September</td>
      <td>1996</td>
      <td>female</td>
    </tr>
    <tr>
      <th>337552</th>
      <td>337552</td>
      <td>ARTS</td>
      <td>-.1560</td>
      <td>152 (OLD)</td>
      <td>4693 (OLD)</td>
      <td>2020</td>
      <td>HOME ECONOMICS</td>
      <td>...</td>
      <td>030</td>
      <td>Absent</td>
      <td>old</td>
      <td>27.0</td>
      <td>April</td>
      <td>1994</td>
      <td>male</td>
    </tr>
  </tbody>
</table>
<p>337553 rows × 19 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('df', 'df', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-performance-gce-al-exam-2020-sri-lanka/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total number of students born on each month of the year for each gender (0:Male,1:Female)? Row indices are the gender categories and the columns are the months of the year.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def gender_int(x):
    try:
        x=int(x)
        if x==0:
          return 'Male'
        else:
          return 'Female'
    except:
        return np.nan

df['gender']=df['gender'].apply(gender_int)

pd.pivot_table(df, values='index', index=['gender'],
                columns=['birth_month'], aggfunc=np.count_nonzero)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def gender_int(x):
    try:
        x=int(x)
        if x==0:
          return 'Male'
        else:
          return 'Female'
    except:
        return np.nan

df['gender']=df['gender'].apply(gender_int)

pd.pivot_table(df, values='index', index=['gender'],
                columns=['birth_month'], aggfunc=np.count_nonzero)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def gender_int(x):
    try:
        x = int(x)
        if x == 0:
            return 'Male'
        else:
            return 'Female'
    except:
        return np.nan


df['gender'] = df['gender'].apply(gender_int)
__output__ = pd.pivot_table(df, values='index', index=['gender'], columns=[
    'birth_month'], aggfunc=np.count_nonzero)
</code></pre>
        <p><span onclick="$('#var_output_60180611').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_60180611" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>birth_month</th>
    </tr>
    <tr>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
<p>0 rows × 0 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>stream</th>
      <th>Zscore</th>
      <th>district_rank</th>
      <th>island_rank</th>
      <th>al_year</th>
      <th>sub1</th>
      <th>...</th>
      <th>cgt_r</th>
      <th>ge_r</th>
      <th>syllabus</th>
      <th>birth_day</th>
      <th>birth_month</th>
      <th>birth_year</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>ARTS</td>
      <td>-.3550</td>
      <td>4336 (NEW)</td>
      <td>64994 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>056</td>
      <td>S</td>
      <td>new</td>
      <td>15.0</td>
      <td>May</td>
      <td>2001</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>ARTS</td>
      <td>-.2648</td>
      <td>4154 (NEW)</td>
      <td>62338 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>032</td>
      <td>C</td>
      <td>new</td>
      <td>13.0</td>
      <td>January</td>
      <td>2002</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>COMMERCE</td>
      <td>-.4760</td>
      <td>6910 (NEW)</td>
      <td>37307 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>050</td>
      <td>S</td>
      <td>new</td>
      <td>16.0</td>
      <td>August</td>
      <td>2001</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>COMMERCE</td>
      <td>-.1012</td>
      <td>5678 (NEW)</td>
      <td>30449 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>034</td>
      <td>S</td>
      <td>new</td>
      <td>16.0</td>
      <td>August</td>
      <td>2001</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>COMMERCE</td>
      <td>.6014</td>
      <td>3269 (NEW)</td>
      <td>17010 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>036</td>
      <td>S</td>
      <td>new</td>
      <td>7.0</td>
      <td>August</td>
      <td>2000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>ARTS</td>
      <td>-.5061</td>
      <td>4602 (NEW)</td>
      <td>68521 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>022</td>
      <td>S</td>
      <td>new</td>
      <td>9.0</td>
      <td>January</td>
      <td>2002</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
      <td>ARTS</td>
      <td>.0177</td>
      <td>3419 (NEW)</td>
      <td>52426 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>028</td>
      <td>F</td>
      <td>new</td>
      <td>15.0</td>
      <td>December</td>
      <td>2001</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>337546</th>
      <td>337546</td>
      <td>BIOLOGICAL SCIENCE</td>
      <td>-.0393</td>
      <td>74 (OLD)</td>
      <td>4417 (OLD)</td>
      <td>2020</td>
      <td>PHYSICS</td>
      <td>...</td>
      <td>058</td>
      <td>F</td>
      <td>old</td>
      <td>21.0</td>
      <td>September</td>
      <td>1999</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337547</th>
      <td>337547</td>
      <td>ARTS</td>
      <td>-.0586</td>
      <td>140 (OLD)</td>
      <td>4438 (OLD)</td>
      <td>2020</td>
      <td>AGRICULTURAL SCIENCE</td>
      <td>...</td>
      <td>043</td>
      <td>C</td>
      <td>old</td>
      <td>22.0</td>
      <td>August</td>
      <td>1995</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337548</th>
      <td>337548</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>2020</td>
      <td>MATHEMATICS</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>28.0</td>
      <td>October</td>
      <td>1996</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337549</th>
      <td>337549</td>
      <td>ARTS</td>
      <td>-.3467</td>
      <td>184 (OLD)</td>
      <td>5184 (OLD)</td>
      <td>2020</td>
      <td>HOME ECONOMICS</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>25.0</td>
      <td>March</td>
      <td>1997</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337550</th>
      <td>337550</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>2020</td>
      <td>INFORMATION &amp; COMMUNICATION TECHNOLOGY</td>
      <td>...</td>
      <td>055</td>
      <td>B</td>
      <td>old</td>
      <td>11.0</td>
      <td>July</td>
      <td>1999</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337551</th>
      <td>337551</td>
      <td>BIOSYSTEMS TECHNOLOGY</td>
      <td>.0509</td>
      <td>24 (OLD)</td>
      <td>366 (OLD)</td>
      <td>2020</td>
      <td>AGRICULTURAL SCIENCE</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>3.0</td>
      <td>September</td>
      <td>1996</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337552</th>
      <td>337552</td>
      <td>ARTS</td>
      <td>-.1560</td>
      <td>152 (OLD)</td>
      <td>4693 (OLD)</td>
      <td>2020</td>
      <td>HOME ECONOMICS</td>
      <td>...</td>
      <td>030</td>
      <td>Absent</td>
      <td>old</td>
      <td>27.0</td>
      <td>April</td>
      <td>1994</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>337553 rows × 19 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>birth_month</th>
    </tr>
    <tr>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
<p>0 rows × 0 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-performance-gce-al-exam-2020-sri-lanka/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What subjects do students take in Arts?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>subjects=df[df['stream']=='ARTS'][['sub1','sub2','sub3']].values
list(np.unique(subjects))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>subjects=df[df['stream']=='ARTS'][['sub1','sub2','sub3']].values
list(np.unique(subjects))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>subjects = df[df['stream'] == 'ARTS'][['sub1', 'sub2', 'sub3']].values
__output__ = list(np.unique(subjects))
</code></pre>
        <p><span onclick="$('#var_output_6bb7ecc6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6bb7ecc6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['ACCOUNTING', 'AGRICULTURAL SCIENCE', 'AGRO TECHNOLOGY', 'ARABIC', 'ART', 'BIO-RESOURCE TECHNOLOGY', 'BUDDHISM', 'BUDDHIST CIVILIZATION', 'BUSINESS STATISTICS', 'CARNATIC MUSIC', 'CHINESE', 'CHRISTIAN CIVILIZATION', 'CHRISTIANITY', 'CIVIL TECHNOLOGY', 'COMBINED MATHEMATICS', 'COMMUNICATION & MEDIA STUDIES', 'DANCING(BHARATHA)', 'DANCING(INDIGENOUS)', 'DRAMA AND THEATRE (ENGLISH)', 'DRAMA AND THEATRE (SINHALA)', 'DRAMA AND THEATRE (TAMIL)', 'ECONOMICS', 'ELECTRICAL,ELECTRONIC AND IT', 'ENGLISH', 'FOOD TECHNOLOGY', 'FRENCH', 'GEOGRAPHY', 'GERMAN', 'GREEK & ROMAN CIVILIZATION', 'HINDI', 'HINDU CIVILIZATION', 'HINDUISM', 'HISTORY OF EUROPE', 'HISTORY OF INDIA', 'HISTORY OF MODERN WORLD', 'HISTORY OF SRI LANKA & EUROPE', 'HISTORY OF SRI LANKA & INDIA', 'HISTORY OF SRI LANKA & MODERN WORLD', 'HOME ECONOMICS', 'INFORMATION & COMMUNICATION TECHNOLOGY', 'ISLAM', 'ISLAMIC CIVILIZATION', 'JAPANESE', 'LOGIC & SCIENTIFIC METHOD', 'MATHEMATICS', 'MECHANICAL TECHNOLOGY', 'ORIENTAL MUSIC', 'PALI', 'POLITICAL SCIENCE', 'RUSSIAN', 'SANSKRIT', 'SINHALA', 'TAMIL', 'WESTERN MUSIC']</code></pre>
      
        <p><strong>Hyp output variables:</strong> subjects, __output__ </p>
    
          <p>subjects (ndarray):</p>
          <pre><code>[['POLITICAL SCIENCE' 'DANCING(BHARATHA)' 'TAMIL']
 ['POLITICAL SCIENCE' 'CARNATIC MUSIC' 'TAMIL']
 ['POLITICAL SCIENCE' 'HINDU CIVILIZATION' 'TAMIL']
 ...
 ['AGRICULTURAL SCIENCE' 'POLITICAL SCIENCE'
  'COMMUNICATION & MEDIA STUDIES']
 ['HOME ECONOMICS' 'CHRISTIANITY' 'DRAMA AND THEATRE (TAMIL)']
 ['HOME ECONOMICS' 'COMMUNICATION & MEDIA STUDIES' 'ISLAM']]</code></pre>
      
          <p>__output__ (list):</p>
          <pre><code>['ACCOUNTING', 'AGRICULTURAL SCIENCE', 'AGRO TECHNOLOGY', 'ARABIC', 'ART', 'BIO-RESOURCE TECHNOLOGY', 'BUDDHISM', 'BUDDHIST CIVILIZATION', 'BUSINESS STATISTICS', 'CARNATIC MUSIC', 'CHINESE', 'CHRISTIAN CIVILIZATION', 'CHRISTIANITY', 'CIVIL TECHNOLOGY', 'COMBINED MATHEMATICS', 'COMMUNICATION & MEDIA STUDIES', 'DANCING(BHARATHA)', 'DANCING(INDIGENOUS)', 'DRAMA AND THEATRE (ENGLISH)', 'DRAMA AND THEATRE (SINHALA)', 'DRAMA AND THEATRE (TAMIL)', 'ECONOMICS', 'ELECTRICAL,ELECTRONIC AND IT', 'ENGLISH', 'FOOD TECHNOLOGY', 'FRENCH', 'GEOGRAPHY', 'GERMAN', 'GREEK & ROMAN CIVILIZATION', 'HINDI', 'HINDU CIVILIZATION', 'HINDUISM', 'HISTORY OF EUROPE', 'HISTORY OF INDIA', 'HISTORY OF MODERN WORLD', 'HISTORY OF SRI LANKA & EUROPE', 'HISTORY OF SRI LANKA & INDIA', 'HISTORY OF SRI LANKA & MODERN WORLD', 'HOME ECONOMICS', 'INFORMATION & COMMUNICATION TECHNOLOGY', 'ISLAM', 'ISLAMIC CIVILIZATION', 'JAPANESE', 'LOGIC & SCIENTIFIC METHOD', 'MATHEMATICS', 'MECHANICAL TECHNOLOGY', 'ORIENTAL MUSIC', 'PALI', 'POLITICAL SCIENCE', 'RUSSIAN', 'SANSKRIT', 'SINHALA', 'TAMIL', 'WESTERN MUSIC']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-performance-gce-al-exam-2020-sri-lanka/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the streams taken by students who have ranked within the top 10 in their district?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def to_num2(x):
    try:
        x=int(x)
        return x
    except:
        return np.nan
df['district_rank']=df['district_rank'].apply(to_num2)
list(df[df['district_rank']<=10]['stream'].unique())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def to_num2(x):
    try:
        x=int(x)
        return x
    except:
        return np.nan
df['district_rank']=df['district_rank'].apply(to_num2)
list(df[df['district_rank']<=10]['stream'].unique())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def to_num2(x):
    try:
        x = int(x)
        return x
    except:
        return np.nan


df['district_rank'] = df['district_rank'].apply(to_num2)
__output__ = list(df[df['district_rank'] <= 10]['stream'].unique())
</code></pre>
        <p><span onclick="$('#var_output_10df8fde').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_10df8fde" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>[]</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>stream</th>
      <th>Zscore</th>
      <th>district_rank</th>
      <th>island_rank</th>
      <th>al_year</th>
      <th>sub1</th>
      <th>...</th>
      <th>cgt_r</th>
      <th>ge_r</th>
      <th>syllabus</th>
      <th>birth_day</th>
      <th>birth_month</th>
      <th>birth_year</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>ARTS</td>
      <td>-.3550</td>
      <td>NaN</td>
      <td>64994 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>056</td>
      <td>S</td>
      <td>new</td>
      <td>15.0</td>
      <td>May</td>
      <td>2001</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>ARTS</td>
      <td>-.2648</td>
      <td>NaN</td>
      <td>62338 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>032</td>
      <td>C</td>
      <td>new</td>
      <td>13.0</td>
      <td>January</td>
      <td>2002</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>COMMERCE</td>
      <td>-.4760</td>
      <td>NaN</td>
      <td>37307 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>050</td>
      <td>S</td>
      <td>new</td>
      <td>16.0</td>
      <td>August</td>
      <td>2001</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>COMMERCE</td>
      <td>-.1012</td>
      <td>NaN</td>
      <td>30449 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>034</td>
      <td>S</td>
      <td>new</td>
      <td>16.0</td>
      <td>August</td>
      <td>2001</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>COMMERCE</td>
      <td>.6014</td>
      <td>NaN</td>
      <td>17010 (NEW)</td>
      <td>2020</td>
      <td>ECONOMICS</td>
      <td>...</td>
      <td>036</td>
      <td>S</td>
      <td>new</td>
      <td>7.0</td>
      <td>August</td>
      <td>2000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>ARTS</td>
      <td>-.5061</td>
      <td>NaN</td>
      <td>68521 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>022</td>
      <td>S</td>
      <td>new</td>
      <td>9.0</td>
      <td>January</td>
      <td>2002</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
      <td>ARTS</td>
      <td>.0177</td>
      <td>NaN</td>
      <td>52426 (NEW)</td>
      <td>2020</td>
      <td>POLITICAL SCIENCE</td>
      <td>...</td>
      <td>028</td>
      <td>F</td>
      <td>new</td>
      <td>15.0</td>
      <td>December</td>
      <td>2001</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>337546</th>
      <td>337546</td>
      <td>BIOLOGICAL SCIENCE</td>
      <td>-.0393</td>
      <td>NaN</td>
      <td>4417 (OLD)</td>
      <td>2020</td>
      <td>PHYSICS</td>
      <td>...</td>
      <td>058</td>
      <td>F</td>
      <td>old</td>
      <td>21.0</td>
      <td>September</td>
      <td>1999</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337547</th>
      <td>337547</td>
      <td>ARTS</td>
      <td>-.0586</td>
      <td>NaN</td>
      <td>4438 (OLD)</td>
      <td>2020</td>
      <td>AGRICULTURAL SCIENCE</td>
      <td>...</td>
      <td>043</td>
      <td>C</td>
      <td>old</td>
      <td>22.0</td>
      <td>August</td>
      <td>1995</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337548</th>
      <td>337548</td>
      <td>-</td>
      <td>-</td>
      <td>NaN</td>
      <td>-</td>
      <td>2020</td>
      <td>MATHEMATICS</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>28.0</td>
      <td>October</td>
      <td>1996</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337549</th>
      <td>337549</td>
      <td>ARTS</td>
      <td>-.3467</td>
      <td>NaN</td>
      <td>5184 (OLD)</td>
      <td>2020</td>
      <td>HOME ECONOMICS</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>25.0</td>
      <td>March</td>
      <td>1997</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337550</th>
      <td>337550</td>
      <td>-</td>
      <td>-</td>
      <td>NaN</td>
      <td>-</td>
      <td>2020</td>
      <td>INFORMATION &amp; COMMUNICATION TECHNOLOGY</td>
      <td>...</td>
      <td>055</td>
      <td>B</td>
      <td>old</td>
      <td>11.0</td>
      <td>July</td>
      <td>1999</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337551</th>
      <td>337551</td>
      <td>BIOSYSTEMS TECHNOLOGY</td>
      <td>.0509</td>
      <td>NaN</td>
      <td>366 (OLD)</td>
      <td>2020</td>
      <td>AGRICULTURAL SCIENCE</td>
      <td>...</td>
      <td>Absent</td>
      <td>Absent</td>
      <td>old</td>
      <td>3.0</td>
      <td>September</td>
      <td>1996</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>337552</th>
      <td>337552</td>
      <td>ARTS</td>
      <td>-.1560</td>
      <td>NaN</td>
      <td>4693 (OLD)</td>
      <td>2020</td>
      <td>HOME ECONOMICS</td>
      <td>...</td>
      <td>030</td>
      <td>Absent</td>
      <td>old</td>
      <td>27.0</td>
      <td>April</td>
      <td>1994</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>337553 rows × 19 columns</p>
      
          <p>__output__ (list):</p>
          <pre><code>[]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-performance-gce-al-exam-2020-sri-lanka/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many students were absent in more than one subject?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def sum_1(a,b,c,d):
    all_value=[a,b,c,d]
    sum_value=0
    for i in all_value:
        if i=='Absent':
            sum_value+=1    
    if sum_value>1:
        return True

df.apply(lambda row: sum_1(row['sub1_r'], row['sub2_r'],row['sub3_r'],row['ge_r']), axis=1).value_counts().values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def sum_1(a,b,c,d):
    all_value=[a,b,c,d]
    sum_value=0
    for i in all_value:
        if i=='Absent':
            sum_value+=1    
    if sum_value>1:
        return True

df.apply(lambda row: sum_1(row['sub1_r'], row['sub2_r'],row['sub3_r'],row['ge_r']), axis=1).value_counts().values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def sum_1(a, b, c, d):
    all_value = [a, b, c, d]
    sum_value = 0
    for i in all_value:
        if i == 'Absent':
            sum_value += 1
    if sum_value > 1:
        return True


__output__ = df.apply(lambda row: sum_1(row['sub1_r'], row['sub2_r'], row[
    'sub3_r'], row['ge_r']), axis=1).value_counts().values[0]
</code></pre>
        <p><span onclick="$('#var_output_4458998f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4458998f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>44561</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>44561</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> alternative-fuel-vehicles-in-the-us/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many distinct vehicle categories having the word 'Bus' does Ford produce?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>len(df[(df['Category'].str.contains('Bus')) & (df['Manufacturer']=='Ford')]['Category'].unique())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>len(df[(df['Category'].str.contains('Bus')) & (df['Manufacturer']=='Ford')]['Category'].unique())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = len(df[df['Category'].str.contains('Bus') & (df['Manufacturer'
    ] == 'Ford')]['Category'].unique())
</code></pre>
        <p><span onclick="$('#var_output_e547c74c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e547c74c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>2</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>2</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> alternative-fuel-vehicles-in-the-us/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Drop columns with more than 70 percent null values</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>percent_missing = df.isnull().sum() * 100 / len(df)
columns_todrop=list(percent_missing[percent_missing>70].index)
df.drop(columns_todrop,axis=1,inplace=True)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>percent_missing = df.isnull().sum() * 100 / len(df)
columns_todrop=list(percent_missing[percent_missing>70].index)
df.drop(columns_todrop,axis=1,inplace=True)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>percent_missing = df.isnull().sum() * 100 / len(df)
columns_todrop = list(percent_missing[percent_missing > 70].index)
__output__ = df.drop(columns_todrop, axis=1, inplace=True)
</code></pre>
        <p><span onclick="$('#var_output_07b32463').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_07b32463" style="display: none;">
          
        <p><strong>Ref output variables:</strong> df </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Category</th>
      <th>Model</th>
      <th>Model Year</th>
      <th>Manufacturer</th>
      <th>Fuel</th>
      <th>Conventional Fuel Economy City</th>
      <th>Conventional Fuel Economy Highway</th>
      <th>Conventional Fuel Economy Combined</th>
      <th>Transmission Type</th>
      <th>Engine Type</th>
      <th>Engine Size</th>
      <th>Engine Cylinder Count</th>
      <th>Drivetrain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Sedan/Wagon</td>
      <td>NSX</td>
      <td>2022.0</td>
      <td>Acura</td>
      <td>Hybrid Electric</td>
      <td>21.0</td>
      <td>22.0</td>
      <td>21.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>3.5L</td>
      <td>6.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Sedan/Wagon</td>
      <td>A3</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>29.0</td>
      <td>38.0</td>
      <td>32.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>FWD</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Sedan/Wagon</td>
      <td>A3 quattro</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>28.0</td>
      <td>36.0</td>
      <td>31.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sedan/Wagon</td>
      <td>A4 allroad quattro</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>24.0</td>
      <td>30.0</td>
      <td>26.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Sedan/Wagon</td>
      <td>A4 quattro</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>26.0</td>
      <td>34.0</td>
      <td>29.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Sedan/Wagon</td>
      <td>A4 S line quattro</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>24.0</td>
      <td>31.0</td>
      <td>27.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Sedan/Wagon</td>
      <td>A5 Cabriolet quattro</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>23.0</td>
      <td>31.0</td>
      <td>26.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>875</th>
      <td>Street Sweeper</td>
      <td>500x</td>
      <td>NaN</td>
      <td>TYMCO</td>
      <td>CNG - Compressed Natural Gas</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>876</th>
      <td>Street Sweeper</td>
      <td>600</td>
      <td>NaN</td>
      <td>TYMCO</td>
      <td>CNG - Compressed Natural Gas</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>877</th>
      <td>Street Sweeper</td>
      <td>HSP</td>
      <td>NaN</td>
      <td>TYMCO</td>
      <td>CNG - Compressed Natural Gas</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>878</th>
      <td>Step Van</td>
      <td>(various models)</td>
      <td>NaN</td>
      <td>Utilimaster</td>
      <td>Electric</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Automatic</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>879</th>
      <td>Transit Bus</td>
      <td>CX45E</td>
      <td>NaN</td>
      <td>Van Hool</td>
      <td>Electric</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>880</th>
      <td>Tractor</td>
      <td>VNR Electric - Class 8</td>
      <td>NaN</td>
      <td>Volvo</td>
      <td>Electric</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>881</th>
      <td>Step Van</td>
      <td>C-Series</td>
      <td>NaN</td>
      <td>Workhorse</td>
      <td>Electric</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Automatic</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>882 rows × 13 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, percent_missing, columns_todrop </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Category</th>
      <th>Model</th>
      <th>Model Year</th>
      <th>Manufacturer</th>
      <th>Fuel</th>
      <th>Conventional Fuel Economy City</th>
      <th>Conventional Fuel Economy Highway</th>
      <th>Conventional Fuel Economy Combined</th>
      <th>Transmission Type</th>
      <th>Engine Type</th>
      <th>Engine Size</th>
      <th>Engine Cylinder Count</th>
      <th>Drivetrain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Sedan/Wagon</td>
      <td>NSX</td>
      <td>2022.0</td>
      <td>Acura</td>
      <td>Hybrid Electric</td>
      <td>21.0</td>
      <td>22.0</td>
      <td>21.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>3.5L</td>
      <td>6.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Sedan/Wagon</td>
      <td>A3</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>29.0</td>
      <td>38.0</td>
      <td>32.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>FWD</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Sedan/Wagon</td>
      <td>A3 quattro</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>28.0</td>
      <td>36.0</td>
      <td>31.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sedan/Wagon</td>
      <td>A4 allroad quattro</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>24.0</td>
      <td>30.0</td>
      <td>26.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Sedan/Wagon</td>
      <td>A4 quattro</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>26.0</td>
      <td>34.0</td>
      <td>29.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Sedan/Wagon</td>
      <td>A4 S line quattro</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>24.0</td>
      <td>31.0</td>
      <td>27.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Sedan/Wagon</td>
      <td>A5 Cabriolet quattro</td>
      <td>2022.0</td>
      <td>Audi</td>
      <td>Hybrid Electric</td>
      <td>23.0</td>
      <td>31.0</td>
      <td>26.0</td>
      <td>Auto</td>
      <td>SI</td>
      <td>2.0L</td>
      <td>4.0</td>
      <td>AWD</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>875</th>
      <td>Street Sweeper</td>
      <td>500x</td>
      <td>NaN</td>
      <td>TYMCO</td>
      <td>CNG - Compressed Natural Gas</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>876</th>
      <td>Street Sweeper</td>
      <td>600</td>
      <td>NaN</td>
      <td>TYMCO</td>
      <td>CNG - Compressed Natural Gas</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>877</th>
      <td>Street Sweeper</td>
      <td>HSP</td>
      <td>NaN</td>
      <td>TYMCO</td>
      <td>CNG - Compressed Natural Gas</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>878</th>
      <td>Step Van</td>
      <td>(various models)</td>
      <td>NaN</td>
      <td>Utilimaster</td>
      <td>Electric</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Automatic</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>879</th>
      <td>Transit Bus</td>
      <td>CX45E</td>
      <td>NaN</td>
      <td>Van Hool</td>
      <td>Electric</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>880</th>
      <td>Tractor</td>
      <td>VNR Electric - Class 8</td>
      <td>NaN</td>
      <td>Volvo</td>
      <td>Electric</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>881</th>
      <td>Step Van</td>
      <td>C-Series</td>
      <td>NaN</td>
      <td>Workhorse</td>
      <td>Electric</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Automatic</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>882 rows × 13 columns</p>
      
          <p>percent_missing (Series):</p>
          <pre><code>Category                    0.000000
Model                       0.000000
Model Year                 32.653061
Manufacturer                0.000000
Fuel                        0.000000
                             ...    
Engine Cylinder Count      49.092971
Number of Passengers       86.281179
Heavy-Duty Power System    72.222222
Notes                      79.705215
Drivetrain                 62.698413
Length: 22, dtype: float64</code></pre>
      
          <p>columns_todrop (list):</p>
          <pre><code>['All-Electric Range', 'PHEV Total Range', 'Alternative Fuel Economy City', 'Alternative Fuel Economy Highway', 'Alternative Fuel Economy Combined', 'Transmission Make', 'Number of Passengers', 'Heavy-Duty Power System', 'Notes']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('df', 'df', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> alternative-fuel-vehicles-in-the-us/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many models does each manufacturer have for each year? (Years as index, Manufacturer as columns and fill null values with zeros)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.pivot_table(df,index='Model Year',columns="Manufacturer",aggfunc=np.count_nonzero,fill_value=0)['Category']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.pivot_table(df,index='Model Year',columns="Manufacturer",aggfunc=np.count_nonzero,fill_value=0)['Category']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.pivot_table(df, index='Model Year', columns='Manufacturer',
    aggfunc=np.count_nonzero, fill_value=0)['Category']
</code></pre>
        <p><span onclick="$('#var_output_a7443853').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a7443853" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Manufacturer</th>
      <th>Acura</th>
      <th>Audi</th>
      <th>BMW</th>
      <th>Bentley Motors</th>
      <th>Cadillac</th>
      <th>Chevrolet</th>
      <th>Chrysler</th>
      <th>...</th>
      <th>Ram</th>
      <th>Rivian</th>
      <th>Subaru</th>
      <th>Tesla</th>
      <th>Toyota</th>
      <th>Volkswagen</th>
      <th>Volvo</th>
    </tr>
    <tr>
      <th>Model Year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2021.0</th>
      <td>1</td>
      <td>28</td>
      <td>22</td>
      <td>1</td>
      <td>2</td>
      <td>12</td>
      <td>1</td>
      <td>...</td>
      <td>5</td>
      <td>0</td>
      <td>1</td>
      <td>11</td>
      <td>19</td>
      <td>5</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2022.0</th>
      <td>1</td>
      <td>37</td>
      <td>28</td>
      <td>1</td>
      <td>2</td>
      <td>16</td>
      <td>1</td>
      <td>...</td>
      <td>5</td>
      <td>2</td>
      <td>0</td>
      <td>13</td>
      <td>22</td>
      <td>4</td>
      <td>12</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 35 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Manufacturer</th>
      <th>Acura</th>
      <th>Audi</th>
      <th>BMW</th>
      <th>Bentley Motors</th>
      <th>Cadillac</th>
      <th>Chevrolet</th>
      <th>Chrysler</th>
      <th>...</th>
      <th>Ram</th>
      <th>Rivian</th>
      <th>Subaru</th>
      <th>Tesla</th>
      <th>Toyota</th>
      <th>Volkswagen</th>
      <th>Volvo</th>
    </tr>
    <tr>
      <th>Model Year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2021.0</th>
      <td>1</td>
      <td>28</td>
      <td>22</td>
      <td>1</td>
      <td>2</td>
      <td>12</td>
      <td>1</td>
      <td>...</td>
      <td>5</td>
      <td>0</td>
      <td>1</td>
      <td>11</td>
      <td>19</td>
      <td>5</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2022.0</th>
      <td>1</td>
      <td>37</td>
      <td>28</td>
      <td>1</td>
      <td>2</td>
      <td>16</td>
      <td>1</td>
      <td>...</td>
      <td>5</td>
      <td>2</td>
      <td>0</td>
      <td>13</td>
      <td>22</td>
      <td>4</td>
      <td>12</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 35 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> alternative-fuel-vehicles-in-the-us/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For the different categories of hybrid electrical vehicles, what are the average combined fuel economy? (Sorted from the highest to the lowest)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['Fuel']=='Hybrid Electric'].groupby('Category').mean()['Conventional Fuel Economy Combined'].sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['Fuel']=='Hybrid Electric'].groupby('Category').mean()['Conventional Fuel Economy Combined'].sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['Fuel'] == 'Hybrid Electric'].groupby('Category').mean()[
    'Conventional Fuel Economy Combined'].sort_values(ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_fe0bd146').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_fe0bd146" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Category
Van                          35.333333
Sedan/Wagon                  32.786667
SUV                          24.076190
Pickup                       22.444444
Passenger Van/Shuttle Bus          NaN
Vocational/Cab Chassis             NaN
Name: Conventional Fuel Economy Combined, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Category
Van                          35.333333
Sedan/Wagon                  32.786667
SUV                          24.076190
Pickup                       22.444444
Passenger Van/Shuttle Bus          NaN
Vocational/Cab Chassis             NaN
Name: Conventional Fuel Economy Combined, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> alternative-fuel-vehicles-in-the-us/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many models did Audi manufacture in 2022 for each drivetrain?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['Manufacturer']=='Audi')& (df['Model Year']==2022.0)].groupby('Drivetrain').count()['Model']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['Manufacturer']=='Audi')& (df['Model Year']==2022.0)].groupby('Drivetrain').count()['Model']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['Manufacturer'] == 'Audi') & (df['Model Year'] == 2022.0)
    ].groupby('Drivetrain').count()['Model']
</code></pre>
        <p><span onclick="$('#var_output_be0bfd9c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_be0bfd9c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Drivetrain
AWD    36
FWD     1
Name: Model, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Drivetrain
AWD    36
FWD     1
Name: Model, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> alternative-fuel-vehicles-in-the-us/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many toyota models have a six-cylinder engine?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(df[df['Manufacturer']=='Toyota']['Engine Cylinder Count']==6).value_counts()[1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(df[df['Manufacturer']=='Toyota']['Engine Cylinder Count']==6).value_counts()[1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = (df[df['Manufacturer'] == 'Toyota']['Engine Cylinder Count'] == 6
    ).value_counts()[1]
</code></pre>
        <p><span onclick="$('#var_output_bd4e7e62').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bd4e7e62" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>3</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>3</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> alternative-fuel-vehicles-in-the-us/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many quattro models have Audi produced thus far?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>len(df[df['Model'].str.contains('quattro') & (df['Manufacturer']=='Audi')]['Model'].unique())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>len(df[df['Model'].str.contains('quattro') & (df['Manufacturer']=='Audi')]['Model'].unique())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = len(df[df['Model'].str.contains('quattro') & (df[
    'Manufacturer'] == 'Audi')]['Model'].unique())
</code></pre>
        <p><span onclick="$('#var_output_fa370769').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_fa370769" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>24</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>24</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> alternative-fuel-vehicles-in-the-us/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common type of engine used in the production of automatic vans?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['Category']=='Van') & (df['Transmission Type']=='Auto')]['Engine Type'].value_counts().index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['Category']=='Van') & (df['Transmission Type']=='Auto')]['Engine Type'].value_counts().index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['Category'] == 'Van') & (df['Transmission Type'] == 'Auto')
    ]['Engine Type'].value_counts().index[0]
</code></pre>
        <p><span onclick="$('#var_output_f58f872e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f58f872e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>SI</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>SI</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> amazon-seller-order-status-prediction/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many items purchased within the month of November were returned to seller?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def months(x):
    x=x.split(',')[1][-3:]
    return x
df['Month']=df['order_date'].apply(months)
len(df[(df['Month']=='Nov') & (df['order_status']=='Returned to seller')])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def months(x):
    x=x.split(',')[1][-3:]
    return x
df['Month']=df['order_date'].apply(months)
len(df[(df['Month']=='Nov') & (df['order_status']=='Returned to seller')])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def months(x):
    x = x.split(',')[1][-3:]
    return x


df['Month'] = df['order_date'].apply(months)
__output__ = len(df[(df['Month'] == 'Nov') & (df['order_status'] ==
    'Returned to seller')])
</code></pre>
        <p><span onclick="$('#var_output_7fd33c0b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7fd33c0b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>2</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_no</th>
      <th>order_date</th>
      <th>buyer</th>
      <th>ship_city</th>
      <th>ship_state</th>
      <th>sku</th>
      <th>description</th>
      <th>quantity</th>
      <th>item_total</th>
      <th>shipping_fee</th>
      <th>cod</th>
      <th>order_status</th>
      <th>Month</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>405-9763961-5211537</td>
      <td>Sun, 18 Jul, 2021, 10:38 pm IST</td>
      <td>Mr.</td>
      <td>CHANDIGARH,</td>
      <td>CHANDIGARH</td>
      <td>SKU:  2X-3C0F-KNJE</td>
      <td>100% Leather Elephant Shaped Piggy Coin Bank | Block Printed West Bengal Handicrafts (Shantiniketan Art) | Money Bank for Kids | Children's Gift Ideas</td>
      <td>1</td>
      <td>₹449.00</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Jul</td>
    </tr>
    <tr>
      <th>1</th>
      <td>404-3964908-7850720</td>
      <td>Tue, 19 Oct, 2021, 6:05 pm IST</td>
      <td>Minam</td>
      <td>PASIGHAT,</td>
      <td>ARUNACHAL PRADESH</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>1</td>
      <td>₹449.00</td>
      <td>₹60.18</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Oct</td>
    </tr>
    <tr>
      <th>2</th>
      <td>171-8103182-4289117</td>
      <td>Sun, 28 Nov, 2021, 10:20 pm IST</td>
      <td>yatipertin</td>
      <td>PASIGHAT,</td>
      <td>ARUNACHAL PRADESH</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>1</td>
      <td>₹449.00</td>
      <td>₹60.18</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Nov</td>
    </tr>
    <tr>
      <th>3</th>
      <td>405-3171677-9557154</td>
      <td>Wed, 28 Jul, 2021, 4:06 am IST</td>
      <td>aciya</td>
      <td>DEVARAKONDA,</td>
      <td>TELANGANA</td>
      <td>SKU:  AH-J3AO-R7DN</td>
      <td>Pure 100% Leather Block Print Rectangular Jewelry Box with Mirror | Button Closure Multiple Utility Case (Shantiniketan Handicrafts) (Yellow)</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Jul</td>
    </tr>
    <tr>
      <th>4</th>
      <td>402-8910771-1215552</td>
      <td>Tue, 28 Sept, 2021, 2:50 pm IST</td>
      <td>Susmita</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  KL-7WAA-Z82I</td>
      <td>Pure Leather Sling Bag with Multiple Pockets and Adjustable Strap | Shantiniketan Block Print Cross-Body Bags for Women (1 pc) (Brown)</td>
      <td>1</td>
      <td>₹1,099.00</td>
      <td>₹84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>ept</td>
    </tr>
    <tr>
      <th>5</th>
      <td>406-9292208-6725123</td>
      <td>Thu, 17 Jun, 2021, 9:12 pm IST</td>
      <td>Subinita</td>
      <td>HOWRAH,</td>
      <td>WEST BENGAL</td>
      <td>SKU:  HH-FOWV-5YWO</td>
      <td>Women's Trendy Pure Leather Clutch Purse | Leather Zipper Wallet</td>
      <td>1</td>
      <td>₹200.00</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Jun</td>
    </tr>
    <tr>
      <th>6</th>
      <td>404-5794317-7737924</td>
      <td>Thu, 12 Aug, 2021, 8:03 pm IST</td>
      <td>shailendra</td>
      <td>ORAI,</td>
      <td>UTTAR PRADESH</td>
      <td>SKU:  TQ-OE6K-9DIK</td>
      <td>Ultra Slim 100% Pure Leather Men's Wallet with Cash, Card and Coin Compartments | Jet Black Gent's Money Organizer with Cover (1 pc)</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Cash On Delivery</td>
      <td>Returned to seller</td>
      <td>Aug</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>164</th>
      <td>402-8044719-8889119</td>
      <td>Sat, 4 Dec, 2021, 10:28 pm IST</td>
      <td>Swathi</td>
      <td>Visakhapatnam,</td>
      <td>Andhra Pradesh</td>
      <td>SKU:  3F-4R9N-Z8NJ</td>
      <td>Set of 2 Pure Leather Block Print Round Jewelry Boxes | Button Closure Multiple Utility Case (Shantiniketan Handicrafts) (Yellow)</td>
      <td>1</td>
      <td>₹399.00</td>
      <td>₹84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>165</th>
      <td>402-1808225-2809140</td>
      <td>Sat, 25 Dec, 2021, 4:03 pm IST</td>
      <td>User</td>
      <td>Solan,</td>
      <td>Himachal Pradesh</td>
      <td>SKU:  S1-A92Q-JU3X</td>
      <td>100% Pure Leather Shantiniketan Clutch Purse: Traditional Block Print Bi-color Women's Wallets with Multiple Pockets and Zipper Compartments (1 pc) (G</td>
      <td>1</td>
      <td>₹399.00</td>
      <td>₹84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>166</th>
      <td>171-2829978-1258758</td>
      <td>Mon, 13 Dec, 2021, 11:30 am IST</td>
      <td>Shahin</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>3</td>
      <td>₹1,347.00</td>
      <td>₹84.96</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>167</th>
      <td>402-3045457-5360311</td>
      <td>Wed, 1 Dec, 2021, 12:18 pm IST</td>
      <td>Sharmistha</td>
      <td>DEHRADUN,</td>
      <td>UTTARAKHAND</td>
      <td>SKU:  SB-WDQN-SDN9</td>
      <td>Traditional Block-Printed Women's 100% Pure Leather Shoulder Bag: Double Handle Red Handbag | Multi-pocket Shantiniketan Leather Bag for Women</td>
      <td>1</td>
      <td>₹1,299.00</td>
      <td>₹114.46</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>168</th>
      <td>408-2260162-8323567</td>
      <td>Thu, 9 Dec, 2021, 6:55 pm IST</td>
      <td>shashank</td>
      <td>Durg,</td>
      <td>CHHATTISGARH</td>
      <td>SKU:  SB-WDQN-SDN9</td>
      <td>Traditional Block-Printed Women's 100% Pure Leather Shoulder Bag: Double Handle Red Handbag | Multi-pocket Shantiniketan Leather Bag for Women</td>
      <td>1</td>
      <td>₹1,299.00</td>
      <td>₹105.02</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>169</th>
      <td>403-5664951-8941100</td>
      <td>Wed, 23 Feb, 2022, 12:43 am IST</td>
      <td>Jayeta</td>
      <td>KOLKATA,</td>
      <td>WEST BENGAL</td>
      <td>SKU:  N8-YFZF-P74I</td>
      <td>Stylish and Sleek Multiple Pockets 100 Percent Leather Shoulder Bag Contemporary Indian Leather Handicrafts for Women (Yellow) (BL335)</td>
      <td>1</td>
      <td>₹1,499.00</td>
      <td>₹80.24</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Feb</td>
    </tr>
    <tr>
      <th>170</th>
      <td>402-4845680-8041921</td>
      <td>Sun, 26 Dec, 2021, 6:21 pm IST</td>
      <td>Varun</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  2X-3C0F-KNJE</td>
      <td>100% Leather Elephant Shaped Piggy Coin Bank | Block Printed West Bengal Handicrafts (Shantiniketan Art) | Money Bank for Kids | Children's Gift Ideas</td>
      <td>1</td>
      <td>₹449.00</td>
      <td>₹84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
  </tbody>
</table>
<p>171 rows × 13 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>2</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> amazon-seller-order-status-prediction/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert item total column from string to float</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def total_float(price):
    try:
        return float(price.strip('₹').strip(',').replace(',',""))
    except:
        try:
            return float(price)
        except:
            return np.NaN
df['item_total']=df['item_total'].apply(total_float)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def total_float(price):
    try:
        return float(price.strip('₹').strip(',').replace(',',""))
    except:
        try:
            return float(price)
        except:
            return np.NaN
df['item_total']=df['item_total'].apply(total_float)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def total_float(price):
    try:
        return float(price.strip('₹').strip(',').replace(',', ''))
    except:
        try:
            return float(price)
        except:
            return np.NaN


__output__ = df['item_total'] = df['item_total'].apply(total_float)
</code></pre>
        <p><span onclick="$('#var_output_2bfd1a64').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2bfd1a64" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0       449.0
1       449.0
2       449.0
3         NaN
4      1099.0
        ...  
166    1347.0
167    1299.0
168    1299.0
169    1499.0
170     449.0
Name: item_total, Length: 171, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_no</th>
      <th>order_date</th>
      <th>buyer</th>
      <th>ship_city</th>
      <th>ship_state</th>
      <th>sku</th>
      <th>description</th>
      <th>quantity</th>
      <th>item_total</th>
      <th>shipping_fee</th>
      <th>cod</th>
      <th>order_status</th>
      <th>Month</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>405-9763961-5211537</td>
      <td>Sun, 18 Jul, 2021, 10:38 pm IST</td>
      <td>Mr.</td>
      <td>CHANDIGARH,</td>
      <td>CHANDIGARH</td>
      <td>SKU:  2X-3C0F-KNJE</td>
      <td>100% Leather Elephant Shaped Piggy Coin Bank | Block Printed West Bengal Handicrafts (Shantiniketan Art) | Money Bank for Kids | Children's Gift Ideas</td>
      <td>1</td>
      <td>449.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Jul</td>
    </tr>
    <tr>
      <th>1</th>
      <td>404-3964908-7850720</td>
      <td>Tue, 19 Oct, 2021, 6:05 pm IST</td>
      <td>Minam</td>
      <td>PASIGHAT,</td>
      <td>ARUNACHAL PRADESH</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>1</td>
      <td>449.0</td>
      <td>₹60.18</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Oct</td>
    </tr>
    <tr>
      <th>2</th>
      <td>171-8103182-4289117</td>
      <td>Sun, 28 Nov, 2021, 10:20 pm IST</td>
      <td>yatipertin</td>
      <td>PASIGHAT,</td>
      <td>ARUNACHAL PRADESH</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>1</td>
      <td>449.0</td>
      <td>₹60.18</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Nov</td>
    </tr>
    <tr>
      <th>3</th>
      <td>405-3171677-9557154</td>
      <td>Wed, 28 Jul, 2021, 4:06 am IST</td>
      <td>aciya</td>
      <td>DEVARAKONDA,</td>
      <td>TELANGANA</td>
      <td>SKU:  AH-J3AO-R7DN</td>
      <td>Pure 100% Leather Block Print Rectangular Jewelry Box with Mirror | Button Closure Multiple Utility Case (Shantiniketan Handicrafts) (Yellow)</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Jul</td>
    </tr>
    <tr>
      <th>4</th>
      <td>402-8910771-1215552</td>
      <td>Tue, 28 Sept, 2021, 2:50 pm IST</td>
      <td>Susmita</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  KL-7WAA-Z82I</td>
      <td>Pure Leather Sling Bag with Multiple Pockets and Adjustable Strap | Shantiniketan Block Print Cross-Body Bags for Women (1 pc) (Brown)</td>
      <td>1</td>
      <td>1099.0</td>
      <td>₹84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>ept</td>
    </tr>
    <tr>
      <th>5</th>
      <td>406-9292208-6725123</td>
      <td>Thu, 17 Jun, 2021, 9:12 pm IST</td>
      <td>Subinita</td>
      <td>HOWRAH,</td>
      <td>WEST BENGAL</td>
      <td>SKU:  HH-FOWV-5YWO</td>
      <td>Women's Trendy Pure Leather Clutch Purse | Leather Zipper Wallet</td>
      <td>1</td>
      <td>200.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Jun</td>
    </tr>
    <tr>
      <th>6</th>
      <td>404-5794317-7737924</td>
      <td>Thu, 12 Aug, 2021, 8:03 pm IST</td>
      <td>shailendra</td>
      <td>ORAI,</td>
      <td>UTTAR PRADESH</td>
      <td>SKU:  TQ-OE6K-9DIK</td>
      <td>Ultra Slim 100% Pure Leather Men's Wallet with Cash, Card and Coin Compartments | Jet Black Gent's Money Organizer with Cover (1 pc)</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Cash On Delivery</td>
      <td>Returned to seller</td>
      <td>Aug</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>164</th>
      <td>402-8044719-8889119</td>
      <td>Sat, 4 Dec, 2021, 10:28 pm IST</td>
      <td>Swathi</td>
      <td>Visakhapatnam,</td>
      <td>Andhra Pradesh</td>
      <td>SKU:  3F-4R9N-Z8NJ</td>
      <td>Set of 2 Pure Leather Block Print Round Jewelry Boxes | Button Closure Multiple Utility Case (Shantiniketan Handicrafts) (Yellow)</td>
      <td>1</td>
      <td>399.0</td>
      <td>₹84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>165</th>
      <td>402-1808225-2809140</td>
      <td>Sat, 25 Dec, 2021, 4:03 pm IST</td>
      <td>User</td>
      <td>Solan,</td>
      <td>Himachal Pradesh</td>
      <td>SKU:  S1-A92Q-JU3X</td>
      <td>100% Pure Leather Shantiniketan Clutch Purse: Traditional Block Print Bi-color Women's Wallets with Multiple Pockets and Zipper Compartments (1 pc) (G</td>
      <td>1</td>
      <td>399.0</td>
      <td>₹84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>166</th>
      <td>171-2829978-1258758</td>
      <td>Mon, 13 Dec, 2021, 11:30 am IST</td>
      <td>Shahin</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>3</td>
      <td>1347.0</td>
      <td>₹84.96</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>167</th>
      <td>402-3045457-5360311</td>
      <td>Wed, 1 Dec, 2021, 12:18 pm IST</td>
      <td>Sharmistha</td>
      <td>DEHRADUN,</td>
      <td>UTTARAKHAND</td>
      <td>SKU:  SB-WDQN-SDN9</td>
      <td>Traditional Block-Printed Women's 100% Pure Leather Shoulder Bag: Double Handle Red Handbag | Multi-pocket Shantiniketan Leather Bag for Women</td>
      <td>1</td>
      <td>1299.0</td>
      <td>₹114.46</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>168</th>
      <td>408-2260162-8323567</td>
      <td>Thu, 9 Dec, 2021, 6:55 pm IST</td>
      <td>shashank</td>
      <td>Durg,</td>
      <td>CHHATTISGARH</td>
      <td>SKU:  SB-WDQN-SDN9</td>
      <td>Traditional Block-Printed Women's 100% Pure Leather Shoulder Bag: Double Handle Red Handbag | Multi-pocket Shantiniketan Leather Bag for Women</td>
      <td>1</td>
      <td>1299.0</td>
      <td>₹105.02</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>169</th>
      <td>403-5664951-8941100</td>
      <td>Wed, 23 Feb, 2022, 12:43 am IST</td>
      <td>Jayeta</td>
      <td>KOLKATA,</td>
      <td>WEST BENGAL</td>
      <td>SKU:  N8-YFZF-P74I</td>
      <td>Stylish and Sleek Multiple Pockets 100 Percent Leather Shoulder Bag Contemporary Indian Leather Handicrafts for Women (Yellow) (BL335)</td>
      <td>1</td>
      <td>1499.0</td>
      <td>₹80.24</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Feb</td>
    </tr>
    <tr>
      <th>170</th>
      <td>402-4845680-8041921</td>
      <td>Sun, 26 Dec, 2021, 6:21 pm IST</td>
      <td>Varun</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  2X-3C0F-KNJE</td>
      <td>100% Leather Elephant Shaped Piggy Coin Bank | Block Printed West Bengal Handicrafts (Shantiniketan Art) | Money Bank for Kids | Children's Gift Ideas</td>
      <td>1</td>
      <td>449.0</td>
      <td>₹84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
  </tbody>
</table>
<p>171 rows × 13 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0       449.0
1       449.0
2       449.0
3         NaN
4      1099.0
        ...  
166    1347.0
167    1299.0
168    1299.0
169    1499.0
170     449.0
Name: item_total, Length: 171, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> amazon-seller-order-status-prediction/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average price for leather wallets?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['description'].str.lower().str.contains('wallet') & df['description'].str.lower().str.contains('leather')]['item_total'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['description'].str.lower().str.contains('wallet') & df['description'].str.lower().str.contains('leather')]['item_total'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['description'].str.lower().str.contains('wallet') & df[
    'description'].str.lower().str.contains('leather')]['item_total'].mean()
</code></pre>
        <p><span onclick="$('#var_output_38d09102').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_38d09102" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>442.7916666666667</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>442.7916666666667</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> amazon-seller-order-status-prediction/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # In what distinct years have the orders been placed in?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>list(pd.to_datetime(df['order_date'].map(lambda x: x[:-4])).dt.year.unique())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>list(pd.to_datetime(df['order_date'].map(lambda x: x[:-4])).dt.year.unique())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = list(pd.to_datetime(df['order_date'].map(lambda x: x[:-4])).dt
    .year.unique())
</code></pre>
        <p><span onclick="$('#var_output_eb88a179').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_eb88a179" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>[2021, 2022]</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>[2021, 2022]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> amazon-seller-order-status-prediction/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What item is sold the most?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['sku']==df['sku'].value_counts(ascending=False).index[0]]['description'].values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['sku']==df['sku'].value_counts(ascending=False).index[0]]['description'].values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['sku'] == df['sku'].value_counts(ascending=False).index[0]][
    'description'].values[0]
</code></pre>
        <p><span onclick="$('#var_output_02955b3f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_02955b3f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> amazon-seller-order-status-prediction/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the city that had cash on delivery as the most common payment method?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby('ship_city').count()['cod'].sort_values(ascending=False).index[0][:-1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby('ship_city').count()['cod'].sort_values(ascending=False).index[0][:-1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('ship_city').count()['cod'].sort_values(ascending=False
    ).index[0][:-1]
</code></pre>
        <p><span onclick="$('#var_output_2e0f1b02').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2e0f1b02" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>MUMBAI</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>MUMBAI</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> amazon-seller-order-status-prediction/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the average shipping fees for each state, starting from highest to lowest? (rounded to 2 decimal places)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['shipping_fee']=df['shipping_fee'].apply(total_float)
df.groupby('ship_state').mean()['shipping_fee'].sort_values(ascending=False).round(2)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['shipping_fee']=df['shipping_fee'].apply(total_float)
df.groupby('ship_state').mean()['shipping_fee'].sort_values(ascending=False).round(2)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['shipping_fee'] = df['shipping_fee'].apply(total_float)
__output__ = df.groupby('ship_state').mean()['shipping_fee'].sort_values(
    ascending=False).round(2)
</code></pre>
        <p><span onclick="$('#var_output_0dce5fb7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0dce5fb7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>ship_state
RAJASTHAN            126.65
KERALA               126.65
UTTARAKHAND          114.46
GUJARAT              103.60
TAMIL NADU            99.03
                      ...  
ARUNACHAL PRADESH     60.18
Odisha                60.18
ODISHA                60.18
TRIPURA               60.18
WEST BENGAL           59.35
Name: shipping_fee, Length: 30, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_no</th>
      <th>order_date</th>
      <th>buyer</th>
      <th>ship_city</th>
      <th>ship_state</th>
      <th>sku</th>
      <th>description</th>
      <th>quantity</th>
      <th>item_total</th>
      <th>shipping_fee</th>
      <th>cod</th>
      <th>order_status</th>
      <th>Month</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>405-9763961-5211537</td>
      <td>Sun, 18 Jul, 2021, 10:38 pm IST</td>
      <td>Mr.</td>
      <td>CHANDIGARH,</td>
      <td>CHANDIGARH</td>
      <td>SKU:  2X-3C0F-KNJE</td>
      <td>100% Leather Elephant Shaped Piggy Coin Bank | Block Printed West Bengal Handicrafts (Shantiniketan Art) | Money Bank for Kids | Children's Gift Ideas</td>
      <td>1</td>
      <td>449.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Jul</td>
    </tr>
    <tr>
      <th>1</th>
      <td>404-3964908-7850720</td>
      <td>Tue, 19 Oct, 2021, 6:05 pm IST</td>
      <td>Minam</td>
      <td>PASIGHAT,</td>
      <td>ARUNACHAL PRADESH</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>1</td>
      <td>449.0</td>
      <td>60.18</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Oct</td>
    </tr>
    <tr>
      <th>2</th>
      <td>171-8103182-4289117</td>
      <td>Sun, 28 Nov, 2021, 10:20 pm IST</td>
      <td>yatipertin</td>
      <td>PASIGHAT,</td>
      <td>ARUNACHAL PRADESH</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>1</td>
      <td>449.0</td>
      <td>60.18</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Nov</td>
    </tr>
    <tr>
      <th>3</th>
      <td>405-3171677-9557154</td>
      <td>Wed, 28 Jul, 2021, 4:06 am IST</td>
      <td>aciya</td>
      <td>DEVARAKONDA,</td>
      <td>TELANGANA</td>
      <td>SKU:  AH-J3AO-R7DN</td>
      <td>Pure 100% Leather Block Print Rectangular Jewelry Box with Mirror | Button Closure Multiple Utility Case (Shantiniketan Handicrafts) (Yellow)</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Jul</td>
    </tr>
    <tr>
      <th>4</th>
      <td>402-8910771-1215552</td>
      <td>Tue, 28 Sept, 2021, 2:50 pm IST</td>
      <td>Susmita</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  KL-7WAA-Z82I</td>
      <td>Pure Leather Sling Bag with Multiple Pockets and Adjustable Strap | Shantiniketan Block Print Cross-Body Bags for Women (1 pc) (Brown)</td>
      <td>1</td>
      <td>1099.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>ept</td>
    </tr>
    <tr>
      <th>5</th>
      <td>406-9292208-6725123</td>
      <td>Thu, 17 Jun, 2021, 9:12 pm IST</td>
      <td>Subinita</td>
      <td>HOWRAH,</td>
      <td>WEST BENGAL</td>
      <td>SKU:  HH-FOWV-5YWO</td>
      <td>Women's Trendy Pure Leather Clutch Purse | Leather Zipper Wallet</td>
      <td>1</td>
      <td>200.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Jun</td>
    </tr>
    <tr>
      <th>6</th>
      <td>404-5794317-7737924</td>
      <td>Thu, 12 Aug, 2021, 8:03 pm IST</td>
      <td>shailendra</td>
      <td>ORAI,</td>
      <td>UTTAR PRADESH</td>
      <td>SKU:  TQ-OE6K-9DIK</td>
      <td>Ultra Slim 100% Pure Leather Men's Wallet with Cash, Card and Coin Compartments | Jet Black Gent's Money Organizer with Cover (1 pc)</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Cash On Delivery</td>
      <td>Returned to seller</td>
      <td>Aug</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>164</th>
      <td>402-8044719-8889119</td>
      <td>Sat, 4 Dec, 2021, 10:28 pm IST</td>
      <td>Swathi</td>
      <td>Visakhapatnam,</td>
      <td>Andhra Pradesh</td>
      <td>SKU:  3F-4R9N-Z8NJ</td>
      <td>Set of 2 Pure Leather Block Print Round Jewelry Boxes | Button Closure Multiple Utility Case (Shantiniketan Handicrafts) (Yellow)</td>
      <td>1</td>
      <td>399.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>165</th>
      <td>402-1808225-2809140</td>
      <td>Sat, 25 Dec, 2021, 4:03 pm IST</td>
      <td>User</td>
      <td>Solan,</td>
      <td>Himachal Pradesh</td>
      <td>SKU:  S1-A92Q-JU3X</td>
      <td>100% Pure Leather Shantiniketan Clutch Purse: Traditional Block Print Bi-color Women's Wallets with Multiple Pockets and Zipper Compartments (1 pc) (G</td>
      <td>1</td>
      <td>399.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>166</th>
      <td>171-2829978-1258758</td>
      <td>Mon, 13 Dec, 2021, 11:30 am IST</td>
      <td>Shahin</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>3</td>
      <td>1347.0</td>
      <td>84.96</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>167</th>
      <td>402-3045457-5360311</td>
      <td>Wed, 1 Dec, 2021, 12:18 pm IST</td>
      <td>Sharmistha</td>
      <td>DEHRADUN,</td>
      <td>UTTARAKHAND</td>
      <td>SKU:  SB-WDQN-SDN9</td>
      <td>Traditional Block-Printed Women's 100% Pure Leather Shoulder Bag: Double Handle Red Handbag | Multi-pocket Shantiniketan Leather Bag for Women</td>
      <td>1</td>
      <td>1299.0</td>
      <td>114.46</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>168</th>
      <td>408-2260162-8323567</td>
      <td>Thu, 9 Dec, 2021, 6:55 pm IST</td>
      <td>shashank</td>
      <td>Durg,</td>
      <td>CHHATTISGARH</td>
      <td>SKU:  SB-WDQN-SDN9</td>
      <td>Traditional Block-Printed Women's 100% Pure Leather Shoulder Bag: Double Handle Red Handbag | Multi-pocket Shantiniketan Leather Bag for Women</td>
      <td>1</td>
      <td>1299.0</td>
      <td>105.02</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
    <tr>
      <th>169</th>
      <td>403-5664951-8941100</td>
      <td>Wed, 23 Feb, 2022, 12:43 am IST</td>
      <td>Jayeta</td>
      <td>KOLKATA,</td>
      <td>WEST BENGAL</td>
      <td>SKU:  N8-YFZF-P74I</td>
      <td>Stylish and Sleek Multiple Pockets 100 Percent Leather Shoulder Bag Contemporary Indian Leather Handicrafts for Women (Yellow) (BL335)</td>
      <td>1</td>
      <td>1499.0</td>
      <td>80.24</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Feb</td>
    </tr>
    <tr>
      <th>170</th>
      <td>402-4845680-8041921</td>
      <td>Sun, 26 Dec, 2021, 6:21 pm IST</td>
      <td>Varun</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  2X-3C0F-KNJE</td>
      <td>100% Leather Elephant Shaped Piggy Coin Bank | Block Printed West Bengal Handicrafts (Shantiniketan Art) | Money Bank for Kids | Children's Gift Ideas</td>
      <td>1</td>
      <td>449.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
    </tr>
  </tbody>
</table>
<p>171 rows × 13 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>ship_state
RAJASTHAN            126.65
KERALA               126.65
UTTARAKHAND          114.46
GUJARAT              103.60
TAMIL NADU            99.03
                      ...  
ARUNACHAL PRADESH     60.18
Odisha                60.18
ODISHA                60.18
TRIPURA               60.18
WEST BENGAL           59.35
Name: shipping_fee, Length: 30, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> amazon-seller-order-status-prediction/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What day of the week has the highest amount of product purchases by customers?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['day_of_week']=df['order_date'].map(lambda x:x[:3])
df.groupby(['day_of_week']).count()['item_total'].sort_values(ascending=False).index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['day_of_week']=df['order_date'].map(lambda x:x[:3])
df.groupby(['day_of_week']).count()['item_total'].sort_values(ascending=False).index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['day_of_week'] = df['order_date'].map(lambda x: x[:3])
__output__ = df.groupby(['day_of_week']).count()['item_total'].sort_values(
    ascending=False).index[0]
</code></pre>
        <p><span onclick="$('#var_output_377631ef').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_377631ef" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Wed</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_no</th>
      <th>order_date</th>
      <th>buyer</th>
      <th>ship_city</th>
      <th>ship_state</th>
      <th>sku</th>
      <th>description</th>
      <th>quantity</th>
      <th>item_total</th>
      <th>shipping_fee</th>
      <th>cod</th>
      <th>order_status</th>
      <th>Month</th>
      <th>day_of_week</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>405-9763961-5211537</td>
      <td>Sun, 18 Jul, 2021, 10:38 pm IST</td>
      <td>Mr.</td>
      <td>CHANDIGARH,</td>
      <td>CHANDIGARH</td>
      <td>SKU:  2X-3C0F-KNJE</td>
      <td>100% Leather Elephant Shaped Piggy Coin Bank | Block Printed West Bengal Handicrafts (Shantiniketan Art) | Money Bank for Kids | Children's Gift Ideas</td>
      <td>1</td>
      <td>449.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Jul</td>
      <td>Sun</td>
    </tr>
    <tr>
      <th>1</th>
      <td>404-3964908-7850720</td>
      <td>Tue, 19 Oct, 2021, 6:05 pm IST</td>
      <td>Minam</td>
      <td>PASIGHAT,</td>
      <td>ARUNACHAL PRADESH</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>1</td>
      <td>449.0</td>
      <td>60.18</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Oct</td>
      <td>Tue</td>
    </tr>
    <tr>
      <th>2</th>
      <td>171-8103182-4289117</td>
      <td>Sun, 28 Nov, 2021, 10:20 pm IST</td>
      <td>yatipertin</td>
      <td>PASIGHAT,</td>
      <td>ARUNACHAL PRADESH</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>1</td>
      <td>449.0</td>
      <td>60.18</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Nov</td>
      <td>Sun</td>
    </tr>
    <tr>
      <th>3</th>
      <td>405-3171677-9557154</td>
      <td>Wed, 28 Jul, 2021, 4:06 am IST</td>
      <td>aciya</td>
      <td>DEVARAKONDA,</td>
      <td>TELANGANA</td>
      <td>SKU:  AH-J3AO-R7DN</td>
      <td>Pure 100% Leather Block Print Rectangular Jewelry Box with Mirror | Button Closure Multiple Utility Case (Shantiniketan Handicrafts) (Yellow)</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Jul</td>
      <td>Wed</td>
    </tr>
    <tr>
      <th>4</th>
      <td>402-8910771-1215552</td>
      <td>Tue, 28 Sept, 2021, 2:50 pm IST</td>
      <td>Susmita</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  KL-7WAA-Z82I</td>
      <td>Pure Leather Sling Bag with Multiple Pockets and Adjustable Strap | Shantiniketan Block Print Cross-Body Bags for Women (1 pc) (Brown)</td>
      <td>1</td>
      <td>1099.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>ept</td>
      <td>Tue</td>
    </tr>
    <tr>
      <th>5</th>
      <td>406-9292208-6725123</td>
      <td>Thu, 17 Jun, 2021, 9:12 pm IST</td>
      <td>Subinita</td>
      <td>HOWRAH,</td>
      <td>WEST BENGAL</td>
      <td>SKU:  HH-FOWV-5YWO</td>
      <td>Women's Trendy Pure Leather Clutch Purse | Leather Zipper Wallet</td>
      <td>1</td>
      <td>200.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Jun</td>
      <td>Thu</td>
    </tr>
    <tr>
      <th>6</th>
      <td>404-5794317-7737924</td>
      <td>Thu, 12 Aug, 2021, 8:03 pm IST</td>
      <td>shailendra</td>
      <td>ORAI,</td>
      <td>UTTAR PRADESH</td>
      <td>SKU:  TQ-OE6K-9DIK</td>
      <td>Ultra Slim 100% Pure Leather Men's Wallet with Cash, Card and Coin Compartments | Jet Black Gent's Money Organizer with Cover (1 pc)</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Cash On Delivery</td>
      <td>Returned to seller</td>
      <td>Aug</td>
      <td>Thu</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>164</th>
      <td>402-8044719-8889119</td>
      <td>Sat, 4 Dec, 2021, 10:28 pm IST</td>
      <td>Swathi</td>
      <td>Visakhapatnam,</td>
      <td>Andhra Pradesh</td>
      <td>SKU:  3F-4R9N-Z8NJ</td>
      <td>Set of 2 Pure Leather Block Print Round Jewelry Boxes | Button Closure Multiple Utility Case (Shantiniketan Handicrafts) (Yellow)</td>
      <td>1</td>
      <td>399.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Sat</td>
    </tr>
    <tr>
      <th>165</th>
      <td>402-1808225-2809140</td>
      <td>Sat, 25 Dec, 2021, 4:03 pm IST</td>
      <td>User</td>
      <td>Solan,</td>
      <td>Himachal Pradesh</td>
      <td>SKU:  S1-A92Q-JU3X</td>
      <td>100% Pure Leather Shantiniketan Clutch Purse: Traditional Block Print Bi-color Women's Wallets with Multiple Pockets and Zipper Compartments (1 pc) (G</td>
      <td>1</td>
      <td>399.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Sat</td>
    </tr>
    <tr>
      <th>166</th>
      <td>171-2829978-1258758</td>
      <td>Mon, 13 Dec, 2021, 11:30 am IST</td>
      <td>Shahin</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>3</td>
      <td>1347.0</td>
      <td>84.96</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Mon</td>
    </tr>
    <tr>
      <th>167</th>
      <td>402-3045457-5360311</td>
      <td>Wed, 1 Dec, 2021, 12:18 pm IST</td>
      <td>Sharmistha</td>
      <td>DEHRADUN,</td>
      <td>UTTARAKHAND</td>
      <td>SKU:  SB-WDQN-SDN9</td>
      <td>Traditional Block-Printed Women's 100% Pure Leather Shoulder Bag: Double Handle Red Handbag | Multi-pocket Shantiniketan Leather Bag for Women</td>
      <td>1</td>
      <td>1299.0</td>
      <td>114.46</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Wed</td>
    </tr>
    <tr>
      <th>168</th>
      <td>408-2260162-8323567</td>
      <td>Thu, 9 Dec, 2021, 6:55 pm IST</td>
      <td>shashank</td>
      <td>Durg,</td>
      <td>CHHATTISGARH</td>
      <td>SKU:  SB-WDQN-SDN9</td>
      <td>Traditional Block-Printed Women's 100% Pure Leather Shoulder Bag: Double Handle Red Handbag | Multi-pocket Shantiniketan Leather Bag for Women</td>
      <td>1</td>
      <td>1299.0</td>
      <td>105.02</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Thu</td>
    </tr>
    <tr>
      <th>169</th>
      <td>403-5664951-8941100</td>
      <td>Wed, 23 Feb, 2022, 12:43 am IST</td>
      <td>Jayeta</td>
      <td>KOLKATA,</td>
      <td>WEST BENGAL</td>
      <td>SKU:  N8-YFZF-P74I</td>
      <td>Stylish and Sleek Multiple Pockets 100 Percent Leather Shoulder Bag Contemporary Indian Leather Handicrafts for Women (Yellow) (BL335)</td>
      <td>1</td>
      <td>1499.0</td>
      <td>80.24</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Feb</td>
      <td>Wed</td>
    </tr>
    <tr>
      <th>170</th>
      <td>402-4845680-8041921</td>
      <td>Sun, 26 Dec, 2021, 6:21 pm IST</td>
      <td>Varun</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  2X-3C0F-KNJE</td>
      <td>100% Leather Elephant Shaped Piggy Coin Bank | Block Printed West Bengal Handicrafts (Shantiniketan Art) | Money Bank for Kids | Children's Gift Ideas</td>
      <td>1</td>
      <td>449.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Sun</td>
    </tr>
  </tbody>
</table>
<p>171 rows × 14 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>Wed</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> amazon-seller-order-status-prediction/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the total purchase value of items for each state per month? (Show state names as index, Months as columns and replace null values with 0)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pd.pivot_table(data=df,values='item_total',index='ship_state',columns='Month',aggfunc=np.sum,fill_value=0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pd.pivot_table(data=df,values='item_total',index='ship_state',columns='Month',aggfunc=np.sum,fill_value=0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = pd.pivot_table(data=df, values='item_total', index=
    'ship_state', columns='Month', aggfunc=np.sum, fill_value=0)
</code></pre>
        <p><span onclick="$('#var_output_b971f68c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b971f68c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Month</th>
      <th>Aug</th>
      <th>Dec</th>
      <th>Feb</th>
      <th>Jan</th>
      <th>Jul</th>
      <th>Jun</th>
      <th>Nov</th>
      <th>Oct</th>
      <th>ept</th>
    </tr>
    <tr>
      <th>ship_state</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ANDHRA PRADESH</th>
      <td>0</td>
      <td>399</td>
      <td>0</td>
      <td>475</td>
      <td>250</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>ARUNACHAL PRADESH</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>449</td>
      <td>449</td>
      <td>0</td>
    </tr>
    <tr>
      <th>ASSAM</th>
      <td>1099</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>899</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Andhra Pradesh</th>
      <td>0</td>
      <td>399</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>BIHAR</th>
      <td>0</td>
      <td>549</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>CHANDIGARH</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>449</td>
      <td>449</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>CHANDIGARH,</th>
      <td>0</td>
      <td>0</td>
      <td>475</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>RAJASTHAN</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>449</td>
      <td>0</td>
      <td>0</td>
      <td>1299</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>TAMIL NADU</th>
      <td>250</td>
      <td>4745</td>
      <td>1948</td>
      <td>874</td>
      <td>998</td>
      <td>624</td>
      <td>898</td>
      <td>449</td>
      <td>399</td>
    </tr>
    <tr>
      <th>TELANGANA</th>
      <td>0</td>
      <td>449</td>
      <td>399</td>
      <td>449</td>
      <td>349</td>
      <td>175</td>
      <td>1197</td>
      <td>449</td>
      <td>1198</td>
    </tr>
    <tr>
      <th>TRIPURA</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>449</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>UTTAR PRADESH</th>
      <td>0</td>
      <td>1748</td>
      <td>1247</td>
      <td>449</td>
      <td>0</td>
      <td>0</td>
      <td>848</td>
      <td>0</td>
      <td>399</td>
    </tr>
    <tr>
      <th>UTTARAKHAND</th>
      <td>0</td>
      <td>1299</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>WEST BENGAL</th>
      <td>250</td>
      <td>6619</td>
      <td>2397</td>
      <td>1124</td>
      <td>0</td>
      <td>200</td>
      <td>399</td>
      <td>1198</td>
      <td>1548</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 9 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Month</th>
      <th>Aug</th>
      <th>Dec</th>
      <th>Feb</th>
      <th>Jan</th>
      <th>Jul</th>
      <th>Jun</th>
      <th>Nov</th>
      <th>Oct</th>
      <th>ept</th>
    </tr>
    <tr>
      <th>ship_state</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ANDHRA PRADESH</th>
      <td>0</td>
      <td>399</td>
      <td>0</td>
      <td>475</td>
      <td>250</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>ARUNACHAL PRADESH</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>449</td>
      <td>449</td>
      <td>0</td>
    </tr>
    <tr>
      <th>ASSAM</th>
      <td>1099</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>899</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Andhra Pradesh</th>
      <td>0</td>
      <td>399</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>BIHAR</th>
      <td>0</td>
      <td>549</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>CHANDIGARH</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>449</td>
      <td>449</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>CHANDIGARH,</th>
      <td>0</td>
      <td>0</td>
      <td>475</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>RAJASTHAN</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>449</td>
      <td>0</td>
      <td>0</td>
      <td>1299</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>TAMIL NADU</th>
      <td>250</td>
      <td>4745</td>
      <td>1948</td>
      <td>874</td>
      <td>998</td>
      <td>624</td>
      <td>898</td>
      <td>449</td>
      <td>399</td>
    </tr>
    <tr>
      <th>TELANGANA</th>
      <td>0</td>
      <td>449</td>
      <td>399</td>
      <td>449</td>
      <td>349</td>
      <td>175</td>
      <td>1197</td>
      <td>449</td>
      <td>1198</td>
    </tr>
    <tr>
      <th>TRIPURA</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>449</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>UTTAR PRADESH</th>
      <td>0</td>
      <td>1748</td>
      <td>1247</td>
      <td>449</td>
      <td>0</td>
      <td>0</td>
      <td>848</td>
      <td>0</td>
      <td>399</td>
    </tr>
    <tr>
      <th>UTTARAKHAND</th>
      <td>0</td>
      <td>1299</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>WEST BENGAL</th>
      <td>250</td>
      <td>6619</td>
      <td>2397</td>
      <td>1124</td>
      <td>0</td>
      <td>200</td>
      <td>399</td>
      <td>1198</td>
      <td>1548</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 9 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> amazon-seller-order-status-prediction/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Make a new column "total_category" for prices category (Expensive >= 90% percentile , Average 50%-90% percentile , Cheap: <= 50% percentile )</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>q_5=df['item_total'].quantile(0.5)
q_9=df['item_total'].quantile(0.9)
def price_category(x):
    if x<=q_5:
        return ("Cheap")
    elif x>=q_9:
        return ("Expensive")
    else:
        return("Average")

df['total_category']=df['item_total'].apply(price_category)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>q_5=df['item_total'].quantile(0.5)
q_9=df['item_total'].quantile(0.9)
def price_category(x):
    if x<=q_5:
        return ("Cheap")
    elif x>=q_9:
        return ("Expensive")
    else:
        return("Average")

df['total_category']=df['item_total'].apply(price_category)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>q_5 = df['item_total'].quantile(0.5)
q_9 = df['item_total'].quantile(0.9)


def price_category(x):
    if x <= q_5:
        return 'Cheap'
    elif x >= q_9:
        return 'Expensive'
    else:
        return 'Average'


__output__ = df['total_category'] = df['item_total'].apply(price_category)
</code></pre>
        <p><span onclick="$('#var_output_f2a4ec44').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f2a4ec44" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0          Cheap
1          Cheap
2          Cheap
3        Average
4      Expensive
         ...    
166    Expensive
167    Expensive
168    Expensive
169    Expensive
170        Cheap
Name: item_total, Length: 171, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, q_5, q_9, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_no</th>
      <th>order_date</th>
      <th>buyer</th>
      <th>ship_city</th>
      <th>ship_state</th>
      <th>sku</th>
      <th>description</th>
      <th>quantity</th>
      <th>item_total</th>
      <th>shipping_fee</th>
      <th>cod</th>
      <th>order_status</th>
      <th>Month</th>
      <th>day_of_week</th>
      <th>total_category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>405-9763961-5211537</td>
      <td>Sun, 18 Jul, 2021, 10:38 pm IST</td>
      <td>Mr.</td>
      <td>CHANDIGARH,</td>
      <td>CHANDIGARH</td>
      <td>SKU:  2X-3C0F-KNJE</td>
      <td>100% Leather Elephant Shaped Piggy Coin Bank | Block Printed West Bengal Handicrafts (Shantiniketan Art) | Money Bank for Kids | Children's Gift Ideas</td>
      <td>1</td>
      <td>449.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Jul</td>
      <td>Sun</td>
      <td>Cheap</td>
    </tr>
    <tr>
      <th>1</th>
      <td>404-3964908-7850720</td>
      <td>Tue, 19 Oct, 2021, 6:05 pm IST</td>
      <td>Minam</td>
      <td>PASIGHAT,</td>
      <td>ARUNACHAL PRADESH</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>1</td>
      <td>449.0</td>
      <td>60.18</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Oct</td>
      <td>Tue</td>
      <td>Cheap</td>
    </tr>
    <tr>
      <th>2</th>
      <td>171-8103182-4289117</td>
      <td>Sun, 28 Nov, 2021, 10:20 pm IST</td>
      <td>yatipertin</td>
      <td>PASIGHAT,</td>
      <td>ARUNACHAL PRADESH</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>1</td>
      <td>449.0</td>
      <td>60.18</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Nov</td>
      <td>Sun</td>
      <td>Cheap</td>
    </tr>
    <tr>
      <th>3</th>
      <td>405-3171677-9557154</td>
      <td>Wed, 28 Jul, 2021, 4:06 am IST</td>
      <td>aciya</td>
      <td>DEVARAKONDA,</td>
      <td>TELANGANA</td>
      <td>SKU:  AH-J3AO-R7DN</td>
      <td>Pure 100% Leather Block Print Rectangular Jewelry Box with Mirror | Button Closure Multiple Utility Case (Shantiniketan Handicrafts) (Yellow)</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Jul</td>
      <td>Wed</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>4</th>
      <td>402-8910771-1215552</td>
      <td>Tue, 28 Sept, 2021, 2:50 pm IST</td>
      <td>Susmita</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  KL-7WAA-Z82I</td>
      <td>Pure Leather Sling Bag with Multiple Pockets and Adjustable Strap | Shantiniketan Block Print Cross-Body Bags for Women (1 pc) (Brown)</td>
      <td>1</td>
      <td>1099.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>ept</td>
      <td>Tue</td>
      <td>Expensive</td>
    </tr>
    <tr>
      <th>5</th>
      <td>406-9292208-6725123</td>
      <td>Thu, 17 Jun, 2021, 9:12 pm IST</td>
      <td>Subinita</td>
      <td>HOWRAH,</td>
      <td>WEST BENGAL</td>
      <td>SKU:  HH-FOWV-5YWO</td>
      <td>Women's Trendy Pure Leather Clutch Purse | Leather Zipper Wallet</td>
      <td>1</td>
      <td>200.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Jun</td>
      <td>Thu</td>
      <td>Cheap</td>
    </tr>
    <tr>
      <th>6</th>
      <td>404-5794317-7737924</td>
      <td>Thu, 12 Aug, 2021, 8:03 pm IST</td>
      <td>shailendra</td>
      <td>ORAI,</td>
      <td>UTTAR PRADESH</td>
      <td>SKU:  TQ-OE6K-9DIK</td>
      <td>Ultra Slim 100% Pure Leather Men's Wallet with Cash, Card and Coin Compartments | Jet Black Gent's Money Organizer with Cover (1 pc)</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Cash On Delivery</td>
      <td>Returned to seller</td>
      <td>Aug</td>
      <td>Thu</td>
      <td>Average</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>164</th>
      <td>402-8044719-8889119</td>
      <td>Sat, 4 Dec, 2021, 10:28 pm IST</td>
      <td>Swathi</td>
      <td>Visakhapatnam,</td>
      <td>Andhra Pradesh</td>
      <td>SKU:  3F-4R9N-Z8NJ</td>
      <td>Set of 2 Pure Leather Block Print Round Jewelry Boxes | Button Closure Multiple Utility Case (Shantiniketan Handicrafts) (Yellow)</td>
      <td>1</td>
      <td>399.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Sat</td>
      <td>Cheap</td>
    </tr>
    <tr>
      <th>165</th>
      <td>402-1808225-2809140</td>
      <td>Sat, 25 Dec, 2021, 4:03 pm IST</td>
      <td>User</td>
      <td>Solan,</td>
      <td>Himachal Pradesh</td>
      <td>SKU:  S1-A92Q-JU3X</td>
      <td>100% Pure Leather Shantiniketan Clutch Purse: Traditional Block Print Bi-color Women's Wallets with Multiple Pockets and Zipper Compartments (1 pc) (G</td>
      <td>1</td>
      <td>399.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Sat</td>
      <td>Cheap</td>
    </tr>
    <tr>
      <th>166</th>
      <td>171-2829978-1258758</td>
      <td>Mon, 13 Dec, 2021, 11:30 am IST</td>
      <td>Shahin</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  DN-0WDX-VYOT</td>
      <td>Women's Set of 5 Multicolor Pure Leather Single Lipstick Cases with Mirror, Handy and Compact Handcrafted Shantiniketan Block Printed Jewelry Boxes</td>
      <td>3</td>
      <td>1347.0</td>
      <td>84.96</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Mon</td>
      <td>Expensive</td>
    </tr>
    <tr>
      <th>167</th>
      <td>402-3045457-5360311</td>
      <td>Wed, 1 Dec, 2021, 12:18 pm IST</td>
      <td>Sharmistha</td>
      <td>DEHRADUN,</td>
      <td>UTTARAKHAND</td>
      <td>SKU:  SB-WDQN-SDN9</td>
      <td>Traditional Block-Printed Women's 100% Pure Leather Shoulder Bag: Double Handle Red Handbag | Multi-pocket Shantiniketan Leather Bag for Women</td>
      <td>1</td>
      <td>1299.0</td>
      <td>114.46</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Wed</td>
      <td>Expensive</td>
    </tr>
    <tr>
      <th>168</th>
      <td>408-2260162-8323567</td>
      <td>Thu, 9 Dec, 2021, 6:55 pm IST</td>
      <td>shashank</td>
      <td>Durg,</td>
      <td>CHHATTISGARH</td>
      <td>SKU:  SB-WDQN-SDN9</td>
      <td>Traditional Block-Printed Women's 100% Pure Leather Shoulder Bag: Double Handle Red Handbag | Multi-pocket Shantiniketan Leather Bag for Women</td>
      <td>1</td>
      <td>1299.0</td>
      <td>105.02</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Thu</td>
      <td>Expensive</td>
    </tr>
    <tr>
      <th>169</th>
      <td>403-5664951-8941100</td>
      <td>Wed, 23 Feb, 2022, 12:43 am IST</td>
      <td>Jayeta</td>
      <td>KOLKATA,</td>
      <td>WEST BENGAL</td>
      <td>SKU:  N8-YFZF-P74I</td>
      <td>Stylish and Sleek Multiple Pockets 100 Percent Leather Shoulder Bag Contemporary Indian Leather Handicrafts for Women (Yellow) (BL335)</td>
      <td>1</td>
      <td>1499.0</td>
      <td>80.24</td>
      <td>Cash On Delivery</td>
      <td>Delivered to buyer</td>
      <td>Feb</td>
      <td>Wed</td>
      <td>Expensive</td>
    </tr>
    <tr>
      <th>170</th>
      <td>402-4845680-8041921</td>
      <td>Sun, 26 Dec, 2021, 6:21 pm IST</td>
      <td>Varun</td>
      <td>MUMBAI,</td>
      <td>MAHARASHTRA</td>
      <td>SKU:  2X-3C0F-KNJE</td>
      <td>100% Leather Elephant Shaped Piggy Coin Bank | Block Printed West Bengal Handicrafts (Shantiniketan Art) | Money Bank for Kids | Children's Gift Ideas</td>
      <td>1</td>
      <td>449.0</td>
      <td>84.96</td>
      <td>NaN</td>
      <td>Delivered to buyer</td>
      <td>Dec</td>
      <td>Sun</td>
      <td>Cheap</td>
    </tr>
  </tbody>
</table>
<p>171 rows × 15 columns</p>
      
          <p>q_5 (float64):</p>
          <pre><code>449.0</code></pre>
      
          <p>q_9 (float64):</p>
          <pre><code>1099.0</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>0          Cheap
1          Cheap
2          Cheap
3        Average
4      Expensive
         ...    
166    Expensive
167    Expensive
168    Expensive
169    Expensive
170        Cheap
Name: item_total, Length: 171, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> complete-football-data-89000-matches-18-leagues/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # In which year was the first premier league game played in?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>((df[df['League']=='premier-league'])['Date'].map(lambda x:x[-4:]).sort_values(ascending=True)).iloc[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>((df[df['League']=='premier-league'])['Date'].map(lambda x:x[-4:]).sort_values(ascending=True)).iloc[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['League'] == 'premier-league']['Date'].map(lambda x: x[-4:]
    ).sort_values(ascending=True).iloc[0]
</code></pre>
        <p><span onclick="$('#var_output_a3dde707').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a3dde707" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>2002</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>2002</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> complete-football-data-89000-matches-18-leagues/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which league has the most played games?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby('League').count()['Home'].sort_values(ascending=False).index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby('League').count()['Home'].sort_values(ascending=False).index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('League').count()['Home'].sort_values(ascending=False
    ).index[0]
</code></pre>
        <p><span onclick="$('#var_output_799a82c7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_799a82c7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>premier-league</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>premier-league</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> complete-football-data-89000-matches-18-leagues/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many times has Swansea played at home against different teams in the championship?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>len(df[(df['Home']=='Swansea') & (df['League']=='championship')]['Away'].unique())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>len(df[(df['Home']=='Swansea') & (df['League']=='championship')]['Away'].unique())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = len(df[(df['Home'] == 'Swansea') & (df['League'] ==
    'championship')]['Away'].unique())
</code></pre>
        <p><span onclick="$('#var_output_44cf9571').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_44cf9571" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>41</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>41</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> complete-football-data-89000-matches-18-leagues/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many goals did Cardiff score at home in premier league in 2014?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>filtred=df[(df['Home']=='Cardiff')& (df['League']=='premier-league')]
filtred[filtred['Date'].apply(lambda x:x[-4:])=="2014"]["H_Score"].sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>filtred=df[(df['Home']=='Cardiff')& (df['League']=='premier-league')]
filtred[filtred['Date'].apply(lambda x:x[-4:])=="2014"]["H_Score"].sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>filtred = df[(df['Home'] == 'Cardiff') & (df['League'] == 'premier-league')]
__output__ = filtred[filtred['Date'].apply(lambda x: x[-4:]) == '2014'][
    'H_Score'].sum()
</code></pre>
        <p><span onclick="$('#var_output_8a3ef046').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8a3ef046" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>9.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> filtred, __output__ </p>
    
          <p>filtred (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>League</th>
      <th>Home</th>
      <th>Away</th>
      <th>INC</th>
      <th>Round</th>
      <th>Date</th>
      <th>Time</th>
      <th>...</th>
      <th>H_Goalkeeper_Saves</th>
      <th>A_Goalkeeper_Saves</th>
      <th>H_Fouls</th>
      <th>A_Fouls</th>
      <th>H_Yellow_Cards</th>
      <th>A_Yellow_Cards</th>
      <th>Game Link</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10864</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Chelsea</td>
      <td>["15' Goal_Home - Bellamy C.(Whittingham P.)", "33' Yellow_Away - Mikel J. O.", "51' Yellow_Home - Whittingham P.", "72' Goal_Away - Schurrle A.", "75' Goal_Away - Torres F.(Schurrle A.)", "88' Yellow_Away - Matic N."]</td>
      <td>38</td>
      <td>11.05.2014</td>
      <td>16:00</td>
      <td>...</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>7.0</td>
      <td>9.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>https://www.flashscore.com/match/nch9U8kc/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>10903</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Stoke</td>
      <td>["45+3' Goal_Away - Arnautovic M.(Penalty )", "48' Yellow_Away - Odemwingie P.", "51' Goal_Home - Whittingham P.(Penalty )", "51' Yellow_Away - N", "66' Yellow_Home - Mutch J.", "74' Yellow_Home - Cala J.", "85' Yellow_Away - Crouch P."]</td>
      <td>35</td>
      <td>19.04.2014</td>
      <td>16:00</td>
      <td>...</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>6.0</td>
      <td>12.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>https://www.flashscore.com/match/ShLrEm5G/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>10923</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Crystal Palace</td>
      <td>["31' Goal_Away - Puncheon J.(Ledley J.)", "35' Yellow_Away - Jerome C.", "38' Yellow_Away - Ward J.", "68' Yellow_Home - Turner B.", "70' Yellow_Home - Medel G.", "71' Goal_Away - Ledley J.", "74' Yellow_Away - Mariappa A.", "78' Yellow_Away - Ledley J.", "88' Goal_Away - Puncheon J.(Mariappa A.)"]</td>
      <td>33</td>
      <td>05.04.2014</td>
      <td>16:00</td>
      <td>...</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>13.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>https://www.flashscore.com/match/EVESHV5i/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>10946</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Liverpool</td>
      <td>["02' Yellow_Away - Gerrard S.", "09' Goal_Home - Mutch J.(Campbell F.)", "16' Goal_Away - Suarez L.(Johnson G.)", "25' Goal_Home - Campbell F.(Mutch J.)", "33' Yellow_Home - Cala J.", "41' Goal_Away - Skrtel M.(Coutinho)", "50' Yellow_Home - Fabio", "54' Goal_Away - Skrtel M.(Coutinho)", "60' Goal_Away - Suarez L.(Sturridge D.)", "75' Goal_Away - Sturridge D.(Suarez L.)", "88' Goal_Home - Mutch J.(Jones K.)", "90+2' Yellow_Away - Skrtel M.", "90+4' Yellow_Away - Allen J.", "90+6' Goal_Away - Suarez L.(Skrtel M.)"]</td>
      <td>31</td>
      <td>22.03.2014</td>
      <td>16:00</td>
      <td>...</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>14.0</td>
      <td>11.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>https://www.flashscore.com/match/SvtAaljN/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>10964</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Fulham</td>
      <td>["45+1' Goal_Home - Caulker S.", "56' Yellow_Home - Kim Bo-Kyung", "59' Goal_Away - Holtby L.(Heitinga J.)", "67' Goal_Home - Caulker S.(Mutch J.)", "71' Own_Home - Riether S.()"]</td>
      <td>29</td>
      <td>08.03.2014</td>
      <td>16:00</td>
      <td>...</td>
      <td>5.0</td>
      <td>6.0</td>
      <td>9.0</td>
      <td>12.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>https://www.flashscore.com/match/bahc2j64/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>10981</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Hull</td>
      <td>["18' Goal_Away - Huddlestone T.(Livermore J.)", "33' Yellow_Home - Zaha W.", "38' Goal_Away - Jelavic N.(Long S.)", "57' Goal_Away - Jelavic N.(Rosenior L.)", "67' Goal_Away - Livermore J.(Elmohamady A.)", "86' Yellow_Away - Boyd G."]</td>
      <td>27</td>
      <td>22.02.2014</td>
      <td>16:00</td>
      <td>...</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>https://www.flashscore.com/match/YDlZcyFI/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>10991</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Aston Villa</td>
      <td>[]</td>
      <td>26</td>
      <td>11.02.2014</td>
      <td>20:45</td>
      <td>...</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>5.0</td>
      <td>9.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>https://www.flashscore.com/match/xneQacp6/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>13033</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Brighton</td>
      <td>["06' Goal_Away - Dunk L.(March S.)", "28' Goal_Home - Paterson C.", "34' Red_Card_Away - Stephens D.(Nadmierna ostrość)", "35' Yellow_Home - Paterson C.(Niesportowe zachowanie)", "71' Yellow_Home - Cunningham G.(Nadmierna ostrość)", "90' Goal_Home - Bamba S.", "90+5' Yellow_Away - Bissouma Y.(Niesportowe zachowanie)"]</td>
      <td>12</td>
      <td>10.11.2018</td>
      <td>13:30</td>
      <td>...</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>7.0</td>
      <td>21.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>https://www.flashscore.com/match/2XdK0uDh/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>13039</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Leicester</td>
      <td>["33' Yellow_Away - Pereira R.(Podcięcie)", "45+1' Yellow_Home - Arter H.(Faul)", "55' Goal_Away - Gray D.(Chilwell B.)", "55' Yellow_Away - Gray D.(Niesportowe zachowanie)", "81' Yellow_Home - Hoilett J.(Podcięcie)"]</td>
      <td>11</td>
      <td>03.11.2018</td>
      <td>16:00</td>
      <td>...</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>13.0</td>
      <td>12.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>https://www.flashscore.com/match/8AcG1Lcn/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>13058</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Fulham</td>
      <td>["11' Goal_Away - Schurrle A.(Seri J.)", "15' Goal_Home - Murphy J.(Bamba S.)", "19' Yellow_Away - Chambers C.(Przytrzymywanie)", "20' Goal_Home - Reid B.", "33' Yellow_Home - Gunnarsson A.(Przytrzymywanie)", "34' Goal_Away - Sessegnon R.(Mitrovic A.)", "36' Yellow_Away - McDonald K.(Faul)", "45+3' Yellow_Away - Johansen S.(Faul)", "65' Goal_Home - Paterson C.(Reid B.)", "68' Yellow_Home - Morrison S.(Faul)", "78' Yellow_Home - Bamba S.(Niesportowe zachowanie)", "87' Goal_Home - Harris K.(Camarasa V.)"]</td>
      <td>9</td>
      <td>20.10.2018</td>
      <td>16:00</td>
      <td>...</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>15.0</td>
      <td>16.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>https://www.flashscore.com/match/UqS5sICU/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>13075</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Burnley</td>
      <td>["45+1' Yellow_Away - Westwood A.(Faul)", "51' Goal_Away - Gudmundsson J.(Westwood A.)", "60' Goal_Home - Murphy J.(Ecuele B.)", "69' Yellow_Home - Cunningham G.(Podcięcie)", "70' Goal_Away - Vokes S.(Gudmundsson J.)", "87' Yellow_Away - Lowton M.(Podcięcie)", "90+3' Yellow_Away - Lennon A.(Podcięcie)"]</td>
      <td>7</td>
      <td>30.09.2018</td>
      <td>17:00</td>
      <td>...</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>15.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>https://www.flashscore.com/match/MJOcqvrI/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>13088</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Manchester City</td>
      <td>["32' Goal_Away - Aguero S.(Silva B.)", "35' Goal_Away - Silva B.(Sane L.)", "44' Goal_Away - Gundogan I.(Sterling R.)", "45+1' Yellow_Home - Ralls J.(Nadmierna ostrość)", "60' Yellow_Away - Fernandinho(Podcięcie)", "67' Goal_Away - Mahrez R.(Gundogan I.)", "89' Goal_Away - Mahrez R."]</td>
      <td>6</td>
      <td>22.09.2018</td>
      <td>16:00</td>
      <td>...</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>https://www.flashscore.com/match/rTPgpKSB/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>13106</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Arsenal</td>
      <td>["12' Goal_Away - Mustafi S.(Xhaka G.)", "25' Yellow_Away - Monreal N.(Nadmierna ostrość)", "45+2' Goal_Home - Camarasa V.(Bennett J.)", "51' Yellow_Away - Bellerin H.(Zagranie ręką)", "58' Yellow_Away - Guendouzi M.(Przytrzymywanie)", "62' Goal_Away - Aubameyang P.(Lacazette A.)", "66' Yellow_Away - Xhaka G.(Przytrzymywanie)", "70' Goal_Home - Ward D.(Morrison S.)", "71' Yellow_Home - Hoilett J.(Podcięcie)", "77' Yellow_Home - Camarasa V.(Podcięcie)", "81' Goal_Away - Lacazette A.(Torreira L.)", "90+3' Yellow_Home - Arter H.(Podcięcie)"]</td>
      <td>4</td>
      <td>02.09.2018</td>
      <td>14:30</td>
      <td>...</td>
      <td>8.0</td>
      <td>1.0</td>
      <td>12.0</td>
      <td>14.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>https://www.flashscore.com/match/lUWpntba/#/match-summary/match-summary</td>
    </tr>
    <tr>
      <th>13133</th>
      <td>premier-league</td>
      <td>Cardiff</td>
      <td>Newcastle</td>
      <td>["03' Yellow_Away - Ritchie M.(Podcięcie)", "30' Yellow_Away - Manquillo J.(Przytrzymywanie)", "62' Yellow_Home - Camarasa V.(Przytrzymywanie)", "66' Red_Card_Away - Hayden I.(Podcięcie)", "80' Yellow_Home - Arter H.(Podcięcie)", "90+6' Penalty_Missed_Away -  Kenedy()"]</td>
      <td>2</td>
      <td>18.08.2018</td>
      <td>13:30</td>
      <td>...</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>14.0</td>
      <td>16.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>https://www.flashscore.com/match/GGYxl2Tn/#/match-summary/match-summary</td>
    </tr>
  </tbody>
</table>
<p>38 rows × 56 columns</p>
      
          <p>__output__ (float64):</p>
          <pre><code>9.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> complete-football-data-89000-matches-18-leagues/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the maximum total score in each league? (sorted from the highest to the lowest)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['Total_Score']=df['H_Score']+df['A_Score']
df.groupby('League')['Total_Score'].max().sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['Total_Score']=df['H_Score']+df['A_Score']
df.groupby('League')['Total_Score'].max().sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['Total_Score'] = df['H_Score'] + df['A_Score']
__output__ = df.groupby('League')['Total_Score'].max().sort_values(ascending
    =False)
</code></pre>
        <p><span onclick="$('#var_output_e36adace').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e36adace" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>League
championship          14.0
eredivisie            13.0
laliga2               12.0
laliga                12.0
premier-league        11.0
                      ... 
fortuna-1-liga         9.0
pko-bp-ekstraklasa     9.0
ligue-1                9.0
super-lig              9.0
serie-b                8.0
Name: Total_Score, Length: 18, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>League</th>
      <th>Home</th>
      <th>Away</th>
      <th>INC</th>
      <th>Round</th>
      <th>Date</th>
      <th>Time</th>
      <th>...</th>
      <th>A_Goalkeeper_Saves</th>
      <th>H_Fouls</th>
      <th>A_Fouls</th>
      <th>H_Yellow_Cards</th>
      <th>A_Yellow_Cards</th>
      <th>Game Link</th>
      <th>Total_Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>championship</td>
      <td>Swansea</td>
      <td>Reading</td>
      <td>["08' Yellow_Away - Griffin A.", "12' Yellow_Away - Khizanishvili Z.", "12' Yellow_Home - Borini F.", "21' Goal_Home - Penalty Sinclair S.(Penalty )", "22' Goal_Home - Sinclair S.(Dobbie S.)", "39' Yellow_Away - McAnuff J.", "40' Goal_Home - Dobbie S.", "46' Red_Card_Away - Tabb J.", "49' Own_Away - Allen J.()", "54' Yellow_Home - Allen J.", "57' Goal_Away - Mills M.(McAnuff J.)", "80+0' Goal_Home - Penalty Sinclair S.(Penalty )", "82' Yellow_Home - Gower M."]</td>
      <td>Play-off</td>
      <td>30.05.2011</td>
      <td>16:00</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>https://www.flashscore.com/match/feOBWmKD/#/match-summary/match-summary</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>championship</td>
      <td>Cardiff</td>
      <td>Reading</td>
      <td>["28' Goal_Away - Long S.", "44' Yellow_Home - Keinan D.", "45+0' Goal_Away - Penalty Long S.(Penalty )", "78' Yellow_Away - Long S.", "84' Goal_Away - McAnuff J.", "90+0' Yellow_Home - Koumas J."]</td>
      <td>Play-off</td>
      <td>17.05.2011</td>
      <td>20:45</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>https://www.flashscore.com/match/IJUfyp3o/#/match-summary/match-summary</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>championship</td>
      <td>Swansea</td>
      <td>Nottingham</td>
      <td>["26' Yellow_Away - Gunter C.", "28' Goal_Home - Britton L.", "33' Goal_Home - Dobbie S.", "80+0' Goal_Away - Earnshaw R.", "90+2' Goal_Home - Pratley D.", "90+4' Yellow_Home - Pratley D."]</td>
      <td>Play-off</td>
      <td>16.05.2011</td>
      <td>20:45</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>https://www.flashscore.com/match/QoD4C0Qp/#/match-summary/match-summary</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>championship</td>
      <td>Reading</td>
      <td>Cardiff</td>
      <td>["26' Yellow_Home - McAnuff J.", "38' Yellow_Home - Mills M.", "40+0' Yellow_Away - Bothroyd J."]</td>
      <td>Play-off</td>
      <td>13.05.2011</td>
      <td>20:45</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>https://www.flashscore.com/match/lMkyUSeI/#/match-summary/match-summary</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>championship</td>
      <td>Nottingham</td>
      <td>Swansea</td>
      <td>["02' Red_Card_Away - Taylor N.", "47' Yellow_Home - Gunter C.", "51' Yellow_Home - Morgan W.", "80+0' Yellow_Away - Rangel A.", "90+0' Yellow_Home - McGugan L."]</td>
      <td>Play-off</td>
      <td>12.05.2011</td>
      <td>20:45</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>https://www.flashscore.com/match/6c0WU8tC/#/match-summary/match-summary</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>championship</td>
      <td>Barnsley</td>
      <td>Millwall</td>
      <td>["57' Yellow_Away - Bouazza H.", "60' Goal_Home - Noble-Lazarus R.", "66' Yellow_Home - Doyle N.", "67' Yellow_Away - Dunne A.", "71' Yellow_Home - Haynes D.", "90+0' Yellow_Away - Henry J."]</td>
      <td>46</td>
      <td>07.05.2011</td>
      <td>13:45</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>https://www.flashscore.com/match/tGEY5w9i/#/match-summary/match-summary</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>championship</td>
      <td>Bristol City</td>
      <td>Hull</td>
      <td>["03' Goal_Home - Stead J.", "14' Goal_Home - Pitman B.", "56' Goal_Home - Campbell-Ryce J."]</td>
      <td>46</td>
      <td>07.05.2011</td>
      <td>13:45</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>https://www.flashscore.com/match/E56o3ygA/#/match-summary/match-summary</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>96330</th>
      <td>league-two</td>
      <td>Mansfield</td>
      <td>Bristol Rovers</td>
      <td>["23' Yellow_Home - Maris G.", "42' Goal_Home - Hawkins O.(McLaughlin S.)", "62' Goal_Away - Harries C.", "77' Red_Card_Away - Coutts P.", "78' Yellow_Away - Harries C.", "79' Yellow_Home - Johnson D.", "86' Yellow_Away - Westbrooke Z.", "90+6' Goal_Home - Penalty Johnson D.(Penalty )"]</td>
      <td>1</td>
      <td>07.08.2021</td>
      <td>16:00</td>
      <td>...</td>
      <td>1.0</td>
      <td>14.0</td>
      <td>15.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>https://www.flashscore.com/match/dOLNiwxk/#/match-summary/match-summary</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>96331</th>
      <td>league-two</td>
      <td>Northampton</td>
      <td>Port Vale</td>
      <td>["23' Goal_Home - Ashley-Seal B.", "27' Yellow_Away - Johnson R.", "55' Red_Card_Away - Covolan L.", "71' Yellow_Home - Guthrie J.", "73' Yellow_Home - McGowan A.", "77' Yellow_Home - Connolly D.", "79' Yellow_Home - Rose D.", "81' Yellow_Away - Martin A."]</td>
      <td>1</td>
      <td>07.08.2021</td>
      <td>16:00</td>
      <td>...</td>
      <td>1.0</td>
      <td>11.0</td>
      <td>16.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>https://www.flashscore.com/match/zFKRjcie/#/match-summary/match-summary</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>96332</th>
      <td>league-two</td>
      <td>Oldham</td>
      <td>Newport</td>
      <td>["14' Yellow_Away - Norman C.", "14' Yellow_Home - Piergianni C.", "22' Yellow_Home - Hart S.", "36' Yellow_Home - Blyth J.", "88' Goal_Away - Ellison K.(Haynes R.)", "90+5' Yellow_Away - Abraham T."]</td>
      <td>1</td>
      <td>07.08.2021</td>
      <td>16:00</td>
      <td>...</td>
      <td>0.0</td>
      <td>17.0</td>
      <td>7.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>https://www.flashscore.com/match/CAtvrBOT/#/match-summary/match-summary</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>96333</th>
      <td>league-two</td>
      <td>Salford</td>
      <td>Leyton Orient</td>
      <td>["33' Goal_Away - Beckles O.", "41' Goal_Home - Willock M.(Touray I.)", "80' Yellow_Home - Turnbull J.", "88' Yellow_Away - Pratley D."]</td>
      <td>1</td>
      <td>07.08.2021</td>
      <td>16:00</td>
      <td>...</td>
      <td>5.0</td>
      <td>11.0</td>
      <td>11.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>https://www.flashscore.com/match/IwAWkH61/#/match-summary/match-summary</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>96334</th>
      <td>league-two</td>
      <td>Scunthorpe</td>
      <td>Swindon</td>
      <td>["48' Goal_Home - Penalty Loft R.(Penalty )", "57' Goal_Away - Penalty Payne J.(Penalty )", "59' Yellow_Away - Conroy D.", "68' Goal_Away - Gladwin B.", "78' Yellow_Away - Grant A.", "88' Goal_Away - McKirdy H.", "90+1' Yellow_Away - Simpson T."]</td>
      <td>1</td>
      <td>07.08.2021</td>
      <td>16:00</td>
      <td>...</td>
      <td>3.0</td>
      <td>20.0</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>https://www.flashscore.com/match/WtEzkyM7/#/match-summary/match-summary</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>96335</th>
      <td>league-two</td>
      <td>Stevenage</td>
      <td>Barrow</td>
      <td>["21' Yellow_Away - Taylor J.", "22' Yellow_Away - Banks O.", "45+1' Yellow_Home - Lines C.", "45+2' Yellow_Away - Platt M.", "46' Goal_Home - Reeves J.(Reid J.)", "51' Yellow_Away - Kay J.", "52' Yellow_Home - Cuthbert S.", "55' Yellow_Home - Vancooten T.", "68' Yellow_Away - Ntlhe K.", "79' Yellow_Away - Devitt J.", "90' Yellow_Home - Taylor J."]</td>
      <td>1</td>
      <td>07.08.2021</td>
      <td>16:00</td>
      <td>...</td>
      <td>2.0</td>
      <td>20.0</td>
      <td>14.0</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>https://www.flashscore.com/match/pp2IDKb8/#/match-summary/match-summary</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>96336</th>
      <td>league-two</td>
      <td>Tranmere</td>
      <td>Walsall</td>
      <td>["15' Yellow_Away - Taylor A.", "42' Yellow_Home - McManaman C.", "67' Yellow_Home - Davies T.", "73' Goal_Home - McManaman C.(Merrie C.)", "86' Red_Card_Home - Merrie C.", "87' Yellow_Home - Murphy J.", "90+2' Yellow_Away - Labadie J."]</td>
      <td>1</td>
      <td>07.08.2021</td>
      <td>16:00</td>
      <td>...</td>
      <td>2.0</td>
      <td>13.0</td>
      <td>17.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>https://www.flashscore.com/match/Oz1MCvEE/#/match-summary/match-summary</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>96337 rows × 57 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>League
championship          14.0
eredivisie            13.0
laliga2               12.0
laliga                12.0
premier-league        11.0
                      ... 
fortuna-1-liga         9.0
pko-bp-ekstraklasa     9.0
ligue-1                9.0
super-lig              9.0
serie-b                8.0
Name: Total_Score, Length: 18, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> complete-football-data-89000-matches-18-leagues/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many draw games were played for each team at home in league two? (sorted from the highest to the lowest)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['WIN']=='Draw') & (df['League']=='league-two')].groupby('Home').count()['League'].sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['WIN']=='Draw') & (df['League']=='league-two')].groupby('Home').count()['League'].sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['WIN'] == 'Draw') & (df['League'] == 'league-two')
    ].groupby('Home').count()['League'].sort_values(ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_1eb44542').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1eb44542" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Home
Morecambe        68
Mansfield        64
Cheltenham       62
Exeter           62
Newport          61
                 ..
Bolton            5
Coventry          5
Milton Keynes     5
Rotherham         5
Hereford          4
Name: League, Length: 59, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Home
Morecambe        68
Mansfield        64
Cheltenham       62
Exeter           62
Newport          61
                 ..
Bolton            5
Coventry          5
Milton Keynes     5
Rotherham         5
Hereford          4
Name: League, Length: 59, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> complete-football-data-89000-matches-18-leagues/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which league had the most number of missing players?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby('League').sum()['Missing_Players'].sort_values(ascending=False).index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby('League').sum()['Missing_Players'].sort_values(ascending=False).index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('League').sum()['Missing_Players'].sort_values(
    ascending=False).index[0]
</code></pre>
        <p><span onclick="$('#var_output_fe1d0d0c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_fe1d0d0c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>championship</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>championship</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cuisine-rating/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average age for all customers? (Casted to int)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['Age']=[(datetime.now().year) - i for i in df['YOB']]
int(df['Age'].mean())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['Age']=[(datetime.now().year) - i for i in df['YOB']]
int(df['Age'].mean())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['Age'] = [(datetime.now().year - i) for i in df['YOB']]
__output__ = int(df['Age'].mean())
</code></pre>
        <p><span onclick="$('#var_output_3c944c2a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3c944c2a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>37</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>User ID</th>
      <th>Area code</th>
      <th>Location</th>
      <th>Gender</th>
      <th>YOB</th>
      <th>Marital Status</th>
      <th>Activity</th>
      <th>...</th>
      <th>Alcohol</th>
      <th>Smoker</th>
      <th>Food Rating</th>
      <th>Service Rating</th>
      <th>Overall Rating</th>
      <th>Often A S</th>
      <th>Age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>153</td>
      <td>Upper East Side,NY</td>
      <td>Female</td>
      <td>2006</td>
      <td>Single</td>
      <td>Professional</td>
      <td>...</td>
      <td>Never</td>
      <td>Never</td>
      <td>5</td>
      <td>4</td>
      <td>4.5</td>
      <td>No</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>123</td>
      <td>St. George,NY</td>
      <td>Female</td>
      <td>1991</td>
      <td>Married</td>
      <td>Student</td>
      <td>...</td>
      <td>Never</td>
      <td>Socially</td>
      <td>1</td>
      <td>1</td>
      <td>1.0</td>
      <td>No</td>
      <td>31</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>122</td>
      <td>Upper West Side,NY</td>
      <td>Male</td>
      <td>1977</td>
      <td>Single</td>
      <td>Student</td>
      <td>...</td>
      <td>Often</td>
      <td>Often</td>
      <td>5</td>
      <td>5</td>
      <td>5.0</td>
      <td>Yes</td>
      <td>45</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>153</td>
      <td>Upper East Side,NY</td>
      <td>Female</td>
      <td>1956</td>
      <td>Married</td>
      <td>Professional</td>
      <td>...</td>
      <td>Never</td>
      <td>Socially</td>
      <td>3</td>
      <td>1</td>
      <td>2.0</td>
      <td>No</td>
      <td>66</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>129</td>
      <td>Central Park,NY</td>
      <td>Male</td>
      <td>1997</td>
      <td>Single</td>
      <td>Student</td>
      <td>...</td>
      <td>Socially</td>
      <td>Never</td>
      <td>2</td>
      <td>4</td>
      <td>3.0</td>
      <td>No</td>
      <td>25</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>111</td>
      <td>China Town, NY</td>
      <td>Male</td>
      <td>1995</td>
      <td>Single</td>
      <td>Student</td>
      <td>...</td>
      <td>Never</td>
      <td>Never</td>
      <td>5</td>
      <td>1</td>
      <td>3.0</td>
      <td>No</td>
      <td>27</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>111</td>
      <td>China Town, NY</td>
      <td>Female</td>
      <td>1977</td>
      <td>Married</td>
      <td>Professional</td>
      <td>...</td>
      <td>Often</td>
      <td>Socially</td>
      <td>1</td>
      <td>4</td>
      <td>2.5</td>
      <td>No</td>
      <td>45</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>193</th>
      <td>194</td>
      <td>103</td>
      <td>Riverdale,NY</td>
      <td>Female</td>
      <td>1985</td>
      <td>Married</td>
      <td>Student</td>
      <td>...</td>
      <td>Often</td>
      <td>Never</td>
      <td>1</td>
      <td>4</td>
      <td>2.5</td>
      <td>No</td>
      <td>37</td>
    </tr>
    <tr>
      <th>194</th>
      <td>195</td>
      <td>107</td>
      <td>China Town, NY</td>
      <td>Male</td>
      <td>1974</td>
      <td>Married</td>
      <td>Student</td>
      <td>...</td>
      <td>Often</td>
      <td>Often</td>
      <td>2</td>
      <td>5</td>
      <td>3.5</td>
      <td>Yes</td>
      <td>48</td>
    </tr>
    <tr>
      <th>195</th>
      <td>196</td>
      <td>175</td>
      <td>St. George,NY</td>
      <td>Female</td>
      <td>1982</td>
      <td>Single</td>
      <td>Professional</td>
      <td>...</td>
      <td>Never</td>
      <td>Socially</td>
      <td>1</td>
      <td>2</td>
      <td>1.5</td>
      <td>No</td>
      <td>40</td>
    </tr>
    <tr>
      <th>196</th>
      <td>197</td>
      <td>170</td>
      <td>Upper West Side,NY</td>
      <td>Female</td>
      <td>2000</td>
      <td>Married</td>
      <td>Student</td>
      <td>...</td>
      <td>Never</td>
      <td>Often</td>
      <td>1</td>
      <td>2</td>
      <td>1.5</td>
      <td>No</td>
      <td>22</td>
    </tr>
    <tr>
      <th>197</th>
      <td>198</td>
      <td>160</td>
      <td>St. George,NY</td>
      <td>Female</td>
      <td>2006</td>
      <td>Single</td>
      <td>Professional</td>
      <td>...</td>
      <td>Never</td>
      <td>Often</td>
      <td>5</td>
      <td>2</td>
      <td>3.5</td>
      <td>No</td>
      <td>16</td>
    </tr>
    <tr>
      <th>198</th>
      <td>199</td>
      <td>130</td>
      <td>St. George,NY</td>
      <td>Male</td>
      <td>2002</td>
      <td>Married</td>
      <td>Student</td>
      <td>...</td>
      <td>Never</td>
      <td>Socially</td>
      <td>3</td>
      <td>2</td>
      <td>2.5</td>
      <td>No</td>
      <td>20</td>
    </tr>
    <tr>
      <th>199</th>
      <td>200</td>
      <td>140</td>
      <td>Upper East Side,NY</td>
      <td>Male</td>
      <td>2005</td>
      <td>Married</td>
      <td>Student</td>
      <td>...</td>
      <td>Never</td>
      <td>Never</td>
      <td>3</td>
      <td>2</td>
      <td>2.5</td>
      <td>No</td>
      <td>17</td>
    </tr>
  </tbody>
</table>
<p>200 rows × 16 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>37</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cuisine-rating/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of female students for each cuisine?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>values=df[(df["Gender"]=="Female") & (df['Activity']=='Student')]['Cuisines'].value_counts()
((values/df.groupby('Cuisines').count()['User ID'])*100)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>values=df[(df["Gender"]=="Female") & (df['Activity']=='Student')]['Cuisines'].value_counts()
((values/df.groupby('Cuisines').count()['User ID'])*100)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>values = df[(df['Gender'] == 'Female') & (df['Activity'] == 'Student')][
    'Cuisines'].value_counts()
__output__ = values / df.groupby('Cuisines').count()['User ID'] * 100
</code></pre>
        <p><span onclick="$('#var_output_08cf14cc').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_08cf14cc" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Chinese     33.333333
Filipino    17.647059
French      17.647059
Indian      18.750000
Italian     44.444444
Japanese    16.666667
Seafood      9.090909
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> values, __output__ </p>
    
          <p>values (Series):</p>
          <pre><code>Chinese     8
Italian     8
Indian      6
Filipino    6
French      6
Japanese    6
Seafood     2
Name: Cuisines, dtype: int64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Chinese     33.333333
Filipino    17.647059
French      17.647059
Indian      18.750000
Italian     44.444444
Japanese    16.666667
Seafood      9.090909
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cuisine-rating/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many customers with an overall rating of under 3 often visit the restaurant?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(df[df['Often A S']=='Yes']['Overall Rating']<3).value_counts()[1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(df[df['Often A S']=='Yes']['Overall Rating']<3).value_counts()[1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = (df[df['Often A S'] == 'Yes']['Overall Rating'] < 3).value_counts(
    )[1]
</code></pre>
        <p><span onclick="$('#var_output_b3f1b3e7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b3f1b3e7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>2</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>2</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cuisine-rating/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Do customers spend more at seafood cuisine than at other cuisines?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['Cuisines']!='Seafood']['Budget'].mean() < df[df['Cuisines']=='Seafood']['Budget'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['Cuisines']!='Seafood']['Budget'].mean() < df[df['Cuisines']=='Seafood']['Budget'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['Cuisines'] != 'Seafood']['Budget'].mean() < df[df[
    'Cuisines'] == 'Seafood']['Budget'].mean()
</code></pre>
        <p><span onclick="$('#var_output_f53b491c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f53b491c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (bool_):</p>
          <pre><code>False</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (bool_):</p>
          <pre><code>False</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> cuisine-rating/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Where are customers having an average food rating of more than 3 located? (Show the locations as index and the average as values sorted from the highest to the lowest)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>location_mean=df.groupby('Location').mean()
location_mean[location_mean['Food Rating']>3]['Food Rating'].sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>location_mean=df.groupby('Location').mean()
location_mean[location_mean['Food Rating']>3]['Food Rating'].sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>location_mean = df.groupby('Location').mean()
__output__ = location_mean[location_mean['Food Rating'] > 3]['Food Rating'
    ].sort_values(ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_1745ff5f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1745ff5f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Location
Market City, NY    4.050000
Market City, MY    4.000000
Central Park,NY    3.416667
St. George,NY      3.413043
Central Park,ny    3.125000
Riverdale,NY       3.035714
Name: Food Rating, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> location_mean, __output__ </p>
    
          <p>location_mean (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>User ID</th>
      <th>Area code</th>
      <th>YOB</th>
      <th>Budget</th>
      <th>Food Rating</th>
      <th>Service Rating</th>
      <th>Overall Rating</th>
      <th>Age</th>
    </tr>
    <tr>
      <th>Location</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Cedar Hill, NY</th>
      <td>141.000000</td>
      <td>169.500000</td>
      <td>1960.000000</td>
      <td>4.000000</td>
      <td>2.000000</td>
      <td>5.000000</td>
      <td>3.500000</td>
      <td>62.000000</td>
    </tr>
    <tr>
      <th>Central Park,NY</th>
      <td>91.000000</td>
      <td>142.583333</td>
      <td>1994.583333</td>
      <td>3.333333</td>
      <td>3.416667</td>
      <td>3.458333</td>
      <td>3.437500</td>
      <td>27.416667</td>
    </tr>
    <tr>
      <th>Central Park,ny</th>
      <td>91.000000</td>
      <td>138.500000</td>
      <td>1977.500000</td>
      <td>3.500000</td>
      <td>3.125000</td>
      <td>4.250000</td>
      <td>3.687500</td>
      <td>44.500000</td>
    </tr>
    <tr>
      <th>China Town, NY</th>
      <td>106.181818</td>
      <td>132.500000</td>
      <td>1983.818182</td>
      <td>3.454545</td>
      <td>2.681818</td>
      <td>3.636364</td>
      <td>3.159091</td>
      <td>38.181818</td>
    </tr>
    <tr>
      <th>Market City, MY</th>
      <td>82.000000</td>
      <td>156.500000</td>
      <td>1971.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>2.000000</td>
      <td>3.000000</td>
      <td>51.000000</td>
    </tr>
    <tr>
      <th>Market City, NY</th>
      <td>104.200000</td>
      <td>155.500000</td>
      <td>1977.900000</td>
      <td>3.900000</td>
      <td>4.050000</td>
      <td>3.400000</td>
      <td>3.725000</td>
      <td>44.100000</td>
    </tr>
    <tr>
      <th>Riverdale,NY</th>
      <td>94.071429</td>
      <td>127.821429</td>
      <td>1983.714286</td>
      <td>4.285714</td>
      <td>3.035714</td>
      <td>3.071429</td>
      <td>3.053571</td>
      <td>38.285714</td>
    </tr>
    <tr>
      <th>St. George,NY</th>
      <td>105.086957</td>
      <td>137.956522</td>
      <td>1986.434783</td>
      <td>3.978261</td>
      <td>3.413043</td>
      <td>2.826087</td>
      <td>3.119565</td>
      <td>35.565217</td>
    </tr>
    <tr>
      <th>Upper East Side,NY</th>
      <td>96.400000</td>
      <td>155.200000</td>
      <td>1985.533333</td>
      <td>3.866667</td>
      <td>2.966667</td>
      <td>3.066667</td>
      <td>3.016667</td>
      <td>36.466667</td>
    </tr>
    <tr>
      <th>Upper West Side,NY</th>
      <td>109.000000</td>
      <td>134.666667</td>
      <td>1984.777778</td>
      <td>4.000000</td>
      <td>3.000000</td>
      <td>3.277778</td>
      <td>3.138889</td>
      <td>37.222222</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 8 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Location
Market City, NY    4.050000
Market City, MY    4.000000
Central Park,NY    3.416667
St. George,NY      3.413043
Central Park,ny    3.125000
Riverdale,NY       3.035714
Name: Food Rating, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> loan-default-dataset/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the income of the customer that has the lowest credit score?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.iloc[df['Credit_Score'].idxmin()]['income']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.iloc[df['Credit_Score'].idxmin()]['income']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.iloc[df['Credit_Score'].idxmin()]['income']
</code></pre>
        <p><span onclick="$('#var_output_68bb3ff9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_68bb3ff9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>2580.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>2580.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> loan-default-dataset/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many female customers receive an income higher than the average income?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>income_mean=df['income'].mean()
len(df[(df['Gender']=='Female') & (df['income']>income_mean)])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>income_mean=df['income'].mean()
len(df[(df['Gender']=='Female') & (df['income']>income_mean)])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>income_mean = df['income'].mean()
__output__ = len(df[(df['Gender'] == 'Female') & (df['income'] > income_mean)])
</code></pre>
        <p><span onclick="$('#var_output_22312449').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_22312449" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>6353</code></pre>
      
        <p><strong>Hyp output variables:</strong> income_mean, __output__ </p>
    
          <p>income_mean (float64):</p>
          <pre><code>6957.338876146789</code></pre>
      
          <p>__output__ (int):</p>
          <pre><code>6353</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> loan-default-dataset/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which male customer has the lowest credit score within approved loans?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.iloc[df[(df['Status']==1) & (df['Gender']=='Male')]['Credit_Score'].idxmin()]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.iloc[df[(df['Status']==1) & (df['Gender']=='Male')]['Credit_Score'].idxmin()]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.iloc[df[(df['Status'] == 1) & (df['Gender'] == 'Male')][
    'Credit_Score'].idxmin()]
</code></pre>
        <p><span onclick="$('#var_output_006a6c5c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_006a6c5c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>ID                   30896
year                  2019
loan_limit              cf
Gender                Male
approv_in_adv        nopre
                   ...    
LTV              91.881443
Region               North
Security_Type       direct
Status                   1
dtir1                 46.0
Name: 6006, Length: 34, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>ID                   30896
year                  2019
loan_limit              cf
Gender                Male
approv_in_adv        nopre
                   ...    
LTV              91.881443
Region               North
Security_Type       direct
Status                   1
dtir1                 46.0
Name: 6006, Length: 34, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> loan-default-dataset/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many customers in each gender have an approved loan? (Sorted from the highest to the lowest)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['Status']==1].groupby('Gender').count()['ID'].sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['Status']==1].groupby('Gender').count()['ID'].sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['Status'] == 1].groupby('Gender').count()['ID'].sort_values(
    ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_9aa8050e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9aa8050e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Gender
Male                 11091
Sex Not Available    10767
Joint                 7933
Female                6848
Name: ID, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Gender
Male                 11091
Sex Not Available    10767
Joint                 7933
Female                6848
Name: ID, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> loan-default-dataset/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of approved loans for each loan type?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>((df[df['Status']==1].groupby('loan_type').count()['ID'])/(df.groupby('loan_type').count()['ID']))*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>((df[df['Status']==1].groupby('loan_type').count()['ID'])/(df.groupby('loan_type').count()['ID']))*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['Status'] == 1].groupby('loan_type').count()['ID'
    ] / df.groupby('loan_type').count()['ID'] * 100
</code></pre>
        <p><span onclick="$('#var_output_2bafd061').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2bafd061" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>loan_type
type1    22.774867
type2    34.543878
type3    25.055989
Name: ID, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>loan_type
type1    22.774867
type2    34.543878
type3    25.055989
Name: ID, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> loan-default-dataset/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show customers that have the highest income for each age group</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>maxincome=list(df.groupby('age')['income'].idxmax().values)
df.loc[maxincome]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>maxincome=list(df.groupby('age')['income'].idxmax().values)
df.loc[maxincome]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>maxincome = list(df.groupby('age')['income'].idxmax().values)
__output__ = df.loc[maxincome]
</code></pre>
        <p><span onclick="$('#var_output_cafab463').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_cafab463" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>year</th>
      <th>loan_limit</th>
      <th>Gender</th>
      <th>approv_in_adv</th>
      <th>loan_type</th>
      <th>loan_purpose</th>
      <th>...</th>
      <th>age</th>
      <th>submission_of_application</th>
      <th>LTV</th>
      <th>Region</th>
      <th>Security_Type</th>
      <th>Status</th>
      <th>dtir1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>31674</th>
      <td>56564</td>
      <td>2019</td>
      <td>ncf</td>
      <td>Male</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p4</td>
      <td>...</td>
      <td>25-34</td>
      <td>not_inst</td>
      <td>54.699248</td>
      <td>North</td>
      <td>direct</td>
      <td>0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>1055</th>
      <td>25945</td>
      <td>2019</td>
      <td>cf</td>
      <td>Sex Not Available</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p4</td>
      <td>...</td>
      <td>35-44</td>
      <td>to_inst</td>
      <td>52.477974</td>
      <td>south</td>
      <td>direct</td>
      <td>0</td>
      <td>14.0</td>
    </tr>
    <tr>
      <th>62237</th>
      <td>87127</td>
      <td>2019</td>
      <td>ncf</td>
      <td>Sex Not Available</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p3</td>
      <td>...</td>
      <td>45-54</td>
      <td>to_inst</td>
      <td>60.094027</td>
      <td>south</td>
      <td>direct</td>
      <td>1</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>33621</th>
      <td>58511</td>
      <td>2019</td>
      <td>cf</td>
      <td>Joint</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p3</td>
      <td>...</td>
      <td>55-64</td>
      <td>not_inst</td>
      <td>24.460986</td>
      <td>North</td>
      <td>direct</td>
      <td>0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>117307</th>
      <td>142197</td>
      <td>2019</td>
      <td>cf</td>
      <td>Sex Not Available</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p4</td>
      <td>...</td>
      <td>65-74</td>
      <td>to_inst</td>
      <td>43.888013</td>
      <td>south</td>
      <td>direct</td>
      <td>0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>141741</th>
      <td>166631</td>
      <td>2019</td>
      <td>cf</td>
      <td>Male</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p1</td>
      <td>...</td>
      <td>&lt;25</td>
      <td>not_inst</td>
      <td>NaN</td>
      <td>North</td>
      <td>direct</td>
      <td>1</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43154</th>
      <td>68044</td>
      <td>2019</td>
      <td>ncf</td>
      <td>Male</td>
      <td>pre</td>
      <td>type1</td>
      <td>p4</td>
      <td>...</td>
      <td>&gt;74</td>
      <td>to_inst</td>
      <td>NaN</td>
      <td>North</td>
      <td>direct</td>
      <td>1</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 34 columns</p>
      
        <p><strong>Hyp output variables:</strong> maxincome, __output__ </p>
    
          <p>maxincome (list):</p>
          <pre><code>[31674, 1055, 62237, 33621, 117307, 141741, 43154]</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>year</th>
      <th>loan_limit</th>
      <th>Gender</th>
      <th>approv_in_adv</th>
      <th>loan_type</th>
      <th>loan_purpose</th>
      <th>...</th>
      <th>age</th>
      <th>submission_of_application</th>
      <th>LTV</th>
      <th>Region</th>
      <th>Security_Type</th>
      <th>Status</th>
      <th>dtir1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>31674</th>
      <td>56564</td>
      <td>2019</td>
      <td>ncf</td>
      <td>Male</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p4</td>
      <td>...</td>
      <td>25-34</td>
      <td>not_inst</td>
      <td>54.699248</td>
      <td>North</td>
      <td>direct</td>
      <td>0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>1055</th>
      <td>25945</td>
      <td>2019</td>
      <td>cf</td>
      <td>Sex Not Available</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p4</td>
      <td>...</td>
      <td>35-44</td>
      <td>to_inst</td>
      <td>52.477974</td>
      <td>south</td>
      <td>direct</td>
      <td>0</td>
      <td>14.0</td>
    </tr>
    <tr>
      <th>62237</th>
      <td>87127</td>
      <td>2019</td>
      <td>ncf</td>
      <td>Sex Not Available</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p3</td>
      <td>...</td>
      <td>45-54</td>
      <td>to_inst</td>
      <td>60.094027</td>
      <td>south</td>
      <td>direct</td>
      <td>1</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>33621</th>
      <td>58511</td>
      <td>2019</td>
      <td>cf</td>
      <td>Joint</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p3</td>
      <td>...</td>
      <td>55-64</td>
      <td>not_inst</td>
      <td>24.460986</td>
      <td>North</td>
      <td>direct</td>
      <td>0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>117307</th>
      <td>142197</td>
      <td>2019</td>
      <td>cf</td>
      <td>Sex Not Available</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p4</td>
      <td>...</td>
      <td>65-74</td>
      <td>to_inst</td>
      <td>43.888013</td>
      <td>south</td>
      <td>direct</td>
      <td>0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>141741</th>
      <td>166631</td>
      <td>2019</td>
      <td>cf</td>
      <td>Male</td>
      <td>nopre</td>
      <td>type1</td>
      <td>p1</td>
      <td>...</td>
      <td>&lt;25</td>
      <td>not_inst</td>
      <td>NaN</td>
      <td>North</td>
      <td>direct</td>
      <td>1</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43154</th>
      <td>68044</td>
      <td>2019</td>
      <td>ncf</td>
      <td>Male</td>
      <td>pre</td>
      <td>type1</td>
      <td>p4</td>
      <td>...</td>
      <td>&gt;74</td>
      <td>to_inst</td>
      <td>NaN</td>
      <td>North</td>
      <td>direct</td>
      <td>1</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 34 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> loan-default-dataset/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total number of declined loans per each age group per gender? (show age as index and gender as columns)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pd.pivot_table(df[df['Status']==0],index='age',columns='Gender',aggfunc=np.count_nonzero)["ID"]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pd.pivot_table(df[df['Status']==0],index='age',columns='Gender',aggfunc=np.count_nonzero)["ID"]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = pd.pivot_table(df[df['Status'] == 0], index='age', columns=
    'Gender', aggfunc=np.count_nonzero)['ID']
</code></pre>
        <p><span onclick="$('#var_output_710f5516').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_710f5516" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Gender</th>
      <th>Female</th>
      <th>Joint</th>
      <th>Male</th>
      <th>Sex Not Available</th>
    </tr>
    <tr>
      <th>age</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>25-34</th>
      <td>2314</td>
      <td>4811</td>
      <td>5201</td>
      <td>2568</td>
    </tr>
    <tr>
      <th>35-44</th>
      <td>4105</td>
      <td>8111</td>
      <td>7912</td>
      <td>5381</td>
    </tr>
    <tr>
      <th>45-54</th>
      <td>4890</td>
      <td>7681</td>
      <td>7550</td>
      <td>6250</td>
    </tr>
    <tr>
      <th>55-64</th>
      <td>4902</td>
      <td>6615</td>
      <td>5992</td>
      <td>6603</td>
    </tr>
    <tr>
      <th>65-74</th>
      <td>3037</td>
      <td>4556</td>
      <td>3157</td>
      <td>4423</td>
    </tr>
    <tr>
      <th>&lt;25</th>
      <td>169</td>
      <td>227</td>
      <td>395</td>
      <td>159</td>
    </tr>
    <tr>
      <th>&gt;74</th>
      <td>1001</td>
      <td>1465</td>
      <td>1048</td>
      <td>1508</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 4 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Gender</th>
      <th>Female</th>
      <th>Joint</th>
      <th>Male</th>
      <th>Sex Not Available</th>
    </tr>
    <tr>
      <th>age</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>25-34</th>
      <td>2314</td>
      <td>4811</td>
      <td>5201</td>
      <td>2568</td>
    </tr>
    <tr>
      <th>35-44</th>
      <td>4105</td>
      <td>8111</td>
      <td>7912</td>
      <td>5381</td>
    </tr>
    <tr>
      <th>45-54</th>
      <td>4890</td>
      <td>7681</td>
      <td>7550</td>
      <td>6250</td>
    </tr>
    <tr>
      <th>55-64</th>
      <td>4902</td>
      <td>6615</td>
      <td>5992</td>
      <td>6603</td>
    </tr>
    <tr>
      <th>65-74</th>
      <td>3037</td>
      <td>4556</td>
      <td>3157</td>
      <td>4423</td>
    </tr>
    <tr>
      <th>&lt;25</th>
      <td>169</td>
      <td>227</td>
      <td>395</td>
      <td>159</td>
    </tr>
    <tr>
      <th>&gt;74</th>
      <td>1001</td>
      <td>1465</td>
      <td>1048</td>
      <td>1508</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 4 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> loan-default-dataset/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average income of the top 10 customers that have the highest rate of interest and pre-apporved loans.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['approv_in_adv']=='pre'].sort_values('rate_of_interest',ascending=False).head(10)['income'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['approv_in_adv']=='pre'].sort_values('rate_of_interest',ascending=False).head(10)['income'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['approv_in_adv'] == 'pre'].sort_values('rate_of_interest',
    ascending=False).head(10)['income'].mean()
</code></pre>
        <p><span onclick="$('#var_output_a735c142').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a735c142" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>13626.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>13626.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> loan-default-dataset/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the median term value for male customers located in south region?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['Region']=='south') & (df['Gender']=='Male')]['term'].median()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['Region']=='south') & (df['Gender']=='Male')]['term'].median()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['Region'] == 'south') & (df['Gender'] == 'Male')]['term'
    ].median()
</code></pre>
        <p><span onclick="$('#var_output_ccb5060d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ccb5060d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>360.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>360.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> loan-default-dataset/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the number of approved loans in each region?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['Status']==1].groupby('Region')['ID'].count().sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['Status']==1].groupby('Region')['ID'].count().sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['Status'] == 1].groupby('Region')['ID'].count().sort_values(
    ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_3f2f38e4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3f2f38e4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Region
south         17047
North         16821
central        2395
North-East      376
Name: ID, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Region
south         17047
North         16821
central        2395
North-East      376
Name: ID, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> car-price-prediction-challenge/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert Levy and Mileage columns from object to integer.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['Levy'] = df['Levy'].replace(['-'],['0']).astype(int)
df['Mileage'] = df['Mileage'].apply(lambda x : str(x).replace("km"," ")).astype(int)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['Levy'] = df['Levy'].replace(['-'],['0']).astype(int)
df['Mileage'] = df['Mileage'].apply(lambda x : str(x).replace("km"," ")).astype(int)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['Levy'] = df['Levy'].replace(['-'], ['0']).astype(int)
__output__ = df['Mileage'] = df['Mileage'].apply(lambda x: str(x).replace(
    'km', ' ')).astype(int)
</code></pre>
        <p><span onclick="$('#var_output_c9525d7f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c9525d7f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0        186005
1        192000
2        200000
3        168966
4         91901
          ...  
19232    300000
19233    161600
19234    116365
19235     51258
19236    186923
Name: Mileage, Length: 19237, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Price</th>
      <th>Levy</th>
      <th>Manufacturer</th>
      <th>Model</th>
      <th>Prod. year</th>
      <th>Category</th>
      <th>...</th>
      <th>Cylinders</th>
      <th>Gear box type</th>
      <th>Drive wheels</th>
      <th>Doors</th>
      <th>Wheel</th>
      <th>Color</th>
      <th>Airbags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>45654403</td>
      <td>13328</td>
      <td>1399</td>
      <td>LEXUS</td>
      <td>RX 450</td>
      <td>2010</td>
      <td>Jeep</td>
      <td>...</td>
      <td>6.0</td>
      <td>Automatic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>44731507</td>
      <td>16621</td>
      <td>1018</td>
      <td>CHEVROLET</td>
      <td>Equinox</td>
      <td>2011</td>
      <td>Jeep</td>
      <td>...</td>
      <td>6.0</td>
      <td>Tiptronic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>45774419</td>
      <td>8467</td>
      <td>0</td>
      <td>HONDA</td>
      <td>FIT</td>
      <td>2006</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>4.0</td>
      <td>Variator</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Right-hand drive</td>
      <td>Black</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>45769185</td>
      <td>3607</td>
      <td>862</td>
      <td>FORD</td>
      <td>Escape</td>
      <td>2011</td>
      <td>Jeep</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>45809263</td>
      <td>11726</td>
      <td>446</td>
      <td>HONDA</td>
      <td>FIT</td>
      <td>2014</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>4</td>
    </tr>
    <tr>
      <th>5</th>
      <td>45802912</td>
      <td>39493</td>
      <td>891</td>
      <td>HYUNDAI</td>
      <td>Santa FE</td>
      <td>2016</td>
      <td>Jeep</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>4</td>
    </tr>
    <tr>
      <th>6</th>
      <td>45656768</td>
      <td>1803</td>
      <td>761</td>
      <td>TOYOTA</td>
      <td>Prius</td>
      <td>2010</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>12</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19230</th>
      <td>45760891</td>
      <td>470</td>
      <td>645</td>
      <td>TOYOTA</td>
      <td>Prius</td>
      <td>2011</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>12</td>
    </tr>
    <tr>
      <th>19231</th>
      <td>45772306</td>
      <td>5802</td>
      <td>1055</td>
      <td>MERCEDES-BENZ</td>
      <td>E 350</td>
      <td>2013</td>
      <td>Sedan</td>
      <td>...</td>
      <td>6.0</td>
      <td>Automatic</td>
      <td>Rear</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Grey</td>
      <td>12</td>
    </tr>
    <tr>
      <th>19232</th>
      <td>45798355</td>
      <td>8467</td>
      <td>0</td>
      <td>MERCEDES-BENZ</td>
      <td>CLK 200</td>
      <td>1999</td>
      <td>Coupe</td>
      <td>...</td>
      <td>4.0</td>
      <td>Manual</td>
      <td>Rear</td>
      <td>02-Mar</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>5</td>
    </tr>
    <tr>
      <th>19233</th>
      <td>45778856</td>
      <td>15681</td>
      <td>831</td>
      <td>HYUNDAI</td>
      <td>Sonata</td>
      <td>2011</td>
      <td>Sedan</td>
      <td>...</td>
      <td>4.0</td>
      <td>Tiptronic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Red</td>
      <td>8</td>
    </tr>
    <tr>
      <th>19234</th>
      <td>45804997</td>
      <td>26108</td>
      <td>836</td>
      <td>HYUNDAI</td>
      <td>Tucson</td>
      <td>2010</td>
      <td>Jeep</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Grey</td>
      <td>4</td>
    </tr>
    <tr>
      <th>19235</th>
      <td>45793526</td>
      <td>5331</td>
      <td>1288</td>
      <td>CHEVROLET</td>
      <td>Captiva</td>
      <td>2007</td>
      <td>Jeep</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>4</td>
    </tr>
    <tr>
      <th>19236</th>
      <td>45813273</td>
      <td>470</td>
      <td>753</td>
      <td>HYUNDAI</td>
      <td>Sonata</td>
      <td>2012</td>
      <td>Sedan</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>12</td>
    </tr>
  </tbody>
</table>
<p>19237 rows × 18 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0        186005
1        192000
2        200000
3        168966
4         91901
          ...  
19232    300000
19233    161600
19234    116365
19235     51258
19236    186923
Name: Mileage, Length: 19237, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> car-price-prediction-challenge/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many turbo jeep cars does Lexus have?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['Engine volume'].str.contains('Turbo')) & (df.Category=='Jeep') & (df['Manufacturer']=='LEXUS')].shape[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['Engine volume'].str.contains('Turbo')) & (df.Category=='Jeep') & (df['Manufacturer']=='LEXUS')].shape[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['Engine volume'].str.contains('Turbo') & (df.Category ==
    'Jeep') & (df['Manufacturer'] == 'LEXUS')].shape[0]
</code></pre>
        <p><span onclick="$('#var_output_4b82d11b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4b82d11b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>12</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>12</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> car-price-prediction-challenge/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # On average, how many airbags does Honda have in their hybrid hatchback cars? Round  to the nearest integer.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>round(df.groupby('Manufacturer').get_group('HONDA').groupby('Category').get_group('Hatchback').groupby('Fuel type').get_group('Hybrid')['Airbags'].mean())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>round(df.groupby('Manufacturer').get_group('HONDA').groupby('Category').get_group('Hatchback').groupby('Fuel type').get_group('Hybrid')['Airbags'].mean())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = round(df.groupby('Manufacturer').get_group('HONDA').groupby(
    'Category').get_group('Hatchback').groupby('Fuel type').get_group(
    'Hybrid')['Airbags'].mean())
</code></pre>
        <p><span onclick="$('#var_output_19b4d7dc').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_19b4d7dc" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>4</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>4</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> car-price-prediction-challenge/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show a list of models produced by Ford after 2010 that have a six-cylinder engine.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['Manufacturer']=='FORD') & (df['Prod. year']>2010) & (df['Cylinders']==6)]['Model'].unique().tolist()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['Manufacturer']=='FORD') & (df['Prod. year']>2010) & (df['Cylinders']==6)]['Model'].unique().tolist()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['Manufacturer'] == 'FORD') & (df['Prod. year'] > 2010) &
    (df['Cylinders'] == 6)]['Model'].unique().tolist()
</code></pre>
        <p><span onclick="$('#var_output_e8967c44').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e8967c44" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Taurus', 'Mustang', 'Edge', 'Explorer', 'Taurus interceptor', 'B-MAX', 'Expedition', 'Fusion', 'Escape', 'Mustang cabrio', 'F150', 'C-MAX', 'Ranger']</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Taurus', 'Mustang', 'Edge', 'Explorer', 'Taurus interceptor', 'B-MAX', 'Expedition', 'Fusion', 'Escape', 'Mustang cabrio', 'F150', 'C-MAX', 'Ranger']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> car-price-prediction-challenge/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Is the average price for a 4x4 Lexus higher than that of Lexus's different drive wheel types?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['Manufacturer']=='LEXUS') & (df['Drive wheels']=='4x4')]['Price'].mean()> df[(df['Manufacturer']=='LEXUS') & (df['Drive wheels']!='4x4')]['Price'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['Manufacturer']=='LEXUS') & (df['Drive wheels']=='4x4')]['Price'].mean()> df[(df['Manufacturer']=='LEXUS') & (df['Drive wheels']!='4x4')]['Price'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['Manufacturer'] == 'LEXUS') & (df['Drive wheels'] == '4x4')
    ]['Price'].mean() > df[(df['Manufacturer'] == 'LEXUS') & (df[
    'Drive wheels'] != '4x4')]['Price'].mean()
</code></pre>
        <p><span onclick="$('#var_output_2ab8962c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2ab8962c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (bool_):</p>
          <pre><code>True</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (bool_):</p>
          <pre><code>True</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> car-price-prediction-challenge/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many different colors do Chevrolet cars have available for each model? (Show models and the number of colors in ascending order)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.Manufacturer=='CHEVROLET'].groupby('Model')['Color'].nunique().sort_values()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.Manufacturer=='CHEVROLET'].groupby('Model')['Color'].nunique().sort_values()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.Manufacturer == 'CHEVROLET'].groupby('Model')['Color'
    ].nunique().sort_values()
</code></pre>
        <p><span onclick="$('#var_output_b0580c28').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b0580c28" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Model
Avalanche     1
Colorado      1
Camaro RS     1
Camaro LS     1
Cruze LS      1
             ..
Volt          8
Camaro        8
Aveo          8
Orlando       8
Cruze        13
Name: Color, Length: 50, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Model
Avalanche     1
Colorado      1
Camaro RS     1
Camaro LS     1
Cruze LS      1
             ..
Volt          8
Camaro        8
Aveo          8
Orlando       8
Cruze        13
Name: Color, Length: 50, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> car-price-prediction-challenge/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many non-hybrid left-hand drive cars have more than 2 airbags?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>left_wheel=df.groupby('Wheel').get_group('Left wheel')
left_wheel[(~df['Fuel type'].str.contains('Hybrid')) & (df.Airbags>2)].shape[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>left_wheel=df.groupby('Wheel').get_group('Left wheel')
left_wheel[(~df['Fuel type'].str.contains('Hybrid')) & (df.Airbags>2)].shape[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>left_wheel = df.groupby('Wheel').get_group('Left wheel')
__output__ = left_wheel[~df['Fuel type'].str.contains('Hybrid') & (df.
    Airbags > 2)].shape[0]
</code></pre>
        <p><span onclick="$('#var_output_b03cf37d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b03cf37d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>12047</code></pre>
      
        <p><strong>Hyp output variables:</strong> left_wheel, __output__ </p>
    
          <p>left_wheel (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Price</th>
      <th>Levy</th>
      <th>Manufacturer</th>
      <th>Model</th>
      <th>Prod. year</th>
      <th>Category</th>
      <th>...</th>
      <th>Cylinders</th>
      <th>Gear box type</th>
      <th>Drive wheels</th>
      <th>Doors</th>
      <th>Wheel</th>
      <th>Color</th>
      <th>Airbags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>45654403</td>
      <td>13328</td>
      <td>1399</td>
      <td>LEXUS</td>
      <td>RX 450</td>
      <td>2010</td>
      <td>Jeep</td>
      <td>...</td>
      <td>6.0</td>
      <td>Automatic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>44731507</td>
      <td>16621</td>
      <td>1018</td>
      <td>CHEVROLET</td>
      <td>Equinox</td>
      <td>2011</td>
      <td>Jeep</td>
      <td>...</td>
      <td>6.0</td>
      <td>Tiptronic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>45769185</td>
      <td>3607</td>
      <td>862</td>
      <td>FORD</td>
      <td>Escape</td>
      <td>2011</td>
      <td>Jeep</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>45809263</td>
      <td>11726</td>
      <td>446</td>
      <td>HONDA</td>
      <td>FIT</td>
      <td>2014</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>4</td>
    </tr>
    <tr>
      <th>5</th>
      <td>45802912</td>
      <td>39493</td>
      <td>891</td>
      <td>HYUNDAI</td>
      <td>Santa FE</td>
      <td>2016</td>
      <td>Jeep</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>4</td>
    </tr>
    <tr>
      <th>6</th>
      <td>45656768</td>
      <td>1803</td>
      <td>761</td>
      <td>TOYOTA</td>
      <td>Prius</td>
      <td>2010</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>12</td>
    </tr>
    <tr>
      <th>7</th>
      <td>45816158</td>
      <td>549</td>
      <td>751</td>
      <td>HYUNDAI</td>
      <td>Sonata</td>
      <td>2013</td>
      <td>Sedan</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Grey</td>
      <td>12</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19230</th>
      <td>45760891</td>
      <td>470</td>
      <td>645</td>
      <td>TOYOTA</td>
      <td>Prius</td>
      <td>2011</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>12</td>
    </tr>
    <tr>
      <th>19231</th>
      <td>45772306</td>
      <td>5802</td>
      <td>1055</td>
      <td>MERCEDES-BENZ</td>
      <td>E 350</td>
      <td>2013</td>
      <td>Sedan</td>
      <td>...</td>
      <td>6.0</td>
      <td>Automatic</td>
      <td>Rear</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Grey</td>
      <td>12</td>
    </tr>
    <tr>
      <th>19232</th>
      <td>45798355</td>
      <td>8467</td>
      <td>0</td>
      <td>MERCEDES-BENZ</td>
      <td>CLK 200</td>
      <td>1999</td>
      <td>Coupe</td>
      <td>...</td>
      <td>4.0</td>
      <td>Manual</td>
      <td>Rear</td>
      <td>02-Mar</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>5</td>
    </tr>
    <tr>
      <th>19233</th>
      <td>45778856</td>
      <td>15681</td>
      <td>831</td>
      <td>HYUNDAI</td>
      <td>Sonata</td>
      <td>2011</td>
      <td>Sedan</td>
      <td>...</td>
      <td>4.0</td>
      <td>Tiptronic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Red</td>
      <td>8</td>
    </tr>
    <tr>
      <th>19234</th>
      <td>45804997</td>
      <td>26108</td>
      <td>836</td>
      <td>HYUNDAI</td>
      <td>Tucson</td>
      <td>2010</td>
      <td>Jeep</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Grey</td>
      <td>4</td>
    </tr>
    <tr>
      <th>19235</th>
      <td>45793526</td>
      <td>5331</td>
      <td>1288</td>
      <td>CHEVROLET</td>
      <td>Captiva</td>
      <td>2007</td>
      <td>Jeep</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>4</td>
    </tr>
    <tr>
      <th>19236</th>
      <td>45813273</td>
      <td>470</td>
      <td>753</td>
      <td>HYUNDAI</td>
      <td>Sonata</td>
      <td>2012</td>
      <td>Sedan</td>
      <td>...</td>
      <td>4.0</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>12</td>
    </tr>
  </tbody>
</table>
<p>17753 rows × 18 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>12047</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> car-price-prediction-challenge/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average mileage per year in thousands for each manufacturer?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['Mileage/year']=df['Mileage']/(datetime.now().year - df['Prod. year'])
df.groupby('Manufacturer').mean()['Mileage/year']/1000</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['Mileage/year']=df['Mileage']/(datetime.now().year - df['Prod. year'])
df.groupby('Manufacturer').mean()['Mileage/year']/1000</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['Mileage/year'] = df['Mileage'] / (datetime.now().year - df['Prod. year'])
__output__ = df.groupby('Manufacturer').mean()['Mileage/year'] / 1000
</code></pre>
        <p><span onclick="$('#var_output_45fbd638').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_45fbd638" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Manufacturer
ACURA            11.353083
ALFA ROMEO        9.837442
ASTON MARTIN      4.800000
AUDI             16.507757
BENTLEY           3.290750
                   ...    
VAZ               2.865885
VOLKSWAGEN      241.436456
VOLVO            12.144467
ZAZ               4.053658
სხვა             13.933333
Name: Mileage/year, Length: 65, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Price</th>
      <th>Levy</th>
      <th>Manufacturer</th>
      <th>Model</th>
      <th>Prod. year</th>
      <th>Category</th>
      <th>...</th>
      <th>Gear box type</th>
      <th>Drive wheels</th>
      <th>Doors</th>
      <th>Wheel</th>
      <th>Color</th>
      <th>Airbags</th>
      <th>Mileage/year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>45654403</td>
      <td>13328</td>
      <td>1399</td>
      <td>LEXUS</td>
      <td>RX 450</td>
      <td>2010</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Automatic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>12</td>
      <td>15500.416667</td>
    </tr>
    <tr>
      <th>1</th>
      <td>44731507</td>
      <td>16621</td>
      <td>1018</td>
      <td>CHEVROLET</td>
      <td>Equinox</td>
      <td>2011</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>8</td>
      <td>17454.545455</td>
    </tr>
    <tr>
      <th>2</th>
      <td>45774419</td>
      <td>8467</td>
      <td>0</td>
      <td>HONDA</td>
      <td>FIT</td>
      <td>2006</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>Variator</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Right-hand drive</td>
      <td>Black</td>
      <td>2</td>
      <td>12500.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>45769185</td>
      <td>3607</td>
      <td>862</td>
      <td>FORD</td>
      <td>Escape</td>
      <td>2011</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Automatic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>0</td>
      <td>15360.545455</td>
    </tr>
    <tr>
      <th>4</th>
      <td>45809263</td>
      <td>11726</td>
      <td>446</td>
      <td>HONDA</td>
      <td>FIT</td>
      <td>2014</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>4</td>
      <td>11487.625000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>45802912</td>
      <td>39493</td>
      <td>891</td>
      <td>HYUNDAI</td>
      <td>Santa FE</td>
      <td>2016</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>4</td>
      <td>26821.833333</td>
    </tr>
    <tr>
      <th>6</th>
      <td>45656768</td>
      <td>1803</td>
      <td>761</td>
      <td>TOYOTA</td>
      <td>Prius</td>
      <td>2010</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>12</td>
      <td>21575.750000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19230</th>
      <td>45760891</td>
      <td>470</td>
      <td>645</td>
      <td>TOYOTA</td>
      <td>Prius</td>
      <td>2011</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>12</td>
      <td>27938.636364</td>
    </tr>
    <tr>
      <th>19231</th>
      <td>45772306</td>
      <td>5802</td>
      <td>1055</td>
      <td>MERCEDES-BENZ</td>
      <td>E 350</td>
      <td>2013</td>
      <td>Sedan</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Rear</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Grey</td>
      <td>12</td>
      <td>11977.777778</td>
    </tr>
    <tr>
      <th>19232</th>
      <td>45798355</td>
      <td>8467</td>
      <td>0</td>
      <td>MERCEDES-BENZ</td>
      <td>CLK 200</td>
      <td>1999</td>
      <td>Coupe</td>
      <td>...</td>
      <td>Manual</td>
      <td>Rear</td>
      <td>02-Mar</td>
      <td>Left wheel</td>
      <td>Silver</td>
      <td>5</td>
      <td>13043.478261</td>
    </tr>
    <tr>
      <th>19233</th>
      <td>45778856</td>
      <td>15681</td>
      <td>831</td>
      <td>HYUNDAI</td>
      <td>Sonata</td>
      <td>2011</td>
      <td>Sedan</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Red</td>
      <td>8</td>
      <td>14690.909091</td>
    </tr>
    <tr>
      <th>19234</th>
      <td>45804997</td>
      <td>26108</td>
      <td>836</td>
      <td>HYUNDAI</td>
      <td>Tucson</td>
      <td>2010</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Grey</td>
      <td>4</td>
      <td>9697.083333</td>
    </tr>
    <tr>
      <th>19235</th>
      <td>45793526</td>
      <td>5331</td>
      <td>1288</td>
      <td>CHEVROLET</td>
      <td>Captiva</td>
      <td>2007</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>4</td>
      <td>3417.200000</td>
    </tr>
    <tr>
      <th>19236</th>
      <td>45813273</td>
      <td>470</td>
      <td>753</td>
      <td>HYUNDAI</td>
      <td>Sonata</td>
      <td>2012</td>
      <td>Sedan</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>12</td>
      <td>18692.300000</td>
    </tr>
  </tbody>
</table>
<p>19237 rows × 19 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Manufacturer
ACURA            11.353083
ALFA ROMEO        9.837442
ASTON MARTIN      4.800000
AUDI             16.507757
BENTLEY           3.290750
                   ...    
VAZ               2.865885
VOLKSWAGEN      241.436456
VOLVO            12.144467
ZAZ               4.053658
სხვა             13.933333
Name: Mileage/year, Length: 65, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> car-price-prediction-challenge/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most expensive car for each manufacturer?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.iloc[df.groupby('Manufacturer').idxmax()['Price'].tolist()]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.iloc[df.groupby('Manufacturer').idxmax()['Price'].tolist()]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.iloc[df.groupby('Manufacturer').idxmax()['Price'].tolist()]
</code></pre>
        <p><span onclick="$('#var_output_d1e862bb').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d1e862bb" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Price</th>
      <th>Levy</th>
      <th>Manufacturer</th>
      <th>Model</th>
      <th>Prod. year</th>
      <th>Category</th>
      <th>...</th>
      <th>Gear box type</th>
      <th>Drive wheels</th>
      <th>Doors</th>
      <th>Wheel</th>
      <th>Color</th>
      <th>Airbags</th>
      <th>Mileage/year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5309</th>
      <td>45555548</td>
      <td>39201</td>
      <td>1053</td>
      <td>ACURA</td>
      <td>RDX</td>
      <td>2014</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Automatic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Grey</td>
      <td>10</td>
      <td>10200.000000</td>
    </tr>
    <tr>
      <th>10802</th>
      <td>41858253</td>
      <td>18817</td>
      <td>0</td>
      <td>ALFA ROMEO</td>
      <td>Giulietta</td>
      <td>2013</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Right-hand drive</td>
      <td>Black</td>
      <td>12</td>
      <td>9444.444444</td>
    </tr>
    <tr>
      <th>13325</th>
      <td>43432352</td>
      <td>54000</td>
      <td>0</td>
      <td>ASTON MARTIN</td>
      <td>Virage</td>
      <td>2007</td>
      <td>Coupe</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>Rear</td>
      <td>02-Mar</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>8</td>
      <td>4800.000000</td>
    </tr>
    <tr>
      <th>9013</th>
      <td>44732858</td>
      <td>111332</td>
      <td>0</td>
      <td>AUDI</td>
      <td>A8</td>
      <td>2016</td>
      <td>Sedan</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>12</td>
      <td>5500.000000</td>
    </tr>
    <tr>
      <th>2283</th>
      <td>45786808</td>
      <td>219527</td>
      <td>0</td>
      <td>BENTLEY</td>
      <td>Continental GT</td>
      <td>2012</td>
      <td>Coupe</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>4x4</td>
      <td>02-Mar</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>0</td>
      <td>5550.000000</td>
    </tr>
    <tr>
      <th>7749</th>
      <td>45760644</td>
      <td>288521</td>
      <td>2269</td>
      <td>BMW</td>
      <td>M5 Машина в максимально</td>
      <td>2018</td>
      <td>Sedan</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>0</td>
      <td>3375.000000</td>
    </tr>
    <tr>
      <th>17869</th>
      <td>45404481</td>
      <td>31361</td>
      <td>0</td>
      <td>BUICK</td>
      <td>Encore</td>
      <td>2016</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>0</td>
      <td>4000.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2768</th>
      <td>45772445</td>
      <td>172486</td>
      <td>0</td>
      <td>TOYOTA</td>
      <td>Land Cruiser</td>
      <td>2018</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Automatic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>16</td>
      <td>3250.000000</td>
    </tr>
    <tr>
      <th>9540</th>
      <td>45780546</td>
      <td>10036</td>
      <td>0</td>
      <td>UAZ</td>
      <td>31514</td>
      <td>1987</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Manual</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Green</td>
      <td>4</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>5791</th>
      <td>45816146</td>
      <td>18503</td>
      <td>556</td>
      <td>VAZ</td>
      <td>2121 (Niva)</td>
      <td>2014</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Manual</td>
      <td>4x4</td>
      <td>02-Mar</td>
      <td>Left wheel</td>
      <td>Green</td>
      <td>2</td>
      <td>4375.000000</td>
    </tr>
    <tr>
      <th>14783</th>
      <td>44739429</td>
      <td>68994</td>
      <td>0</td>
      <td>VOLKSWAGEN</td>
      <td>Crafter 2.5 TDI</td>
      <td>2009</td>
      <td>Microbus</td>
      <td>...</td>
      <td>Manual</td>
      <td>Rear</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>4</td>
      <td>10384.615385</td>
    </tr>
    <tr>
      <th>17383</th>
      <td>43485813</td>
      <td>28225</td>
      <td>0</td>
      <td>VOLVO</td>
      <td>S60</td>
      <td>2014</td>
      <td>Sedan</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>12</td>
      <td>11312.500000</td>
    </tr>
    <tr>
      <th>14990</th>
      <td>45791835</td>
      <td>5645</td>
      <td>0</td>
      <td>ZAZ</td>
      <td>969 luaz</td>
      <td>1990</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Manual</td>
      <td>4x4</td>
      <td>02-Mar</td>
      <td>Left wheel</td>
      <td>Green</td>
      <td>0</td>
      <td>2016.406250</td>
    </tr>
    <tr>
      <th>2358</th>
      <td>45779593</td>
      <td>25089</td>
      <td>0</td>
      <td>სხვა</td>
      <td>IVECO DAYLY</td>
      <td>2007</td>
      <td>Microbus</td>
      <td>...</td>
      <td>Manual</td>
      <td>Rear</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>1</td>
      <td>21866.666667</td>
    </tr>
  </tbody>
</table>
<p>65 rows × 19 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Price</th>
      <th>Levy</th>
      <th>Manufacturer</th>
      <th>Model</th>
      <th>Prod. year</th>
      <th>Category</th>
      <th>...</th>
      <th>Gear box type</th>
      <th>Drive wheels</th>
      <th>Doors</th>
      <th>Wheel</th>
      <th>Color</th>
      <th>Airbags</th>
      <th>Mileage/year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5309</th>
      <td>45555548</td>
      <td>39201</td>
      <td>1053</td>
      <td>ACURA</td>
      <td>RDX</td>
      <td>2014</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Automatic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Grey</td>
      <td>10</td>
      <td>10200.000000</td>
    </tr>
    <tr>
      <th>10802</th>
      <td>41858253</td>
      <td>18817</td>
      <td>0</td>
      <td>ALFA ROMEO</td>
      <td>Giulietta</td>
      <td>2013</td>
      <td>Hatchback</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Right-hand drive</td>
      <td>Black</td>
      <td>12</td>
      <td>9444.444444</td>
    </tr>
    <tr>
      <th>13325</th>
      <td>43432352</td>
      <td>54000</td>
      <td>0</td>
      <td>ASTON MARTIN</td>
      <td>Virage</td>
      <td>2007</td>
      <td>Coupe</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>Rear</td>
      <td>02-Mar</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>8</td>
      <td>4800.000000</td>
    </tr>
    <tr>
      <th>9013</th>
      <td>44732858</td>
      <td>111332</td>
      <td>0</td>
      <td>AUDI</td>
      <td>A8</td>
      <td>2016</td>
      <td>Sedan</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>12</td>
      <td>5500.000000</td>
    </tr>
    <tr>
      <th>2283</th>
      <td>45786808</td>
      <td>219527</td>
      <td>0</td>
      <td>BENTLEY</td>
      <td>Continental GT</td>
      <td>2012</td>
      <td>Coupe</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>4x4</td>
      <td>02-Mar</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>0</td>
      <td>5550.000000</td>
    </tr>
    <tr>
      <th>7749</th>
      <td>45760644</td>
      <td>288521</td>
      <td>2269</td>
      <td>BMW</td>
      <td>M5 Машина в максимально</td>
      <td>2018</td>
      <td>Sedan</td>
      <td>...</td>
      <td>Tiptronic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>0</td>
      <td>3375.000000</td>
    </tr>
    <tr>
      <th>17869</th>
      <td>45404481</td>
      <td>31361</td>
      <td>0</td>
      <td>BUICK</td>
      <td>Encore</td>
      <td>2016</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>0</td>
      <td>4000.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2768</th>
      <td>45772445</td>
      <td>172486</td>
      <td>0</td>
      <td>TOYOTA</td>
      <td>Land Cruiser</td>
      <td>2018</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Automatic</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>16</td>
      <td>3250.000000</td>
    </tr>
    <tr>
      <th>9540</th>
      <td>45780546</td>
      <td>10036</td>
      <td>0</td>
      <td>UAZ</td>
      <td>31514</td>
      <td>1987</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Manual</td>
      <td>4x4</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Green</td>
      <td>4</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>5791</th>
      <td>45816146</td>
      <td>18503</td>
      <td>556</td>
      <td>VAZ</td>
      <td>2121 (Niva)</td>
      <td>2014</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Manual</td>
      <td>4x4</td>
      <td>02-Mar</td>
      <td>Left wheel</td>
      <td>Green</td>
      <td>2</td>
      <td>4375.000000</td>
    </tr>
    <tr>
      <th>14783</th>
      <td>44739429</td>
      <td>68994</td>
      <td>0</td>
      <td>VOLKSWAGEN</td>
      <td>Crafter 2.5 TDI</td>
      <td>2009</td>
      <td>Microbus</td>
      <td>...</td>
      <td>Manual</td>
      <td>Rear</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>4</td>
      <td>10384.615385</td>
    </tr>
    <tr>
      <th>17383</th>
      <td>43485813</td>
      <td>28225</td>
      <td>0</td>
      <td>VOLVO</td>
      <td>S60</td>
      <td>2014</td>
      <td>Sedan</td>
      <td>...</td>
      <td>Automatic</td>
      <td>Front</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>Black</td>
      <td>12</td>
      <td>11312.500000</td>
    </tr>
    <tr>
      <th>14990</th>
      <td>45791835</td>
      <td>5645</td>
      <td>0</td>
      <td>ZAZ</td>
      <td>969 luaz</td>
      <td>1990</td>
      <td>Jeep</td>
      <td>...</td>
      <td>Manual</td>
      <td>4x4</td>
      <td>02-Mar</td>
      <td>Left wheel</td>
      <td>Green</td>
      <td>0</td>
      <td>2016.406250</td>
    </tr>
    <tr>
      <th>2358</th>
      <td>45779593</td>
      <td>25089</td>
      <td>0</td>
      <td>სხვა</td>
      <td>IVECO DAYLY</td>
      <td>2007</td>
      <td>Microbus</td>
      <td>...</td>
      <td>Manual</td>
      <td>Rear</td>
      <td>04-May</td>
      <td>Left wheel</td>
      <td>White</td>
      <td>1</td>
      <td>21866.666667</td>
    </tr>
  </tbody>
</table>
<p>65 rows × 19 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> car-price-prediction-challenge/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the count of each model for each manufacturer? (Show a dataframe with the model, and count as columns)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby('Manufacturer')['Model'].value_counts().rename("Count").reset_index().iloc[:,1:]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby('Manufacturer')['Model'].value_counts().rename("Count").reset_index().iloc[:,1:]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('Manufacturer')['Model'].value_counts().rename('Count'
    ).reset_index().iloc[:, 1:]
</code></pre>
        <p><span onclick="$('#var_output_c0743294').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c0743294" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>TSX</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>MDX</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>RDX</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>TL</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>TLX</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>TL saber</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>147</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1594</th>
      <td>V50</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1595</th>
      <td>XC90 2.5turbo</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1596</th>
      <td>XC90 3.2 AWD</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1597</th>
      <td>969 968m</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1598</th>
      <td>969 luaz</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1599</th>
      <td>GONOW</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1600</th>
      <td>IVECO DAYLY</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>1601 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>TSX</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>MDX</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>RDX</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>TL</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>TLX</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>TL saber</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>147</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1594</th>
      <td>V50</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1595</th>
      <td>XC90 2.5turbo</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1596</th>
      <td>XC90 3.2 AWD</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1597</th>
      <td>969 968m</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1598</th>
      <td>969 luaz</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1599</th>
      <td>GONOW</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1600</th>
      <td>IVECO DAYLY</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>1601 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> employee-attrition-for-healthcare/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For each gender, how many attrited employees over 18 for each travel category? (Show gender as index and travel categories as columns)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pd.pivot_table(df.groupby('Attrition').get_group('Yes').groupby('Over18').get_group('Y'),values='EmployeeID',columns='BusinessTravel',index='Gender',aggfunc=np.count_nonzero)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pd.pivot_table(df.groupby('Attrition').get_group('Yes').groupby('Over18').get_group('Y'),values='EmployeeID',columns='BusinessTravel',index='Gender',aggfunc=np.count_nonzero)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = pd.pivot_table(df.groupby('Attrition').get_group('Yes').
    groupby('Over18').get_group('Y'), values='EmployeeID', columns=
    'BusinessTravel', index='Gender', aggfunc=np.count_nonzero)
</code></pre>
        <p><span onclick="$('#var_output_ca06c553').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ca06c553" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>BusinessTravel</th>
      <th>Non-Travel</th>
      <th>Travel_Frequently</th>
      <th>Travel_Rarely</th>
    </tr>
    <tr>
      <th>Gender</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Female</th>
      <td>6</td>
      <td>31</td>
      <td>49</td>
    </tr>
    <tr>
      <th>Male</th>
      <td>10</td>
      <td>26</td>
      <td>77</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>BusinessTravel</th>
      <th>Non-Travel</th>
      <th>Travel_Frequently</th>
      <th>Travel_Rarely</th>
    </tr>
    <tr>
      <th>Gender</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Female</th>
      <td>6</td>
      <td>31</td>
      <td>49</td>
    </tr>
    <tr>
      <th>Male</th>
      <td>10</td>
      <td>26</td>
      <td>77</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> employee-attrition-for-healthcare/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many attrited employees under the age of 30 traveled frequently?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>grouped_df=df.groupby(df.BusinessTravel).get_group('Travel_Frequently').groupby('Attrition').get_group('Yes')
len(grouped_df[grouped_df['Age']<30])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>grouped_df=df.groupby(df.BusinessTravel).get_group('Travel_Frequently').groupby('Attrition').get_group('Yes')
len(grouped_df[grouped_df['Age']<30])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>grouped_df = df.groupby(df.BusinessTravel).get_group('Travel_Frequently'
    ).groupby('Attrition').get_group('Yes')
__output__ = len(grouped_df[grouped_df['Age'] < 30])
</code></pre>
        <p><span onclick="$('#var_output_a5658d0b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a5658d0b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>29</code></pre>
      
        <p><strong>Hyp output variables:</strong> grouped_df, __output__ </p>
    
          <p>grouped_df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>EmployeeID</th>
      <th>Age</th>
      <th>Attrition</th>
      <th>BusinessTravel</th>
      <th>DailyRate</th>
      <th>Department</th>
      <th>DistanceFromHome</th>
      <th>...</th>
      <th>TotalWorkingYears</th>
      <th>TrainingTimesLastYear</th>
      <th>WorkLifeBalance</th>
      <th>YearsAtCompany</th>
      <th>YearsInCurrentRole</th>
      <th>YearsSinceLastPromotion</th>
      <th>YearsWithCurrManager</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26</th>
      <td>1142062</td>
      <td>32</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>1125</td>
      <td>Maternity</td>
      <td>16</td>
      <td>...</td>
      <td>10</td>
      <td>5</td>
      <td>3</td>
      <td>10</td>
      <td>2</td>
      <td>6</td>
      <td>7</td>
    </tr>
    <tr>
      <th>102</th>
      <td>1088304</td>
      <td>20</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>871</td>
      <td>Maternity</td>
      <td>6</td>
      <td>...</td>
      <td>1</td>
      <td>5</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>111</th>
      <td>1851151</td>
      <td>34</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>658</td>
      <td>Maternity</td>
      <td>7</td>
      <td>...</td>
      <td>9</td>
      <td>3</td>
      <td>3</td>
      <td>9</td>
      <td>7</td>
      <td>0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>136</th>
      <td>1612623</td>
      <td>51</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>1150</td>
      <td>Cardiology</td>
      <td>8</td>
      <td>...</td>
      <td>18</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
    </tr>
    <tr>
      <th>171</th>
      <td>1820041</td>
      <td>19</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>602</td>
      <td>Cardiology</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>5</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>216</th>
      <td>1502689</td>
      <td>30</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>334</td>
      <td>Cardiology</td>
      <td>26</td>
      <td>...</td>
      <td>9</td>
      <td>5</td>
      <td>2</td>
      <td>6</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>286</th>
      <td>1353021</td>
      <td>44</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>920</td>
      <td>Maternity</td>
      <td>24</td>
      <td>...</td>
      <td>19</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1652</th>
      <td>1544044</td>
      <td>31</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>754</td>
      <td>Cardiology</td>
      <td>26</td>
      <td>...</td>
      <td>10</td>
      <td>4</td>
      <td>3</td>
      <td>10</td>
      <td>7</td>
      <td>0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>1654</th>
      <td>1751929</td>
      <td>22</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>1256</td>
      <td>Maternity</td>
      <td>3</td>
      <td>...</td>
      <td>1</td>
      <td>5</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1656</th>
      <td>1855095</td>
      <td>27</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>1297</td>
      <td>Neurology</td>
      <td>5</td>
      <td>...</td>
      <td>6</td>
      <td>3</td>
      <td>2</td>
      <td>5</td>
      <td>4</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1660</th>
      <td>1734708</td>
      <td>31</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>1060</td>
      <td>Cardiology</td>
      <td>1</td>
      <td>...</td>
      <td>3</td>
      <td>2</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1662</th>
      <td>1341748</td>
      <td>26</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>426</td>
      <td>Neurology</td>
      <td>17</td>
      <td>...</td>
      <td>8</td>
      <td>2</td>
      <td>2</td>
      <td>7</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1665</th>
      <td>1549806</td>
      <td>21</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>251</td>
      <td>Neurology</td>
      <td>10</td>
      <td>...</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1668</th>
      <td>1655666</td>
      <td>20</td>
      <td>Yes</td>
      <td>Travel_Frequently</td>
      <td>871</td>
      <td>Neurology</td>
      <td>6</td>
      <td>...</td>
      <td>1</td>
      <td>5</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>57 rows × 35 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>29</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> employee-attrition-for-healthcare/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of male employees who are over forty years old in each department?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>males_over40=df[(df['Gender']=='Male') & (df['Age']>40)]
dept_count=df.groupby('Department').count()['EmployeeID']
(males_over40.groupby('Department').count().EmployeeID/dept_count)*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>males_over40=df[(df['Gender']=='Male') & (df['Age']>40)]
dept_count=df.groupby('Department').count()['EmployeeID']
(males_over40.groupby('Department').count().EmployeeID/dept_count)*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>males_over40 = df[(df['Gender'] == 'Male') & (df['Age'] > 40)]
dept_count = df.groupby('Department').count()['EmployeeID']
__output__ = males_over40.groupby('Department').count(
    ).EmployeeID / dept_count * 100
</code></pre>
        <p><span onclick="$('#var_output_2082ec6d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2082ec6d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Department
Cardiology    14.500942
Maternity     17.587940
Neurology     25.214900
Name: EmployeeID, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> males_over40, dept_count, __output__ </p>
    
          <p>males_over40 (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>EmployeeID</th>
      <th>Age</th>
      <th>Attrition</th>
      <th>BusinessTravel</th>
      <th>DailyRate</th>
      <th>Department</th>
      <th>DistanceFromHome</th>
      <th>...</th>
      <th>TotalWorkingYears</th>
      <th>TrainingTimesLastYear</th>
      <th>WorkLifeBalance</th>
      <th>YearsAtCompany</th>
      <th>YearsInCurrentRole</th>
      <th>YearsSinceLastPromotion</th>
      <th>YearsWithCurrManager</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1200302</td>
      <td>49</td>
      <td>No</td>
      <td>Travel_Frequently</td>
      <td>279</td>
      <td>Maternity</td>
      <td>8</td>
      <td>...</td>
      <td>10</td>
      <td>3</td>
      <td>3</td>
      <td>10</td>
      <td>7</td>
      <td>1</td>
      <td>7</td>
    </tr>
    <tr>
      <th>27</th>
      <td>1789756</td>
      <td>42</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>691</td>
      <td>Cardiology</td>
      <td>8</td>
      <td>...</td>
      <td>10</td>
      <td>2</td>
      <td>3</td>
      <td>9</td>
      <td>7</td>
      <td>4</td>
      <td>2</td>
    </tr>
    <tr>
      <th>31</th>
      <td>1397325</td>
      <td>44</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>1459</td>
      <td>Maternity</td>
      <td>10</td>
      <td>...</td>
      <td>9</td>
      <td>5</td>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>36</th>
      <td>1058169</td>
      <td>50</td>
      <td>Yes</td>
      <td>Travel_Rarely</td>
      <td>869</td>
      <td>Cardiology</td>
      <td>3</td>
      <td>...</td>
      <td>3</td>
      <td>2</td>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>48</th>
      <td>1126243</td>
      <td>46</td>
      <td>No</td>
      <td>Travel_Frequently</td>
      <td>1211</td>
      <td>Cardiology</td>
      <td>5</td>
      <td>...</td>
      <td>14</td>
      <td>4</td>
      <td>3</td>
      <td>9</td>
      <td>6</td>
      <td>0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>50</th>
      <td>1708688</td>
      <td>48</td>
      <td>Yes</td>
      <td>Travel_Rarely</td>
      <td>626</td>
      <td>Maternity</td>
      <td>1</td>
      <td>...</td>
      <td>23</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>67</th>
      <td>1503437</td>
      <td>45</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>1339</td>
      <td>Maternity</td>
      <td>7</td>
      <td>...</td>
      <td>25</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1599</th>
      <td>1800484</td>
      <td>42</td>
      <td>No</td>
      <td>Travel_Frequently</td>
      <td>1474</td>
      <td>Neurology</td>
      <td>5</td>
      <td>...</td>
      <td>8</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1600</th>
      <td>1553672</td>
      <td>47</td>
      <td>No</td>
      <td>Non-Travel</td>
      <td>666</td>
      <td>Maternity</td>
      <td>29</td>
      <td>...</td>
      <td>10</td>
      <td>2</td>
      <td>2</td>
      <td>10</td>
      <td>7</td>
      <td>9</td>
      <td>9</td>
    </tr>
    <tr>
      <th>1603</th>
      <td>1087770</td>
      <td>45</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>930</td>
      <td>Cardiology</td>
      <td>9</td>
      <td>...</td>
      <td>18</td>
      <td>2</td>
      <td>3</td>
      <td>5</td>
      <td>4</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1614</th>
      <td>1586182</td>
      <td>52</td>
      <td>No</td>
      <td>Non-Travel</td>
      <td>585</td>
      <td>Cardiology</td>
      <td>29</td>
      <td>...</td>
      <td>16</td>
      <td>3</td>
      <td>2</td>
      <td>9</td>
      <td>8</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1626</th>
      <td>1285943</td>
      <td>50</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>1207</td>
      <td>Neurology</td>
      <td>28</td>
      <td>...</td>
      <td>20</td>
      <td>3</td>
      <td>3</td>
      <td>20</td>
      <td>8</td>
      <td>3</td>
      <td>8</td>
    </tr>
    <tr>
      <th>1644</th>
      <td>1505419</td>
      <td>50</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>410</td>
      <td>Cardiology</td>
      <td>28</td>
      <td>...</td>
      <td>20</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1648</th>
      <td>1101293</td>
      <td>44</td>
      <td>No</td>
      <td>Non-Travel</td>
      <td>381</td>
      <td>Neurology</td>
      <td>24</td>
      <td>...</td>
      <td>9</td>
      <td>5</td>
      <td>3</td>
      <td>5</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>305 rows × 35 columns</p>
      
          <p>dept_count (Series):</p>
          <pre><code>Department
Cardiology    531
Maternity     796
Neurology     349
Name: EmployeeID, dtype: int64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Department
Cardiology    14.500942
Maternity     17.587940
Neurology     25.214900
Name: EmployeeID, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> employee-attrition-for-healthcare/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For each job role, what is the percentage of employees in each job satisfaction category? (Show job role as the index, Job satisfaction as columns, and values to the nearest 1 decimal place)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>role_with_satisfaction=pd.pivot_table(df,values='EmployeeID',index='JobSatisfaction',columns='JobRole',aggfunc=np.count_nonzero)
(((role_with_satisfaction/role_with_satisfaction.sum())).T.round(1))*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>role_with_satisfaction=pd.pivot_table(df,values='EmployeeID',index='JobSatisfaction',columns='JobRole',aggfunc=np.count_nonzero)
(((role_with_satisfaction/role_with_satisfaction.sum())).T.round(1))*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>role_with_satisfaction = pd.pivot_table(df, values='EmployeeID', index=
    'JobSatisfaction', columns='JobRole', aggfunc=np.count_nonzero)
__output__ = (role_with_satisfaction / role_with_satisfaction.sum()).T.round(1
    ) * 100
</code></pre>
        <p><span onclick="$('#var_output_99885fc4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_99885fc4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>JobSatisfaction</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
    <tr>
      <th>JobRole</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Admin</th>
      <td>10.0</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>40.0</td>
    </tr>
    <tr>
      <th>Administrative</th>
      <td>20.0</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>30.0</td>
    </tr>
    <tr>
      <th>Nurse</th>
      <td>20.0</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>30.0</td>
    </tr>
    <tr>
      <th>Other</th>
      <td>20.0</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>30.0</td>
    </tr>
    <tr>
      <th>Therapist</th>
      <td>20.0</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>30.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 4 columns</p>
      
        <p><strong>Hyp output variables:</strong> role_with_satisfaction, __output__ </p>
    
          <p>role_with_satisfaction (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>JobRole</th>
      <th>Admin</th>
      <th>Administrative</th>
      <th>Nurse</th>
      <th>Other</th>
      <th>Therapist</th>
    </tr>
    <tr>
      <th>JobSatisfaction</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>20</td>
      <td>171</td>
      <td>101</td>
      <td>35</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>26</td>
      <td>135</td>
      <td>110</td>
      <td>36</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5</td>
      <td>32</td>
      <td>240</td>
      <td>166</td>
      <td>64</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6</td>
      <td>37</td>
      <td>276</td>
      <td>157</td>
      <td>54</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 5 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>JobSatisfaction</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
    <tr>
      <th>JobRole</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Admin</th>
      <td>10.0</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>40.0</td>
    </tr>
    <tr>
      <th>Administrative</th>
      <td>20.0</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>30.0</td>
    </tr>
    <tr>
      <th>Nurse</th>
      <td>20.0</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>30.0</td>
    </tr>
    <tr>
      <th>Other</th>
      <td>20.0</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>30.0</td>
    </tr>
    <tr>
      <th>Therapist</th>
      <td>20.0</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>30.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 4 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> employee-attrition-for-healthcare/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average monthly income for each decade of work experience?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def decades(x):
    if x<10:
        return "0-10"
    elif x<20:
        return "10-20"
    elif x<30:
        return "20-30"
    else:
        return "30-40" 
df['WorkExperinceDecades']=df['TotalWorkingYears'].apply(decades)
df.groupby(df.WorkExperinceDecades).mean()['MonthlyIncome']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def decades(x):
    if x<10:
        return "0-10"
    elif x<20:
        return "10-20"
    elif x<30:
        return "20-30"
    else:
        return "30-40" 
df['WorkExperinceDecades']=df['TotalWorkingYears'].apply(decades)
df.groupby(df.WorkExperinceDecades).mean()['MonthlyIncome']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def decades(x):
    if x < 10:
        return '0-10'
    elif x < 20:
        return '10-20'
    elif x < 30:
        return '20-30'
    else:
        return '30-40'


df['WorkExperinceDecades'] = df['TotalWorkingYears'].apply(decades)
__output__ = df.groupby(df.WorkExperinceDecades).mean()['MonthlyIncome']
</code></pre>
        <p><span onclick="$('#var_output_b4116c45').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b4116c45" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>WorkExperinceDecades
0-10      3950.653659
10-20     6361.692573
20-30    14075.200935
30-40    15660.730159
Name: MonthlyIncome, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>EmployeeID</th>
      <th>Age</th>
      <th>Attrition</th>
      <th>BusinessTravel</th>
      <th>DailyRate</th>
      <th>Department</th>
      <th>DistanceFromHome</th>
      <th>...</th>
      <th>TrainingTimesLastYear</th>
      <th>WorkLifeBalance</th>
      <th>YearsAtCompany</th>
      <th>YearsInCurrentRole</th>
      <th>YearsSinceLastPromotion</th>
      <th>YearsWithCurrManager</th>
      <th>WorkExperinceDecades</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1313919</td>
      <td>41</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>1102</td>
      <td>Cardiology</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>6</td>
      <td>4</td>
      <td>0</td>
      <td>5</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1200302</td>
      <td>49</td>
      <td>No</td>
      <td>Travel_Frequently</td>
      <td>279</td>
      <td>Maternity</td>
      <td>8</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>10</td>
      <td>7</td>
      <td>1</td>
      <td>7</td>
      <td>10-20</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1060315</td>
      <td>37</td>
      <td>Yes</td>
      <td>Travel_Rarely</td>
      <td>1373</td>
      <td>Maternity</td>
      <td>2</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1272912</td>
      <td>33</td>
      <td>No</td>
      <td>Travel_Frequently</td>
      <td>1392</td>
      <td>Maternity</td>
      <td>3</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>8</td>
      <td>7</td>
      <td>3</td>
      <td>0</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1414939</td>
      <td>27</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>591</td>
      <td>Maternity</td>
      <td>2</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1633361</td>
      <td>32</td>
      <td>No</td>
      <td>Travel_Frequently</td>
      <td>1005</td>
      <td>Maternity</td>
      <td>2</td>
      <td>...</td>
      <td>2</td>
      <td>2</td>
      <td>7</td>
      <td>7</td>
      <td>3</td>
      <td>6</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1329390</td>
      <td>59</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>1324</td>
      <td>Maternity</td>
      <td>3</td>
      <td>...</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>10-20</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1669</th>
      <td>1602218</td>
      <td>33</td>
      <td>Yes</td>
      <td>Travel_Rarely</td>
      <td>1017</td>
      <td>Maternity</td>
      <td>25</td>
      <td>...</td>
      <td>0</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>1670</th>
      <td>1336016</td>
      <td>28</td>
      <td>Yes</td>
      <td>Travel_Rarely</td>
      <td>654</td>
      <td>Maternity</td>
      <td>1</td>
      <td>...</td>
      <td>4</td>
      <td>3</td>
      <td>7</td>
      <td>7</td>
      <td>3</td>
      <td>7</td>
      <td>10-20</td>
    </tr>
    <tr>
      <th>1671</th>
      <td>1117656</td>
      <td>26</td>
      <td>Yes</td>
      <td>Travel_Rarely</td>
      <td>471</td>
      <td>Neurology</td>
      <td>24</td>
      <td>...</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>1672</th>
      <td>1152327</td>
      <td>46</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>1125</td>
      <td>Cardiology</td>
      <td>10</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>10-20</td>
    </tr>
    <tr>
      <th>1673</th>
      <td>1812428</td>
      <td>20</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>959</td>
      <td>Maternity</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>1674</th>
      <td>1812429</td>
      <td>39</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>466</td>
      <td>Neurology</td>
      <td>1</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>21</td>
      <td>6</td>
      <td>11</td>
      <td>8</td>
      <td>20-30</td>
    </tr>
    <tr>
      <th>1675</th>
      <td>1152329</td>
      <td>27</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>511</td>
      <td>Cardiology</td>
      <td>2</td>
      <td>...</td>
      <td>5</td>
      <td>2</td>
      <td>8</td>
      <td>7</td>
      <td>0</td>
      <td>7</td>
      <td>0-10</td>
    </tr>
  </tbody>
</table>
<p>1676 rows × 36 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>WorkExperinceDecades
0-10      3950.653659
10-20     6361.692573
20-30    14075.200935
30-40    15660.730159
Name: MonthlyIncome, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> employee-attrition-for-healthcare/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many married female employees have a higher monthly income in comparison to the average of all employees?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>marriedfemale=df[(df['Gender']=='Female') & (df['MaritalStatus']=='Married')]
len(marriedfemale[marriedfemale['MonthlyIncome']>df['MonthlyIncome'].mean()])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>marriedfemale=df[(df['Gender']=='Female') & (df['MaritalStatus']=='Married')]
len(marriedfemale[marriedfemale['MonthlyIncome']>df['MonthlyIncome'].mean()])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>marriedfemale = df[(df['Gender'] == 'Female') & (df['MaritalStatus'] ==
    'Married')]
__output__ = len(marriedfemale[marriedfemale['MonthlyIncome'] > df[
    'MonthlyIncome'].mean()])
</code></pre>
        <p><span onclick="$('#var_output_26e5e0d2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_26e5e0d2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>121</code></pre>
      
        <p><strong>Hyp output variables:</strong> marriedfemale, __output__ </p>
    
          <p>marriedfemale (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>EmployeeID</th>
      <th>Age</th>
      <th>Attrition</th>
      <th>BusinessTravel</th>
      <th>DailyRate</th>
      <th>Department</th>
      <th>DistanceFromHome</th>
      <th>...</th>
      <th>TrainingTimesLastYear</th>
      <th>WorkLifeBalance</th>
      <th>YearsAtCompany</th>
      <th>YearsInCurrentRole</th>
      <th>YearsSinceLastPromotion</th>
      <th>YearsWithCurrManager</th>
      <th>WorkExperinceDecades</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>1272912</td>
      <td>33</td>
      <td>No</td>
      <td>Travel_Frequently</td>
      <td>1392</td>
      <td>Maternity</td>
      <td>3</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>8</td>
      <td>7</td>
      <td>3</td>
      <td>0</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1329390</td>
      <td>59</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>1324</td>
      <td>Maternity</td>
      <td>3</td>
      <td>...</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>10-20</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1599218</td>
      <td>53</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>1219</td>
      <td>Cardiology</td>
      <td>2</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>25</td>
      <td>8</td>
      <td>3</td>
      <td>7</td>
      <td>30-40</td>
    </tr>
    <tr>
      <th>28</th>
      <td>1126009</td>
      <td>44</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>477</td>
      <td>Maternity</td>
      <td>7</td>
      <td>...</td>
      <td>4</td>
      <td>3</td>
      <td>22</td>
      <td>6</td>
      <td>5</td>
      <td>17</td>
      <td>20-30</td>
    </tr>
    <tr>
      <th>37</th>
      <td>1319183</td>
      <td>35</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>890</td>
      <td>Cardiology</td>
      <td>2</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>38</th>
      <td>1872551</td>
      <td>36</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>852</td>
      <td>Maternity</td>
      <td>5</td>
      <td>...</td>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>39</th>
      <td>1060693</td>
      <td>33</td>
      <td>No</td>
      <td>Travel_Frequently</td>
      <td>1141</td>
      <td>Cardiology</td>
      <td>1</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>5</td>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>10-20</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1616</th>
      <td>1522053</td>
      <td>53</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>661</td>
      <td>Cardiology</td>
      <td>7</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>5</td>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>30-40</td>
    </tr>
    <tr>
      <th>1634</th>
      <td>1389834</td>
      <td>44</td>
      <td>No</td>
      <td>Travel_Frequently</td>
      <td>383</td>
      <td>Cardiology</td>
      <td>1</td>
      <td>...</td>
      <td>4</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>10-20</td>
    </tr>
    <tr>
      <th>1635</th>
      <td>1533883</td>
      <td>38</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>723</td>
      <td>Cardiology</td>
      <td>2</td>
      <td>...</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>20-30</td>
    </tr>
    <tr>
      <th>1657</th>
      <td>1837772</td>
      <td>26</td>
      <td>Yes</td>
      <td>Travel_Rarely</td>
      <td>1443</td>
      <td>Cardiology</td>
      <td>23</td>
      <td>...</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>1747750</td>
      <td>29</td>
      <td>Yes</td>
      <td>Travel_Rarely</td>
      <td>942</td>
      <td>Maternity</td>
      <td>15</td>
      <td>...</td>
      <td>2</td>
      <td>2</td>
      <td>5</td>
      <td>4</td>
      <td>1</td>
      <td>3</td>
      <td>0-10</td>
    </tr>
    <tr>
      <th>1672</th>
      <td>1152327</td>
      <td>46</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>1125</td>
      <td>Cardiology</td>
      <td>10</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>10-20</td>
    </tr>
    <tr>
      <th>1674</th>
      <td>1812429</td>
      <td>39</td>
      <td>No</td>
      <td>Travel_Rarely</td>
      <td>466</td>
      <td>Neurology</td>
      <td>1</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>21</td>
      <td>6</td>
      <td>11</td>
      <td>8</td>
      <td>20-30</td>
    </tr>
  </tbody>
</table>
<p>313 rows × 36 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>121</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> employee-attrition-for-healthcare/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What educational field is studied most by divorced male employees? (show education field and its frequency)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['Gender']=='Male') & (df['MaritalStatus']=='Divorced')]['EducationField'].value_counts().sort_values(ascending=False).head(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['Gender']=='Male') & (df['MaritalStatus']=='Divorced')]['EducationField'].value_counts().sort_values(ascending=False).head(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['Gender'] == 'Male') & (df['MaritalStatus'] == 'Divorced')
    ]['EducationField'].value_counts().sort_values(ascending=False).head(1)
</code></pre>
        <p><span onclick="$('#var_output_066b6e1c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_066b6e1c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Life Sciences    104
Name: EducationField, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Life Sciences    104
Name: EducationField, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> employee-attrition-for-healthcare/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the number of employees for each work-life balance category who are highly satisfied with their job and relationship?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['JobSatisfaction']==4) & (df['RelationshipSatisfaction']==4)].groupby('WorkLifeBalance').count()['EmployeeID']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['JobSatisfaction']==4) & (df['RelationshipSatisfaction']==4)].groupby('WorkLifeBalance').count()['EmployeeID']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['JobSatisfaction'] == 4) & (df[
    'RelationshipSatisfaction'] == 4)].groupby('WorkLifeBalance').count()[
    'EmployeeID']
</code></pre>
        <p><span onclick="$('#var_output_52201e8f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_52201e8f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>WorkLifeBalance
1     6
2    32
3    86
4    17
Name: EmployeeID, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>WorkLifeBalance
1     6
2    32
3    86
4    17
Name: EmployeeID, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> employee-attrition-for-healthcare/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average monthly income for attrited employees with more than 10 years of experience yet who had never received a promotion?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df['YearsSinceLastPromotion']==0) & (df['TotalWorkingYears']>10)].groupby('Attrition').get_group('Yes')['MonthlyIncome'].mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df['YearsSinceLastPromotion']==0) & (df['TotalWorkingYears']>10)].groupby('Attrition').get_group('Yes')['MonthlyIncome'].mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df['YearsSinceLastPromotion'] == 0) & (df[
    'TotalWorkingYears'] > 10)].groupby('Attrition').get_group('Yes')[
    'MonthlyIncome'].mean()
</code></pre>
        <p><span onclick="$('#var_output_cf0925a0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_cf0925a0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>6951.666666666667</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>6951.666666666667</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> employee-attrition-for-healthcare/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many female employees live further away from work have high job satisfaction? (Distance>20 is far from work)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def dist_cat(x):
    if x>20:
        return "Far"
    else:
        return "Average" 
df[(df['JobSatisfaction']==4) & (df['Gender']=="Female")]['DistanceFromHome'].apply(dist_cat).value_counts().tail(1)[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def dist_cat(x):
    if x>20:
        return "Far"
    else:
        return "Average" 
df[(df['JobSatisfaction']==4) & (df['Gender']=="Female")]['DistanceFromHome'].apply(dist_cat).value_counts().tail(1)[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def dist_cat(x):
    if x > 20:
        return 'Far'
    else:
        return 'Average'


__output__ = df[(df['JobSatisfaction'] == 4) & (df['Gender'] == 'Female')][
    'DistanceFromHome'].apply(dist_cat).value_counts().tail(1)[0]
</code></pre>
        <p><span onclick="$('#var_output_fa4d9272').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_fa4d9272" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>29</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>29</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> full-filled-brain-stroke-dataset/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the work type of patients that have high blood pressure who are sixty years old?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['hypertension']==1].groupby('age').get_group(60)['work_type'].values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['hypertension']==1].groupby('age').get_group(60)['work_type'].values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['hypertension'] == 1].groupby('age').get_group(60)[
    'work_type'].values[0]
</code></pre>
        <p><span onclick="$('#var_output_8291313a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8291313a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Private</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Private</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> full-filled-brain-stroke-dataset/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Make a new column "sugarlevel" for glucose level categories (Diabetes:200+, Prediabetes:140-200, Normal:<140)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def sugar_level(x):
    if x>=200:
        return "Diabetes"
    elif x >=140:
        return "Prediabetes"
    else:
        return "Normal"

df['sugarlevel']=df['avg_glucose_level'].apply(sugar_level)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def sugar_level(x):
    if x>=200:
        return "Diabetes"
    elif x >=140:
        return "Prediabetes"
    else:
        return "Normal"

df['sugarlevel']=df['avg_glucose_level'].apply(sugar_level)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def sugar_level(x):
    if x >= 200:
        return 'Diabetes'
    elif x >= 140:
        return 'Prediabetes'
    else:
        return 'Normal'


__output__ = df['sugarlevel'] = df['avg_glucose_level'].apply(sugar_level)
</code></pre>
        <p><span onclick="$('#var_output_1f92f716').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1f92f716" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0         Diabetes
1           Normal
2         Diabetes
3         Diabetes
4      Prediabetes
          ...     
196         Normal
197    Prediabetes
198         Normal
199         Normal
200         Normal
Name: avg_glucose_level, Length: 201, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gender</th>
      <th>age</th>
      <th>hypertension</th>
      <th>heart_disease</th>
      <th>ever_married</th>
      <th>work_type</th>
      <th>Residence_type</th>
      <th>avg_glucose_level</th>
      <th>bmi</th>
      <th>smoking_status</th>
      <th>stroke</th>
      <th>sugarlevel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Female</td>
      <td>61.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Self-employed</td>
      <td>Rural</td>
      <td>202.21</td>
      <td>31.555602</td>
      <td>never smoked</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Female</td>
      <td>59.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>76.15</td>
      <td>30.242937</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Male</td>
      <td>78.0</td>
      <td>0</td>
      <td>1</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>219.84</td>
      <td>30.698951</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Male</td>
      <td>57.0</td>
      <td>0</td>
      <td>1</td>
      <td>No</td>
      <td>Govt_job</td>
      <td>Urban</td>
      <td>217.08</td>
      <td>33.808410</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Male</td>
      <td>58.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>189.84</td>
      <td>31.378534</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Prediabetes</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Male</td>
      <td>59.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>211.78</td>
      <td>33.484568</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Female</td>
      <td>63.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>90.90</td>
      <td>30.042545</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>194</th>
      <td>Male</td>
      <td>58.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Govt_job</td>
      <td>Urban</td>
      <td>84.94</td>
      <td>30.199571</td>
      <td>never smoked</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>195</th>
      <td>Male</td>
      <td>31.0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Private</td>
      <td>Urban</td>
      <td>215.07</td>
      <td>32.721655</td>
      <td>smokes</td>
      <td>0</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>196</th>
      <td>Male</td>
      <td>41.0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Private</td>
      <td>Rural</td>
      <td>70.15</td>
      <td>29.756631</td>
      <td>formerly smoked</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>197</th>
      <td>Male</td>
      <td>40.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>191.15</td>
      <td>31.124172</td>
      <td>smokes</td>
      <td>0</td>
      <td>Prediabetes</td>
    </tr>
    <tr>
      <th>198</th>
      <td>Female</td>
      <td>45.0</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Govt_job</td>
      <td>Rural</td>
      <td>95.02</td>
      <td>31.798304</td>
      <td>smokes</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>199</th>
      <td>Male</td>
      <td>40.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>83.94</td>
      <td>29.951301</td>
      <td>smokes</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>200</th>
      <td>Female</td>
      <td>80.0</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>83.75</td>
      <td>29.097421</td>
      <td>never smoked</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
  </tbody>
</table>
<p>201 rows × 12 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0         Diabetes
1           Normal
2         Diabetes
3         Diabetes
4      Prediabetes
          ...     
196         Normal
197    Prediabetes
198         Normal
199         Normal
200         Normal
Name: avg_glucose_level, Length: 201, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> full-filled-brain-stroke-dataset/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average BMI for each gender for patients with diabetes that have suffered from strokes? (Show dataframe that has gender and bmi as columns)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df.sugarlevel=='Diabetes') & df.stroke].groupby('gender').mean()['bmi'].reset_index()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df.sugarlevel=='Diabetes') & df.stroke].groupby('gender').mean()['bmi'].reset_index()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df.sugarlevel == 'Diabetes') & df.stroke].groupby('gender'
    ).mean()['bmi'].reset_index()
</code></pre>
        <p><span onclick="$('#var_output_1f9f492f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1f9f492f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gender</th>
      <th>bmi</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Female</td>
      <td>31.837986</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Male</td>
      <td>32.051133</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gender</th>
      <th>bmi</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Female</td>
      <td>31.837986</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Male</td>
      <td>32.051133</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> full-filled-brain-stroke-dataset/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For each residence type, what is the youngest age of patients who have suffered from a stroke?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>stroke = df.loc[df['stroke'] == 1].reset_index()
stroke['age']=stroke['age'].astype(int)
stroke.groupby('Residence_type').min()['age']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>stroke = df.loc[df['stroke'] == 1].reset_index()
stroke['age']=stroke['age'].astype(int)
stroke.groupby('Residence_type').min()['age']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>stroke = df.loc[df['stroke'] == 1].reset_index()
stroke['age'] = stroke['age'].astype(int)
__output__ = stroke.groupby('Residence_type').min()['age']
</code></pre>
        <p><span onclick="$('#var_output_57863a65').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_57863a65" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Residence_type
Rural    38
Urban     1
Name: age, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> stroke, __output__ </p>
    
          <p>stroke (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>gender</th>
      <th>age</th>
      <th>hypertension</th>
      <th>heart_disease</th>
      <th>ever_married</th>
      <th>work_type</th>
      <th>Residence_type</th>
      <th>avg_glucose_level</th>
      <th>bmi</th>
      <th>smoking_status</th>
      <th>stroke</th>
      <th>sugarlevel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>Female</td>
      <td>61</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Self-employed</td>
      <td>Rural</td>
      <td>202.21</td>
      <td>31.555602</td>
      <td>never smoked</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>Female</td>
      <td>59</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>76.15</td>
      <td>30.242937</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>Male</td>
      <td>78</td>
      <td>0</td>
      <td>1</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>219.84</td>
      <td>30.698951</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>Male</td>
      <td>57</td>
      <td>0</td>
      <td>1</td>
      <td>No</td>
      <td>Govt_job</td>
      <td>Urban</td>
      <td>217.08</td>
      <td>33.808410</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>Male</td>
      <td>58</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>189.84</td>
      <td>31.378534</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Prediabetes</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>Male</td>
      <td>59</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>211.78</td>
      <td>33.484568</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
      <td>Female</td>
      <td>63</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>90.90</td>
      <td>30.042545</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>33</th>
      <td>33</td>
      <td>Female</td>
      <td>77</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Private</td>
      <td>Urban</td>
      <td>81.32</td>
      <td>28.081474</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>34</th>
      <td>34</td>
      <td>Male</td>
      <td>61</td>
      <td>0</td>
      <td>1</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>209.86</td>
      <td>32.947045</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>35</th>
      <td>35</td>
      <td>Male</td>
      <td>79</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>114.77</td>
      <td>27.243396</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>36</th>
      <td>36</td>
      <td>Male</td>
      <td>74</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>167.13</td>
      <td>28.736400</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Prediabetes</td>
    </tr>
    <tr>
      <th>37</th>
      <td>37</td>
      <td>Female</td>
      <td>76</td>
      <td>1</td>
      <td>1</td>
      <td>Yes</td>
      <td>Self-employed</td>
      <td>Urban</td>
      <td>199.86</td>
      <td>31.684031</td>
      <td>smokes</td>
      <td>1</td>
      <td>Prediabetes</td>
    </tr>
    <tr>
      <th>38</th>
      <td>38</td>
      <td>Male</td>
      <td>74</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Self-employed</td>
      <td>Rural</td>
      <td>60.98</td>
      <td>28.070472</td>
      <td>never smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>39</th>
      <td>39</td>
      <td>Male</td>
      <td>71</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Self-employed</td>
      <td>Rural</td>
      <td>87.80</td>
      <td>30.763683</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
  </tbody>
</table>
<p>40 rows × 13 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Residence_type
Rural    38
Urban     1
Name: age, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> full-filled-brain-stroke-dataset/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many patients with heart disease smoke for each stroke category?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>smokes_df=df[(df['smoking_status']=='formerly smoked') | (df['smoking_status']=='smokes')]
smokes_df[smokes_df['heart_disease']==1].groupby('stroke').count()['smoking_status']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>smokes_df=df[(df['smoking_status']=='formerly smoked') | (df['smoking_status']=='smokes')]
smokes_df[smokes_df['heart_disease']==1].groupby('stroke').count()['smoking_status']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>smokes_df = df[(df['smoking_status'] == 'formerly smoked') | (df[
    'smoking_status'] == 'smokes')]
__output__ = smokes_df[smokes_df['heart_disease'] == 1].groupby('stroke'
    ).count()['smoking_status']
</code></pre>
        <p><span onclick="$('#var_output_71a49320').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_71a49320" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>stroke
0    11
1     2
Name: smoking_status, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> smokes_df, __output__ </p>
    
          <p>smokes_df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gender</th>
      <th>age</th>
      <th>hypertension</th>
      <th>heart_disease</th>
      <th>ever_married</th>
      <th>work_type</th>
      <th>Residence_type</th>
      <th>avg_glucose_level</th>
      <th>bmi</th>
      <th>smoking_status</th>
      <th>stroke</th>
      <th>sugarlevel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>Male</td>
      <td>59.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>211.78</td>
      <td>33.484568</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Female</td>
      <td>63.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>90.90</td>
      <td>30.042545</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Male</td>
      <td>78.0</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>75.32</td>
      <td>29.139780</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Male</td>
      <td>78.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>237.75</td>
      <td>29.316692</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Female</td>
      <td>76.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Govt_job</td>
      <td>Rural</td>
      <td>62.57</td>
      <td>27.954912</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Male</td>
      <td>58.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>82.30</td>
      <td>30.199571</td>
      <td>smokes</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Female</td>
      <td>76.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Self-employed</td>
      <td>Urban</td>
      <td>106.41</td>
      <td>28.202069</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>191</th>
      <td>Male</td>
      <td>37.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>107.06</td>
      <td>29.702373</td>
      <td>smokes</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>192</th>
      <td>Male</td>
      <td>72.0</td>
      <td>0</td>
      <td>1</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>238.27</td>
      <td>30.697650</td>
      <td>smokes</td>
      <td>0</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>195</th>
      <td>Male</td>
      <td>31.0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Private</td>
      <td>Urban</td>
      <td>215.07</td>
      <td>32.721655</td>
      <td>smokes</td>
      <td>0</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>196</th>
      <td>Male</td>
      <td>41.0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Private</td>
      <td>Rural</td>
      <td>70.15</td>
      <td>29.756631</td>
      <td>formerly smoked</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>197</th>
      <td>Male</td>
      <td>40.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>191.15</td>
      <td>31.124172</td>
      <td>smokes</td>
      <td>0</td>
      <td>Prediabetes</td>
    </tr>
    <tr>
      <th>198</th>
      <td>Female</td>
      <td>45.0</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Govt_job</td>
      <td>Rural</td>
      <td>95.02</td>
      <td>31.798304</td>
      <td>smokes</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>199</th>
      <td>Male</td>
      <td>40.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>83.94</td>
      <td>29.951301</td>
      <td>smokes</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 12 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>stroke
0    11
1     2
Name: smoking_status, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> full-filled-brain-stroke-dataset/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which residence type has the most number of patients not suffering from diseases?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df.hypertension==0) & (df.heart_disease==0) & (df.stroke==0) & (df.sugarlevel=="Normal")]['Residence_type'].value_counts().index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df.hypertension==0) & (df.heart_disease==0) & (df.stroke==0) & (df.sugarlevel=="Normal")]['Residence_type'].value_counts().index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df.hypertension == 0) & (df.heart_disease == 0) & (df.
    stroke == 0) & (df.sugarlevel == 'Normal')]['Residence_type'].value_counts(
    ).index[0]
</code></pre>
        <p><span onclick="$('#var_output_882d1c61').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_882d1c61" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Urban</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Urban</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> full-filled-brain-stroke-dataset/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show patients that suffer from only one disease.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def one_disease(x):
    if (((x.hypertension + x.heart_disease + x.stroke) ==1)& (x.sugarlevel=="Normal")):
        return True
    elif((x.hypertension + x.heart_disease + x.stroke) == 0) & ((x.sugarlevel=="Diabetes") | (x.sugarlevel=="Prediabetes")):
        return True
    else:
        return False
df[df.apply(one_disease,axis=1)]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def one_disease(x):
    if (((x.hypertension + x.heart_disease + x.stroke) ==1)& (x.sugarlevel=="Normal")):
        return True
    elif((x.hypertension + x.heart_disease + x.stroke) == 0) & ((x.sugarlevel=="Diabetes") | (x.sugarlevel=="Prediabetes")):
        return True
    else:
        return False
df[df.apply(one_disease,axis=1)]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def one_disease(x):
    if (x.hypertension + x.heart_disease + x.stroke == 1) & (x.sugarlevel ==
        'Normal'):
        return True
    elif (x.hypertension + x.heart_disease + x.stroke == 0) & ((x.
        sugarlevel == 'Diabetes') | (x.sugarlevel == 'Prediabetes')):
        return True
    else:
        return False


__output__ = df[df.apply(one_disease, axis=1)]
</code></pre>
        <p><span onclick="$('#var_output_5225ab21').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5225ab21" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gender</th>
      <th>age</th>
      <th>hypertension</th>
      <th>heart_disease</th>
      <th>ever_married</th>
      <th>work_type</th>
      <th>Residence_type</th>
      <th>avg_glucose_level</th>
      <th>bmi</th>
      <th>smoking_status</th>
      <th>stroke</th>
      <th>sugarlevel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Female</td>
      <td>59.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>76.15</td>
      <td>30.242937</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Female</td>
      <td>63.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>90.90</td>
      <td>30.042545</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Female</td>
      <td>76.0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Private</td>
      <td>Urban</td>
      <td>89.96</td>
      <td>28.397893</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Male</td>
      <td>75.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>104.72</td>
      <td>28.318273</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Female</td>
      <td>76.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Govt_job</td>
      <td>Rural</td>
      <td>62.57</td>
      <td>27.954912</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Female</td>
      <td>66.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Self-employed</td>
      <td>Urban</td>
      <td>101.45</td>
      <td>29.292953</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Male</td>
      <td>58.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>71.20</td>
      <td>30.003881</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>186</th>
      <td>Female</td>
      <td>65.0</td>
      <td>0</td>
      <td>1</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>57.52</td>
      <td>29.420252</td>
      <td>formerly smoked</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>187</th>
      <td>Male</td>
      <td>59.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>223.16</td>
      <td>33.175309</td>
      <td>Unknown</td>
      <td>0</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>189</th>
      <td>Female</td>
      <td>70.0</td>
      <td>0</td>
      <td>1</td>
      <td>Yes</td>
      <td>Self-employed</td>
      <td>Rural</td>
      <td>65.68</td>
      <td>28.642253</td>
      <td>Unknown</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>195</th>
      <td>Male</td>
      <td>31.0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Private</td>
      <td>Urban</td>
      <td>215.07</td>
      <td>32.721655</td>
      <td>smokes</td>
      <td>0</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>197</th>
      <td>Male</td>
      <td>40.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>191.15</td>
      <td>31.124172</td>
      <td>smokes</td>
      <td>0</td>
      <td>Prediabetes</td>
    </tr>
    <tr>
      <th>198</th>
      <td>Female</td>
      <td>45.0</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Govt_job</td>
      <td>Rural</td>
      <td>95.02</td>
      <td>31.798304</td>
      <td>smokes</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>200</th>
      <td>Female</td>
      <td>80.0</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>83.75</td>
      <td>29.097421</td>
      <td>never smoked</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
  </tbody>
</table>
<p>94 rows × 12 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gender</th>
      <th>age</th>
      <th>hypertension</th>
      <th>heart_disease</th>
      <th>ever_married</th>
      <th>work_type</th>
      <th>Residence_type</th>
      <th>avg_glucose_level</th>
      <th>bmi</th>
      <th>smoking_status</th>
      <th>stroke</th>
      <th>sugarlevel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Female</td>
      <td>59.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>76.15</td>
      <td>30.242937</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Female</td>
      <td>63.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>90.90</td>
      <td>30.042545</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Female</td>
      <td>76.0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Private</td>
      <td>Urban</td>
      <td>89.96</td>
      <td>28.397893</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Male</td>
      <td>75.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>104.72</td>
      <td>28.318273</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Female</td>
      <td>76.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Govt_job</td>
      <td>Rural</td>
      <td>62.57</td>
      <td>27.954912</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Female</td>
      <td>66.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Self-employed</td>
      <td>Urban</td>
      <td>101.45</td>
      <td>29.292953</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Male</td>
      <td>58.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>71.20</td>
      <td>30.003881</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>186</th>
      <td>Female</td>
      <td>65.0</td>
      <td>0</td>
      <td>1</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>57.52</td>
      <td>29.420252</td>
      <td>formerly smoked</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>187</th>
      <td>Male</td>
      <td>59.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>223.16</td>
      <td>33.175309</td>
      <td>Unknown</td>
      <td>0</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>189</th>
      <td>Female</td>
      <td>70.0</td>
      <td>0</td>
      <td>1</td>
      <td>Yes</td>
      <td>Self-employed</td>
      <td>Rural</td>
      <td>65.68</td>
      <td>28.642253</td>
      <td>Unknown</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>195</th>
      <td>Male</td>
      <td>31.0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Private</td>
      <td>Urban</td>
      <td>215.07</td>
      <td>32.721655</td>
      <td>smokes</td>
      <td>0</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>197</th>
      <td>Male</td>
      <td>40.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>191.15</td>
      <td>31.124172</td>
      <td>smokes</td>
      <td>0</td>
      <td>Prediabetes</td>
    </tr>
    <tr>
      <th>198</th>
      <td>Female</td>
      <td>45.0</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Govt_job</td>
      <td>Rural</td>
      <td>95.02</td>
      <td>31.798304</td>
      <td>smokes</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>200</th>
      <td>Female</td>
      <td>80.0</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>83.75</td>
      <td>29.097421</td>
      <td>never smoked</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
  </tbody>
</table>
<p>94 rows × 12 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> full-filled-brain-stroke-dataset/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the oldest age for a child with diabetes? (Show the age as integer)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>int(df[(df['work_type']=='children') & (df.sugarlevel=='Diabetes')]['age'].max())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>int(df[(df['work_type']=='children') & (df.sugarlevel=='Diabetes')]['age'].max())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = int(df[(df['work_type'] == 'children') & (df.sugarlevel ==
    'Diabetes')]['age'].max())
</code></pre>
        <p><span onclick="$('#var_output_ef5b71c7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ef5b71c7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>13</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>13</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> full-filled-brain-stroke-dataset/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of each gender that has suffered from a stroke?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>all_male=(df[df.gender=='Male']).shape[0]
stroke.groupby('gender').count()['stroke']/[df.shape[0]-all_male,all_male]*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>all_male=(df[df.gender=='Male']).shape[0]
stroke.groupby('gender').count()['stroke']/[df.shape[0]-all_male,all_male]*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>all_male = df[df.gender == 'Male'].shape[0]
__output__ = stroke.groupby('gender').count()['stroke'] / [df.shape[0] -
    all_male, all_male] * 100
</code></pre>
        <p><span onclick="$('#var_output_729c29cd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_729c29cd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>gender
Female    21.649485
Male      18.269231
Name: stroke, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> all_male, __output__ </p>
    
          <p>all_male (int):</p>
          <pre><code>104</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>gender
Female    21.649485
Male      18.269231
Name: stroke, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> full-filled-brain-stroke-dataset/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of married male patients who work for the government?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>married_male=df[(df.ever_married=='Yes') &(df.gender=='Male')]
(married_male[married_male.work_type=='Govt_job'].shape[0]/married_male.shape[0])*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>married_male=df[(df.ever_married=='Yes') &(df.gender=='Male')]
(married_male[married_male.work_type=='Govt_job'].shape[0]/married_male.shape[0])*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>married_male = df[(df.ever_married == 'Yes') & (df.gender == 'Male')]
__output__ = married_male[married_male.work_type == 'Govt_job'].shape[0
    ] / married_male.shape[0] * 100
</code></pre>
        <p><span onclick="$('#var_output_5d709a69').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5d709a69" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>12.345679012345679</code></pre>
      
        <p><strong>Hyp output variables:</strong> married_male, __output__ </p>
    
          <p>married_male (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gender</th>
      <th>age</th>
      <th>hypertension</th>
      <th>heart_disease</th>
      <th>ever_married</th>
      <th>work_type</th>
      <th>Residence_type</th>
      <th>avg_glucose_level</th>
      <th>bmi</th>
      <th>smoking_status</th>
      <th>stroke</th>
      <th>sugarlevel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>Male</td>
      <td>78.0</td>
      <td>0</td>
      <td>1</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>219.84</td>
      <td>30.698951</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Male</td>
      <td>58.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>189.84</td>
      <td>31.378534</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Prediabetes</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Male</td>
      <td>59.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>211.78</td>
      <td>33.484568</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Male</td>
      <td>78.0</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>75.32</td>
      <td>29.139780</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Male</td>
      <td>78.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>237.75</td>
      <td>29.316692</td>
      <td>formerly smoked</td>
      <td>1</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Male</td>
      <td>75.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>104.72</td>
      <td>28.318273</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Male</td>
      <td>58.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>71.20</td>
      <td>30.003881</td>
      <td>Unknown</td>
      <td>1</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>185</th>
      <td>Male</td>
      <td>52.0</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Govt_job</td>
      <td>Rural</td>
      <td>116.62</td>
      <td>31.749263</td>
      <td>smokes</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>187</th>
      <td>Male</td>
      <td>59.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>223.16</td>
      <td>33.175309</td>
      <td>Unknown</td>
      <td>0</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>191</th>
      <td>Male</td>
      <td>37.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>107.06</td>
      <td>29.702373</td>
      <td>smokes</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>192</th>
      <td>Male</td>
      <td>72.0</td>
      <td>0</td>
      <td>1</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>238.27</td>
      <td>30.697650</td>
      <td>smokes</td>
      <td>0</td>
      <td>Diabetes</td>
    </tr>
    <tr>
      <th>194</th>
      <td>Male</td>
      <td>58.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Govt_job</td>
      <td>Urban</td>
      <td>84.94</td>
      <td>30.199571</td>
      <td>never smoked</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
    <tr>
      <th>197</th>
      <td>Male</td>
      <td>40.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>191.15</td>
      <td>31.124172</td>
      <td>smokes</td>
      <td>0</td>
      <td>Prediabetes</td>
    </tr>
    <tr>
      <th>199</th>
      <td>Male</td>
      <td>40.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>83.94</td>
      <td>29.951301</td>
      <td>smokes</td>
      <td>0</td>
      <td>Normal</td>
    </tr>
  </tbody>
</table>
<p>81 rows × 12 columns</p>
      
          <p>__output__ (float):</p>
          <pre><code>12.345679012345679</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new dataframe by merging df_trade and df_iso, remove duplicated columns and calculate the number of null values in each column.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df=pd.merge(df_trade,df_iso,left_on='Partner ISO',right_on='ISO (3)')
df.drop(columns=['ISO (3)','Country','index'],axis=1,inplace=True)
df.isnull().sum().sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df=pd.merge(df_trade,df_iso,left_on='Partner ISO',right_on='ISO (3)')
df.drop(columns=['ISO (3)','Country','index'],axis=1,inplace=True)
df.isnull().sum().sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = pd.merge(df_trade, df_iso, left_on='Partner ISO', right_on='ISO (3)')
__tmp_1 = df.drop(columns=['ISO (3)', 'Country', 'index'], axis=1, inplace=True
    )
__output__ = df.isnull().sum().sort_values(ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_22566f45').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_22566f45" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Qty                  96169
Netweight (kg)       57909
Classification           0
Aggregate Level          0
Year                     0
                     ...  
Commodity                0
Qty Unit                 0
Trade Value (US$)        0
Continent                0
Region                   0
Length: 19, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Classification</th>
      <th>Year</th>
      <th>Aggregate Level</th>
      <th>Is Leaf Code</th>
      <th>Reporter Code</th>
      <th>Reporter</th>
      <th>Reporter ISO</th>
      <th>...</th>
      <th>Qty Unit Code</th>
      <th>Qty Unit</th>
      <th>Qty</th>
      <th>Netweight (kg)</th>
      <th>Trade Value (US$)</th>
      <th>Continent</th>
      <th>Region</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S4</td>
      <td>2011</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>75591</td>
      <td>Americas</td>
      <td>West Indies</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S4</td>
      <td>2012</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>27778</td>
      <td>Americas</td>
      <td>West Indies</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S4</td>
      <td>2015</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2131579</td>
      <td>Americas</td>
      <td>West Indies</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S4</td>
      <td>2016</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>9055543</td>
      <td>Americas</td>
      <td>West Indies</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S4</td>
      <td>2017</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>19952598</td>
      <td>Americas</td>
      <td>West Indies</td>
    </tr>
    <tr>
      <th>5</th>
      <td>S4</td>
      <td>2018</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>14199947</td>
      <td>Americas</td>
      <td>West Indies</td>
    </tr>
    <tr>
      <th>6</th>
      <td>S4</td>
      <td>2019</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>13773062</td>
      <td>Americas</td>
      <td>West Indies</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1322619</th>
      <td>S4</td>
      <td>2015</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1851467</td>
      <td>Africa</td>
      <td>Southern Africa</td>
    </tr>
    <tr>
      <th>1322620</th>
      <td>S4</td>
      <td>2016</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>251</td>
      <td>Africa</td>
      <td>Southern Africa</td>
    </tr>
    <tr>
      <th>1322621</th>
      <td>S4</td>
      <td>2017</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1339699</td>
      <td>Africa</td>
      <td>Southern Africa</td>
    </tr>
    <tr>
      <th>1322622</th>
      <td>S4</td>
      <td>2018</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>838057</td>
      <td>Africa</td>
      <td>Southern Africa</td>
    </tr>
    <tr>
      <th>1322623</th>
      <td>S4</td>
      <td>2019</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>812152</td>
      <td>Africa</td>
      <td>Southern Africa</td>
    </tr>
    <tr>
      <th>1322624</th>
      <td>S4</td>
      <td>2020</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>43484</td>
      <td>Africa</td>
      <td>Southern Africa</td>
    </tr>
    <tr>
      <th>1322625</th>
      <td>S4</td>
      <td>2020</td>
      <td>1</td>
      <td>0</td>
      <td>643</td>
      <td>Russian Federation</td>
      <td>RUS</td>
      <td>...</td>
      <td>1</td>
      <td>No Quantity</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>60323</td>
      <td>Africa</td>
      <td>Southern Africa</td>
    </tr>
  </tbody>
</table>
<p>1322626 rows × 19 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Qty                  96169
Netweight (kg)       57909
Classification           0
Aggregate Level          0
Year                     0
                     ...  
Commodity                0
Qty Unit                 0
Trade Value (US$)        0
Continent                0
Region                   0
Length: 19, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Remove columns that have only one distinct value.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>unique_values=df.nunique()
unique_values=unique_values[df.nunique()==1].index.tolist()
df.drop(unique_values,axis=1,inplace=True)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>unique_values=df.nunique()
unique_values=unique_values[df.nunique()==1].index.tolist()
df.drop(unique_values,axis=1,inplace=True)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>unique_values = df.nunique()
unique_values = unique_values[df.nunique() == 1].index.tolist()
__output__ = df.drop(unique_values, axis=1, inplace=True)
</code></pre>
              <div>
                <h3 style="color:red">Trace Error</h3>
                <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_1</p>
                <p><strong>Intent:</strong> # Remove columns that have only one distinct value.</p>
                <p><strong>Target:</strong></p> <pre><code>unique_values=df.nunique()
unique_values=unique_values[df.nunique()==1].index.tolist()
df.drop(unique_values,axis=1,inplace=True)</code></pre>
                <p><strong>Hyp:</strong></p>
                <pre><code>unique_values=df.nunique()
unique_values=unique_values[df.nunique()==1].index.tolist()
df.drop(unique_values,axis=1,inplace=True)</code></pre>
                <p><strong>Error Message:</strong></p>
                <pre><code>Pickling or OS Error: </code></pre>
                <hr>
              </div>
            

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For each continent, What is the total trade value to the nearest billion annually? (Show years as index and continents as columns)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(pd.pivot_table(df,index='Year',columns='Continent',values='Trade Value (US$)',aggfunc=np.sum)/1000000000).round(0).astype(int)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(pd.pivot_table(df,index='Year',columns='Continent',values='Trade Value (US$)',aggfunc=np.sum)/1000000000).round(0).astype(int)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = (pd.pivot_table(df, index='Year', columns='Continent', values=
    'Trade Value (US$)', aggfunc=np.sum) / 1000000000).round(0).astype(int)
</code></pre>
        <p><span onclick="$('#var_output_2839a553').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2839a553" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Continent</th>
      <th>Africa</th>
      <th>Americas</th>
      <th>Asia</th>
      <th>Europe</th>
      <th>Oceania</th>
    </tr>
    <tr>
      <th>Year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2007</th>
      <td>18</td>
      <td>57</td>
      <td>331</td>
      <td>834</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>23</td>
      <td>87</td>
      <td>407</td>
      <td>1040</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2009</th>
      <td>18</td>
      <td>51</td>
      <td>303</td>
      <td>590</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>21</td>
      <td>76</td>
      <td>407</td>
      <td>878</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>35</td>
      <td>108</td>
      <td>521</td>
      <td>1107</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>41</td>
      <td>94</td>
      <td>560</td>
      <td>1154</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>31</td>
      <td>92</td>
      <td>588</td>
      <td>1113</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>36</td>
      <td>77</td>
      <td>590</td>
      <td>1014</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>33</td>
      <td>64</td>
      <td>442</td>
      <td>636</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>51</td>
      <td>76</td>
      <td>447</td>
      <td>641</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>65</td>
      <td>90</td>
      <td>584</td>
      <td>796</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>74</td>
      <td>96</td>
      <td>680</td>
      <td>967</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>59</td>
      <td>92</td>
      <td>677</td>
      <td>896</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>51</td>
      <td>72</td>
      <td>594</td>
      <td>675</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 5 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Continent</th>
      <th>Africa</th>
      <th>Americas</th>
      <th>Asia</th>
      <th>Europe</th>
      <th>Oceania</th>
    </tr>
    <tr>
      <th>Year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2007</th>
      <td>18</td>
      <td>57</td>
      <td>331</td>
      <td>834</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>23</td>
      <td>87</td>
      <td>407</td>
      <td>1040</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2009</th>
      <td>18</td>
      <td>51</td>
      <td>303</td>
      <td>590</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>21</td>
      <td>76</td>
      <td>407</td>
      <td>878</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>35</td>
      <td>108</td>
      <td>521</td>
      <td>1107</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>41</td>
      <td>94</td>
      <td>560</td>
      <td>1154</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>31</td>
      <td>92</td>
      <td>588</td>
      <td>1113</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>36</td>
      <td>77</td>
      <td>590</td>
      <td>1014</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>33</td>
      <td>64</td>
      <td>442</td>
      <td>636</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>51</td>
      <td>76</td>
      <td>447</td>
      <td>641</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>65</td>
      <td>90</td>
      <td>584</td>
      <td>796</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>74</td>
      <td>96</td>
      <td>680</td>
      <td>967</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>59</td>
      <td>92</td>
      <td>677</td>
      <td>896</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>51</td>
      <td>72</td>
      <td>594</td>
      <td>675</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 5 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which country has the highest trade value for each year? (Show year, country names, and trade value)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>grouped_df=(df.groupby(['Year','Partner']).sum()['Trade Value (US$)'].sort_values(ascending=False).reset_index())
list_max=grouped_df.groupby('Year').idxmax().values.tolist()
flat_list = [item for sublist in list_max for item in sublist]
grouped_df.iloc[flat_list]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>grouped_df=(df.groupby(['Year','Partner']).sum()['Trade Value (US$)'].sort_values(ascending=False).reset_index())
list_max=grouped_df.groupby('Year').idxmax().values.tolist()
flat_list = [item for sublist in list_max for item in sublist]
grouped_df.iloc[flat_list]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>grouped_df = df.groupby(['Year', 'Partner']).sum()['Trade Value (US$)'
    ].sort_values(ascending=False).reset_index()
list_max = grouped_df.groupby('Year').idxmax().values.tolist()
flat_list = [item for sublist in list_max for item in sublist]
__output__ = grouped_df.iloc[flat_list]
</code></pre>
              <div>
                <h3 style="color:red">Trace Error</h3>
                <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_3</p>
                <p><strong>Intent:</strong> # Which country has the highest trade value for each year? (Show year, country names, and trade value)</p>
                <p><strong>Target:</strong></p> <pre><code>grouped_df=(df.groupby(['Year','Partner']).sum()['Trade Value (US$)'].sort_values(ascending=False).reset_index())
list_max=grouped_df.groupby('Year').idxmax().values.tolist()
flat_list = [item for sublist in list_max for item in sublist]
grouped_df.iloc[flat_list]</code></pre>
                <p><strong>Hyp:</strong></p>
                <pre><code>grouped_df=(df.groupby(['Year','Partner']).sum()['Trade Value (US$)'].sort_values(ascending=False).reset_index())
list_max=grouped_df.groupby('Year').idxmax().values.tolist()
flat_list = [item for sublist in list_max for item in sublist]
grouped_df.iloc[flat_list]</code></pre>
                <p><strong>Error Message:</strong></p>
                <pre><code>Pickling or OS Error: </code></pre>
                <hr>
              </div>
            

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What Continent has the most trade values?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby('Continent').sum()['Trade Value (US$)'].sort_values().tail(1).index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby('Continent').sum()['Trade Value (US$)'].sort_values().tail(1).index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('Continent').sum()['Trade Value (US$)'].sort_values(
    ).tail(1).index[0]
</code></pre>
              <div>
                <h3 style="color:red">Trace Error</h3>
                <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_4</p>
                <p><strong>Intent:</strong> # What Continent has the most trade values?</p>
                <p><strong>Target:</strong></p> <pre><code>df.groupby('Continent').sum()['Trade Value (US$)'].sort_values().tail(1).index[0]</code></pre>
                <p><strong>Hyp:</strong></p>
                <pre><code>df.groupby('Continent').sum()['Trade Value (US$)'].sort_values().tail(1).index[0]</code></pre>
                <p><strong>Error Message:</strong></p>
                <pre><code>Pickling or OS Error: </code></pre>
                <hr>
              </div>
            

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 5 regions that import the highest value of chemical products? (Show the region and the total trade value)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['Commodity'].str.contains('Chemical products')].groupby('Region').sum()['Trade Value (US$)'].sort_values(ascending=False).head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['Commodity'].str.contains('Chemical products')].groupby('Region').sum()['Trade Value (US$)'].sort_values(ascending=False).head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['Commodity'].str.contains('Chemical products')].groupby(
    'Region').sum()['Trade Value (US$)'].sort_values(ascending=False).head(5)
</code></pre>
              <div>
                <h3 style="color:red">Trace Error</h3>
                <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_5</p>
                <p><strong>Intent:</strong> # What are the top 5 regions that import the highest value of chemical products? (Show the region and the total trade value)</p>
                <p><strong>Target:</strong></p> <pre><code>df[df['Commodity'].str.contains('Chemical products')].groupby('Region').sum()['Trade Value (US$)'].sort_values(ascending=False).head(5)</code></pre>
                <p><strong>Hyp:</strong></p>
                <pre><code>df[df['Commodity'].str.contains('Chemical products')].groupby('Region').sum()['Trade Value (US$)'].sort_values(ascending=False).head(5)</code></pre>
                <p><strong>Error Message:</strong></p>
                <pre><code>Pickling or OS Error: </code></pre>
                <hr>
              </div>
            

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What two countries are the highest importers of electricity?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['Commodity']=='Electric current'].groupby('Partner').sum()['Trade Value (US$)'].sort_values().tail(2).index.tolist()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['Commodity']=='Electric current'].groupby('Partner').sum()['Trade Value (US$)'].sort_values().tail(2).index.tolist()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['Commodity'] == 'Electric current'].groupby('Partner').sum(
    )['Trade Value (US$)'].sort_values().tail(2).index.tolist()
</code></pre>
        <p><span onclick="$('#var_output_26496c70').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_26496c70" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Lithuania', 'Finland']</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Lithuania', 'Finland']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many countries have a higher trade value than the average trade value of all countries?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>groupped_countries=df.groupby('Partner').mean()['Trade Value (US$)']
len(groupped_countries[groupped_countries>groupped_countries.mean()])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>groupped_countries=df.groupby('Partner').mean()['Trade Value (US$)']
len(groupped_countries[groupped_countries>groupped_countries.mean()])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>groupped_countries = df.groupby('Partner').mean()['Trade Value (US$)']
__output__ = len(groupped_countries[groupped_countries > groupped_countries
    .mean()])
</code></pre>
        <p><span onclick="$('#var_output_f2c7328f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f2c7328f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>46</code></pre>
      
        <p><strong>Hyp output variables:</strong> groupped_countries, __output__ </p>
    
          <p>groupped_countries (Series):</p>
          <pre><code>Partner
Afghanistan       3.628508e+06
Albania           2.126999e+06
Algeria           1.311155e+07
American Samoa    5.003720e+05
Andorra           5.593928e+05
                      ...     
Venezuela         6.678889e+06
Viet Nam          4.929333e+06
Western Sahara    1.047858e+05
Yemen             5.205795e+06
Zimbabwe          2.730676e+05
Name: Trade Value (US$), Length: 204, dtype: float64</code></pre>
      
          <p>__output__ (int):</p>
          <pre><code>46</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the annual trade value as a percentage of all time total trade value.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby('Year').sum()['Trade Value (US$)'] / (df.groupby('Year').sum()['Trade Value (US$)'].sum())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby('Year').sum()['Trade Value (US$)'] / (df.groupby('Year').sum()['Trade Value (US$)'].sum())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('Year').sum()['Trade Value (US$)'] / df.groupby('Year'
    ).sum()['Trade Value (US$)'].sum()
</code></pre>
        <p><span onclick="$('#var_output_420850c6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_420850c6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Year
2007    0.058600
2008    0.073547
2009    0.045438
2010    0.065304
2011    0.083678
2012    0.087314
2013    0.086242
2014    0.081234
2015    0.055594
2016    0.057397
2017    0.072548
2018    0.085792
2019    0.081492
2020    0.065821
Name: Trade Value (US$), dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Year
2007    0.058600
2008    0.073547
2009    0.045438
2010    0.065304
2011    0.083678
2012    0.087314
2013    0.086242
2014    0.081234
2015    0.055594
2016    0.057397
2017    0.072548
2018    0.085792
2019    0.081492
2020    0.065821
Name: Trade Value (US$), dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-to-world-trade14m-data-points/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which country has the maximum trade value in each Continent?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby(['Continent','Partner'])['Trade Value (US$)'].sum().unstack().idxmax(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby(['Continent','Partner'])['Trade Value (US$)'].sum().unstack().idxmax(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby(['Continent', 'Partner'])['Trade Value (US$)'].sum(
    ).unstack().idxmax(1)
</code></pre>
        <p><span onclick="$('#var_output_44b7f7d5').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_44b7f7d5" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Continent
Africa            Egypt
Americas            USA
Asia              China
Europe      Netherlands
Oceania     New Zealand
dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Continent
Africa            Egypt
Americas            USA
Asia              China
Europe      Netherlands
Oceania     New Zealand
dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bigbasket-entire-product-list-28k-datapoints/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show a list of the top five rated Nivea products.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(~df.brand.isna()) & (df.brand.str.contains('Nivea'))].groupby('product').mean()['rating'].sort_values(ascending=False)[:5].index.tolist()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(~df.brand.isna()) & (df.brand.str.contains('Nivea'))].groupby('product').mean()['rating'].sort_values(ascending=False)[:5].index.tolist()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[~df.brand.isna() & df.brand.str.contains('Nivea')].groupby(
    'product').mean()['rating'].sort_values(ascending=False)[:5].index.tolist()
</code></pre>
        <p><span onclick="$('#var_output_4f5142a1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4f5142a1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['42k Deodorant Roll On', 'Sensitive Cooling Shaving Gel', 'Whitening Talc Touch Deodorant', 'Body Wash, Protect & Care With Aloe Vera, Shower Gel For Body, Face & Hair', 'Milk Delights Women Face Wash With Turmeric For Acne Prone Skin']</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['42k Deodorant Roll On', 'Sensitive Cooling Shaving Gel', 'Whitening Talc Touch Deodorant', 'Body Wash, Protect & Care With Aloe Vera, Shower Gel For Body, Face & Hair', 'Milk Delights Women Face Wash With Turmeric For Acne Prone Skin']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bigbasket-entire-product-list-28k-datapoints/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many Claycraft products have the word gift in their descriptions?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>gift_products=df[df['brand']=='Claycraft'].description.str.lower().str.contains('gift')
gift_products.value_counts().values[1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>gift_products=df[df['brand']=='Claycraft'].description.str.lower().str.contains('gift')
gift_products.value_counts().values[1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>gift_products = df[df['brand'] == 'Claycraft'].description.str.lower(
    ).str.contains('gift')
__output__ = gift_products.value_counts().values[1]
</code></pre>
        <p><span onclick="$('#var_output_0a62defe').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0a62defe" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>20</code></pre>
      
        <p><strong>Hyp output variables:</strong> gift_products, __output__ </p>
    
          <p>gift_products (Series):</p>
          <pre><code>1354     False
1627     False
2351     False
2599     False
2653     False
         ...  
26105    False
26344     True
26390    False
26929    False
27368    False
Name: description, Length: 93, dtype: bool</code></pre>
      
          <p>__output__ (int64):</p>
          <pre><code>20</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bigbasket-entire-product-list-28k-datapoints/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which one of these products has the lowest sale price?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.iloc[gift_products.index].sort_values('sale_price').iloc[0]['product']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.iloc[gift_products.index].sort_values('sale_price').iloc[0]['product']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.iloc[gift_products.index].sort_values('sale_price').iloc[0][
    'product']
</code></pre>
        <p><span onclick="$('#var_output_baa85409').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_baa85409" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Muddy Milk Mug - M323</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Muddy Milk Mug - M323</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bigbasket-entire-product-list-28k-datapoints/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a column "Discount" representing the difference between the market price and the sale price in percentage and show a list of the top ten discounted products.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['Discount']=((df['market_price']-df['sale_price'])/df['market_price']*100)
df.sort_values('Discount', ascending=False).head(10)['product'].tolist()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['Discount']=((df['market_price']-df['sale_price'])/df['market_price']*100)
df.sort_values('Discount', ascending=False).head(10)['product'].tolist()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['Discount'] = (df['market_price'] - df['sale_price']) / df['market_price'
    ] * 100
__output__ = df.sort_values('Discount', ascending=False).head(10)['product'
    ].tolist()
</code></pre>
        <p><span onclick="$('#var_output_a8a905ff').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a8a905ff" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Curry Leaves', 'Fruit & Vegetables Hand Juicer', 'Small Silicone Spatula With Plastic Handle - Assorted Colours', 'Decorative Party Light Big Star String LED Light 2 M - Multicolour', 'NHS 860 Temperature Control Professional Hair Straightener', 'Concealer Brush 930', 'Decorative Party Light Golden Bell String LED Light 7 M - Warm White', 'Decorative Party Light Golden Bell String LED Light 7 M - Multicolour', 'USB String Fairy Lights 3M 30 LED For Decoration - Multicolour', 'Steel Belly Shape Storage Dabba/ Container Set With PP Lid - Silver & Blue']</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product</th>
      <th>category</th>
      <th>sub_category</th>
      <th>brand</th>
      <th>sale_price</th>
      <th>market_price</th>
      <th>type</th>
      <th>rating</th>
      <th>description</th>
      <th>Discount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Garlic Oil - Vegetarian Capsule 500 mg</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Hair Care</td>
      <td>Sri Sri Ayurveda</td>
      <td>220.00</td>
      <td>220.0</td>
      <td>Hair Oil &amp; Serum</td>
      <td>4.1</td>
      <td>This Product contains Garlic Oil that is known to help proper digestion, maintain proper cholesterol levels, support cardiovascular and also build immunity.  For Beauty tips, tricks &amp; more visit https://bigbasket.blog/</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Water Bottle - Orange</td>
      <td>Kitchen, Garden &amp; Pets</td>
      <td>Storage &amp; Accessories</td>
      <td>Mastercook</td>
      <td>180.00</td>
      <td>180.0</td>
      <td>Water &amp; Fridge Bottles</td>
      <td>2.3</td>
      <td>Each product is microwave safe (without lid), refrigerator safe, dishwasher safe and can also be used for re-heating food and not for cooking. All containers come with airtight lids and a wide variety of attractive colours. Stack these stylish and colourful containers in your kitchen with ease and for a look-good factor.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Brass Angle Deep - Plain, No.2</td>
      <td>Cleaning &amp; Household</td>
      <td>Pooja Needs</td>
      <td>Trm</td>
      <td>119.00</td>
      <td>250.0</td>
      <td>Lamp &amp; Lamp Oil</td>
      <td>3.4</td>
      <td>A perfect gift for all occasions, be it your mother, sister, in-laws, boss or your friends, this beautiful designer piece wherever placed, is sure to beautify the surroundings Traditional design This type diya has been used for Diwali and All other Festivals for centuries. Sturdy and easy to carry The feet keep it balanced to ensure safety. Wonderful Oil Lamp made in Brass also called as Jyoti. This is a handcrafted piece of Indian brass Deepak.</td>
      <td>52.400000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Cereal Flip Lid Container/Storage Jar - Assorted Colour</td>
      <td>Cleaning &amp; Household</td>
      <td>Bins &amp; Bathroom Ware</td>
      <td>Nakoda</td>
      <td>149.00</td>
      <td>176.0</td>
      <td>Laundry, Storage Baskets</td>
      <td>3.7</td>
      <td>Multipurpose container with an attractive design and made from food-grade plastic for your hygiene and safety ideal for storing pulses. Grains, spices, and more with easy opening and closing flip-open lid. Strong, durable and transparent body for longevity and easy identification of contents. Multipurpose storage solution for your daily needs stores your everyday food essentials in style with the Nakoda container set. With transparent bodies, you can easily identify your stored items without having to open the lids. These containers are ideal for storing a large variety of items such as food grains, snacks and pulses to sugar, spices, condiments and more. Featuring unique flip-open lids, you can easily open and close this container without any hassles.\nThe Nakoda container is made from high-quality food-grade and BPA-free plastic that is 100% safe for storing food items. You can safely store your food items in this container without worrying about contamination and harmful toxins. As they are constructed using highly durable virgin plastic, this container will last for a long time even with regular use. This container can enhance the overall look of your kitchen decor. Being dishwasher safe, cleaning and maintaining this container is an easy task. You can also use a simple soap solution to manually wash and retain their looks for a long time.</td>
      <td>15.340909</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Creme Soft Soap - For Hands &amp; Body</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Bath &amp; Hand Wash</td>
      <td>Nivea</td>
      <td>162.00</td>
      <td>162.0</td>
      <td>Bathing Bars &amp; Soaps</td>
      <td>4.4</td>
      <td>Nivea Creme Soft Soap gives your skin the best care that it must get. The soft bar consists of Vitamins F and Almonds which are really skin gracious and help you get great skin. It provides the skin with moisture and leaves behind flawless and smooth skin. It makes sure that your body is totally free of germs &amp; dirt and at the same time well nourished.For Beauty tips, tricks &amp; more visit https://bigbasket.blog/</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Germ - Removal Multipurpose Wipes</td>
      <td>Cleaning &amp; Household</td>
      <td>All Purpose Cleaners</td>
      <td>Nature Protect</td>
      <td>169.00</td>
      <td>199.0</td>
      <td>Disinfectant Spray &amp; Cleaners</td>
      <td>3.3</td>
      <td>Stay protected from contamination with Multipurpose Germ Removal Wipes by Nature Protect, a quality product by Hindustan Unilever Limited, the makers of Surf Excel and Lifebuoy. Infused with neem extract Nature Protect Multipurpose Germ removal wipes helps in cleaning and 99.9% germ removal^. Neem extracts are known to have the power of 100 bio-actives with both anti-viral and anti-bacterial capabilities.\nWipes made from 100% biodegradable fabric and balanced with skin’s pH level, our on-the-go hygiene wipes are safe to use on not just surfaces, but human skin, so you can disinfect any exposed parts of your body – such as your hands, elbows, or wrists – as well as the surfaces they’ve touched.  A thorough cleaning with on-the-go hygiene wipes helps in keeping surfaces hygienically clean, both inside and outside your home. Packaged neatly to enable quick, easy removal, these on-the-go hygiene wipes will help you stay protected whether you stay indoors or move out and about.\n^ As per lab test conducted on representative organisms.* Always spot test on hidden area to check compatibility.</td>
      <td>15.075377</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Multani Mati</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Skin Care</td>
      <td>Satinance</td>
      <td>58.00</td>
      <td>58.0</td>
      <td>Face Care</td>
      <td>3.6</td>
      <td>Satinance multani matti is an excellent skin toner and astringent. reduces oiliness and while nourishing the skin, keeps it soft and grime. improves complexion by facilitating better blood circulation.  For Beauty tips, tricks &amp; more visit https://bigbasket.blog/</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>27548</th>
      <td>Apple Cider Vinegar Shampoo</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Hair Care</td>
      <td>Morpheme Remedies</td>
      <td>499.00</td>
      <td>499.0</td>
      <td>Shampoo &amp; Conditioner</td>
      <td>5.0</td>
      <td>Say no to dull, lifeless, dry and damaged hair with Morpheme Remedies Apple Cider Vinegar Shampoo made with nutritive organic apple cider vinegar &amp; rich in proven effective ingredients. The perfect deep cleansing head wash helps to get rid your hair residue, build-up caused by styling products. Our formulation also contains Vitamin E, B5 to moisturize, nurture and condition the hair. Added Shea Butter locks in moisture to keep the scalp nourished and hydrated. Tea Tree Oil famous for its anti-fungal and antiseptic benefits, help heals and fights itch, dryness, and irritation. The precious oils of Golden Virgin Jojoba, Sweet Almond, and Castor help soothe, rejuvenate &amp; hydrates hair and scalp while encouraging hair growth. Cruelty-free product tested only on humans with the intent and goal of restoring hair and giving our users the fullest. Result: Natural, soft hair alongside a beautiful sheen unmatched with other formulas. Free from parabens, sulfates and silicones. Safe &amp; suitable for all hair types. Clarify &amp; Restore: Created to gently but thoroughly remove product buildup and repair damaged follicles without stripping hair of moisture. Soothe scalp and renew hair for healthy beautiful hair</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>27549</th>
      <td>Papad - Garlic Disco</td>
      <td>Snacks &amp; Branded Foods</td>
      <td>Ready To Cook &amp; Eat</td>
      <td>Atish</td>
      <td>61.00</td>
      <td>61.0</td>
      <td>Papads, Ready To Fry</td>
      <td>4.0</td>
      <td>Papads are prepared from urad dal flour and spiced with taste. They are supplied roasted on an open flame, which creates them fluffy and crunchy appetizers.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>27550</th>
      <td>Wottagirl! Perfume Spray - Heaven, Classic</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Fragrances &amp; Deos</td>
      <td>Layerr</td>
      <td>199.20</td>
      <td>249.0</td>
      <td>Perfume</td>
      <td>3.9</td>
      <td>Layerr brings you Wottagirl Classic fragrant body splashes. For the confident, smart, genuine woman who doesnt get caught up in fads, diets and all things nonsense; comes a range of pure, exquisite fragrances that are just as pure, beautiful, resilient and bold.</td>
      <td>20.000000</td>
    </tr>
    <tr>
      <th>27551</th>
      <td>Rosemary</td>
      <td>Gourmet &amp; World Food</td>
      <td>Cooking &amp; Baking Needs</td>
      <td>Puramate</td>
      <td>67.50</td>
      <td>75.0</td>
      <td>Herbs, Seasonings &amp; Rubs</td>
      <td>4.0</td>
      <td>Puramate rosemary is enough to transform a dish into something\r\nextraordinary. It is vibrant , dynamic ,aromatic and a perfect flavor booster.\r\nSprinkle some in your , breads &amp; baked goods , salads, sautéed vegetables,\r\ncurries, fried rice and even dips and sauces, as well as herbal teas and\r\nseasoning blends and they can lend that instant zing. Pairs well with bay, garlic,\r\nmarjoram, oregano, parsley, sage, savory, and thyme.</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>27552</th>
      <td>Peri-Peri Sweet Potato Chips</td>
      <td>Gourmet &amp; World Food</td>
      <td>Snacks, Dry Fruits, Nuts</td>
      <td>FabBox</td>
      <td>200.00</td>
      <td>200.0</td>
      <td>Nachos &amp; Chips</td>
      <td>3.8</td>
      <td>We have taken the richness of Sweet Potatoes (Shakarkand) and given it a spicy delicious Peri Peri twist! The crispiness is unlike anything before and before you know it, you would have finished the whole pack even before the movie introductions would have been over! :p\r\r\n\r\r\nThe best part is that these chips are non-fried, which means they have almost 82% less oil than standard market chips. So yes, you can be on a diet and still relish chips like never before!</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>27553</th>
      <td>Green Tea - Pure Original</td>
      <td>Beverages</td>
      <td>Tea</td>
      <td>Tetley</td>
      <td>396.00</td>
      <td>495.0</td>
      <td>Tea Bags</td>
      <td>4.2</td>
      <td>Tetley Green Tea with its refreshing pure, original flavour contains five times more antioxidants than fruits and vegetables. A cup of Tetley Natural Green Tea helps cleanse from within and eliminates all those pollutants and toxins that our bodies are exposed to on a daily basis!! Rejuvenate yourself every day with a cup of Tetley Natural Green Tea.</td>
      <td>20.000000</td>
    </tr>
    <tr>
      <th>27554</th>
      <td>United Dreams Go Far Deodorant</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Men's Grooming</td>
      <td>United Colors Of Benetton</td>
      <td>214.53</td>
      <td>390.0</td>
      <td>Men's Deodorants</td>
      <td>4.5</td>
      <td>The new mens fragrance from the United Dreams collection is dedicated to any man who loves setting his sights high. This cologne with frizzy hints of brackenwood, perfectly embodies a person who refuses to limit himself to whats possible. Hints of bitter orange, grapefruit and lemon combine with aromatic mint, nutmeg, sage and geranium. A mix that is intensified by exotic dashes of patchouli, vetiver, musk and amber.</td>
      <td>44.992308</td>
    </tr>
  </tbody>
</table>
<p>27555 rows × 10 columns</p>
      
          <p>__output__ (list):</p>
          <pre><code>['Curry Leaves', 'Fruit & Vegetables Hand Juicer', 'Small Silicone Spatula With Plastic Handle - Assorted Colours', 'Decorative Party Light Big Star String LED Light 2 M - Multicolour', 'NHS 860 Temperature Control Professional Hair Straightener', 'Concealer Brush 930', 'Decorative Party Light Golden Bell String LED Light 7 M - Warm White', 'Decorative Party Light Golden Bell String LED Light 7 M - Multicolour', 'USB String Fairy Lights 3M 30 LED For Decoration - Multicolour', 'Steel Belly Shape Storage Dabba/ Container Set With PP Lid - Silver & Blue']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bigbasket-entire-product-list-28k-datapoints/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which product has the highest discount in each type? Show a dataframe that has product,type and discount as columns</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.iloc[df.groupby('type')['Discount'].idxmax()][['product','type','Discount']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.iloc[df.groupby('type')['Discount'].idxmax()][['product','type','Discount']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.iloc[df.groupby('type')['Discount'].idxmax()][['product',
    'type', 'Discount']]
</code></pre>
        <p><span onclick="$('#var_output_1d13092e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1d13092e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product</th>
      <th>type</th>
      <th>Discount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>19528</th>
      <td>Adult Diapers Large</td>
      <td>Adult Diapers</td>
      <td>44.545455</td>
    </tr>
    <tr>
      <th>639</th>
      <td>Cranberry Kombucha</td>
      <td>Aerated, Still, Sparkling</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>87</th>
      <td>Avida 3-in-1 Semi Economy Pouch -  FG01248</td>
      <td>Agarbatti, Incense Sticks</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>1782</th>
      <td>Fragrance-Scented Oil - Lemon LMN BB 433</td>
      <td>Air Freshener</td>
      <td>55.454545</td>
    </tr>
    <tr>
      <th>5599</th>
      <td>Almond/Badam - Californian, Giri</td>
      <td>Almonds</td>
      <td>47.000000</td>
    </tr>
    <tr>
      <th>14416</th>
      <td>Aluminium Foil - 10.5 Microns</td>
      <td>Aluminium Foil, Clingwrap</td>
      <td>23.333333</td>
    </tr>
    <tr>
      <th>2764</th>
      <td>Sanitize - Antiseptic Liquid</td>
      <td>Antiseptics &amp; Bandages</td>
      <td>35.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1288</th>
      <td>Plastic Cloth Hangers - Blue</td>
      <td>Wall Hooks &amp; Hangers</td>
      <td>60.200669</td>
    </tr>
    <tr>
      <th>18693</th>
      <td>Pet Solitaire Premium water Bottle - Turkish Blue</td>
      <td>Water &amp; Fridge Bottles</td>
      <td>64.884569</td>
    </tr>
    <tr>
      <th>18007</th>
      <td>Disinfectant Skin &amp; Surface Wipes, Original 40 Count + Lime Fresh 500 ml</td>
      <td>Wet Wipe, Pocket Tissues</td>
      <td>19.223602</td>
    </tr>
    <tr>
      <th>4763</th>
      <td>Cumin/Jeera/Jeerige - Whole</td>
      <td>Whole Spices</td>
      <td>50.000000</td>
    </tr>
    <tr>
      <th>3328</th>
      <td>Rice Vinegar - Imported</td>
      <td>Wine &amp; Rice Vinegar</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>8447</th>
      <td>Perfumed Deo - Enchante</td>
      <td>Women's Deodorants</td>
      <td>59.998246</td>
    </tr>
    <tr>
      <th>592</th>
      <td>Fruit Yoghurt - Mango</td>
      <td>Yogurt &amp; Shrikhand</td>
      <td>50.625000</td>
    </tr>
  </tbody>
</table>
<p>426 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product</th>
      <th>type</th>
      <th>Discount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>19528</th>
      <td>Adult Diapers Large</td>
      <td>Adult Diapers</td>
      <td>44.545455</td>
    </tr>
    <tr>
      <th>639</th>
      <td>Cranberry Kombucha</td>
      <td>Aerated, Still, Sparkling</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>87</th>
      <td>Avida 3-in-1 Semi Economy Pouch -  FG01248</td>
      <td>Agarbatti, Incense Sticks</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>1782</th>
      <td>Fragrance-Scented Oil - Lemon LMN BB 433</td>
      <td>Air Freshener</td>
      <td>55.454545</td>
    </tr>
    <tr>
      <th>5599</th>
      <td>Almond/Badam - Californian, Giri</td>
      <td>Almonds</td>
      <td>47.000000</td>
    </tr>
    <tr>
      <th>14416</th>
      <td>Aluminium Foil - 10.5 Microns</td>
      <td>Aluminium Foil, Clingwrap</td>
      <td>23.333333</td>
    </tr>
    <tr>
      <th>2764</th>
      <td>Sanitize - Antiseptic Liquid</td>
      <td>Antiseptics &amp; Bandages</td>
      <td>35.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1288</th>
      <td>Plastic Cloth Hangers - Blue</td>
      <td>Wall Hooks &amp; Hangers</td>
      <td>60.200669</td>
    </tr>
    <tr>
      <th>18693</th>
      <td>Pet Solitaire Premium water Bottle - Turkish Blue</td>
      <td>Water &amp; Fridge Bottles</td>
      <td>64.884569</td>
    </tr>
    <tr>
      <th>18007</th>
      <td>Disinfectant Skin &amp; Surface Wipes, Original 40 Count + Lime Fresh 500 ml</td>
      <td>Wet Wipe, Pocket Tissues</td>
      <td>19.223602</td>
    </tr>
    <tr>
      <th>4763</th>
      <td>Cumin/Jeera/Jeerige - Whole</td>
      <td>Whole Spices</td>
      <td>50.000000</td>
    </tr>
    <tr>
      <th>3328</th>
      <td>Rice Vinegar - Imported</td>
      <td>Wine &amp; Rice Vinegar</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>8447</th>
      <td>Perfumed Deo - Enchante</td>
      <td>Women's Deodorants</td>
      <td>59.998246</td>
    </tr>
    <tr>
      <th>592</th>
      <td>Fruit Yoghurt - Mango</td>
      <td>Yogurt &amp; Shrikhand</td>
      <td>50.625000</td>
    </tr>
  </tbody>
</table>
<p>426 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bigbasket-entire-product-list-28k-datapoints/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How expensive are gourmet products compared to beverage products in average? Show the value as a percentage of beverage products.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>market_beverages=df.groupby('category').get_group('Beverages')['market_price'].mean()
market_gourment=df.groupby('category').get_group('Gourmet & World Food')['market_price'].mean()
((market_gourment-market_beverages)/market_gourment)*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>market_beverages=df.groupby('category').get_group('Beverages')['market_price'].mean()
market_gourment=df.groupby('category').get_group('Gourmet & World Food')['market_price'].mean()
((market_gourment-market_beverages)/market_gourment)*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>market_beverages = df.groupby('category').get_group('Beverages')['market_price'
    ].mean()
market_gourment = df.groupby('category').get_group('Gourmet & World Food')[
    'market_price'].mean()
__output__ = (market_gourment - market_beverages) / market_gourment * 100
</code></pre>
        <p><span onclick="$('#var_output_d41c1a06').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d41c1a06" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>24.046307064290907</code></pre>
      
        <p><strong>Hyp output variables:</strong> market_beverages, market_gourment, __output__ </p>
    
          <p>market_beverages (float64):</p>
          <pre><code>272.2338983050847</code></pre>
      
          <p>market_gourment (float64):</p>
          <pre><code>358.4208848614073</code></pre>
      
          <p>__output__ (float64):</p>
          <pre><code>24.046307064290907</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bigbasket-entire-product-list-28k-datapoints/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For each category, which brand has the most number of products with no-zero price and five-star rating?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pd.pivot_table(df[df.rating==5],index='category',columns='brand',values='market_price',aggfunc=np.count_nonzero).idxmax(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pd.pivot_table(df[df.rating==5],index='category',columns='brand',values='market_price',aggfunc=np.count_nonzero).idxmax(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = pd.pivot_table(df[df.rating == 5], index='category', columns=
    'brand', values='market_price', aggfunc=np.count_nonzero).idxmax(1)
</code></pre>
        <p><span onclick="$('#var_output_40b5e631').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_40b5e631" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>category
Baby Care                         Huggies
Bakery, Cakes & Dairy       Hello Tempayy
Beauty & Hygiene                  INATUR 
Beverages                          VAHDAM
Cleaning & Household               Nakoda
Foodgrains, Oil & Masala          Earthon
Gourmet & World Food             Puramate
Kitchen, Garden & Pets                 DP
Snacks & Branded Foods      Sangam Sweets
dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>category
Baby Care                         Huggies
Bakery, Cakes & Dairy       Hello Tempayy
Beauty & Hygiene                  INATUR 
Beverages                          VAHDAM
Cleaning & Household               Nakoda
Foodgrains, Oil & Masala          Earthon
Gourmet & World Food             Puramate
Kitchen, Garden & Pets                 DP
Snacks & Branded Foods      Sangam Sweets
dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bigbasket-entire-product-list-28k-datapoints/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which Morpheme Remedies' hair care product is the cheapest with a rating of more than 4?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df.sub_category=='Hair Care') & (df.rating>4) & (df.brand=='Morpheme Remedies')].sort_values('sale_price').iloc[0]['product']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df.sub_category=='Hair Care') & (df.rating>4) & (df.brand=='Morpheme Remedies')].sort_values('sale_price').iloc[0]['product']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df.sub_category == 'Hair Care') & (df.rating > 4) & (df.
    brand == 'Morpheme Remedies')].sort_values('sale_price').iloc[0]['product']
</code></pre>
        <p><span onclick="$('#var_output_96fe2b93').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_96fe2b93" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Organic Virgin Coconut Oil - Pure Coldpressed & Undiluted Oil</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Organic Virgin Coconut Oil - Pure Coldpressed & Undiluted Oil</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bigbasket-entire-product-list-28k-datapoints/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many products are vegetarian based on the name or description?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>nonull=df.fillna('N/A')
vegetarian_df=nonull[(nonull['product'].str.contains('Vegetarian')) | (nonull['description'].str.upper().str.contains('VEGETARIAN'))]
vegetarian_df.shape[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>nonull=df.fillna('N/A')
vegetarian_df=nonull[(nonull['product'].str.contains('Vegetarian')) | (nonull['description'].str.upper().str.contains('VEGETARIAN'))]
vegetarian_df.shape[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>nonull = df.fillna('N/A')
vegetarian_df = nonull[nonull['product'].str.contains('Vegetarian') |
    nonull['description'].str.upper().str.contains('VEGETARIAN')]
__output__ = vegetarian_df.shape[0]
</code></pre>
        <p><span onclick="$('#var_output_c09e14b3').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c09e14b3" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>675</code></pre>
      
        <p><strong>Hyp output variables:</strong> nonull, vegetarian_df, __output__ </p>
    
          <p>nonull (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product</th>
      <th>category</th>
      <th>sub_category</th>
      <th>brand</th>
      <th>sale_price</th>
      <th>market_price</th>
      <th>type</th>
      <th>rating</th>
      <th>description</th>
      <th>Discount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Garlic Oil - Vegetarian Capsule 500 mg</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Hair Care</td>
      <td>Sri Sri Ayurveda</td>
      <td>220.00</td>
      <td>220.0</td>
      <td>Hair Oil &amp; Serum</td>
      <td>4.1</td>
      <td>This Product contains Garlic Oil that is known to help proper digestion, maintain proper cholesterol levels, support cardiovascular and also build immunity.  For Beauty tips, tricks &amp; more visit https://bigbasket.blog/</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Water Bottle - Orange</td>
      <td>Kitchen, Garden &amp; Pets</td>
      <td>Storage &amp; Accessories</td>
      <td>Mastercook</td>
      <td>180.00</td>
      <td>180.0</td>
      <td>Water &amp; Fridge Bottles</td>
      <td>2.3</td>
      <td>Each product is microwave safe (without lid), refrigerator safe, dishwasher safe and can also be used for re-heating food and not for cooking. All containers come with airtight lids and a wide variety of attractive colours. Stack these stylish and colourful containers in your kitchen with ease and for a look-good factor.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Brass Angle Deep - Plain, No.2</td>
      <td>Cleaning &amp; Household</td>
      <td>Pooja Needs</td>
      <td>Trm</td>
      <td>119.00</td>
      <td>250.0</td>
      <td>Lamp &amp; Lamp Oil</td>
      <td>3.4</td>
      <td>A perfect gift for all occasions, be it your mother, sister, in-laws, boss or your friends, this beautiful designer piece wherever placed, is sure to beautify the surroundings Traditional design This type diya has been used for Diwali and All other Festivals for centuries. Sturdy and easy to carry The feet keep it balanced to ensure safety. Wonderful Oil Lamp made in Brass also called as Jyoti. This is a handcrafted piece of Indian brass Deepak.</td>
      <td>52.400000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Cereal Flip Lid Container/Storage Jar - Assorted Colour</td>
      <td>Cleaning &amp; Household</td>
      <td>Bins &amp; Bathroom Ware</td>
      <td>Nakoda</td>
      <td>149.00</td>
      <td>176.0</td>
      <td>Laundry, Storage Baskets</td>
      <td>3.7</td>
      <td>Multipurpose container with an attractive design and made from food-grade plastic for your hygiene and safety ideal for storing pulses. Grains, spices, and more with easy opening and closing flip-open lid. Strong, durable and transparent body for longevity and easy identification of contents. Multipurpose storage solution for your daily needs stores your everyday food essentials in style with the Nakoda container set. With transparent bodies, you can easily identify your stored items without having to open the lids. These containers are ideal for storing a large variety of items such as food grains, snacks and pulses to sugar, spices, condiments and more. Featuring unique flip-open lids, you can easily open and close this container without any hassles.\nThe Nakoda container is made from high-quality food-grade and BPA-free plastic that is 100% safe for storing food items. You can safely store your food items in this container without worrying about contamination and harmful toxins. As they are constructed using highly durable virgin plastic, this container will last for a long time even with regular use. This container can enhance the overall look of your kitchen decor. Being dishwasher safe, cleaning and maintaining this container is an easy task. You can also use a simple soap solution to manually wash and retain their looks for a long time.</td>
      <td>15.340909</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Creme Soft Soap - For Hands &amp; Body</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Bath &amp; Hand Wash</td>
      <td>Nivea</td>
      <td>162.00</td>
      <td>162.0</td>
      <td>Bathing Bars &amp; Soaps</td>
      <td>4.4</td>
      <td>Nivea Creme Soft Soap gives your skin the best care that it must get. The soft bar consists of Vitamins F and Almonds which are really skin gracious and help you get great skin. It provides the skin with moisture and leaves behind flawless and smooth skin. It makes sure that your body is totally free of germs &amp; dirt and at the same time well nourished.For Beauty tips, tricks &amp; more visit https://bigbasket.blog/</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Germ - Removal Multipurpose Wipes</td>
      <td>Cleaning &amp; Household</td>
      <td>All Purpose Cleaners</td>
      <td>Nature Protect</td>
      <td>169.00</td>
      <td>199.0</td>
      <td>Disinfectant Spray &amp; Cleaners</td>
      <td>3.3</td>
      <td>Stay protected from contamination with Multipurpose Germ Removal Wipes by Nature Protect, a quality product by Hindustan Unilever Limited, the makers of Surf Excel and Lifebuoy. Infused with neem extract Nature Protect Multipurpose Germ removal wipes helps in cleaning and 99.9% germ removal^. Neem extracts are known to have the power of 100 bio-actives with both anti-viral and anti-bacterial capabilities.\nWipes made from 100% biodegradable fabric and balanced with skin’s pH level, our on-the-go hygiene wipes are safe to use on not just surfaces, but human skin, so you can disinfect any exposed parts of your body – such as your hands, elbows, or wrists – as well as the surfaces they’ve touched.  A thorough cleaning with on-the-go hygiene wipes helps in keeping surfaces hygienically clean, both inside and outside your home. Packaged neatly to enable quick, easy removal, these on-the-go hygiene wipes will help you stay protected whether you stay indoors or move out and about.\n^ As per lab test conducted on representative organisms.* Always spot test on hidden area to check compatibility.</td>
      <td>15.075377</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Multani Mati</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Skin Care</td>
      <td>Satinance</td>
      <td>58.00</td>
      <td>58.0</td>
      <td>Face Care</td>
      <td>3.6</td>
      <td>Satinance multani matti is an excellent skin toner and astringent. reduces oiliness and while nourishing the skin, keeps it soft and grime. improves complexion by facilitating better blood circulation.  For Beauty tips, tricks &amp; more visit https://bigbasket.blog/</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>27548</th>
      <td>Apple Cider Vinegar Shampoo</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Hair Care</td>
      <td>Morpheme Remedies</td>
      <td>499.00</td>
      <td>499.0</td>
      <td>Shampoo &amp; Conditioner</td>
      <td>5.0</td>
      <td>Say no to dull, lifeless, dry and damaged hair with Morpheme Remedies Apple Cider Vinegar Shampoo made with nutritive organic apple cider vinegar &amp; rich in proven effective ingredients. The perfect deep cleansing head wash helps to get rid your hair residue, build-up caused by styling products. Our formulation also contains Vitamin E, B5 to moisturize, nurture and condition the hair. Added Shea Butter locks in moisture to keep the scalp nourished and hydrated. Tea Tree Oil famous for its anti-fungal and antiseptic benefits, help heals and fights itch, dryness, and irritation. The precious oils of Golden Virgin Jojoba, Sweet Almond, and Castor help soothe, rejuvenate &amp; hydrates hair and scalp while encouraging hair growth. Cruelty-free product tested only on humans with the intent and goal of restoring hair and giving our users the fullest. Result: Natural, soft hair alongside a beautiful sheen unmatched with other formulas. Free from parabens, sulfates and silicones. Safe &amp; suitable for all hair types. Clarify &amp; Restore: Created to gently but thoroughly remove product buildup and repair damaged follicles without stripping hair of moisture. Soothe scalp and renew hair for healthy beautiful hair</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>27549</th>
      <td>Papad - Garlic Disco</td>
      <td>Snacks &amp; Branded Foods</td>
      <td>Ready To Cook &amp; Eat</td>
      <td>Atish</td>
      <td>61.00</td>
      <td>61.0</td>
      <td>Papads, Ready To Fry</td>
      <td>4.0</td>
      <td>Papads are prepared from urad dal flour and spiced with taste. They are supplied roasted on an open flame, which creates them fluffy and crunchy appetizers.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>27550</th>
      <td>Wottagirl! Perfume Spray - Heaven, Classic</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Fragrances &amp; Deos</td>
      <td>Layerr</td>
      <td>199.20</td>
      <td>249.0</td>
      <td>Perfume</td>
      <td>3.9</td>
      <td>Layerr brings you Wottagirl Classic fragrant body splashes. For the confident, smart, genuine woman who doesnt get caught up in fads, diets and all things nonsense; comes a range of pure, exquisite fragrances that are just as pure, beautiful, resilient and bold.</td>
      <td>20.000000</td>
    </tr>
    <tr>
      <th>27551</th>
      <td>Rosemary</td>
      <td>Gourmet &amp; World Food</td>
      <td>Cooking &amp; Baking Needs</td>
      <td>Puramate</td>
      <td>67.50</td>
      <td>75.0</td>
      <td>Herbs, Seasonings &amp; Rubs</td>
      <td>4.0</td>
      <td>Puramate rosemary is enough to transform a dish into something\r\nextraordinary. It is vibrant , dynamic ,aromatic and a perfect flavor booster.\r\nSprinkle some in your , breads &amp; baked goods , salads, sautéed vegetables,\r\ncurries, fried rice and even dips and sauces, as well as herbal teas and\r\nseasoning blends and they can lend that instant zing. Pairs well with bay, garlic,\r\nmarjoram, oregano, parsley, sage, savory, and thyme.</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>27552</th>
      <td>Peri-Peri Sweet Potato Chips</td>
      <td>Gourmet &amp; World Food</td>
      <td>Snacks, Dry Fruits, Nuts</td>
      <td>FabBox</td>
      <td>200.00</td>
      <td>200.0</td>
      <td>Nachos &amp; Chips</td>
      <td>3.8</td>
      <td>We have taken the richness of Sweet Potatoes (Shakarkand) and given it a spicy delicious Peri Peri twist! The crispiness is unlike anything before and before you know it, you would have finished the whole pack even before the movie introductions would have been over! :p\r\r\n\r\r\nThe best part is that these chips are non-fried, which means they have almost 82% less oil than standard market chips. So yes, you can be on a diet and still relish chips like never before!</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>27553</th>
      <td>Green Tea - Pure Original</td>
      <td>Beverages</td>
      <td>Tea</td>
      <td>Tetley</td>
      <td>396.00</td>
      <td>495.0</td>
      <td>Tea Bags</td>
      <td>4.2</td>
      <td>Tetley Green Tea with its refreshing pure, original flavour contains five times more antioxidants than fruits and vegetables. A cup of Tetley Natural Green Tea helps cleanse from within and eliminates all those pollutants and toxins that our bodies are exposed to on a daily basis!! Rejuvenate yourself every day with a cup of Tetley Natural Green Tea.</td>
      <td>20.000000</td>
    </tr>
    <tr>
      <th>27554</th>
      <td>United Dreams Go Far Deodorant</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Men's Grooming</td>
      <td>United Colors Of Benetton</td>
      <td>214.53</td>
      <td>390.0</td>
      <td>Men's Deodorants</td>
      <td>4.5</td>
      <td>The new mens fragrance from the United Dreams collection is dedicated to any man who loves setting his sights high. This cologne with frizzy hints of brackenwood, perfectly embodies a person who refuses to limit himself to whats possible. Hints of bitter orange, grapefruit and lemon combine with aromatic mint, nutmeg, sage and geranium. A mix that is intensified by exotic dashes of patchouli, vetiver, musk and amber.</td>
      <td>44.992308</td>
    </tr>
  </tbody>
</table>
<p>27555 rows × 10 columns</p>
      
          <p>vegetarian_df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product</th>
      <th>category</th>
      <th>sub_category</th>
      <th>brand</th>
      <th>sale_price</th>
      <th>market_price</th>
      <th>type</th>
      <th>rating</th>
      <th>description</th>
      <th>Discount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Garlic Oil - Vegetarian Capsule 500 mg</td>
      <td>Beauty &amp; Hygiene</td>
      <td>Hair Care</td>
      <td>Sri Sri Ayurveda</td>
      <td>220.0</td>
      <td>220.0</td>
      <td>Hair Oil &amp; Serum</td>
      <td>4.1</td>
      <td>This Product contains Garlic Oil that is known to help proper digestion, maintain proper cholesterol levels, support cardiovascular and also build immunity.  For Beauty tips, tricks &amp; more visit https://bigbasket.blog/</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Butter Cookies Gold Collection</td>
      <td>Gourmet &amp; World Food</td>
      <td>Chocolates &amp; Biscuits</td>
      <td>Sapphire</td>
      <td>600.0</td>
      <td>600.0</td>
      <td>Luxury Chocolates, Gifts</td>
      <td>2.2</td>
      <td>Enjoy a tin full of delicious butter cookies made with pure Danish recipe. Enjoy them as an energy snack. or with tea and coffee. Sapphire Butter cookies make a perfect gift pack for your loved ones. This product is 100% vegetarian.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Chia Seeds</td>
      <td>Foodgrains, Oil &amp; Masala</td>
      <td>Dry Fruits</td>
      <td>NaturoBell</td>
      <td>120.0</td>
      <td>120.0</td>
      <td>Other Dry Fruits</td>
      <td>3.9</td>
      <td>Raw Chia seeds, naturally gluten free, lyva raw chia seeds are a whole, vegetarian food, naturally rich in omega-3 and omega-6 essential fatty acids, dietary fiber, protein and other essential minerals. just a spoonful of lyva raw chia seeds a day is an easy and delicious way to support your digestive health and satiate your appetite homemade buffalo manure has been used as a compost during the cultivation of these seeds. no pesticides or insecticides were used making it near organic suggested uses - 1 tbsp. Daily mixes easily in water or juice. excellent when used as a topping for yogurt, salad, breakfast cereals, blended smoothie beverages and fresh coconut water ingredients - organically grown 100% chia seed (salvia hispanica) 15 g of chia seeds provide - all your daily requirement of omega-3 and omega 6 - also boosts the fiber, antioxidants and protein in your diet.  Click here for unique and delicious recipes - https://www.bigbasket.com/flavors/collections/231/dry-fruits-berries-nuts/</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>281</th>
      <td>Toor/Arhar Dal</td>
      <td>Foodgrains, Oil &amp; Masala</td>
      <td>Dals &amp; Pulses</td>
      <td>bb Popular</td>
      <td>128.0</td>
      <td>160.0</td>
      <td>Toor, Channa &amp; Moong Dal</td>
      <td>N/A</td>
      <td>Toor Dal is not only delicious but also has nutritional value. It contains a good amount of fiber. Toor dal is an excellent source of nutrients and plant protein, and it also contains dietary fiber. In essence, legumes are nutritional though they represent a low-fat and low-cholesterol alternative. Legumes such as toor dal provide essential nutrients, fiber and protein for vegetarians. Toor dal rich in protein, vitamins and iron is often served with rich spices over rice and Rotis.</td>
      <td>20.000000</td>
    </tr>
    <tr>
      <th>325</th>
      <td>Dazzle Livid Lilac Dinner Set - White</td>
      <td>Kitchen, Garden &amp; Pets</td>
      <td>Crockery &amp; Cutlery</td>
      <td>Cello</td>
      <td>1229.0</td>
      <td>1895.0</td>
      <td>Dinner Sets</td>
      <td>3.8</td>
      <td>Tableware that is infused with beauty and strength, charming dishes, gaily patterned in colourful new designs serve every purpose. Cello Opalware is produced in the most advanced state-of-the-art manufacturing facility using German Technology. Cello Opalware has beguiling designs delicately poised between fantasy and fiction. Tableware that is infused with beauty and strength, charming dishes, gaily patterned in colourful new designs serve every purpose. Bacteria free-non porous and hygienic for your family.\n100 percent vegetarian with bone ash free and made of green material. Thermal resistant, no cracks on heating food in the microwave from refrigerator and stackable.  It's a break, chip and scratch-resistant product made for everyday use. It is fully tempered up to 3X stronger, recyclable, easy to clean.</td>
      <td>35.145119</td>
    </tr>
    <tr>
      <th>331</th>
      <td>Wafer Roll - Twister, Black With Vanilla Flavoured Cream</td>
      <td>Gourmet &amp; World Food</td>
      <td>Chocolates &amp; Biscuits</td>
      <td>Delfi</td>
      <td>275.0</td>
      <td>275.0</td>
      <td>Cookies, Biscotti, Wafer</td>
      <td>N/A</td>
      <td>Delfi Wafer Rolls are crispy and crunchy wafer sticks wrapped around delicious vanilla cream filling, which are a favourite amongst children and adults. It is an ideal snack to pack for school, to relished on-the-go or to savour as a midday snack. They are made using vegetarian ingredients only.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>336</th>
      <td>Roasted Soyanuts - Wasabi</td>
      <td>Gourmet &amp; World Food</td>
      <td>Snacks, Dry Fruits, Nuts</td>
      <td>FabBox</td>
      <td>185.0</td>
      <td>185.0</td>
      <td>Roasted Seeds &amp; Nuts</td>
      <td>N/A</td>
      <td>WARNING: Having this snack on a daily basis can make you addicted to health and yumminess! Vegetarians have always relied on paneer and soya as their sources of protein, even though none of these are generally available as a munchable snack. But no more! We've jazzed up soya and made it hot spicy with some tangy, wasabi flavour! The result is just impeccable, and we ourselves can't resist having a handful in the office during team meetings! :p It's also especially great to add to your bhel and chaats to make them crunchier and zingier.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>27384</th>
      <td>bb Royal Idli Rice 5kg + Gota Urad 1kg + Raw Peanut 500g</td>
      <td>Foodgrains, Oil &amp; Masala</td>
      <td>Rice &amp; Rice Products</td>
      <td>bb Combo</td>
      <td>423.0</td>
      <td>625.0</td>
      <td>Raw Rice</td>
      <td>N/A</td>
      <td>BB Royal Idli Rice as the name indicates is perfect for making soft and fluffy idlis, which are easy to digest. This rice is loaded with dietary fibres, gives energy and is good for your digestive health. It also contains healthy carbohydrates, proteins and can manage your overall well-being when consumed daily. You can also use this rice to prepare dosas or kanji for the elderly and babies. Make light and fluffy idlis with this rice and enjoy them with sambhar, chutney or podi. \r\r\n\r\r\nBB Royal Urad Whole/Gota is a delicious and nutritious legume with a strong flavour. Urad is off-white in colour and rich in dietary fibres, proteins, and many essential minerals and vitamins too. Vegetarians can especially consume the dal made from this lentil with idlis to get adequate energy and stay active. Urad is helpful in developing muscles, can ease digestion, fight constipation, boost heart health and regulate the circulation of blood. You can also soak and ground it to make a batter for idlis, vadas, dosas, or use it in curries and chutneys. \r\r\n\r\r\nBB Royal Raw Peanuts/Mungphali are full of healthy monounsaturated and polyunsaturated fats, which are good for your heart. When raw, they are loaded with fibre and also contain antioxidants. Peanuts can be consumed raw as a snack or also added to vegetable curries, dals, condiments, chutneys for enjoying with idlis and vadas. You can add raw peanuts to poha or puffed rice for a tasty and light meal.  Click here for unique and delicious recipes - https://www.bigbasket.com/flavors/collections/233/rice-rice-products/</td>
      <td>32.320000</td>
    </tr>
    <tr>
      <th>27428</th>
      <td>Mayonnaise - Olive Oil</td>
      <td>Snacks &amp; Branded Foods</td>
      <td>Spreads, Sauces, Ketchup</td>
      <td>Veeba</td>
      <td>149.0</td>
      <td>149.0</td>
      <td>Mayonnaise</td>
      <td>4.4</td>
      <td>100% Pure &amp; Vegetarian .78% fat free.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>27447</th>
      <td>Ready To Eat Lemon Poha</td>
      <td>Snacks &amp; Branded Foods</td>
      <td>Ready To Cook &amp; Eat</td>
      <td>Instafeast</td>
      <td>55.0</td>
      <td>55.0</td>
      <td>Breakfast &amp; Snack Mixes</td>
      <td>3.0</td>
      <td>Express Feast is the brainchild of two dynamic ladies. This mother- in- law and daughter-in-law duo along with three others in the family brings to you a wide range of authentic, rich heritage of South Indian favourites. Our ready to cook meals are healthy, high on convenience and free of artificial flavours. When two mothers work together to create something special, all you can expect is true love. Healthy, homely, hearty meals just for you. It contains no preservatives and no artificial colours.This popular recipe from the Karnataka cuisine is a pot of rice-lentil-vegetables. Rich in South Indian spices, Bisibelebath is a wholesome nutritious meal. It can be savoured with a cup of curds.Shelf Life: It has a shelf life of 6 months and is vegetarian food.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>27506</th>
      <td>Ready To Eat Tamarind Poha</td>
      <td>Snacks &amp; Branded Foods</td>
      <td>Ready To Cook &amp; Eat</td>
      <td>Instafeast</td>
      <td>55.0</td>
      <td>55.0</td>
      <td>Breakfast &amp; Snack Mixes</td>
      <td>3.4</td>
      <td>Express Feast is the brainchild of two dynamic ladies. This mother- in- law and daughter-in-law duo along with three others in the family brings to you a wide range of authentic, rich heritage of South Indian favourites. Our ready to cook meals are healthy, high on convenience and free of artificial flavours. When two mothers work together to create something special all you can expect is true love. Healthy, Homely, Hearty meals just for you. It contains no preservatives and no artificial colours.Tamarind Poha or puli aval is made from flattened rice. The very well spiced and flavourful dish may be served for breakfast, brunch or snack.Shelf Life: It has a shelf life of 6 months and is vegetarian food.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>27507</th>
      <td>Extra Crisp Sweet Corn</td>
      <td>Gourmet &amp; World Food</td>
      <td>Tinned &amp; Processed Food</td>
      <td>Daucy</td>
      <td>202.5</td>
      <td>225.0</td>
      <td>Beans &amp; Pulses</td>
      <td>5.0</td>
      <td>We bring for you Europe’s leading brand of canned vegetables from the Cooperative d’aucy Group, France, consisting of more than 25000 farmer members and 60 production sites. The history of Daucy began in Brittany in 1965. In 1979, d'aucy became part of a cooperative enterprise. Today, and for almost 50 years now, d'aucy has been trying to offer you the best of its vegetables, whether canned, frozen or in our prepared dishes. The vegetables are processed and packed within a few hours of picking, thus ensuring that the micronutrients are saved from deterioration. Each vegetable awakens in its own season, at its own pace so that you can enjoy all year round all their flavors and all their benefits, daucy's mission is to harvest them in the right season when they are ripe and then find the best way to keep them. Daucy guarantees top quality and traceability of its products. We ensure this guarantee by controlling all the stages of the production from the farmer’s field to the consumer’s plate. Our Extra Crisp Sweet Corn are picked and packed at the peak of freshness for the highest standard in rich, sweet flavor. They are already cleaned and ready to eat vegetables. Daucy canned vegetables are Suitable for vegetarians and vegans and is naturally gluten-free as it only contains vegetable,water and salt. Mix corn with salsa and black beans to make a crowd-pleasing dip for tortilla chips, great in a salad or as a side dish, sweetcorn bring crispiness and vitality to your meal.</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>27525</th>
      <td>FunFoods Veg Mayonnaise Original</td>
      <td>Snacks &amp; Branded Foods</td>
      <td>Spreads, Sauces, Ketchup</td>
      <td>Dr. Oetker</td>
      <td>39.0</td>
      <td>39.0</td>
      <td>Mayonnaise</td>
      <td>4.2</td>
      <td>Veg Mayonnaise is a FunFoods innovation that was done keeping in view that many Indians are vegetarian. It is rich, smooth and creamy. Its neutral and adaptable taste makes it the perfect core ingredient for a wide array of western dishes such as sandwiches, burgers, wraps and quick white-sauce for macaroni.\nIt is 100% Veg, Cholesterol and Trans Fat-Free. It is India's largest selling mayonnaise. Make your sandwiches, wraps, macaroni and other exciting recipes, saucier, creamier, juicer. Comes in a smaller pack for easy application.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>27528</th>
      <td>Nacho Crisps - Peri Peri</td>
      <td>Gourmet &amp; World Food</td>
      <td>Snacks, Dry Fruits, Nuts</td>
      <td>Cornitos</td>
      <td>76.5</td>
      <td>85.0</td>
      <td>Nachos &amp; Chips</td>
      <td>4.2</td>
      <td>Experience the heat of Peri Peri chilli with tangy lemon flavour and then feel the warm African glow. Crispy tortilla chips made from stone ground non GMO corn and is completelty gluten free. What make Cornitos different is its unique preparation and ingredients used. Cornitos products are exported globally to over 30 countries. It is 100% vegetarian and is cooked in corn oil which makes it a healthy snack option as it has zero cholestrol and transfat. The perfect snack for a movie date or a picnic outside!</td>
      <td>10.000000</td>
    </tr>
  </tbody>
</table>
<p>675 rows × 10 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>675</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bigbasket-entire-product-list-28k-datapoints/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What percentage of these products are dairy products with more than a 10% discount?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>dairy_prod=vegetarian_df[((vegetarian_df.sub_category=='Dairy') | (vegetarian_df.sub_category=='Dairy & Cheese'))]
dairy_prod[dairy_prod.Discount>10].shape[0]/len(vegetarian_df)*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>dairy_prod=vegetarian_df[((vegetarian_df.sub_category=='Dairy') | (vegetarian_df.sub_category=='Dairy & Cheese'))]
dairy_prod[dairy_prod.Discount>10].shape[0]/len(vegetarian_df)*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>dairy_prod = vegetarian_df[(vegetarian_df.sub_category == 'Dairy') | (
    vegetarian_df.sub_category == 'Dairy & Cheese')]
__output__ = dairy_prod[dairy_prod.Discount > 10].shape[0] / len(vegetarian_df
    ) * 100
</code></pre>
        <p><span onclick="$('#var_output_13eb3589').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_13eb3589" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>1.6296296296296295</code></pre>
      
        <p><strong>Hyp output variables:</strong> dairy_prod, __output__ </p>
    
          <p>dairy_prod (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product</th>
      <th>category</th>
      <th>sub_category</th>
      <th>brand</th>
      <th>sale_price</th>
      <th>market_price</th>
      <th>type</th>
      <th>rating</th>
      <th>description</th>
      <th>Discount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>379</th>
      <td>Cheddar - English</td>
      <td>Gourmet &amp; World Food</td>
      <td>Dairy &amp; Cheese</td>
      <td>Dairy Craft</td>
      <td>530.00</td>
      <td>530.0</td>
      <td>International Cheese</td>
      <td>N/A</td>
      <td>100% pure vegetarian and natural cheddar with mild creamy flavour. It has a rich tendency to melt in the mouth with a hazelnut flavour.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1040</th>
      <td>Garlic &amp; Herbs Butter</td>
      <td>Gourmet &amp; World Food</td>
      <td>Dairy &amp; Cheese</td>
      <td>Murginns</td>
      <td>160.00</td>
      <td>160.0</td>
      <td>Butter &amp; Cream</td>
      <td>4.2</td>
      <td>A mouth-watering combination of smooth creamy butter, freshly crushed garlic cloves and fresh herbs. With the tantalising combination of garlic and butter, create the ultimate garlic bread or revolutionise your baked potatoes. Use with chicken, meat, steaks and fish. Delicious when tossed with vegetables, particularly mushrooms and sweetcorn. Pure and best quality milk, which is suitable for vegetarians. Also, it contains milk.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1137</th>
      <td>Almond Milk - Chocolate</td>
      <td>Bakery, Cakes &amp; Dairy</td>
      <td>Dairy</td>
      <td>Sofit</td>
      <td>148.96</td>
      <td>190.0</td>
      <td>Flavoured, Soya Milk</td>
      <td>3.8</td>
      <td>Enjoy the goodness of milk with the amazing taste of chocolate with Sofit Chocolate Almond Milk. It is enriched with calcium that helps to keep bones healthy. One Serving 200ml of Sofit Almond milk - Contains vegetarian protein equivalent to glass 200ml of Cow's Milk. Contains Dietary fibre equivalent to 100g of green gram (whole). It is naturally lactose-free, gluten-free, cholesterol-free and vegan.</td>
      <td>21.600000</td>
    </tr>
    <tr>
      <th>1235</th>
      <td>Garlic &amp; Chilly Toasty Cheese Slices</td>
      <td>Gourmet &amp; World Food</td>
      <td>Dairy &amp; Cheese</td>
      <td>MOOZ</td>
      <td>250.00</td>
      <td>250.0</td>
      <td>International Cheese</td>
      <td>N/A</td>
      <td>We at Mooz manufacture, Fresh Cheese, also commonly known as soft cheese. Our cheese is handcrafted by an Italian cheese maker, from milk directly procured from farmers. Mild, creamy flavour with mild garlic and chilly taste optimum for portion control. Great flavour that would be enhanced by heat. It is suitable for vegetarians. Farmer-owned - care in every step, from cow to you. Bring the taste of Italy into your own kitchen with our mild and milky mozzarella cheese. Makes a delicious after-school or midnight snack or adds the perfect melt to a meatball sandwich or panini.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2840</th>
      <td>Cheese - Slices</td>
      <td>Bakery, Cakes &amp; Dairy</td>
      <td>Dairy</td>
      <td>D'Lecta</td>
      <td>270.00</td>
      <td>360.0</td>
      <td>Cheese</td>
      <td>4.1</td>
      <td>D'lecta cheese slices are 100% vegetarian and made from processed cheddar cheese.Each slice is individually wrapped to provide ease of use, this also guarantees less wastage. It provdes fresh flavour and superior rich taste. Club it with sandwiches, burgers and other snacks to experience the cheesy taste. It can be enjoyed directly as well.This cheese is made from cow’s milk &amp; is enriched with proteins, calcium &amp; nutrients</td>
      <td>25.000000</td>
    </tr>
    <tr>
      <th>2977</th>
      <td>Cheese - Mozzarella &amp; Cheddar</td>
      <td>Gourmet &amp; World Food</td>
      <td>Dairy &amp; Cheese</td>
      <td>Dairy Craft</td>
      <td>135.00</td>
      <td>135.0</td>
      <td>International Cheese</td>
      <td>N/A</td>
      <td>A unique combination of mozzarella &amp; cheddar, that gives the pizza a great flavour and a lip-smacking taste. Mozzarella cheese aids in perfect melting over pizzas. While the subtle nutty taste of cheddar adds that extra aroma making you even more hungry. With its choicest blend of flavours, every bite is pure bliss and super delicious which also adds a stringy texture to the pizza. \r\n\r\nThe pizza cheese can also be used to experiment with the recipes of Bread Pizza or Roti pizza with veggies and ketchup and trust us, your family, especiall the kids will go crazy. Prepare mouthwatering recipes with Dairy Craft Pizza Cheese and never have a boring snack or dinner time ever. \r\n\r\nThis pizza cheese is surely going to be loved by all. Grate extra cheese on your pizza and never stop eating and spreading some cheesy love! \r\n\r\nDairy Craft India Pvt. Ltd. is a certified cheese manufacturer incorporating an extensive range of cheese products.\r\n\r\nThe pizza cheese is suitable for Vegetarians.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>3636</th>
      <td>Smoked Processed Cheese - Black Pepper</td>
      <td>Gourmet &amp; World Food</td>
      <td>Dairy &amp; Cheese</td>
      <td>West Frisian</td>
      <td>245.00</td>
      <td>245.0</td>
      <td>International Cheese</td>
      <td>N/A</td>
      <td>Smooth, semi- soft, 100% vegetarian cheese that represents the dutch tradition. This fine derivative can be identified by a smokey tint from outside and a milky white interior, having a delicate nutty cracked Black Pepper flavour.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>22396</th>
      <td>Cheese - Mascarpone</td>
      <td>Gourmet &amp; World Food</td>
      <td>Dairy &amp; Cheese</td>
      <td>Impero</td>
      <td>439.00</td>
      <td>439.0</td>
      <td>International Cheese</td>
      <td>N/A</td>
      <td>Impero cheese mascarpone is a 100% vegetarian cheese, it is milky white colour, layered in tiramisu or used as filling desserts such as cheese cakes.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>24559</th>
      <td>Cheddar</td>
      <td>Gourmet &amp; World Food</td>
      <td>Dairy &amp; Cheese</td>
      <td>Kodai Cheese</td>
      <td>250.00</td>
      <td>250.0</td>
      <td>International Cheese</td>
      <td>N/A</td>
      <td>Kodai english cheddar is 100% pure vegetarian and natural cheddar with mild creamy flavour made out of pasteurized milk, dairy culture, iodised salt, microbial veg. Rennet and contains 30.4% fat. It has a rich tendency to melt in the mouth with a hazelnut flavour. Smooth, creamy taste of the english cheddar will make your sandwich, burger, or pizza even more delicious.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25913</th>
      <td>Almond Milk - Unsweetened</td>
      <td>Bakery, Cakes &amp; Dairy</td>
      <td>Dairy</td>
      <td>Sofit</td>
      <td>148.96</td>
      <td>190.0</td>
      <td>Flavoured, Soya Milk</td>
      <td>3.6</td>
      <td>This unsweetened almond milk by Sofit is rich in protein and fibre and is a healthy energy source. A great source of calcium that helps to keep bones healthy. One Serving (200ml) of Sofit Almond milk contains vegetarian protein equivalent to glass 200ml of Cow's Milk. It contains dietary fibre equivalent to 100g of green gram (whole). It is naturally lactose-free, gluten-free, cholesterol-free and vegan.</td>
      <td>21.600000</td>
    </tr>
    <tr>
      <th>26306</th>
      <td>Malai Paneer - Block</td>
      <td>Bakery, Cakes &amp; Dairy</td>
      <td>Dairy</td>
      <td>Amul</td>
      <td>350.00</td>
      <td>350.0</td>
      <td>Paneer, Tofu &amp; Cream</td>
      <td>3.9</td>
      <td>Amul Malai Paneer blocks are Indian cottage cheese cubes which are known for their great taste, amazing nutritional value, soft and smooth texture. Paneer has always been a great source of nutrition for vegetarians. The best thing about Amul paneer is that it can be kept frozen for six months; because it contains less moisture than the loose paneer that is sold in markets. Whether you are making Malai Paneer or Paneer Butter Masala, you simply cannot do without these chunks of goodness.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>26517</th>
      <td>Kool Cafe - Milk &amp; Coffee</td>
      <td>Bakery, Cakes &amp; Dairy</td>
      <td>Dairy</td>
      <td>Amul</td>
      <td>30.00</td>
      <td>30.0</td>
      <td>Flavoured, Soya Milk</td>
      <td>4.3</td>
      <td>Carry your favourite beverage wherever you go with this easy-to-carry can of Amul Kool Cafe in Milk &amp; Coffee flavour. This flavoured milk from the country's most loved and trusted dairy brand gives you a refreshing caffeine boost whenever you need an instant pick me up! It is best enjoyed chilled. Amul's range of Kool Kafe is made from fresh milk and coffee of the best quality to give for a creamy and rich taste that cools you down in no time. It is also enriched with protein and calcium. Amul Kool Cafe Milk &amp; Coffee flavour is available in 200 ml glass bottle, Tetrapak, PET bottle and can packaging variations which are easy-to-use and carry. So whether you want to make it a part of your daily routine or carry many with you to a weekend trip, this refreshing flavoured milk from Amul is a must-have on your shopping list! This is a vegetarian product, It is sterilized, homogenized, flavoured double-toned milk in coffee flavour. It has a shelf life of up to six months when stored properly. Make sure the packet is not puffed before consuming or the bottle cap is not broken or tampered.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>26520</th>
      <td>Chilli Mozzarella Cheese</td>
      <td>Gourmet &amp; World Food</td>
      <td>Dairy &amp; Cheese</td>
      <td>MOOZ</td>
      <td>250.00</td>
      <td>250.0</td>
      <td>International Cheese</td>
      <td>N/A</td>
      <td>We at Mooz manufacture, Fresh Cheese, also commonly known as soft Cheese. Our cheese is handcrafted by an Italian cheese maker, from milk directly procured from farmers. Mooz proudly presents everyone's favourite pizza topping, the mozzarella cheese with a kick of chilly. Pizzas are never going to be boring again. Suitable for vegetarians. Farmer-owned - care in every step, from cow to you. It is traditionally made using buffalo milk and is generally white in colour. MOOZ mozzarella is mild, delicate with a dash of sourness and tastes fresh. It can be grated over pizzas, pasta, or salads, or into a simple tomato soup. #Good source of protein, niacin, riboflavin, thiamine, biotin, and rich in vitamin B6.</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>27212</th>
      <td>Processed Cheese Block</td>
      <td>Bakery, Cakes &amp; Dairy</td>
      <td>Dairy</td>
      <td>Amul</td>
      <td>94.50</td>
      <td>106.0</td>
      <td>Cheese</td>
      <td>4.2</td>
      <td>Amul Processed Cheese Block is completed from graded cow/buffalo milk using microbial rennet. It is delectably creamy and superior supply of vitamin A, protein and Calcium. It is very healthful and rich in milk protein. It is 100 % vegetarian. It improves its flavor in melted dishes like soups and saucy spicy and hot recipes. It is especially strong for your diet due to its dietary value.</td>
      <td>10.849057</td>
    </tr>
  </tbody>
</table>
<p>37 rows × 10 columns</p>
      
          <p>__output__ (float):</p>
          <pre><code>1.6296296296296295</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> myntra-reviews-on-women-dresses-comprehensive/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top five age groups that exist in this dataset? (Show the age and percentage)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>top_ages=(df.groupby('age').count()['s.no']/len(df)*100).sort_values(ascending=False)
top_ages.head()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>top_ages=(df.groupby('age').count()['s.no']/len(df)*100).sort_values(ascending=False)
top_ages.head()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>top_ages = (df.groupby('age').count()['s.no'] / len(df) * 100).sort_values(
    ascending=False)
__output__ = top_ages.head()
</code></pre>
        <p><span onclick="$('#var_output_a61f91db').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a61f91db" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>age
39    5.609806
35    3.702573
34    3.402502
36    3.377073
38    3.346557
Name: s.no, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> top_ages, __output__ </p>
    
          <p>top_ages (Series):</p>
          <pre><code>age
39    5.609806
35    3.702573
34    3.402502
36    3.377073
38    3.346557
        ...   
81    0.010172
87    0.005086
92    0.005086
94    0.005086
99    0.005086
Name: s.no, Length: 77, dtype: float64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>age
39    5.609806
35    3.702573
34    3.402502
36    3.377073
38    3.346557
Name: s.no, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> myntra-reviews-on-women-dresses-comprehensive/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which of those age groups has the highest ratings</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby('age').mean()['rating'].loc[top_ages.head().index].index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby('age').mean()['rating'].loc[top_ages.head().index].index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('age').mean()['rating'].loc[top_ages.head().index
    ].index[0]
</code></pre>
        <p><span onclick="$('#var_output_94d0749c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_94d0749c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>39</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>39</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> myntra-reviews-on-women-dresses-comprehensive/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What item of clothing from each class has the highest rating?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby(['class_name','clothing_id'])['rating'].mean().unstack().idxmax(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby(['class_name','clothing_id'])['rating'].mean().unstack().idxmax(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby(['class_name', 'clothing_id'])['rating'].mean(
    ).unstack().idxmax(1)
</code></pre>
        <p><span onclick="$('#var_output_66295933').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_66295933" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>class_name
Blouses            846
Casual bottoms      45
Chemises            10
Dresses             16
Fine gauge          21
                  ... 
Skirts            1014
Sleep              122
Sweaters             4
Swim                28
Trend              550
Length: 20, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>class_name
Blouses            846
Casual bottoms      45
Chemises            10
Dresses             16
Fine gauge          21
                  ... 
Skirts            1014
Sleep              122
Sweaters             4
Swim                28
Trend              550
Length: 20, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> myntra-reviews-on-women-dresses-comprehensive/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average word count of reviews for each department? (to the nearest integer)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['review_length']=df.review_text.str.split().str.len()
df.groupby('department_name')['review_length'].mean().round(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['review_length']=df.review_text.str.split().str.len()
df.groupby('department_name')['review_length'].mean().round(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['review_length'] = df.review_text.str.split().str.len()
__output__ = df.groupby('department_name')['review_length'].mean().round(0)
</code></pre>
        <p><span onclick="$('#var_output_6b2a868e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6b2a868e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>department_name
Bottoms     63.0
Dresses     67.0
Intimate    57.0
Jackets     66.0
Tops        59.0
Trend       71.0
Name: review_length, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>s.no</th>
      <th>age</th>
      <th>division_name</th>
      <th>department_name</th>
      <th>class_name</th>
      <th>clothing_id</th>
      <th>title</th>
      <th>review_text</th>
      <th>alike_feedback_count</th>
      <th>rating</th>
      <th>recommend_index</th>
      <th>review_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>40</td>
      <td>General</td>
      <td>Bottoms</td>
      <td>Jeans</td>
      <td>1028</td>
      <td>Amazing fit and wash</td>
      <td>Like other reviewers i was hesitant to spend this much on a pair of jeans. however, i purchased them at  20% off on retailer day and...honestly...they look so good i probably would have paid full price. these jeans are fresh!</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>40</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>62</td>
      <td>General Petite</td>
      <td>Tops</td>
      <td>Blouses</td>
      <td>850</td>
      <td>Lovely and unique!</td>
      <td>As is true of a bunch of the fall clothing photos, the colors are totally washed out in these model images which is such a shame. the embroidery is bright and vivid and totally unique on this! the bib area is actually a soft corduroy which i think is nice to transition into fall and winter. in terms of fit, i do feel like this is maybe geared more towards the slender build - it is a slim cut which i found really flattering for me since i sometimes swim in tunics. at 5'7", 128# with a very small</td>
      <td>12</td>
      <td>5</td>
      <td>1</td>
      <td>99</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>47</td>
      <td>General Petite</td>
      <td>Bottoms</td>
      <td>Skirts</td>
      <td>993</td>
      <td>Meh</td>
      <td>I so wanted this skirt to work, love the design! but, it's way, way too long... i am 5, 5, 116lb, and the small is 1 inch on the floor. i step on the skirt as i walk.</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>38</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>45</td>
      <td>General Petite</td>
      <td>Bottoms</td>
      <td>Pants</td>
      <td>1068</td>
      <td>Wow</td>
      <td>Love love this! i was hesitant to buy this at first - the reviews made it seem so big and i wasn't sure if it was my kind of outfit. but i wanted to try a jumpsuit and this was the perfect find! the xs was a typical retailer size for me, so the size was good in this, too. the color is fabulous and the fit is great. the rise is slightly short, but not a problem. i can't wait to where it for my next great event. i wish i could buy it in the black, too.</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>99</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>37</td>
      <td>Initmates</td>
      <td>Intimate</td>
      <td>Swim</td>
      <td>24</td>
      <td>Great for bigger busts</td>
      <td>I absolutely love the retro look of this swimsuit. i first saw it on blogger amber fillerup-clark (barefoot blonde) and i knew i had to have it. this is the first one piece suit i've purchased in about six years. i've avoided one pieces because most of the ones i tried made me feel frumpy, and the mono-kini look just looked odd on me. i have a smaller frame and a larger bust (32ddd), so finding swimsuits that fit properly is a challenge. i am a size 4 but i ordered a size 6 after reading reviews</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>97</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>43</td>
      <td>General</td>
      <td>Tops</td>
      <td>Sweaters</td>
      <td>933</td>
      <td>Love the pattern and color</td>
      <td>I love this sweater but i'm on the fence about keeping it only because i haven't figured out a way to layer and wear it. it really does appear best with a plain white top and jeans. i've tried it with several other things in my closet and just haven't found another combination that sells it for me - i really like my pieces to be more versatile so i can mix and match them into other outfits. this piece is just enough of a "statement" that - for me - wearing it with more simple clothing staples is</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>99</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
      <td>83</td>
      <td>General</td>
      <td>Tops</td>
      <td>Sweaters</td>
      <td>937</td>
      <td>Beautiful and unique.</td>
      <td>Love this sweater!\r\nsoft and cozy and the ruffles are not overwhelming.....just a touch of pretty!\r\nit will look pretty with a turquoise necklace for a pop of color!\r\nclassic, comfy and classy!\r\nan anhtro a ++++++++\r\nruns very true to size, ordered my usual size an it fits perfectly.</td>
      <td>4</td>
      <td>5</td>
      <td>1</td>
      <td>50</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19655</th>
      <td>23476</td>
      <td>51</td>
      <td>General</td>
      <td>Tops</td>
      <td>Blouses</td>
      <td>830</td>
      <td>Very femenine and pretty!</td>
      <td>Well, i totally disagree with the previous reviewer on this one! i think this top is very pretty. yes, it does hide any flaws in the tummy, but it is not wide nor does it make you look pregnant (side or front view). i am 5 ft, 2 inches, broad shouldered, 36c and the small fit nicely (i usually wear a small to medium in retailer tops). i am thinking of purchasing the xs as there is still plenty of room around the chest/arm area. the lace is pretty, looks good worn with a dark colored pant. the only</td>
      <td>9</td>
      <td>4</td>
      <td>1</td>
      <td>99</td>
    </tr>
    <tr>
      <th>19656</th>
      <td>23477</td>
      <td>60</td>
      <td>General Petite</td>
      <td>Tops</td>
      <td>Knits</td>
      <td>863</td>
      <td>Cute!</td>
      <td>Purchased this top in medium. i am 5'9" so normally wear medium. however, could probably have ordered a small. sleeves are very long and it's very full around bottom. love the gold color!</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>33</td>
    </tr>
    <tr>
      <th>19657</th>
      <td>23478</td>
      <td>26</td>
      <td>General</td>
      <td>Tops</td>
      <td>Knits</td>
      <td>883</td>
      <td>I like the feel of the fabric but...</td>
      <td>It feels soft and like a good quality. however it really does run large and long. i was looking for a loose tank but this one was almost a tunic on my short height and even with a cardigan to give it a shape didn't work out. i also thought it would shrink in the dryer but it didn't. also wrinkles easily.</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>62</td>
    </tr>
    <tr>
      <th>19658</th>
      <td>23481</td>
      <td>44</td>
      <td>General Petite</td>
      <td>Dresses</td>
      <td>Dresses</td>
      <td>1081</td>
      <td>Love it!</td>
      <td>I oot this dress in the blue. it fits great--hits at the knee, not too short or awkwardly long. i just wish they had it in short sleeve so i could wear one for the summer. beautiful and easy to wear for work or fun.</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>45</td>
    </tr>
    <tr>
      <th>19659</th>
      <td>23482</td>
      <td>39</td>
      <td>General</td>
      <td>Dresses</td>
      <td>Dresses</td>
      <td>1110</td>
      <td>Great piece</td>
      <td>I was very patient with this dress. i was waiting almost forever till this dress gets on sale. when i tried my usual 6 size it was way too tight but i could zip it. ( i am 5'6'' 145 lbs). the dress covers my knees and it's a perfect length, so when i sit it does not show too much of my length so it's a work friendly. it has side pockets, which can be very comfortable as well. the cut is great, it's a line,the thickness of material makes belly look great (in case if you care). i also like color a</td>
      <td>1</td>
      <td>5</td>
      <td>1</td>
      <td>104</td>
    </tr>
    <tr>
      <th>19660</th>
      <td>23483</td>
      <td>29</td>
      <td>General Petite</td>
      <td>Tops</td>
      <td>Knits</td>
      <td>862</td>
      <td>So soft and flattering</td>
      <td>The deep v doesn't gape, and flatters the neckline, while the waist-high side slits reveal enough to keep this drapey shirt from looking shapeless. the material is so lovely and soft and comfy, but clings in the right places to really flatter, while problem areas get draped in the most perfect way.</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>52</td>
    </tr>
    <tr>
      <th>19661</th>
      <td>23484</td>
      <td>57</td>
      <td>General</td>
      <td>Dresses</td>
      <td>Dresses</td>
      <td>1082</td>
      <td>Another winner from isabella sinclair</td>
      <td>I saw this dress online this morning, went into a store this afternoon and walked out with it! i love this brand because the designs are modest, but feminine and practical. this dress is made of a thicker study cotton with beautiful all over embroidery. the fit is tts, and you can adjust the waist to fit loose or a bit more snug. the length is just above my knee at 5'3. i plan to wear this now with black boots and a furry vest, and later by itself with sandals and big sunnies!</td>
      <td>10</td>
      <td>5</td>
      <td>1</td>
      <td>94</td>
    </tr>
  </tbody>
</table>
<p>19662 rows × 12 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>department_name
Bottoms     63.0
Dresses     67.0
Intimate    57.0
Jackets     66.0
Tops        59.0
Trend       71.0
Name: review_length, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> myntra-reviews-on-women-dresses-comprehensive/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of the customers who recommended an item in each department? (from the lowest to the higehst)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(df.groupby('department_name').sum()['recommend_index']/df.groupby('department_name').count()['recommend_index']*100).sort_values()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(df.groupby('department_name').sum()['recommend_index']/df.groupby('department_name').count()['recommend_index']*100).sort_values()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = (df.groupby('department_name').sum()['recommend_index'] / df.
    groupby('department_name').count()['recommend_index'] * 100).sort_values()
</code></pre>
        <p><span onclick="$('#var_output_7ced8850').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7ced8850" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>department_name
Trend       75.700935
Dresses     80.320238
Tops        80.879146
Jackets     84.072810
Intimate    84.588068
Bottoms     85.270101
Name: recommend_index, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>department_name
Trend       75.700935
Dresses     80.320238
Tops        80.879146
Jackets     84.072810
Intimate    84.588068
Bottoms     85.270101
Name: recommend_index, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> myntra-reviews-on-women-dresses-comprehensive/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top five liked feedback titles?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>titles=df.loc[df['alike_feedback_count'].sort_values(ascending=False).head(5).index,'title']
titles.values</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>titles=df.loc[df['alike_feedback_count'].sort_values(ascending=False).head(5).index,'title']
titles.values</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>titles = df.loc[df['alike_feedback_count'].sort_values(ascending=False).
    head(5).index, 'title']
__output__ = titles.values
</code></pre>
        <p><span onclick="$('#var_output_0ba3670f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0ba3670f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>["Beware if you're fuller in the chest" 'Quality does not merit cost'
 'A navy trench-yes!' 'Super flattering, beautiful dress'
 "At least it's not a swing top! tts?"]</code></pre>
      
        <p><strong>Hyp output variables:</strong> titles, __output__ </p>
    
          <p>titles (Series):</p>
          <pre><code>2744     Beware if you're fuller in the chest
14887             Quality does not merit cost
9727                       A navy trench-yes!
2894        Super flattering, beautiful dress
10728     At least it's not a swing top! tts?
Name: title, dtype: object</code></pre>
      
          <p>__output__ (ndarray):</p>
          <pre><code>["Beware if you're fuller in the chest" 'Quality does not merit cost'
 'A navy trench-yes!' 'Super flattering, beautiful dress'
 "At least it's not a swing top! tts?"]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> myntra-reviews-on-women-dresses-comprehensive/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which review among these is recommended but has the lowest rating?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>new_df=df.iloc[titles.index]
df.iloc[new_df[new_df['recommend_index']==1].rating.idxmin()]['title']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>new_df=df.iloc[titles.index]
df.iloc[new_df[new_df['recommend_index']==1].rating.idxmin()]['title']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>new_df = df.iloc[titles.index]
__output__ = df.iloc[new_df[new_df['recommend_index'] == 1].rating.idxmin()][
    'title']
</code></pre>
        <p><span onclick="$('#var_output_db46806f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_db46806f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Beware if you're fuller in the chest</code></pre>
      
        <p><strong>Hyp output variables:</strong> new_df, __output__ </p>
    
          <p>new_df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>s.no</th>
      <th>age</th>
      <th>division_name</th>
      <th>department_name</th>
      <th>class_name</th>
      <th>clothing_id</th>
      <th>title</th>
      <th>review_text</th>
      <th>alike_feedback_count</th>
      <th>rating</th>
      <th>recommend_index</th>
      <th>review_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2744</th>
      <td>3329</td>
      <td>34</td>
      <td>General</td>
      <td>Dresses</td>
      <td>Dresses</td>
      <td>1092</td>
      <td>Beware if you're fuller in the chest</td>
      <td>I loved the lace detailing all over this dress and the fact it had pockets and was mostly cotton. it just looked so inviting, so i grabbed two sizes to try on (10 &amp; 12) that 99% of the time fit me with retailer clothes. here are my thoughts:\n__________\npros:\n- lace detailing is lovely all over.\n- everything runs tts except at the bust (see below).\n- breathable fabric, comfortable.\n_________\ncons:\n- i'm a 36c and could not button the top two buttons of this dress in a size 10 (i'm 5'9, hourglass, a</td>
      <td>122</td>
      <td>3</td>
      <td>1</td>
      <td>97</td>
    </tr>
    <tr>
      <th>14887</th>
      <td>17823</td>
      <td>43</td>
      <td>General</td>
      <td>Jackets</td>
      <td>Jackets</td>
      <td>986</td>
      <td>Quality does not merit cost</td>
      <td>I generally don't write bad reviews, but there is a real discrepancy between the quality of this kimono and the cost. the design and colors are great, but the fabric is ripping on all the kimonos on the rack in my store where the manufacturer's tag is at the back of the neck. the material is very thin, so there are other small holes beginning throughout the garment. i shop at retailer all the time, and this is not a $98 item of clothing.</td>
      <td>108</td>
      <td>1</td>
      <td>0</td>
      <td>84</td>
    </tr>
    <tr>
      <th>9727</th>
      <td>11655</td>
      <td>35</td>
      <td>General</td>
      <td>Jackets</td>
      <td>Outerwear</td>
      <td>1121</td>
      <td>A navy trench-yes!</td>
      <td>I am a big fan of trench coats and i love that this one is navy. i typically gravitate toward blues because it brings out my eyes and my wardrobe tends to fall in a blue-ish category. i love that the color of this coat will compliment other pieces of clothing in my closet wonderfully.\n\ni especially love the design of the trench with the wider, pleated bottom which allows for fluffier dresses but also creates an illusion that is slimming for anyone's figure. this is a fantastic, unique design for</td>
      <td>99</td>
      <td>5</td>
      <td>1</td>
      <td>91</td>
    </tr>
    <tr>
      <th>2894</th>
      <td>3502</td>
      <td>23</td>
      <td>General</td>
      <td>Dresses</td>
      <td>Dresses</td>
      <td>1078</td>
      <td>Super flattering, beautiful dress</td>
      <td>This is my favorite dress i've bought in the past year! it is super flattering and can be worn for work or casual wear. the fabric is soft and comfortable. can't wait till the weather gets warmer so i can start wearing it regularly!\n\ni'm 5'5 145lbs, 37-29-39. i got the medium petite and it fits perfectly!</td>
      <td>98</td>
      <td>5</td>
      <td>1</td>
      <td>57</td>
    </tr>
    <tr>
      <th>10728</th>
      <td>12852</td>
      <td>56</td>
      <td>General</td>
      <td>Tops</td>
      <td>Knits</td>
      <td>867</td>
      <td>At least it's not a swing top! tts?</td>
      <td>I loved the idea of the placement print around the neckline and shoulders and even the nape. the print transforms an otherwise basic t-shirt into an eye catching top. it lacked in the length department, and there was extra fabric under the sleeves that wasn't flattering just above the girls.\r\n\r\nthis is made by retailer brand postmark. i own several tops by this brand, and found that their printed fabric tends to fade out from wash #1. as is usual for postmark, the brand was not stated on the produ</td>
      <td>95</td>
      <td>4</td>
      <td>1</td>
      <td>90</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 12 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>Beware if you're fuller in the chest</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> myntra-reviews-on-women-dresses-comprehensive/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many reviews have the word love in them?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>love_reviews=df[(~df['review_text'].isna()) & (df['review_text'].str.lower().str.contains('love'))]
love_reviews.shape[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>love_reviews=df[(~df['review_text'].isna()) & (df['review_text'].str.lower().str.contains('love'))]
love_reviews.shape[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>love_reviews = df[~df['review_text'].isna() & df['review_text'].str.lower()
    .str.contains('love')]
__output__ = love_reviews.shape[0]
</code></pre>
        <p><span onclick="$('#var_output_a3933e4b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a3933e4b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>8083</code></pre>
      
        <p><strong>Hyp output variables:</strong> love_reviews, __output__ </p>
    
          <p>love_reviews (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>s.no</th>
      <th>age</th>
      <th>division_name</th>
      <th>department_name</th>
      <th>class_name</th>
      <th>clothing_id</th>
      <th>title</th>
      <th>review_text</th>
      <th>alike_feedback_count</th>
      <th>rating</th>
      <th>recommend_index</th>
      <th>review_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>47</td>
      <td>General Petite</td>
      <td>Bottoms</td>
      <td>Skirts</td>
      <td>993</td>
      <td>Meh</td>
      <td>I so wanted this skirt to work, love the design! but, it's way, way too long... i am 5, 5, 116lb, and the small is 1 inch on the floor. i step on the skirt as i walk.</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>38</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>45</td>
      <td>General Petite</td>
      <td>Bottoms</td>
      <td>Pants</td>
      <td>1068</td>
      <td>Wow</td>
      <td>Love love this! i was hesitant to buy this at first - the reviews made it seem so big and i wasn't sure if it was my kind of outfit. but i wanted to try a jumpsuit and this was the perfect find! the xs was a typical retailer size for me, so the size was good in this, too. the color is fabulous and the fit is great. the rise is slightly short, but not a problem. i can't wait to where it for my next great event. i wish i could buy it in the black, too.</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>99</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>37</td>
      <td>Initmates</td>
      <td>Intimate</td>
      <td>Swim</td>
      <td>24</td>
      <td>Great for bigger busts</td>
      <td>I absolutely love the retro look of this swimsuit. i first saw it on blogger amber fillerup-clark (barefoot blonde) and i knew i had to have it. this is the first one piece suit i've purchased in about six years. i've avoided one pieces because most of the ones i tried made me feel frumpy, and the mono-kini look just looked odd on me. i have a smaller frame and a larger bust (32ddd), so finding swimsuits that fit properly is a challenge. i am a size 4 but i ordered a size 6 after reading reviews</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>97</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>43</td>
      <td>General</td>
      <td>Tops</td>
      <td>Sweaters</td>
      <td>933</td>
      <td>Love the pattern and color</td>
      <td>I love this sweater but i'm on the fence about keeping it only because i haven't figured out a way to layer and wear it. it really does appear best with a plain white top and jeans. i've tried it with several other things in my closet and just haven't found another combination that sells it for me - i really like my pieces to be more versatile so i can mix and match them into other outfits. this piece is just enough of a "statement" that - for me - wearing it with more simple clothing staples is</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>99</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
      <td>83</td>
      <td>General</td>
      <td>Tops</td>
      <td>Sweaters</td>
      <td>937</td>
      <td>Beautiful and unique.</td>
      <td>Love this sweater!\r\nsoft and cozy and the ruffles are not overwhelming.....just a touch of pretty!\r\nit will look pretty with a turquoise necklace for a pop of color!\r\nclassic, comfy and classy!\r\nan anhtro a ++++++++\r\nruns very true to size, ordered my usual size an it fits perfectly.</td>
      <td>4</td>
      <td>5</td>
      <td>1</td>
      <td>50</td>
    </tr>
    <tr>
      <th>8</th>
      <td>8</td>
      <td>49</td>
      <td>General Petite</td>
      <td>Tops</td>
      <td>Fine gauge</td>
      <td>900</td>
      <td>Great look all in one</td>
      <td>I love everything about this sweater. it is very well made, beautiful material and such an effortless way to pull it all together. it runs large which was unfortunate for me as i bought the xs petite and i really need xxs in this one, but none are left. i am 5 ft. tall and weigh about 96 pounds. i can wear a 0 but not in this sweater. it runs very well and i highly recommend it. hope they make more in this style. it is so fresh looking and so comfortable.</td>
      <td>4</td>
      <td>5</td>
      <td>1</td>
      <td>93</td>
    </tr>
    <tr>
      <th>9</th>
      <td>9</td>
      <td>49</td>
      <td>General</td>
      <td>Tops</td>
      <td>Knits</td>
      <td>873</td>
      <td>Beauty meets comfort</td>
      <td>I love this top, the details at the neck and shoulders are lovely, both front and back. it's also very comfortable and soft, allowing you look nicely dressed while feeling like you are wearing a soft tee-shirt. the sleeves are a good length with some elastic at the cuffs so you can push them up. sadly, it's sold out in in my size online and in the stores, otherwise i would certainly snap it up at the sale price.</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>79</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19649</th>
      <td>23470</td>
      <td>50</td>
      <td>Initmates</td>
      <td>Intimate</td>
      <td>Intimates</td>
      <td>38</td>
      <td>Perfect fit</td>
      <td>I love this bralette. i have it in other colors as well and it is always the one i go to when i want comfort.</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>25</td>
    </tr>
    <tr>
      <th>19651</th>
      <td>23472</td>
      <td>60</td>
      <td>General</td>
      <td>Jackets</td>
      <td>Jackets</td>
      <td>975</td>
      <td>Perfect spring jacket!</td>
      <td>I love the style of this jacket! \r\ni will be curious to see how it holds up in the rain.\r\nit's very well made and has cute details.\r\nit does run large.</td>
      <td>4</td>
      <td>5</td>
      <td>1</td>
      <td>32</td>
    </tr>
    <tr>
      <th>19653</th>
      <td>23474</td>
      <td>46</td>
      <td>General</td>
      <td>Bottoms</td>
      <td>Jeans</td>
      <td>1030</td>
      <td>Great jean love mother</td>
      <td>Love these vintage soft jeans.. they do run small so be sure get a size larger.. i am typically a 27 and i ordered a 28... look amazing with boots, flip flops and slip ons... love mother jeans.. work every time</td>
      <td>1</td>
      <td>5</td>
      <td>1</td>
      <td>41</td>
    </tr>
    <tr>
      <th>19654</th>
      <td>23475</td>
      <td>25</td>
      <td>General Petite</td>
      <td>Bottoms</td>
      <td>Skirts</td>
      <td>1008</td>
      <td>Love this shirt</td>
      <td>I wasn't sure how the fabric would be since i ordered it online but i wasn't disappointed. its got a lot of movement which makes it really comfortable while still being cute. it's a little longer than i anticipated but i don't mind that. it just gives it a little more versatility. also it has pockets!! i love pockets so maybe i'm a little biased.</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>65</td>
    </tr>
    <tr>
      <th>19656</th>
      <td>23477</td>
      <td>60</td>
      <td>General Petite</td>
      <td>Tops</td>
      <td>Knits</td>
      <td>863</td>
      <td>Cute!</td>
      <td>Purchased this top in medium. i am 5'9" so normally wear medium. however, could probably have ordered a small. sleeves are very long and it's very full around bottom. love the gold color!</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>33</td>
    </tr>
    <tr>
      <th>19660</th>
      <td>23483</td>
      <td>29</td>
      <td>General Petite</td>
      <td>Tops</td>
      <td>Knits</td>
      <td>862</td>
      <td>So soft and flattering</td>
      <td>The deep v doesn't gape, and flatters the neckline, while the waist-high side slits reveal enough to keep this drapey shirt from looking shapeless. the material is so lovely and soft and comfy, but clings in the right places to really flatter, while problem areas get draped in the most perfect way.</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>52</td>
    </tr>
    <tr>
      <th>19661</th>
      <td>23484</td>
      <td>57</td>
      <td>General</td>
      <td>Dresses</td>
      <td>Dresses</td>
      <td>1082</td>
      <td>Another winner from isabella sinclair</td>
      <td>I saw this dress online this morning, went into a store this afternoon and walked out with it! i love this brand because the designs are modest, but feminine and practical. this dress is made of a thicker study cotton with beautiful all over embroidery. the fit is tts, and you can adjust the waist to fit loose or a bit more snug. the length is just above my knee at 5'3. i plan to wear this now with black boots and a furry vest, and later by itself with sandals and big sunnies!</td>
      <td>10</td>
      <td>5</td>
      <td>1</td>
      <td>94</td>
    </tr>
  </tbody>
</table>
<p>8083 rows × 12 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>8083</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> myntra-reviews-on-women-dresses-comprehensive/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What percentage of these reviews are for Pants and Jeans? (rounded to the nearest percentage)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>round((love_reviews[(love_reviews['class_name']=='Jeans') | (love_reviews['class_name']=='Pants')].shape[0]/love_reviews.shape[0]*100),0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>round((love_reviews[(love_reviews['class_name']=='Jeans') | (love_reviews['class_name']=='Pants')].shape[0]/love_reviews.shape[0]*100),0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = round(love_reviews[(love_reviews['class_name'] == 'Jeans') | (
    love_reviews['class_name'] == 'Pants')].shape[0] / love_reviews.shape[0
    ] * 100, 0)
</code></pre>
        <p><span onclick="$('#var_output_a6f32080').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a6f32080" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>11.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>11.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> myntra-reviews-on-women-dresses-comprehensive/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How old is the youngest customer who bought a dress and gave a rating of 5?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby('class_name').get_group('Dresses').groupby('rating').get_group(5)['age'].min()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby('class_name').get_group('Dresses').groupby('rating').get_group(5)['age'].min()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('class_name').get_group('Dresses').groupby('rating'
    ).get_group(5)['age'].min()
</code></pre>
        <p><span onclick="$('#var_output_0067ec59').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0067ec59" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>18</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>18</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> political-ads-20220630/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Drop columns that have the number of distinct values less than 50% of the data.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.drop(df.nunique()[(df.nunique()>len(df)/2)].index,axis=1,inplace=True)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.drop(df.nunique()[(df.nunique()>len(df)/2)].index,axis=1,inplace=True)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.drop(df.nunique()[df.nunique() > len(df) / 2].index, axis=1,
    inplace=True)
</code></pre>
        <p><span onclick="$('#var_output_6f09c97a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6f09c97a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> df </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>advertiser</th>
      <th>grossSpend</th>
      <th>periodStart</th>
      <th>periodEnd</th>
      <th>stationId</th>
      <th>year</th>
      <th>folderPath</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>COFFMAN FOR CONGRESS</td>
      <td>2355000</td>
      <td>2018-09-20</td>
      <td>2018-09-26</td>
      <td>126</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Coffman-NRCC/Coffman-NRCC Ord 733925 Sep20-Sep26</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Scott for Senate</td>
      <td>283000</td>
      <td>2018-09-25</td>
      <td>2018-10-01</td>
      <td>131</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US Senate</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Glassman/D/Congress/CT</td>
      <td>100000</td>
      <td>2018-07-17</td>
      <td>2018-07-23</td>
      <td>147</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Congress CT-05/GLASSMAN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>LINDA MCMAHON</td>
      <td>2842500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Federal/US Senate/Linda McMahon/a1770fde-3745-3606-3126-6f34a240a8c6-McMahon-399218</td>
    </tr>
    <tr>
      <th>4</th>
      <td>LINDA MCMAHON</td>
      <td>18174500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Federal/US Senate/Linda McMahon/c1f448db-b17e-0aa4-db78-fbefc7954025-McMahon-Rev6-386264</td>
    </tr>
    <tr>
      <th>5</th>
      <td>DEMOCRATIC SENATORIAL CAMPAIGN COMMITTEE</td>
      <td>6337500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Non-Candidate Issue Ads/DSCC MURPHY/c9ff0b02-e5db-be1a-ae76-b95176e1df24-DSCC-Rev3-398241</td>
    </tr>
    <tr>
      <th>6</th>
      <td>SENATE MAJORITY PAC</td>
      <td>6795000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Non-Candidate Issue Ads/SENATE MAJORITY PAC/88ff4f56-0c9d-7932-ca6d-8629495ee643-Senate Majority-398532</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6738</th>
      <td>Warren For President</td>
      <td>950000</td>
      <td>02/17/20</td>
      <td>02/23/20</td>
      <td>83969</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Elizabeth Warren for President</td>
    </tr>
    <tr>
      <th>6739</th>
      <td>Bernie Sanders for President-D (106300)</td>
      <td>179200</td>
      <td>11/19/19</td>
      <td>11/25/19</td>
      <td>84088</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Bernie Sanders for President</td>
    </tr>
    <tr>
      <th>6740</th>
      <td>POLI/A DELGADO/D/CONNY</td>
      <td>65000</td>
      <td>2018-06-05</td>
      <td>2018-06-11</td>
      <td>86537</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Antonio Delgado For Congess NY 19th District/5168</td>
    </tr>
    <tr>
      <th>6741</th>
      <td>Delgado for Congress</td>
      <td>154000</td>
      <td>2018-09-18</td>
      <td>2018-09-24</td>
      <td>136751</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Antonio Delgado</td>
    </tr>
    <tr>
      <th>6742</th>
      <td>Bernie 2020</td>
      <td>19000</td>
      <td>08/27/19</td>
      <td>09/07/19</td>
      <td>166331</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Q3 2019</td>
    </tr>
    <tr>
      <th>6743</th>
      <td>Bernie 2020</td>
      <td>20000</td>
      <td>09/18/19</td>
      <td>09/29/19</td>
      <td>166331</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Q3 2019</td>
    </tr>
    <tr>
      <th>6744</th>
      <td>WALDEN, GREG</td>
      <td>85000</td>
      <td>2018-09-05</td>
      <td>2018-09-11</td>
      <td>166534</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Greg Walden for Congress-Republican</td>
    </tr>
  </tbody>
</table>
<p>6745 rows × 7 columns</p>
      
        <p><strong>Hyp output variables:</strong> df </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>advertiser</th>
      <th>grossSpend</th>
      <th>periodStart</th>
      <th>periodEnd</th>
      <th>stationId</th>
      <th>year</th>
      <th>folderPath</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>COFFMAN FOR CONGRESS</td>
      <td>2355000</td>
      <td>2018-09-20</td>
      <td>2018-09-26</td>
      <td>126</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Coffman-NRCC/Coffman-NRCC Ord 733925 Sep20-Sep26</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Scott for Senate</td>
      <td>283000</td>
      <td>2018-09-25</td>
      <td>2018-10-01</td>
      <td>131</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US Senate</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Glassman/D/Congress/CT</td>
      <td>100000</td>
      <td>2018-07-17</td>
      <td>2018-07-23</td>
      <td>147</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Congress CT-05/GLASSMAN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>LINDA MCMAHON</td>
      <td>2842500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Federal/US Senate/Linda McMahon/a1770fde-3745-3606-3126-6f34a240a8c6-McMahon-399218</td>
    </tr>
    <tr>
      <th>4</th>
      <td>LINDA MCMAHON</td>
      <td>18174500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Federal/US Senate/Linda McMahon/c1f448db-b17e-0aa4-db78-fbefc7954025-McMahon-Rev6-386264</td>
    </tr>
    <tr>
      <th>5</th>
      <td>DEMOCRATIC SENATORIAL CAMPAIGN COMMITTEE</td>
      <td>6337500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Non-Candidate Issue Ads/DSCC MURPHY/c9ff0b02-e5db-be1a-ae76-b95176e1df24-DSCC-Rev3-398241</td>
    </tr>
    <tr>
      <th>6</th>
      <td>SENATE MAJORITY PAC</td>
      <td>6795000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Non-Candidate Issue Ads/SENATE MAJORITY PAC/88ff4f56-0c9d-7932-ca6d-8629495ee643-Senate Majority-398532</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6738</th>
      <td>Warren For President</td>
      <td>950000</td>
      <td>02/17/20</td>
      <td>02/23/20</td>
      <td>83969</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Elizabeth Warren for President</td>
    </tr>
    <tr>
      <th>6739</th>
      <td>Bernie Sanders for President-D (106300)</td>
      <td>179200</td>
      <td>11/19/19</td>
      <td>11/25/19</td>
      <td>84088</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Bernie Sanders for President</td>
    </tr>
    <tr>
      <th>6740</th>
      <td>POLI/A DELGADO/D/CONNY</td>
      <td>65000</td>
      <td>2018-06-05</td>
      <td>2018-06-11</td>
      <td>86537</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Antonio Delgado For Congess NY 19th District/5168</td>
    </tr>
    <tr>
      <th>6741</th>
      <td>Delgado for Congress</td>
      <td>154000</td>
      <td>2018-09-18</td>
      <td>2018-09-24</td>
      <td>136751</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Antonio Delgado</td>
    </tr>
    <tr>
      <th>6742</th>
      <td>Bernie 2020</td>
      <td>19000</td>
      <td>08/27/19</td>
      <td>09/07/19</td>
      <td>166331</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Q3 2019</td>
    </tr>
    <tr>
      <th>6743</th>
      <td>Bernie 2020</td>
      <td>20000</td>
      <td>09/18/19</td>
      <td>09/29/19</td>
      <td>166331</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Q3 2019</td>
    </tr>
    <tr>
      <th>6744</th>
      <td>WALDEN, GREG</td>
      <td>85000</td>
      <td>2018-09-05</td>
      <td>2018-09-11</td>
      <td>166534</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Greg Walden for Congress-Republican</td>
    </tr>
  </tbody>
</table>
<p>6745 rows × 7 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('df', 'df', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> political-ads-20220630/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Fill null values in advertisers using the base folder name in folderpath</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>null_advertiser=df[df['advertiser'].isna()].index
df.iloc[null_advertiser,0]=df.iloc[null_advertiser,-1].str.split('/').str[-1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>null_advertiser=df[df['advertiser'].isna()].index
df.iloc[null_advertiser,0]=df.iloc[null_advertiser,-1].str.split('/').str[-1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>null_advertiser = df[df['advertiser'].isna()].index
__output__ = df.iloc[null_advertiser, 0] = df.iloc[null_advertiser, -1
    ].str.split('/').str[-1]
</code></pre>
        <p><span onclick="$('#var_output_1829a90a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1829a90a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>444                        TED CRUZ
737                       US Senate
3612    Bredesen for US Senate TN D
Name: folderPath, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, null_advertiser, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>advertiser</th>
      <th>grossSpend</th>
      <th>periodStart</th>
      <th>periodEnd</th>
      <th>stationId</th>
      <th>year</th>
      <th>folderPath</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>COFFMAN FOR CONGRESS</td>
      <td>2355000</td>
      <td>2018-09-20</td>
      <td>2018-09-26</td>
      <td>126</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Coffman-NRCC/Coffman-NRCC Ord 733925 Sep20-Sep26</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Scott for Senate</td>
      <td>283000</td>
      <td>2018-09-25</td>
      <td>2018-10-01</td>
      <td>131</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US Senate</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Glassman/D/Congress/CT</td>
      <td>100000</td>
      <td>2018-07-17</td>
      <td>2018-07-23</td>
      <td>147</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Congress CT-05/GLASSMAN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>LINDA MCMAHON</td>
      <td>2842500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Federal/US Senate/Linda McMahon/a1770fde-3745-3606-3126-6f34a240a8c6-McMahon-399218</td>
    </tr>
    <tr>
      <th>4</th>
      <td>LINDA MCMAHON</td>
      <td>18174500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Federal/US Senate/Linda McMahon/c1f448db-b17e-0aa4-db78-fbefc7954025-McMahon-Rev6-386264</td>
    </tr>
    <tr>
      <th>5</th>
      <td>DEMOCRATIC SENATORIAL CAMPAIGN COMMITTEE</td>
      <td>6337500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Non-Candidate Issue Ads/DSCC MURPHY/c9ff0b02-e5db-be1a-ae76-b95176e1df24-DSCC-Rev3-398241</td>
    </tr>
    <tr>
      <th>6</th>
      <td>SENATE MAJORITY PAC</td>
      <td>6795000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Non-Candidate Issue Ads/SENATE MAJORITY PAC/88ff4f56-0c9d-7932-ca6d-8629495ee643-Senate Majority-398532</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6738</th>
      <td>Warren For President</td>
      <td>950000</td>
      <td>02/17/20</td>
      <td>02/23/20</td>
      <td>83969</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Elizabeth Warren for President</td>
    </tr>
    <tr>
      <th>6739</th>
      <td>Bernie Sanders for President-D (106300)</td>
      <td>179200</td>
      <td>11/19/19</td>
      <td>11/25/19</td>
      <td>84088</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Bernie Sanders for President</td>
    </tr>
    <tr>
      <th>6740</th>
      <td>POLI/A DELGADO/D/CONNY</td>
      <td>65000</td>
      <td>2018-06-05</td>
      <td>2018-06-11</td>
      <td>86537</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Antonio Delgado For Congess NY 19th District/5168</td>
    </tr>
    <tr>
      <th>6741</th>
      <td>Delgado for Congress</td>
      <td>154000</td>
      <td>2018-09-18</td>
      <td>2018-09-24</td>
      <td>136751</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Antonio Delgado</td>
    </tr>
    <tr>
      <th>6742</th>
      <td>Bernie 2020</td>
      <td>19000</td>
      <td>08/27/19</td>
      <td>09/07/19</td>
      <td>166331</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Q3 2019</td>
    </tr>
    <tr>
      <th>6743</th>
      <td>Bernie 2020</td>
      <td>20000</td>
      <td>09/18/19</td>
      <td>09/29/19</td>
      <td>166331</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Q3 2019</td>
    </tr>
    <tr>
      <th>6744</th>
      <td>WALDEN, GREG</td>
      <td>85000</td>
      <td>2018-09-05</td>
      <td>2018-09-11</td>
      <td>166534</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Greg Walden for Congress-Republican</td>
    </tr>
  </tbody>
</table>
<p>6745 rows × 7 columns</p>
      
          <p>null_advertiser (Int64Index):</p>
          <pre><code>Int64Index([444, 737, 3612], dtype='int64')</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>444                        TED CRUZ
737                       US Senate
3612    Bredesen for US Senate TN D
Name: folderPath, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> political-ads-20220630/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new column called Duration that has the duration of the ad in days or nan if the date string cannot be parsed.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def convert_time(x):
    try:
        return datetime.strptime(x, '%Y-%m-%d').date()
    except:
        return np.NaN
def duration_days(x):
    try:
        return (x[1]-x[0]).days
    except:
        return np.NaN
df['periodEnd']=df['periodEnd'].apply(convert_time)
df['periodStart']=df['periodStart'].apply(convert_time)
df['Duration']=df[['periodStart','periodEnd']].apply(duration_days,axis=1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def convert_time(x):
    try:
        return datetime.strptime(x, '%Y-%m-%d').date()
    except:
        return np.NaN
def duration_days(x):
    try:
        return (x[1]-x[0]).days
    except:
        return np.NaN
df['periodEnd']=df['periodEnd'].apply(convert_time)
df['periodStart']=df['periodStart'].apply(convert_time)
df['Duration']=df[['periodStart','periodEnd']].apply(duration_days,axis=1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def convert_time(x):
    try:
        return datetime.strptime(x, '%Y-%m-%d').date()
    except:
        return np.NaN


def duration_days(x):
    try:
        return (x[1] - x[0]).days
    except:
        return np.NaN


df['periodEnd'] = df['periodEnd'].apply(convert_time)
df['periodStart'] = df['periodStart'].apply(convert_time)
__output__ = df['Duration'] = df[['periodStart', 'periodEnd']].apply(
    duration_days, axis=1)
</code></pre>
        <p><span onclick="$('#var_output_63f8558a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_63f8558a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0       6.0
1       6.0
2       6.0
3       NaN
4       NaN
       ... 
6740    6.0
6741    6.0
6742    NaN
6743    NaN
6744    6.0
Length: 6745, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>advertiser</th>
      <th>grossSpend</th>
      <th>periodStart</th>
      <th>periodEnd</th>
      <th>stationId</th>
      <th>year</th>
      <th>folderPath</th>
      <th>Duration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>COFFMAN FOR CONGRESS</td>
      <td>2355000</td>
      <td>2018-09-20</td>
      <td>2018-09-26</td>
      <td>126</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Coffman-NRCC/Coffman-NRCC Ord 733925 Sep20-Sep26</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Scott for Senate</td>
      <td>283000</td>
      <td>2018-09-25</td>
      <td>2018-10-01</td>
      <td>131</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US Senate</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Glassman/D/Congress/CT</td>
      <td>100000</td>
      <td>2018-07-17</td>
      <td>2018-07-23</td>
      <td>147</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Congress CT-05/GLASSMAN</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>LINDA MCMAHON</td>
      <td>2842500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Federal/US Senate/Linda McMahon/a1770fde-3745-3606-3126-6f34a240a8c6-McMahon-399218</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>LINDA MCMAHON</td>
      <td>18174500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Federal/US Senate/Linda McMahon/c1f448db-b17e-0aa4-db78-fbefc7954025-McMahon-Rev6-386264</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>DEMOCRATIC SENATORIAL CAMPAIGN COMMITTEE</td>
      <td>6337500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Non-Candidate Issue Ads/DSCC MURPHY/c9ff0b02-e5db-be1a-ae76-b95176e1df24-DSCC-Rev3-398241</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>SENATE MAJORITY PAC</td>
      <td>6795000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>147</td>
      <td>2012</td>
      <td>Political Files/2012/Non-Candidate Issue Ads/SENATE MAJORITY PAC/88ff4f56-0c9d-7932-ca6d-8629495ee643-Senate Majority-398532</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6738</th>
      <td>Warren For President</td>
      <td>950000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>83969</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Elizabeth Warren for President</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6739</th>
      <td>Bernie Sanders for President-D (106300)</td>
      <td>179200</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>84088</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Bernie Sanders for President</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6740</th>
      <td>POLI/A DELGADO/D/CONNY</td>
      <td>65000</td>
      <td>2018-06-05</td>
      <td>2018-06-11</td>
      <td>86537</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Antonio Delgado For Congess NY 19th District/5168</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>6741</th>
      <td>Delgado for Congress</td>
      <td>154000</td>
      <td>2018-09-18</td>
      <td>2018-09-24</td>
      <td>136751</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Antonio Delgado</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>6742</th>
      <td>Bernie 2020</td>
      <td>19000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>166331</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Q3 2019</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6743</th>
      <td>Bernie 2020</td>
      <td>20000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>166331</td>
      <td>2019</td>
      <td>Political Files/2019/Federal/President/Q3 2019</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6744</th>
      <td>WALDEN, GREG</td>
      <td>85000</td>
      <td>2018-09-05</td>
      <td>2018-09-11</td>
      <td>166534</td>
      <td>2018</td>
      <td>Political Files/2018/Federal/US House/Greg Walden for Congress-Republican</td>
      <td>6.0</td>
    </tr>
  </tbody>
</table>
<p>6745 rows × 8 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0       6.0
1       6.0
2       6.0
3       NaN
4       NaN
       ... 
6740    6.0
6741    6.0
6742    NaN
6743    NaN
6744    6.0
Length: 6745, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> political-ads-20220630/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top five most paying advertisers?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(df.groupby('advertiser').sum()['grossSpend']).sort_values(ascending=False).head().index</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(df.groupby('advertiser').sum()['grossSpend']).sort_values(ascending=False).head().index</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('advertiser').sum()['grossSpend'].sort_values(ascending
    =False).head().index
</code></pre>
        <p><span onclick="$('#var_output_b32bd24a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b32bd24a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Index):</p>
          <pre><code>Index(['Steyer/D/President', 'Tom Steyer 2020', 'Steyer for President',
       'Tom Steyer for President-D', 'POL/Tom Steyer/President/US/Dem'],
      dtype='object', name='advertiser')</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Index):</p>
          <pre><code>Index(['Steyer/D/President', 'Tom Steyer 2020', 'Steyer for President',
       'Tom Steyer for President-D', 'POL/Tom Steyer/President/US/Dem'],
      dtype='object', name='advertiser')</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> political-ads-20220630/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show a list of the top ten highest-paid stations in 2018.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>stations=df.groupby('year').get_group(2018).groupby('stationId').sum()['grossSpend'].sort_values(ascending=False).head(10)
stations.index.tolist()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>stations=df.groupby('year').get_group(2018).groupby('stationId').sum()['grossSpend'].sort_values(ascending=False).head(10)
stations.index.tolist()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>stations = df.groupby('year').get_group(2018).groupby('stationId').sum()[
    'grossSpend'].sort_values(ascending=False).head(10)
__output__ = stations.index.tolist()
</code></pre>
        <p><span onclick="$('#var_output_8661018b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8661018b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>[10179, 2455, 10073, 12793, 35920, 51597, 10173, 43328, 34847, 70034]</code></pre>
      
        <p><strong>Hyp output variables:</strong> stations, __output__ </p>
    
          <p>stations (Series):</p>
          <pre><code>stationId
10179    328541000
2455      95850000
10073     69683000
12793     37575000
35920     30274000
51597     30000000
10173     26914800
43328     24772000
34847     19165000
70034     17110000
Name: grossSpend, dtype: int64</code></pre>
      
          <p>__output__ (list):</p>
          <pre><code>[10179, 2455, 10073, 12793, 35920, 51597, 10173, 43328, 34847, 70034]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> political-ads-20220630/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which of these stations had the highest demand?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby('stationId').count()['advertiser'].loc[stations.index].sort_values().index[-1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby('stationId').count()['advertiser'].loc[stations.index].sort_values().index[-1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('stationId').count()['advertiser'].loc[stations.index
    ].sort_values().index[-1]
</code></pre>
        <p><span onclick="$('#var_output_ee273eb0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ee273eb0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>10179</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>10179</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> political-ads-20220630/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many ads were for congress and aired for more than a week?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['Duration']>7]['advertiser'].str.lower().str.contains('congress').value_counts()[1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['Duration']>7]['advertiser'].str.lower().str.contains('congress').value_counts()[1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['Duration'] > 7]['advertiser'].str.lower().str.contains(
    'congress').value_counts()[1]
</code></pre>
        <p><span onclick="$('#var_output_ef07586b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ef07586b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>100</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>100</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> political-ads-20220630/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total amount spent on Tom Steyer ads in each station in 2019?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>sum_values=df[(df['year']==2019) & (df['advertiser'].str.lower().str.contains('tom steyer'))].groupby('stationId').sum()
sum_values['grossSpend']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>sum_values=df[(df['year']==2019) & (df['advertiser'].str.lower().str.contains('tom steyer'))].groupby('stationId').sum()
sum_values['grossSpend']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>sum_values = df[(df['year'] == 2019) & df['advertiser'].str.lower().str.
    contains('tom steyer')].groupby('stationId').sum()
__output__ = sum_values['grossSpend']
</code></pre>
        <p><span onclick="$('#var_output_08da3292').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_08da3292" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>stationId
411          384000
412          739600
416        34316000
590       516802500
593       153587600
            ...    
73988       2492800
74195        556800
77451      49098100
83969       7631000
168338       758800
Name: grossSpend, Length: 73, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> sum_values, __output__ </p>
    
          <p>sum_values (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>grossSpend</th>
      <th>year</th>
      <th>Duration</th>
    </tr>
    <tr>
      <th>stationId</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>411</th>
      <td>384000</td>
      <td>2019</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>412</th>
      <td>739600</td>
      <td>4038</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>416</th>
      <td>34316000</td>
      <td>145368</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>590</th>
      <td>516802500</td>
      <td>22209</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>593</th>
      <td>153587600</td>
      <td>258432</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3133</th>
      <td>3772500</td>
      <td>36342</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3369</th>
      <td>2473500</td>
      <td>22209</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>73937</th>
      <td>37190000</td>
      <td>38361</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>73982</th>
      <td>40754500</td>
      <td>82779</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>73988</th>
      <td>2492800</td>
      <td>8076</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>74195</th>
      <td>556800</td>
      <td>2019</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>77451</th>
      <td>49098100</td>
      <td>179691</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>83969</th>
      <td>7631000</td>
      <td>20190</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>168338</th>
      <td>758800</td>
      <td>2019</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>73 rows × 3 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>stationId
411          384000
412          739600
416        34316000
590       516802500
593       153587600
            ...    
73988       2492800
74195        556800
77451      49098100
83969       7631000
168338       758800
Name: grossSpend, Length: 73, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> political-ads-20220630/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many of these values are within the top 90% quantile</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(sum_values['grossSpend'] >= df.grossSpend.quantile(0.9)).value_counts()[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(sum_values['grossSpend'] >= df.grossSpend.quantile(0.9)).value_counts()[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = (sum_values['grossSpend'] >= df.grossSpend.quantile(0.9)
    ).value_counts()[0]
</code></pre>
        <p><span onclick="$('#var_output_0da3d58c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0da3d58c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>45</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>45</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> political-ads-20220630/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total amount spent on ads that lasted for more than a month for each station in 2018? (in descending order)</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df.Duration>30) & (df.year==2018)].groupby('stationId').sum()['grossSpend'].sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df.Duration>30) & (df.year==2018)].groupby('stationId').sum()['grossSpend'].sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df.Duration > 30) & (df.year == 2018)].groupby('stationId'
    ).sum()['grossSpend'].sort_values(ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_73250644').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_73250644" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>stationId
10179    77240000
51597    30000000
49699     8485000
73905     8261000
16820     6424000
           ...   
72119      215000
35385       83800
37503       66000
24812       60000
51569       30000
Name: grossSpend, Length: 32, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>stationId
10179    77240000
51597    30000000
49699     8485000
73905     8261000
16820     6424000
           ...   
72119      215000
35385       83800
37503       66000
24812       60000
51569       30000
Name: grossSpend, Length: 32, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> pubmed-multilabel-text-classification/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Rename columns A-Z with their corresponding name in meshroot column.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>import ast
import re

mesh_roots = df.meshroot.apply(ast.literal_eval)

unique_mesh_roots = set()
for mesh_roots_list in mesh_roots:
  for root in mesh_roots_list:
    unique_mesh_roots.add(root)

columns_replacement = dict()

for mesh_root in unique_mesh_roots:
  m = re.match('(.+?)\[(.+?)\]', mesh_root)
  root_name = m.group(1).strip()
  letter_id = m.group(2)

  columns_replacement[letter_id] = root_name

print(columns_replacement)
df.rename(columns=columns_replacement,inplace=True)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>import ast
import re

mesh_roots = df.meshroot.apply(ast.literal_eval)

unique_mesh_roots = set()
for mesh_roots_list in mesh_roots:
  for root in mesh_roots_list:
    unique_mesh_roots.add(root)

columns_replacement = dict()

for mesh_root in unique_mesh_roots:
  m = re.match('(.+?)\[(.+?)\]', mesh_root)
  root_name = m.group(1).strip()
  letter_id = m.group(2)

  columns_replacement[letter_id] = root_name

print(columns_replacement)
df.rename(columns=columns_replacement,inplace=True)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>import ast
import re
mesh_roots = df.meshroot.apply(ast.literal_eval)
unique_mesh_roots = set()
for mesh_roots_list in mesh_roots:
    for root in mesh_roots_list:
        unique_mesh_roots.add(root)
columns_replacement = dict()
for mesh_root in unique_mesh_roots:
    m = re.match('(.+?)\\[(.+?)\\]', mesh_root)
    root_name = m.group(1).strip()
    letter_id = m.group(2)
    columns_replacement[letter_id] = root_name
__tmp_7 = columns_replacement
__output__ = df.rename(columns=columns_replacement, inplace=True)
</code></pre>
        <p><span onclick="$('#var_output_3c9f90e0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3c9f90e0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> df </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Title</th>
      <th>abstractText</th>
      <th>meshMajor</th>
      <th>pmid</th>
      <th>meshid</th>
      <th>meshroot</th>
      <th>Anatomy</th>
      <th>...</th>
      <th>Disciplines and Occupations</th>
      <th>Anthropology, Education, Sociology, and Social Phenomena</th>
      <th>Technology, Industry, and Agriculture</th>
      <th>Information Science</th>
      <th>Named Groups</th>
      <th>Health Care</th>
      <th>Geographicals</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Expression of p53 and coexistence of HPV in premalignant lesions and in cervical cancer.</td>
      <td>Fifty-four paraffin embedded tissue sections from patients with dysplasia (21 cases) and with cervical cancer (33 cases) were analysed. HPV was detected and identified in two stages. Firstly, using mixed starters, chosen genomic DNA sequences were amplified; secondly the material thus obtained was analyzed by hybridization method using oligonucleotyde 31-P labelled probe. HPVs of type 6, 11, 16, 18, 33 were identified. The p-53 expression was assayed by immunohistochemical method. HPV infection was often associated with dysplasia and cervical cancer. In cervical cancer mainly HPV 16 and 18 with high oncogenic potential were found. The p-53 was present rarely, and in minute quantities. No correlation was observed between presence of p-53 and HPVs DNA.</td>
      <td>['DNA Probes, HPV', 'DNA, Viral', 'Female', 'Humans', 'Immunohistochemistry', 'Papillomaviridae', 'Tumor Suppressor Protein p53', 'Uterine Cervical Dysplasia', 'Uterine Cervical Neoplasms']</td>
      <td>8549602</td>
      <td>[['D13.444.600.223.555', 'D27.505.259.750.600.223.620', 'D27.720.470.530.600.223.620'], ['D13.444.308.568'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['E01.370.225.500.607.512', 'E01.370.225.750.551.512', 'E05.200.500.607.512', 'E05.200.750.551.512', 'E05.478.583', 'H01.158.100.656.234.512', 'H01.158.201.344.512', 'H01.158.201.486.512', 'H01.181.122.573.512', 'H01.181.122.605.512'], ['B04.280.210.655', 'B04.613.204.655'], ['D12.776.157.687.650', 'D12.776.260.820', 'D12.776.624.776.775', 'D12.776.660.720.650', 'D12.776.744.845'], ['C04.834.818', 'C13.351.500.852.593.074'], ['C04.588.945.418.948.850', 'C13.351.500.852.593.131', 'C13.351.500.852.762.850', 'C13.351.937.418.875.850']]</td>
      <td>['Chemicals and Drugs [D]', 'Organisms [B]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Disciplines and Occupations [H]', 'Diseases [C]']</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Vitamin D status in pregnant Indian women across trimesters and different seasons and its correlation with neonatal serum 25-hydroxyvitamin D levels.</td>
      <td>The present cross-sectional study was conducted to determine the vitamin D status of pregnant Indian women and their breast-fed infants. Subjects were recruited from the Department of Obstetrics, Armed Forces Clinic and Army Hospital (Research and Referral), Delhi. A total of 541 apparently healthy women with uncomplicated, single, intra-uterine gestation reporting in any trimester were consecutively recruited. Of these 541 women, 299 (first trimester, ninety-seven; second trimester, 125; third trimester, seventy-seven) were recruited in summer (April-October) and 242 (first trimester, fifty-nine, second trimester, ninety-three; third trimester, ninety) were recruited in winter (November-March) to study seasonal variations in vitamin D status. Clinical, dietary, biochemical and hormonal evaluations for the Ca-vitamin D-parathormone axis were performed. A subset of 342 mother-infant pairs was re-evaluated 6 weeks postpartum. Mean serum 25-hydroxyvitamin D (25(OH)D) of pregnant women was 23.2 (SD 12.2) nmol/l. Hypovitaminosis D (25(OH)D &lt; 50 nmol/l) was observed in 96.3 % of the subjects. Serum 25(OH)D levels were significantly lower in winter in the second and third trimesters, while serum intact parathormone (iPTH) and alkaline phosphatase levels were significantly higher in winter in all three trimesters. A significant negative correlation was found between serum 25(OH)D and iPTH in mothers (r - 0.367, P = 0.0001) and infants (r - 0.56, P = 0.0001). A strong positive correlation was observed between 25(OH)D levels of mother-infant pairs (r 0.779, P = 0.0001). A high prevalence of hypovitaminosis D was observed in pregnancy, lactation and infancy with no significant inter-trimester differences in serum 25(OH)D levels.</td>
      <td>['Adult', 'Alkaline Phosphatase', 'Breast Feeding', 'Cross-Sectional Studies', 'Female', 'Humans', 'India', 'Infant', 'Infant Nutrition Disorders', 'Lactation', 'Mothers', 'Nutritional Status', 'Parathyroid Hormone', 'Pregnancy', 'Pregnancy Complications', 'Pregnancy Trimesters', 'Seasons', 'Vitamin D', 'Vitamin D Deficiency', 'Vitamins', 'Young Adult']</td>
      <td>21736816</td>
      <td>[['M01.060.116'], ['D08.811.277.352.650.035'], ['F01.145.407.199', 'G07.203.650.195', 'G07.203.650.220.500.500', 'G07.203.650.353.199'], ['E05.318.372.500.875', 'N05.715.360.330.500.875', 'N06.850.520.450.500.875'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['Z01.252.245.393'], ['M01.060.703'], ['C18.654.422'], ['G08.686.523', 'G08.686.702.500'], ['F01.829.263.500.320.200', 'I01.880.853.150.500.340.270', 'M01.620.630'], ['G07.203.650.650', 'N01.224.425.525'], ['D06.472.699.590', 'D12.644.548.587'], ['G08.686.784.769'], ['C13.703'], ['G08.686.707'], ['G01.910.645.661', 'G16.500.275.071.590', 'N06.230.300.100.250.525'], ['D04.210.500.812.768'], ['C18.654.521.500.133.770'], ['D27.505.696.494.600', 'G07.203.300.681.500.600', 'J02.500.681.500.600'], ['M01.060.116.815']]</td>
      <td>['Named Groups [M]', 'Chemicals and Drugs [D]', 'Psychiatry and Psychology [F]', 'Phenomena and Processes [G]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Health Care [N]', 'Organisms [B]', 'Geographicals [Z]', 'Diseases [C]', 'Anthropology, Education, Sociology, and Social Phenomena [I]', 'Technology, Industry, and Agriculture [J]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[Identification of a functionally important dipeptide in sequences of atypical opioid peptides].</td>
      <td>The occurrence of individual amino acids and dipeptide fragments in the sequences of 60 known atypical opioid peptides was analyzed. An expressed predominance of Tyr-Pro fragment suggested a high probability of analgesic activity for this dipeptide, and it was experimentally studied. It was shown on somatic and visceral pain sensitivity models that, on the i.p. administration of Tyr-Pro at doses of 1.0-10 mg/kg of body mass, it exhibits an analgesic activity eliminated by naloxone and naloxone methiodide. However, in tests on ileum preparations of guinea pig and mouse vas deferens in vitro, Tyr-Pro was devoid of opioid activity, which proved its indirect influence on opioid receptors.</td>
      <td>['Amino Acid Sequence', 'Analgesics, Opioid', 'Animals', 'Consensus Sequence', 'Dipeptides', 'Guinea Pigs', 'In Vitro Techniques', 'Male', 'Mice', 'Molecular Sequence Data', 'Muscle Contraction', 'Muscle, Smooth', 'Narcotic Antagonists', 'Opioid Peptides', 'Pain Measurement', 'Rats', 'Receptor, Cannabinoid, CB1', 'Receptors, Opioid']</td>
      <td>19060934</td>
      <td>[['G02.111.570.060', 'L01.453.245.667.060'], ['D27.505.696.277.600.500', 'D27.505.696.663.850.014.760.500', 'D27.505.954.427.040.550.500', 'D27.505.954.427.210.600.500'], ['B01.050'], ['G02.111.570.580.175'], ['D12.644.456.345'], ['B01.050.150.900.649.313.992.550'], ['E05.481'], ['B01.050.150.900.649.313.992.635.505.500'], ['L01.453.245.667'], ['G11.427.494'], ['A02.633.570', 'A10.690.467'], ['D27.505.696.543', 'D27.505.696.663.850.512', 'D27.505.954.427.550'], ['D12.644.400.575', 'D12.776.631.650.575'], ['E01.370.600.550.324'], ['B01.050.150.900.649.313.992.635.505.700'], ['D12.776.543.750.695.125.100'], ['D12.776.543.750.695.620', 'D12.776.543.750.720.600.610', 'D12.776.543.750.750.555.610']]</td>
      <td>['Phenomena and Processes [G]', 'Information Science [L]', 'Chemicals and Drugs [D]', 'Organisms [B]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Anatomy [A]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Multilayer capsules: a promising microencapsulation system for transplantation of pancreatic islets.</td>
      <td>In 1980, Lim and Sun introduced a microcapsule coated with an alginate/polylysine complex for encapsulation of pancreatic islets. Characteristic to this type of capsule is, that it consists of a plain membrane which is formed during a single procedural step. With such a simple process it is difficult to obtain instantly a membrane optimized with respect to all the properties requested for islet transplantation. To overcome these difficulties, it is recommended to build up the membrane in several consecutive steps, each optimized for a certain property. In this study, we have analysed such a multilayer microcapsule for the encapsulation of pancreatic islets. Therefore, empty and islet containing alginate beads were coated with alternating layers of polyethyleneimine, polyacrylacid or carboxymethylcellulose and alginate. By scanning electron microscopy the thickness of the covering multilayer-membrane was estimated to be less than 800 nm by comparison with an apparatus scale. Ellipsometric measurements showed that the membrane thickness is in the range of 145 nm. Neither the encapsulation procedure, nor the membrane-forming step did impede the stimulatory response of the islets. The encapsulation even lead to a significantly better stimulatory response of the encapsulated islets during week three and five of cell culture. Furthermore, the multilayer-membrane did not deteriorate the biocompatibility of the transplanted microcapsules, allowing an easy tuning of the molecular cut-off and the mechanical stability depending on the polycation-polyanion combination used. The multilayer membrane capsule has obvious advantages compared to a one-step encapsulation procedure. These beads guarantee a high biocompatibility, a precisely adjusted cut-off, an optimal insulin-response and high mechanical stability although the membrane is only 145 nm thick.</td>
      <td>['Acrylic Resins', 'Alginates', 'Animals', 'Biocompatible Materials', 'Biopolymers', 'Carboxymethylcellulose Sodium', 'Cells, Cultured', 'Compressive Strength', 'Drug Compounding', 'Female', 'Fibrosis', 'Glucuronic Acid', 'Hexuronic Acids', 'Islets of Langerhans Transplantation', 'Materials Testing', 'Microspheres', 'Muscle, Skeletal', 'Particle Size', 'Permeability', 'Polyethyleneimine', 'Polyethylenes', 'Polylysine', 'Prostheses and Implants', 'Quaternary Ammonium Compounds', 'Rats', 'Rats, Inbred Lew', 'Rats, Sprague-Dawley', 'Transplantation, Heterotopic']</td>
      <td>11426874</td>
      <td>[['D05.750.716.822.111', 'D25.720.716.822.111', 'J01.637.051.720.716.822.111'], ['D09.698.068'], ['B01.050'], ['D25.130', 'D27.720.102.130', 'J01.637.051.130'], ['D05.750.078', 'D25.720.099', 'J01.637.051.720.099'], ['D09.698.365.180.663.329'], ['A11.251'], ['G01.374.180'], ['E05.916.270'], ['C23.550.355'], ['D02.241.081.844.915.162.249', 'D02.241.152.811.162.500', 'D02.241.511.902.915.162.500', 'D09.811.922.162.500'], ['D02.241.081.844.915.400', 'D02.241.152.811.400', 'D02.241.511.902.915.400', 'D09.811.922.400'], ['E02.095.147.500.250', 'E04.270.550', 'E04.936.225.375'], ['E05.570'], ['E07.565'], ['A02.633.567', 'A10.690.552.500'], ['G02.712'], ['G02.723'], ['D02.455.326.271.665.550.600', 'D02.491.650', 'D05.750.716.507.600', 'D25.720.716.507.600', 'J01.637.051.720.716.507.600'], ['D02.455.326.271.665.550', 'D05.750.716.507', 'D25.720.716.507', 'J01.637.051.720.716.507'], ['D12.125.068.555.750', 'D12.125.095.647.750', 'D12.644.760'], ['E07.695'], ['D01.625.062.500', 'D02.092.877', 'D02.675.276'], ['B01.050.150.900.649.313.992.635.505.700'], ['B01.050.050.199.520.760.280', 'B01.050.150.900.649.313.992.635.505.700.400.280'], ['B01.050.150.900.649.313.992.635.505.700.750'], ['E04.936.800']]</td>
      <td>['Chemicals and Drugs [D]', 'Technology, Industry, and Agriculture [J]', 'Organisms [B]', 'Anatomy [A]', 'Phenomena and Processes [G]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Diseases [C]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Nanohydrogel with N,N'-bis(acryloyl)cystine crosslinker for high drug loading.</td>
      <td>Substantially improved hydrogel particles based on poly(N-isopropylacrylamide) (pNIPA) have been obtained. First, as a result of replacing commercially available N,N'-bis(acryloyl)cystamine (BAC), the crosslinker, with acryloyl derivative of cystine containing a carboxylic group (BISS), the hydrogel particles acquired improved stability vs. ionic strength and allowed further chemical modification of the chains, including the attachment of drug molecules. Next, a redox-initiated aqueous precipitation polymerization via the semi-batch method was used. This led to substantially increased BISS content and diminished size of the nanoparticles that made them suitable to an endocytic process. In addition, the obtained nanogels revealed high loading capacity of anticancer drug vs. dry gel (circa 16%) and they exhibited much better stability and enhanced drug release under the typical conditions existing in cancer cells. Size of obtained nanogels was investigated by dynamic light scattering (DLS). It appeared that nanoparticle size was in the range from ca. 40 to 200nm. In 0.01M solution of glutathione (GSH) the -S-S- bonds were reduced and the nanogel particles were degraded. This could be seen in obtained SEM and TEM micrographs. The cytotoxicity investigation against the HeLa cells showed that DOX loaded nanogels were more cytotoxic (IC50=0.51ìM) than free DOX (IC50=0.83ìM), while unloaded nanogels did not inhibit proliferation of the cells. It was also found that the nanogels loaded with DOX reached a high intracellular concentration in HeLa cells just after 2h while free DOX needed 6h for that.</td>
      <td>['Antineoplastic Agents', 'Cell Proliferation', 'Cell Survival', 'Cross-Linking Reagents', 'Cystine', 'Doxorubicin', 'Drug Carriers', 'Drug Liberation', 'HeLa Cells', 'Humans', 'Hydrogels', 'Nanoparticles']</td>
      <td>28323099</td>
      <td>[['D27.505.954.248'], ['G04.161.750', 'G07.345.249.410.750'], ['G04.346'], ['D27.720.470.410.210'], ['D01.248.497.158.874.390.369', 'D01.875.350.850.150.369', 'D02.886.030.230.369', 'D02.886.520.150.087', 'D12.125.095.369', 'D12.125.119.369', 'D12.125.166.230.369'], ['D02.455.426.559.847.562.050.200.175', 'D04.615.562.050.200.175', 'D09.408.051.059.200.175'], ['D26.255.260', 'E02.319.300.380'], ['G02.211', 'G03.787.321', 'G07.690.725.321'], ['A11.251.210.190.400', 'A11.251.860.180.400', 'A11.436.340'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['D20.280.320.375', 'D26.255.165.320.375'], ['J01.637.512.600']]</td>
      <td>['Chemicals and Drugs [D]', 'Phenomena and Processes [G]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Anatomy [A]', 'Organisms [B]', 'Technology, Industry, and Agriculture [J]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>A new &lt;i&gt;Panolis&lt;/i&gt; H?bner, [1821] species from Vietnam (Lepidoptera, Noctuidae, Orthosiini).</td>
      <td>Panolis is a well-defined and compact Palearctic trifine Noctuidae genus within the subfamily Hadeninae, tribus Orthosiini. It is currently represented by seven species and one subspecies: Panolis flammea ([Denis &amp; Schifferm?ller], 1775), Panolis japonica Draudt, 1935, Panolis variegatoides Poole, 1989, Panolis exquisita Draudt, 1950, Panolis pinicortex Draudt, 1950, Panolis pinicortex exornata Hreblay &amp; Ronkay, 1997, Panolis estheri Ronkay, Ronkay, Gyulai &amp; Hacker, 2010 and Panolis ningshan Wang, Fan, Owada, Wang &amp; Nylin, 2014. Only one species (P. flammea) occurs in the Western Palearctic region, while all others are found in the eastern part of Asia. No Panolis species is known outside of the Palearctic region. The genus is connected to coniferous woodlands as the larvae are feed on various species of pines. Imagoes are on the wing during the spring, from late February until May. All Panolis species have an unmistakable, rather decorative external appearance with fine and conspicuous pink-red-purple or dark orange ground colouration, and remarkable noctuid patterns. Most recent information about the genus was provided by Wang et. al, 2014, including his description of a new species, and a morphological and molecular analysis in order to reconstructing the phylogeny of the genus, and exploring its Chines Oriental origin. Present paper contains the description of a new Panolis species found recently in Vietnam, from where the genus was not known so far. This discovery expands our knowledge about Panolis and support the statement of the Chines Oriental origin.</td>
      <td>['Animal Distribution', 'Animals', 'Asia', 'Larva', 'Moths', 'Vietnam']</td>
      <td>28609947</td>
      <td>[['F01.145.113.069', 'G16.049'], ['B01.050'], ['Z01.252'], ['B05.500.500', 'G07.345.500.550.500.500'], ['B01.050.500.131.617.720.500.500.937.650'], ['Z01.252.145.945']]</td>
      <td>['Psychiatry and Psychology [F]', 'Phenomena and Processes [G]', 'Organisms [B]', 'Geographicals [Z]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Characterization of neutron field in a NPP workplace.</td>
      <td>At the Krsko Nuclear Power Plant (NPP), albedo dosimeters are used for personal neutron dosimetry. Spectrometric measurements allow determination of reference dosimetric values of realistic neutron fields to be used for calibration of albedo dosimeters. The Laboratory for Neutron Metrology and Dosimetry from the Institute for Radiological Protection and Nuclear Safety (IRSN) was in charge of characterising neutron fields in the plant at two representative points with high neutron and gamma dose rate. Calibration of the dosimeters in the workplace used to be performed only by a spherical survey meter. Based on the reference dosimetric values, the Plant Dosimetry Laboratory has verified the response of albedo dosimeters.</td>
      <td>['Algorithms', 'Equipment Design', 'Equipment Failure Analysis', 'France', 'Internationality', 'Occupational Exposure', 'Power Plants', 'Radiation Dosage', 'Radiation Monitoring', 'Radiation Protection', 'Reproducibility of Results', 'Sensitivity and Specificity']</td>
      <td>17416593</td>
      <td>[['G17.035', 'L01.224.050'], ['E05.320'], ['E05.325.192'], ['Z01.542.286'], ['I01.615'], ['N06.850.460.350.600'], ['J01.780', 'J03.540.680'], ['E05.799.513', 'G01.750.740', 'N06.850.810.250'], ['E05.799.638', 'N06.850.780.375.700', 'N06.850.810.370'], ['N06.850.810.425'], ['E05.318.370.725', 'E05.337.851', 'N05.715.360.325.685', 'N06.850.520.445.725'], ['E05.318.370.800', 'E05.318.740.872', 'G17.800', 'N05.715.360.325.700', 'N05.715.360.750.725', 'N06.850.520.445.800', 'N06.850.520.830.872']]</td>
      <td>['Phenomena and Processes [G]', 'Information Science [L]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Geographicals [Z]', 'Anthropology, Education, Sociology, and Social Phenomena [I]', 'Health Care [N]', 'Technology, Industry, and Agriculture [J]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>49993</th>
      <td>Influence of SLCO1B1 and CYP2C8 gene polymorphisms on rosiglitazone pharmacokinetics in healthy volunteers.</td>
      <td>Polymorphisms in drug transporter genes and/or drug-metabolising enzyme genes may contribute to inter-individual variability in rosiglitazone pharmacokinetics in humans. We sought to determine the joint effects of polymorphisms in the SLCO1B1 drug transporter gene and the cytochrome P450 ( CYP ) 2C8-metabolising enzyme gene on rosiglitazone pharmacokinetics in healthy volunteers. Healthy Caucasian subjects were prospectively enrolled on the basis of SLCO1B1 521 T &gt; C genotype. Additionally, subjects were genotyped for SLCO1B1 -11187 G &gt; A, -10499 A &gt; C and 388 A &gt; G polymorphisms, and the CYP2C8*3 polymorphism. SLCO1B1 haplotypes and diplotypes were computationally assigned. Rosiglitazone plasma concentrations were determined by high-performance liquid chromatography and analysed using non-compartmental methods. The study population consisted of 26 subjects, with a mean age of 33 +/- 9 years, and a mean weight of 66.6 +/- 11.7 kg. There were no significant differences in rosiglitazone pharmacokinetic parameters between SLCO1B1 diplotype groups. Subjects with the CYP2C8*1/*3 genotype ( n = 7), however, had significantly lower rosiglitazone area under the plasma concentration-time curve (AUC) and significantly higher rosiglitazone oral clearance, compared with CYP2C8 wild-type homozygotes ( n = 19). Stepwise linear regression analysis revealed that CYP2C8 genotype ( p = 0.006) and weight ( p = 0.022) were significant predictors of rosiglitazone AUC (overall p = 0.002; R 2 = 41.6 per cent). We concluded that polymorphisms in the CYP2C8 drug-metabolising enzyme gene, but not the SLCO1B1 drug transporter gene, significantly influence rosiglitazone disposition in humans. Future studies examining the influence of CYP2C8 genotypes and haplotypes on thiazolidinedione disposition and response in patients with type 2 diabetes are warranted.</td>
      <td>['Adolescent', 'Adult', 'Area Under Curve', 'Aryl Hydrocarbon Hydroxylases', 'Cytochrome P-450 CYP2C8', 'Female', 'Genotype', 'Health', 'Humans', 'Liver-Specific Organic Anion Transporter 1', 'Male', 'Middle Aged', 'Organic Anion Transporters', 'Polymorphism, Genetic', 'Rosiglitazone', 'Thiazolidinediones', 'Time Factors']</td>
      <td>19129086</td>
      <td>[['M01.060.057'], ['M01.060.116'], ['E05.318.740.200', 'G03.787.101', 'G07.690.725.064', 'N06.850.520.830.200'], ['D08.244.453.005', 'D08.811.682.690.708.170.010', 'D12.776.422.220.453.010'], ['D08.244.453.005.590', 'D08.244.453.491.368', 'D08.811.682.690.708.170.010.590', 'D08.811.682.690.708.170.450.360', 'D12.776.422.220.453.010.590', 'D12.776.422.220.453.491.360'], ['G05.380'], ['N01.400'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['D12.776.157.530.450.074.500.781.500', 'D12.776.157.530.937.580', 'D12.776.543.585.450.074.500.875.500', 'D12.776.543.585.937.901'], ['M01.060.116.630'], ['D12.776.157.530.450.074.500', 'D12.776.543.585.450.074.500'], ['G05.365.795'], ['D02.886.675.933.500', 'D03.383.129.708.933.500'], ['D02.886.675.933', 'D03.383.129.708.933'], ['G01.910.857']]</td>
      <td>['Named Groups [M]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Phenomena and Processes [G]', 'Health Care [N]', 'Chemicals and Drugs [D]', 'Organisms [B]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49994</th>
      <td>Active growth factor delivery from poly(D,L-lactide-co-glycolide) foams prepared in supercritical CO(2).</td>
      <td>A method for the production of microporous poly(D, L-lactide-co-glycolide) foams containing encapsulated proteins using supercritical carbon dioxide is described. Foams generated as aqueous protein emulsions in a polymer-solvent solution were saturated with carbon dioxide at supercritical conditions, and then suddenly supersaturated at ambient conditions causing bubble nucleation and precipitation of the polymer. Proteins contained in the water phase of the emulsion were encapsulated within the foams, including basic fibroblast growth factor (bFGF), an angiogenic factor of interest in tissue engineering applications. The release and activity of bFGF from these foams was determined in vitro and compared with similar porous scaffolds prepared by traditional solvent casting-salt leaching techniques. Total protein release rate was greater from structures made in CO(2) than those made by the salt leaching technique, however a large initial burst of bFGF was released from the salt leached structures. This initial burst was not observed from the polymer foams processed in CO(2) and active bFGF was released at a relatively constant rate. Residual methylene chloride levels were measured in the foams made with CO(2) and were found to be above the limits imposed by the US Pharmacopoeia implying that further solvent removal would be required prior to in vivo use.</td>
      <td>['Animals', 'Biocompatible Materials', 'Carbon Dioxide', 'Cattle', 'Cold Temperature', 'Drug Carriers', 'Drug Delivery Systems', 'Fibroblast Growth Factor 2', 'Growth Substances', 'Lactic Acid', 'Methylene Chloride', 'Microscopy, Electron, Scanning', 'Polyglycolic Acid', 'Polylactic Acid-Polyglycolic Acid Copolymer', 'Polymers', 'Solutions']</td>
      <td>10742578</td>
      <td>[['B01.050'], ['D25.130', 'D27.720.102.130', 'J01.637.051.130'], ['D01.200.200', 'D01.362.150', 'D01.650.550.200'], ['B01.050.150.900.649.313.500.380.271'], ['G01.906.595.272', 'G16.500.275.063.725.710.300', 'G16.500.750.775.710.300', 'N06.230.300.100.725.154', 'N06.230.300.100.725.710.300'], ['D26.255.260', 'E02.319.300.380'], ['E02.319.300'], ['D12.644.276.624.120', 'D12.776.467.624.120', 'D23.529.624.120'], ['D27.505.696.377'], ['D02.241.511.459.450'], ['D02.455.526.439.642'], ['E01.370.350.515.402.541', 'E05.595.402.541'], ['D05.750.728.780', 'D25.720.728.780', 'J01.637.051.720.728.780'], ['D02.241.511.459.450.500', 'D05.750.728.780.500', 'D25.720.728.780.500', 'J01.637.051.720.728.780.500'], ['D05.750', 'D25.720', 'J01.637.051.720'], ['D26.776']]</td>
      <td>['Organisms [B]', 'Chemicals and Drugs [D]', 'Technology, Industry, and Agriculture [J]', 'Phenomena and Processes [G]', 'Health Care [N]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49995</th>
      <td>Five donors-one recipient: modeling a mosaic of granulocytes, natural killer and T cells from cord-blood and third-party donors.</td>
      <td>BACKGROUND: A 21-year-old man was admitted to hospital because of leukocytosis, thrombocytopenia and anemia. The patient had been in good health until a few days earlier, when he developed fever and night sweats and his performance status dramatically declined.INVESTIGATIONS: Laboratory tests, immunophenotyping, cytogenetic analyses, bone-marrow biopsy, minimal residual disease analysis using quantitative real-time polymerase chain reaction, differential chimerism analysis using flow cytometry, mixed chimerism analysis, CT scans, electro-encephalography, cerebral magnetic resonance tomography.DIAGNOSIS: Bcr-abl-positive and Philadelphia-chromosome-positive acute lymphoblastic leukemia, and primary graft failure complicated by invasive fungal infection and cytomegalovirus encephalitis.MANAGEMENT: Double cord-blood rescue transplantation, third-party CD34-positive stem-cell rescue transplantation, third-party cytomegalovirus-specific T lymphocyte transplantation.</td>
      <td>['Adult', 'Cell Transplantation', 'Cord Blood Stem Cell Transplantation', 'Granulocytes', 'Humans', 'Killer Cells, Natural', 'Male', 'Mosaicism', 'Precursor Cell Lymphoblastic Leukemia-Lymphoma', 'T-Lymphocytes']</td>
      <td>18364724</td>
      <td>[['M01.060.116'], ['E02.095.147.500', 'E04.936.225'], ['E02.095.147.500.500.312', 'E04.936.225.687.312'], ['A11.118.637.415', 'A11.148.350', 'A11.627.340', 'A15.145.229.637.415', 'A15.378.316.340', 'A15.382.490.315'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['A11.118.637.555.567.537', 'A15.145.229.637.555.567.537', 'A15.382.490.555.567.537'], ['G05.365.590.175.595'], ['C04.557.337.428.600', 'C15.604.515.560.600', 'C20.683.515.528.600'], ['A11.118.637.555.567.569', 'A15.145.229.637.555.567.569', 'A15.382.490.555.567.569']]</td>
      <td>['Named Groups [M]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Anatomy [A]', 'Organisms [B]', 'Phenomena and Processes [G]', 'Diseases [C]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49996</th>
      <td>The role of eicosanoids in cyclosporine nephrotoxicity in the rat.</td>
      <td>Nephrotoxicity is the most troublesome complication of cyclosporine (CSA) therapy. The present study was designed to investigate the effects of chronic treatment with CSA on the 24-hr urinary excretion of prostanoids (PGs) and thromboxane (Tx) and on the renal function in the absence or presence of indomethacin. CSA administration to Wistar rats (20 mg/kg/day, i.p.) for 14 days caused a significant increase in plasma creatinine, blood urea nitrogen (BUN), urine osmolality, fractional excretion of sodium and potassium and a reduction in creatinine clearance (CCr) and urine volume. These changes were associated with a significant reduction in urinary excretion of PGE2 (21.1 +/- 3.3 vs 33.0 +/- 2.5 ng/24 hr) and PGF2 alpha (13.4 +/- 1.4 vs 27.9 +/- 3.8 ng/24 hr) and an increase in TxB2 (12.1 +/- 3.0 vs 4.6 +/- 0.5 ng/24 hr), and 6-keto PGF1 alpha (56.2 +/- 7.7 vs 27.7 +/- 1.9 ng/24 hr). However, the synthesis of TxB2 and 6-keto PGF1 alpha by renal medullary and cortical slices prepared from CSA treated rats was not different from values obtained for vehicle treatment. In contrast, PGE2 synthesis by cortical slices prepared from the CSA group was increased. A single injection of indomethacin (10 mg/kg) to vehicle and CSA treated rats resulted in a significant reduction in PGs and TxB2 excretion. This, was associated with a further reduction in CCr (0.81 +/- 0.06 vs 1.03 +/- 0.04 ml/min) and an increase in BUN (38.5 +/- 5.2 vs 28.2 +/- 1.4 mg%) only in the CSA group. We suggest that the vasodilating PGs attenuate the renal toxic effects induced by CSA.</td>
      <td>['Animals', 'Cyclosporins', 'In Vitro Techniques', 'Kidney', 'Kidney Cortex', 'Kidney Medulla', 'Male', 'Prostaglandins', 'Rats', 'Rats, Inbred Strains', 'Reference Values', 'Thromboxane B2']</td>
      <td>2735953</td>
      <td>[['B01.050'], ['D04.345.566.235', 'D12.644.641.235'], ['E05.481'], ['A05.810.453'], ['A05.810.453.324'], ['A05.810.453.466'], ['D10.251.355.255.550', 'D23.469.050.175.725'], ['B01.050.150.900.649.313.992.635.505.700'], ['B01.050.050.199.520.760', 'B01.050.150.900.649.313.992.635.505.700.400'], ['E05.978.810'], ['D10.251.355.255.100.825.810', 'D10.251.355.310.166.971.810']]</td>
      <td>['Organisms [B]', 'Chemicals and Drugs [D]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Anatomy [A]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49997</th>
      <td>Impact of pancreaticoduodenal arcade dilation on postoperative outcomes after pancreaticoduodenectomy.</td>
      <td>BACKGROUND: The aim of this study was to investigate the impact of pancreaticoduodenal arcade (PDA) dilation on postoperative outcomes after pancreaticoduodenectomy.METHODS: Consecutive patients submitted to pancreaticoduodenectomy between 2008 and 2016 underwent preoperative multi-detector computed tomography, the images of which were re-reviewed. The patients were categorized according to the grade of PDA dilation into 3 groups (remarkably-dilated, slightly-dilated, and non-dilated).RESULTS: Among the 443 patients, 25 patients (5.6%) were categorized as remarkably-dilated PDA and 24 patients (5.4%) as having slightly-dilated PDA. The patients with remarkably-dilated PDA had undergone pancreaticoduodenectomy with additional surgical maneuvers to restore celiac arterial flow as needed, and had an uneventful postoperative recovery relative to those with non-dilated PDA. In contrast, patients with slightly-dilated PDA underwent only pancreaticoduodenectomy without additional surgical maneuvers, and developed clinically relevant postoperative pancreatic fistula (POPF) more frequently than those with non-dilated PDA (42% vs. 21%, P = 0.021). Moreover, slightly-dilated PDA was shown to be an independent risk factor for clinically relevant POPF (odds ratio = 2.719, P = 0.042).DISCUSSION: For patients with PDA dilation requiring pancreaticoduodenectomy, a preoperative evaluation of the vascular anatomy, intraoperative assessment of the celiac arterial flow, and additional surgical maneuvers might be necessary to reduce the risk of postoperative complications.</td>
      <td>['Adult', 'Aged', 'Aged, 80 and over', 'Dilatation, Pathologic', 'Duodenum', 'Female', 'Humans', 'Male', 'Middle Aged', 'Pancreas', 'Pancreatic Neoplasms', 'Pancreaticoduodenectomy', 'Postoperative Complications', 'Retrospective Studies', 'Tomography, X-Ray Computed', 'Young Adult']</td>
      <td>28919282</td>
      <td>[['M01.060.116'], ['M01.060.116.100'], ['M01.060.116.100.080'], ['C23.300.325'], ['A03.556.124.684.124', 'A03.556.875.249'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['M01.060.116.630'], ['A03.734'], ['C04.588.274.761', 'C04.588.322.475', 'C06.301.761', 'C06.689.667', 'C19.344.421'], ['E04.210.760'], ['C23.550.767'], ['E05.318.372.500.500.500', 'E05.318.372.500.750.750', 'N05.715.360.330.500.500.500', 'N05.715.360.330.500.750.825', 'N06.850.520.450.500.500.500', 'N06.850.520.450.500.750.825'], ['E01.370.350.350.810', 'E01.370.350.600.350.700.810', 'E01.370.350.700.700.810', 'E01.370.350.700.810.810', 'E01.370.350.825.810.810'], ['M01.060.116.815']]</td>
      <td>['Named Groups [M]', 'Diseases [C]', 'Anatomy [A]', 'Organisms [B]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Health Care [N]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49998</th>
      <td>Outcomes of Preterm Infants following Discussions about Withdrawal or Withholding of Life Support.</td>
      <td>OBJECTIVES: To describe the frequency of postnatal discussions about withdrawal or withholding of life-sustaining therapy (WWLST), ensuing WWLST, and outcomes of infants surviving such discussions. We hypothesized that such survivors have poor outcomes.STUDY DESIGN: This retrospective review included registry data from 18 centers of the National Institute of Child Health and Human Development Neonatal Research Network. Infants born at 22-28 weeks of gestation who survived &gt;12 hours during 2011-2013 were included. Regression analysis identified maternal and infant factors associated with WWLST discussions and factors predicting ensuing WWLST. In-hospital and 18- to 26-month outcomes were evaluated.RESULTS: WWLST discussions occurred in 529 (15.4%) of 3434 infants. These were more frequent at 22-24 weeks (27.0%) compared with 27-28 weeks of gestation (5.6%). Factors associated with WWLST discussion were male sex, gestational age (GA) of ?24 weeks, birth weight small for GA, congenital malformations or syndromes, early onset sepsis, severe brain injury, and necrotizing enterocolitis. Rates of WWLST discussion varied by center (6.4%-29.9%) as did WWLST (5.2%-20.7%). Ensuing WWLST occurred in 406 patients; of these, 5 survived to discharge. Of the 123 infants for whom intensive care was continued, 58 (47%) survived to discharge. Survival after WWLST discussion was associated with higher rates of neonatal morbidities and neurodevelopmental impairment compared with babies for whom WWLST discussions did not occur. Significant predictors of ensuing WWLST were maternal age &gt;25 years, necrotizing enterocolitis, and days on a ventilator.CONCLUSIONS: Wide center variations in WWLST discussions occur, especially at ?24 weeks GA. Outcomes of infants surviving after WWLST discussions are poor.TRIAL REGISTRATION: ClinicalTrials.gov: NCT00063063.</td>
      <td>['Decision Making', 'Female', 'Humans', 'Infant', 'Infant Mortality', 'Infant, Newborn', 'Infant, Premature', 'Life Support Care', 'Male', 'Morbidity', 'Outcome Assessment, Health Care', 'Registries', 'Retrospective Studies', 'Survival Rate', 'Withholding Treatment']</td>
      <td>28647272</td>
      <td>[['F02.463.785.373'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['M01.060.703'], ['E05.318.308.985.550.475', 'N01.224.935.698.489', 'N06.850.505.400.975.550.475', 'N06.850.520.308.985.550.475'], ['M01.060.703.520'], ['M01.060.703.520.520'], ['E02.760.440', 'N02.421.585.440'], ['E05.318.308.985.525', 'N01.224.935.597', 'N06.850.505.400.975.525', 'N06.850.520.308.985.525'], ['H01.770.644.145.431', 'N04.761.559.590', 'N05.715.360.575.575'], ['E05.318.308.970', 'N04.452.859.819', 'N05.715.360.300.715.700', 'N06.850.520.308.970'], ['E05.318.372.500.500.500', 'E05.318.372.500.750.750', 'N05.715.360.330.500.500.500', 'N05.715.360.330.500.750.825', 'N06.850.520.450.500.500.500', 'N06.850.520.450.500.750.825'], ['E05.318.308.985.550.900', 'N01.224.935.698.826', 'N06.850.505.400.975.550.900', 'N06.850.520.308.985.550.900'], ['E02.760.952', 'N02.421.585.952']]</td>
      <td>['Psychiatry and Psychology [F]', 'Organisms [B]', 'Named Groups [M]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Health Care [N]', 'Disciplines and Occupations [H]']</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49999</th>
      <td>Molecular subtyping of Borrelia burgdorferi sensu lato isolates from five patients with solitary lymphocytoma.</td>
      <td>Solitary lymphocytoma is a rare cutaneous manifestation of Lyme borreliosis that has been reported almost exclusively from Europe. This suggests that its etiologic agent may be absent or extremely rare on the North American continent. All three species of B. burgdorferi sensu lato known to be associated with human Lyme borreliosis (B. burgdorferi sensu stricto, B. garinii, and B. afzelii have been isolated in Europe, whereas only B. burgdorferi sensu stricto has been found in North America. This suggests that either B. garinii or B. afzelii might be the etiologic agent of borrelial lymphocytoma. To investigate this hypothesis we characterized five strains of B. burgdorferi sensu lato isolated from lymphocytoma lesions of patients residing in Slovenia. The methods used included: large restriction fragment pattern analysis of restriction enzyme MluI-digested genomic DNA, plasmid profiling, protein profiling, ribotyping using 5S, 16S, and 23S rDNA probes, and polymerase chain reaction amplification of the rrf (5S)-rrl (23S) intergenic spacer region. Molecular subtyping showed that four of the five isolates belonged to the species B. afzelii; however, this species is the predominant patient isolate in Slovenia and, therefore, may not represent a preferential association with lymphocytoma. The fifth isolate appeared to be most closely related to the DN127 genomic group of organisms. Further characterization of the isolate revealed that it possessed a unique molecular "fingerprint." The results not only show that borrelial lymphocytoma can be caused by B. afzelii but also demonstrate an association with another genomic group of B. burgdorferi sensu lato that is present in North America as well.</td>
      <td>['Adult', 'Aged', 'Antigens, Surface', 'Bacterial Outer Membrane Proteins', 'Bacterial Vaccines', 'Biopsy', 'Borrelia burgdorferi Group', 'DNA Primers', 'DNA, Bacterial', 'Electrophoresis, Gel, Pulsed-Field', 'Electrophoresis, Polyacrylamide Gel', 'Europe', 'Female', 'Gene Amplification', 'Humans', 'Leukemia, Lymphocytic, Chronic, B-Cell', 'Lipoproteins', 'Lyme Disease', 'Middle Aged', 'Polymerase Chain Reaction', 'Restriction Mapping', 'Skin', 'Skin Neoplasms', 'Sodium Dodecyl Sulfate']</td>
      <td>8980295</td>
      <td>[['M01.060.116'], ['M01.060.116.100'], ['D23.050.301'], ['D12.776.097.120', 'D12.776.543.100'], ['D20.215.894.135'], ['E01.370.225.500.384.100', 'E01.370.225.998.054', 'E01.370.388.100', 'E04.074', 'E05.200.500.384.100', 'E05.200.998.054', 'E05.242.384.100'], ['B03.440.425.410.711.193.150', 'B03.851.595.193.150'], ['D13.695.578.424.450.275', 'D27.720.470.530.600.223.600'], ['D13.444.308.212'], ['E05.196.401.220', 'E05.301.300.220'], ['E05.196.401.402', 'E05.301.300.319'], ['Z01.542'], ['G05.308.250', 'G05.365.590.310', 'G05.558.315'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['C04.557.337.428.080.125', 'C15.604.515.560.080.125', 'C20.683.515.528.080.125'], ['D10.532', 'D12.776.521'], ['C01.150.252.400.536', 'C01.150.252.400.794.352.250', 'C01.920.930.513'], ['M01.060.116.630'], ['E05.393.620.500'], ['E05.393.183.620.650', 'E05.393.712'], ['A17.815'], ['C04.588.805', 'C17.800.882'], ['D02.033.415.220.720', 'D02.886.645.600.055.050.632', 'D10.289.220.720']]</td>
      <td>['Named Groups [M]', 'Chemicals and Drugs [D]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Organisms [B]', 'Geographicals [Z]', 'Phenomena and Processes [G]', 'Diseases [C]', 'Anatomy [A]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>50000 rows × 20 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, mesh_roots, unique_mesh_roots, mesh_roots_list, root, mesh_root, root_name, letter_id </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Title</th>
      <th>abstractText</th>
      <th>meshMajor</th>
      <th>pmid</th>
      <th>meshid</th>
      <th>meshroot</th>
      <th>Anatomy</th>
      <th>...</th>
      <th>Disciplines and Occupations</th>
      <th>Anthropology, Education, Sociology, and Social Phenomena</th>
      <th>Technology, Industry, and Agriculture</th>
      <th>Information Science</th>
      <th>Named Groups</th>
      <th>Health Care</th>
      <th>Geographicals</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Expression of p53 and coexistence of HPV in premalignant lesions and in cervical cancer.</td>
      <td>Fifty-four paraffin embedded tissue sections from patients with dysplasia (21 cases) and with cervical cancer (33 cases) were analysed. HPV was detected and identified in two stages. Firstly, using mixed starters, chosen genomic DNA sequences were amplified; secondly the material thus obtained was analyzed by hybridization method using oligonucleotyde 31-P labelled probe. HPVs of type 6, 11, 16, 18, 33 were identified. The p-53 expression was assayed by immunohistochemical method. HPV infection was often associated with dysplasia and cervical cancer. In cervical cancer mainly HPV 16 and 18 with high oncogenic potential were found. The p-53 was present rarely, and in minute quantities. No correlation was observed between presence of p-53 and HPVs DNA.</td>
      <td>['DNA Probes, HPV', 'DNA, Viral', 'Female', 'Humans', 'Immunohistochemistry', 'Papillomaviridae', 'Tumor Suppressor Protein p53', 'Uterine Cervical Dysplasia', 'Uterine Cervical Neoplasms']</td>
      <td>8549602</td>
      <td>[['D13.444.600.223.555', 'D27.505.259.750.600.223.620', 'D27.720.470.530.600.223.620'], ['D13.444.308.568'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['E01.370.225.500.607.512', 'E01.370.225.750.551.512', 'E05.200.500.607.512', 'E05.200.750.551.512', 'E05.478.583', 'H01.158.100.656.234.512', 'H01.158.201.344.512', 'H01.158.201.486.512', 'H01.181.122.573.512', 'H01.181.122.605.512'], ['B04.280.210.655', 'B04.613.204.655'], ['D12.776.157.687.650', 'D12.776.260.820', 'D12.776.624.776.775', 'D12.776.660.720.650', 'D12.776.744.845'], ['C04.834.818', 'C13.351.500.852.593.074'], ['C04.588.945.418.948.850', 'C13.351.500.852.593.131', 'C13.351.500.852.762.850', 'C13.351.937.418.875.850']]</td>
      <td>['Chemicals and Drugs [D]', 'Organisms [B]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Disciplines and Occupations [H]', 'Diseases [C]']</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Vitamin D status in pregnant Indian women across trimesters and different seasons and its correlation with neonatal serum 25-hydroxyvitamin D levels.</td>
      <td>The present cross-sectional study was conducted to determine the vitamin D status of pregnant Indian women and their breast-fed infants. Subjects were recruited from the Department of Obstetrics, Armed Forces Clinic and Army Hospital (Research and Referral), Delhi. A total of 541 apparently healthy women with uncomplicated, single, intra-uterine gestation reporting in any trimester were consecutively recruited. Of these 541 women, 299 (first trimester, ninety-seven; second trimester, 125; third trimester, seventy-seven) were recruited in summer (April-October) and 242 (first trimester, fifty-nine, second trimester, ninety-three; third trimester, ninety) were recruited in winter (November-March) to study seasonal variations in vitamin D status. Clinical, dietary, biochemical and hormonal evaluations for the Ca-vitamin D-parathormone axis were performed. A subset of 342 mother-infant pairs was re-evaluated 6 weeks postpartum. Mean serum 25-hydroxyvitamin D (25(OH)D) of pregnant women was 23.2 (SD 12.2) nmol/l. Hypovitaminosis D (25(OH)D &lt; 50 nmol/l) was observed in 96.3 % of the subjects. Serum 25(OH)D levels were significantly lower in winter in the second and third trimesters, while serum intact parathormone (iPTH) and alkaline phosphatase levels were significantly higher in winter in all three trimesters. A significant negative correlation was found between serum 25(OH)D and iPTH in mothers (r - 0.367, P = 0.0001) and infants (r - 0.56, P = 0.0001). A strong positive correlation was observed between 25(OH)D levels of mother-infant pairs (r 0.779, P = 0.0001). A high prevalence of hypovitaminosis D was observed in pregnancy, lactation and infancy with no significant inter-trimester differences in serum 25(OH)D levels.</td>
      <td>['Adult', 'Alkaline Phosphatase', 'Breast Feeding', 'Cross-Sectional Studies', 'Female', 'Humans', 'India', 'Infant', 'Infant Nutrition Disorders', 'Lactation', 'Mothers', 'Nutritional Status', 'Parathyroid Hormone', 'Pregnancy', 'Pregnancy Complications', 'Pregnancy Trimesters', 'Seasons', 'Vitamin D', 'Vitamin D Deficiency', 'Vitamins', 'Young Adult']</td>
      <td>21736816</td>
      <td>[['M01.060.116'], ['D08.811.277.352.650.035'], ['F01.145.407.199', 'G07.203.650.195', 'G07.203.650.220.500.500', 'G07.203.650.353.199'], ['E05.318.372.500.875', 'N05.715.360.330.500.875', 'N06.850.520.450.500.875'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['Z01.252.245.393'], ['M01.060.703'], ['C18.654.422'], ['G08.686.523', 'G08.686.702.500'], ['F01.829.263.500.320.200', 'I01.880.853.150.500.340.270', 'M01.620.630'], ['G07.203.650.650', 'N01.224.425.525'], ['D06.472.699.590', 'D12.644.548.587'], ['G08.686.784.769'], ['C13.703'], ['G08.686.707'], ['G01.910.645.661', 'G16.500.275.071.590', 'N06.230.300.100.250.525'], ['D04.210.500.812.768'], ['C18.654.521.500.133.770'], ['D27.505.696.494.600', 'G07.203.300.681.500.600', 'J02.500.681.500.600'], ['M01.060.116.815']]</td>
      <td>['Named Groups [M]', 'Chemicals and Drugs [D]', 'Psychiatry and Psychology [F]', 'Phenomena and Processes [G]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Health Care [N]', 'Organisms [B]', 'Geographicals [Z]', 'Diseases [C]', 'Anthropology, Education, Sociology, and Social Phenomena [I]', 'Technology, Industry, and Agriculture [J]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[Identification of a functionally important dipeptide in sequences of atypical opioid peptides].</td>
      <td>The occurrence of individual amino acids and dipeptide fragments in the sequences of 60 known atypical opioid peptides was analyzed. An expressed predominance of Tyr-Pro fragment suggested a high probability of analgesic activity for this dipeptide, and it was experimentally studied. It was shown on somatic and visceral pain sensitivity models that, on the i.p. administration of Tyr-Pro at doses of 1.0-10 mg/kg of body mass, it exhibits an analgesic activity eliminated by naloxone and naloxone methiodide. However, in tests on ileum preparations of guinea pig and mouse vas deferens in vitro, Tyr-Pro was devoid of opioid activity, which proved its indirect influence on opioid receptors.</td>
      <td>['Amino Acid Sequence', 'Analgesics, Opioid', 'Animals', 'Consensus Sequence', 'Dipeptides', 'Guinea Pigs', 'In Vitro Techniques', 'Male', 'Mice', 'Molecular Sequence Data', 'Muscle Contraction', 'Muscle, Smooth', 'Narcotic Antagonists', 'Opioid Peptides', 'Pain Measurement', 'Rats', 'Receptor, Cannabinoid, CB1', 'Receptors, Opioid']</td>
      <td>19060934</td>
      <td>[['G02.111.570.060', 'L01.453.245.667.060'], ['D27.505.696.277.600.500', 'D27.505.696.663.850.014.760.500', 'D27.505.954.427.040.550.500', 'D27.505.954.427.210.600.500'], ['B01.050'], ['G02.111.570.580.175'], ['D12.644.456.345'], ['B01.050.150.900.649.313.992.550'], ['E05.481'], ['B01.050.150.900.649.313.992.635.505.500'], ['L01.453.245.667'], ['G11.427.494'], ['A02.633.570', 'A10.690.467'], ['D27.505.696.543', 'D27.505.696.663.850.512', 'D27.505.954.427.550'], ['D12.644.400.575', 'D12.776.631.650.575'], ['E01.370.600.550.324'], ['B01.050.150.900.649.313.992.635.505.700'], ['D12.776.543.750.695.125.100'], ['D12.776.543.750.695.620', 'D12.776.543.750.720.600.610', 'D12.776.543.750.750.555.610']]</td>
      <td>['Phenomena and Processes [G]', 'Information Science [L]', 'Chemicals and Drugs [D]', 'Organisms [B]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Anatomy [A]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Multilayer capsules: a promising microencapsulation system for transplantation of pancreatic islets.</td>
      <td>In 1980, Lim and Sun introduced a microcapsule coated with an alginate/polylysine complex for encapsulation of pancreatic islets. Characteristic to this type of capsule is, that it consists of a plain membrane which is formed during a single procedural step. With such a simple process it is difficult to obtain instantly a membrane optimized with respect to all the properties requested for islet transplantation. To overcome these difficulties, it is recommended to build up the membrane in several consecutive steps, each optimized for a certain property. In this study, we have analysed such a multilayer microcapsule for the encapsulation of pancreatic islets. Therefore, empty and islet containing alginate beads were coated with alternating layers of polyethyleneimine, polyacrylacid or carboxymethylcellulose and alginate. By scanning electron microscopy the thickness of the covering multilayer-membrane was estimated to be less than 800 nm by comparison with an apparatus scale. Ellipsometric measurements showed that the membrane thickness is in the range of 145 nm. Neither the encapsulation procedure, nor the membrane-forming step did impede the stimulatory response of the islets. The encapsulation even lead to a significantly better stimulatory response of the encapsulated islets during week three and five of cell culture. Furthermore, the multilayer-membrane did not deteriorate the biocompatibility of the transplanted microcapsules, allowing an easy tuning of the molecular cut-off and the mechanical stability depending on the polycation-polyanion combination used. The multilayer membrane capsule has obvious advantages compared to a one-step encapsulation procedure. These beads guarantee a high biocompatibility, a precisely adjusted cut-off, an optimal insulin-response and high mechanical stability although the membrane is only 145 nm thick.</td>
      <td>['Acrylic Resins', 'Alginates', 'Animals', 'Biocompatible Materials', 'Biopolymers', 'Carboxymethylcellulose Sodium', 'Cells, Cultured', 'Compressive Strength', 'Drug Compounding', 'Female', 'Fibrosis', 'Glucuronic Acid', 'Hexuronic Acids', 'Islets of Langerhans Transplantation', 'Materials Testing', 'Microspheres', 'Muscle, Skeletal', 'Particle Size', 'Permeability', 'Polyethyleneimine', 'Polyethylenes', 'Polylysine', 'Prostheses and Implants', 'Quaternary Ammonium Compounds', 'Rats', 'Rats, Inbred Lew', 'Rats, Sprague-Dawley', 'Transplantation, Heterotopic']</td>
      <td>11426874</td>
      <td>[['D05.750.716.822.111', 'D25.720.716.822.111', 'J01.637.051.720.716.822.111'], ['D09.698.068'], ['B01.050'], ['D25.130', 'D27.720.102.130', 'J01.637.051.130'], ['D05.750.078', 'D25.720.099', 'J01.637.051.720.099'], ['D09.698.365.180.663.329'], ['A11.251'], ['G01.374.180'], ['E05.916.270'], ['C23.550.355'], ['D02.241.081.844.915.162.249', 'D02.241.152.811.162.500', 'D02.241.511.902.915.162.500', 'D09.811.922.162.500'], ['D02.241.081.844.915.400', 'D02.241.152.811.400', 'D02.241.511.902.915.400', 'D09.811.922.400'], ['E02.095.147.500.250', 'E04.270.550', 'E04.936.225.375'], ['E05.570'], ['E07.565'], ['A02.633.567', 'A10.690.552.500'], ['G02.712'], ['G02.723'], ['D02.455.326.271.665.550.600', 'D02.491.650', 'D05.750.716.507.600', 'D25.720.716.507.600', 'J01.637.051.720.716.507.600'], ['D02.455.326.271.665.550', 'D05.750.716.507', 'D25.720.716.507', 'J01.637.051.720.716.507'], ['D12.125.068.555.750', 'D12.125.095.647.750', 'D12.644.760'], ['E07.695'], ['D01.625.062.500', 'D02.092.877', 'D02.675.276'], ['B01.050.150.900.649.313.992.635.505.700'], ['B01.050.050.199.520.760.280', 'B01.050.150.900.649.313.992.635.505.700.400.280'], ['B01.050.150.900.649.313.992.635.505.700.750'], ['E04.936.800']]</td>
      <td>['Chemicals and Drugs [D]', 'Technology, Industry, and Agriculture [J]', 'Organisms [B]', 'Anatomy [A]', 'Phenomena and Processes [G]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Diseases [C]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Nanohydrogel with N,N'-bis(acryloyl)cystine crosslinker for high drug loading.</td>
      <td>Substantially improved hydrogel particles based on poly(N-isopropylacrylamide) (pNIPA) have been obtained. First, as a result of replacing commercially available N,N'-bis(acryloyl)cystamine (BAC), the crosslinker, with acryloyl derivative of cystine containing a carboxylic group (BISS), the hydrogel particles acquired improved stability vs. ionic strength and allowed further chemical modification of the chains, including the attachment of drug molecules. Next, a redox-initiated aqueous precipitation polymerization via the semi-batch method was used. This led to substantially increased BISS content and diminished size of the nanoparticles that made them suitable to an endocytic process. In addition, the obtained nanogels revealed high loading capacity of anticancer drug vs. dry gel (circa 16%) and they exhibited much better stability and enhanced drug release under the typical conditions existing in cancer cells. Size of obtained nanogels was investigated by dynamic light scattering (DLS). It appeared that nanoparticle size was in the range from ca. 40 to 200nm. In 0.01M solution of glutathione (GSH) the -S-S- bonds were reduced and the nanogel particles were degraded. This could be seen in obtained SEM and TEM micrographs. The cytotoxicity investigation against the HeLa cells showed that DOX loaded nanogels were more cytotoxic (IC50=0.51ìM) than free DOX (IC50=0.83ìM), while unloaded nanogels did not inhibit proliferation of the cells. It was also found that the nanogels loaded with DOX reached a high intracellular concentration in HeLa cells just after 2h while free DOX needed 6h for that.</td>
      <td>['Antineoplastic Agents', 'Cell Proliferation', 'Cell Survival', 'Cross-Linking Reagents', 'Cystine', 'Doxorubicin', 'Drug Carriers', 'Drug Liberation', 'HeLa Cells', 'Humans', 'Hydrogels', 'Nanoparticles']</td>
      <td>28323099</td>
      <td>[['D27.505.954.248'], ['G04.161.750', 'G07.345.249.410.750'], ['G04.346'], ['D27.720.470.410.210'], ['D01.248.497.158.874.390.369', 'D01.875.350.850.150.369', 'D02.886.030.230.369', 'D02.886.520.150.087', 'D12.125.095.369', 'D12.125.119.369', 'D12.125.166.230.369'], ['D02.455.426.559.847.562.050.200.175', 'D04.615.562.050.200.175', 'D09.408.051.059.200.175'], ['D26.255.260', 'E02.319.300.380'], ['G02.211', 'G03.787.321', 'G07.690.725.321'], ['A11.251.210.190.400', 'A11.251.860.180.400', 'A11.436.340'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['D20.280.320.375', 'D26.255.165.320.375'], ['J01.637.512.600']]</td>
      <td>['Chemicals and Drugs [D]', 'Phenomena and Processes [G]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Anatomy [A]', 'Organisms [B]', 'Technology, Industry, and Agriculture [J]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>A new &lt;i&gt;Panolis&lt;/i&gt; H?bner, [1821] species from Vietnam (Lepidoptera, Noctuidae, Orthosiini).</td>
      <td>Panolis is a well-defined and compact Palearctic trifine Noctuidae genus within the subfamily Hadeninae, tribus Orthosiini. It is currently represented by seven species and one subspecies: Panolis flammea ([Denis &amp; Schifferm?ller], 1775), Panolis japonica Draudt, 1935, Panolis variegatoides Poole, 1989, Panolis exquisita Draudt, 1950, Panolis pinicortex Draudt, 1950, Panolis pinicortex exornata Hreblay &amp; Ronkay, 1997, Panolis estheri Ronkay, Ronkay, Gyulai &amp; Hacker, 2010 and Panolis ningshan Wang, Fan, Owada, Wang &amp; Nylin, 2014. Only one species (P. flammea) occurs in the Western Palearctic region, while all others are found in the eastern part of Asia. No Panolis species is known outside of the Palearctic region. The genus is connected to coniferous woodlands as the larvae are feed on various species of pines. Imagoes are on the wing during the spring, from late February until May. All Panolis species have an unmistakable, rather decorative external appearance with fine and conspicuous pink-red-purple or dark orange ground colouration, and remarkable noctuid patterns. Most recent information about the genus was provided by Wang et. al, 2014, including his description of a new species, and a morphological and molecular analysis in order to reconstructing the phylogeny of the genus, and exploring its Chines Oriental origin. Present paper contains the description of a new Panolis species found recently in Vietnam, from where the genus was not known so far. This discovery expands our knowledge about Panolis and support the statement of the Chines Oriental origin.</td>
      <td>['Animal Distribution', 'Animals', 'Asia', 'Larva', 'Moths', 'Vietnam']</td>
      <td>28609947</td>
      <td>[['F01.145.113.069', 'G16.049'], ['B01.050'], ['Z01.252'], ['B05.500.500', 'G07.345.500.550.500.500'], ['B01.050.500.131.617.720.500.500.937.650'], ['Z01.252.145.945']]</td>
      <td>['Psychiatry and Psychology [F]', 'Phenomena and Processes [G]', 'Organisms [B]', 'Geographicals [Z]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Characterization of neutron field in a NPP workplace.</td>
      <td>At the Krsko Nuclear Power Plant (NPP), albedo dosimeters are used for personal neutron dosimetry. Spectrometric measurements allow determination of reference dosimetric values of realistic neutron fields to be used for calibration of albedo dosimeters. The Laboratory for Neutron Metrology and Dosimetry from the Institute for Radiological Protection and Nuclear Safety (IRSN) was in charge of characterising neutron fields in the plant at two representative points with high neutron and gamma dose rate. Calibration of the dosimeters in the workplace used to be performed only by a spherical survey meter. Based on the reference dosimetric values, the Plant Dosimetry Laboratory has verified the response of albedo dosimeters.</td>
      <td>['Algorithms', 'Equipment Design', 'Equipment Failure Analysis', 'France', 'Internationality', 'Occupational Exposure', 'Power Plants', 'Radiation Dosage', 'Radiation Monitoring', 'Radiation Protection', 'Reproducibility of Results', 'Sensitivity and Specificity']</td>
      <td>17416593</td>
      <td>[['G17.035', 'L01.224.050'], ['E05.320'], ['E05.325.192'], ['Z01.542.286'], ['I01.615'], ['N06.850.460.350.600'], ['J01.780', 'J03.540.680'], ['E05.799.513', 'G01.750.740', 'N06.850.810.250'], ['E05.799.638', 'N06.850.780.375.700', 'N06.850.810.370'], ['N06.850.810.425'], ['E05.318.370.725', 'E05.337.851', 'N05.715.360.325.685', 'N06.850.520.445.725'], ['E05.318.370.800', 'E05.318.740.872', 'G17.800', 'N05.715.360.325.700', 'N05.715.360.750.725', 'N06.850.520.445.800', 'N06.850.520.830.872']]</td>
      <td>['Phenomena and Processes [G]', 'Information Science [L]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Geographicals [Z]', 'Anthropology, Education, Sociology, and Social Phenomena [I]', 'Health Care [N]', 'Technology, Industry, and Agriculture [J]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>49993</th>
      <td>Influence of SLCO1B1 and CYP2C8 gene polymorphisms on rosiglitazone pharmacokinetics in healthy volunteers.</td>
      <td>Polymorphisms in drug transporter genes and/or drug-metabolising enzyme genes may contribute to inter-individual variability in rosiglitazone pharmacokinetics in humans. We sought to determine the joint effects of polymorphisms in the SLCO1B1 drug transporter gene and the cytochrome P450 ( CYP ) 2C8-metabolising enzyme gene on rosiglitazone pharmacokinetics in healthy volunteers. Healthy Caucasian subjects were prospectively enrolled on the basis of SLCO1B1 521 T &gt; C genotype. Additionally, subjects were genotyped for SLCO1B1 -11187 G &gt; A, -10499 A &gt; C and 388 A &gt; G polymorphisms, and the CYP2C8*3 polymorphism. SLCO1B1 haplotypes and diplotypes were computationally assigned. Rosiglitazone plasma concentrations were determined by high-performance liquid chromatography and analysed using non-compartmental methods. The study population consisted of 26 subjects, with a mean age of 33 +/- 9 years, and a mean weight of 66.6 +/- 11.7 kg. There were no significant differences in rosiglitazone pharmacokinetic parameters between SLCO1B1 diplotype groups. Subjects with the CYP2C8*1/*3 genotype ( n = 7), however, had significantly lower rosiglitazone area under the plasma concentration-time curve (AUC) and significantly higher rosiglitazone oral clearance, compared with CYP2C8 wild-type homozygotes ( n = 19). Stepwise linear regression analysis revealed that CYP2C8 genotype ( p = 0.006) and weight ( p = 0.022) were significant predictors of rosiglitazone AUC (overall p = 0.002; R 2 = 41.6 per cent). We concluded that polymorphisms in the CYP2C8 drug-metabolising enzyme gene, but not the SLCO1B1 drug transporter gene, significantly influence rosiglitazone disposition in humans. Future studies examining the influence of CYP2C8 genotypes and haplotypes on thiazolidinedione disposition and response in patients with type 2 diabetes are warranted.</td>
      <td>['Adolescent', 'Adult', 'Area Under Curve', 'Aryl Hydrocarbon Hydroxylases', 'Cytochrome P-450 CYP2C8', 'Female', 'Genotype', 'Health', 'Humans', 'Liver-Specific Organic Anion Transporter 1', 'Male', 'Middle Aged', 'Organic Anion Transporters', 'Polymorphism, Genetic', 'Rosiglitazone', 'Thiazolidinediones', 'Time Factors']</td>
      <td>19129086</td>
      <td>[['M01.060.057'], ['M01.060.116'], ['E05.318.740.200', 'G03.787.101', 'G07.690.725.064', 'N06.850.520.830.200'], ['D08.244.453.005', 'D08.811.682.690.708.170.010', 'D12.776.422.220.453.010'], ['D08.244.453.005.590', 'D08.244.453.491.368', 'D08.811.682.690.708.170.010.590', 'D08.811.682.690.708.170.450.360', 'D12.776.422.220.453.010.590', 'D12.776.422.220.453.491.360'], ['G05.380'], ['N01.400'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['D12.776.157.530.450.074.500.781.500', 'D12.776.157.530.937.580', 'D12.776.543.585.450.074.500.875.500', 'D12.776.543.585.937.901'], ['M01.060.116.630'], ['D12.776.157.530.450.074.500', 'D12.776.543.585.450.074.500'], ['G05.365.795'], ['D02.886.675.933.500', 'D03.383.129.708.933.500'], ['D02.886.675.933', 'D03.383.129.708.933'], ['G01.910.857']]</td>
      <td>['Named Groups [M]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Phenomena and Processes [G]', 'Health Care [N]', 'Chemicals and Drugs [D]', 'Organisms [B]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49994</th>
      <td>Active growth factor delivery from poly(D,L-lactide-co-glycolide) foams prepared in supercritical CO(2).</td>
      <td>A method for the production of microporous poly(D, L-lactide-co-glycolide) foams containing encapsulated proteins using supercritical carbon dioxide is described. Foams generated as aqueous protein emulsions in a polymer-solvent solution were saturated with carbon dioxide at supercritical conditions, and then suddenly supersaturated at ambient conditions causing bubble nucleation and precipitation of the polymer. Proteins contained in the water phase of the emulsion were encapsulated within the foams, including basic fibroblast growth factor (bFGF), an angiogenic factor of interest in tissue engineering applications. The release and activity of bFGF from these foams was determined in vitro and compared with similar porous scaffolds prepared by traditional solvent casting-salt leaching techniques. Total protein release rate was greater from structures made in CO(2) than those made by the salt leaching technique, however a large initial burst of bFGF was released from the salt leached structures. This initial burst was not observed from the polymer foams processed in CO(2) and active bFGF was released at a relatively constant rate. Residual methylene chloride levels were measured in the foams made with CO(2) and were found to be above the limits imposed by the US Pharmacopoeia implying that further solvent removal would be required prior to in vivo use.</td>
      <td>['Animals', 'Biocompatible Materials', 'Carbon Dioxide', 'Cattle', 'Cold Temperature', 'Drug Carriers', 'Drug Delivery Systems', 'Fibroblast Growth Factor 2', 'Growth Substances', 'Lactic Acid', 'Methylene Chloride', 'Microscopy, Electron, Scanning', 'Polyglycolic Acid', 'Polylactic Acid-Polyglycolic Acid Copolymer', 'Polymers', 'Solutions']</td>
      <td>10742578</td>
      <td>[['B01.050'], ['D25.130', 'D27.720.102.130', 'J01.637.051.130'], ['D01.200.200', 'D01.362.150', 'D01.650.550.200'], ['B01.050.150.900.649.313.500.380.271'], ['G01.906.595.272', 'G16.500.275.063.725.710.300', 'G16.500.750.775.710.300', 'N06.230.300.100.725.154', 'N06.230.300.100.725.710.300'], ['D26.255.260', 'E02.319.300.380'], ['E02.319.300'], ['D12.644.276.624.120', 'D12.776.467.624.120', 'D23.529.624.120'], ['D27.505.696.377'], ['D02.241.511.459.450'], ['D02.455.526.439.642'], ['E01.370.350.515.402.541', 'E05.595.402.541'], ['D05.750.728.780', 'D25.720.728.780', 'J01.637.051.720.728.780'], ['D02.241.511.459.450.500', 'D05.750.728.780.500', 'D25.720.728.780.500', 'J01.637.051.720.728.780.500'], ['D05.750', 'D25.720', 'J01.637.051.720'], ['D26.776']]</td>
      <td>['Organisms [B]', 'Chemicals and Drugs [D]', 'Technology, Industry, and Agriculture [J]', 'Phenomena and Processes [G]', 'Health Care [N]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49995</th>
      <td>Five donors-one recipient: modeling a mosaic of granulocytes, natural killer and T cells from cord-blood and third-party donors.</td>
      <td>BACKGROUND: A 21-year-old man was admitted to hospital because of leukocytosis, thrombocytopenia and anemia. The patient had been in good health until a few days earlier, when he developed fever and night sweats and his performance status dramatically declined.INVESTIGATIONS: Laboratory tests, immunophenotyping, cytogenetic analyses, bone-marrow biopsy, minimal residual disease analysis using quantitative real-time polymerase chain reaction, differential chimerism analysis using flow cytometry, mixed chimerism analysis, CT scans, electro-encephalography, cerebral magnetic resonance tomography.DIAGNOSIS: Bcr-abl-positive and Philadelphia-chromosome-positive acute lymphoblastic leukemia, and primary graft failure complicated by invasive fungal infection and cytomegalovirus encephalitis.MANAGEMENT: Double cord-blood rescue transplantation, third-party CD34-positive stem-cell rescue transplantation, third-party cytomegalovirus-specific T lymphocyte transplantation.</td>
      <td>['Adult', 'Cell Transplantation', 'Cord Blood Stem Cell Transplantation', 'Granulocytes', 'Humans', 'Killer Cells, Natural', 'Male', 'Mosaicism', 'Precursor Cell Lymphoblastic Leukemia-Lymphoma', 'T-Lymphocytes']</td>
      <td>18364724</td>
      <td>[['M01.060.116'], ['E02.095.147.500', 'E04.936.225'], ['E02.095.147.500.500.312', 'E04.936.225.687.312'], ['A11.118.637.415', 'A11.148.350', 'A11.627.340', 'A15.145.229.637.415', 'A15.378.316.340', 'A15.382.490.315'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['A11.118.637.555.567.537', 'A15.145.229.637.555.567.537', 'A15.382.490.555.567.537'], ['G05.365.590.175.595'], ['C04.557.337.428.600', 'C15.604.515.560.600', 'C20.683.515.528.600'], ['A11.118.637.555.567.569', 'A15.145.229.637.555.567.569', 'A15.382.490.555.567.569']]</td>
      <td>['Named Groups [M]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Anatomy [A]', 'Organisms [B]', 'Phenomena and Processes [G]', 'Diseases [C]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49996</th>
      <td>The role of eicosanoids in cyclosporine nephrotoxicity in the rat.</td>
      <td>Nephrotoxicity is the most troublesome complication of cyclosporine (CSA) therapy. The present study was designed to investigate the effects of chronic treatment with CSA on the 24-hr urinary excretion of prostanoids (PGs) and thromboxane (Tx) and on the renal function in the absence or presence of indomethacin. CSA administration to Wistar rats (20 mg/kg/day, i.p.) for 14 days caused a significant increase in plasma creatinine, blood urea nitrogen (BUN), urine osmolality, fractional excretion of sodium and potassium and a reduction in creatinine clearance (CCr) and urine volume. These changes were associated with a significant reduction in urinary excretion of PGE2 (21.1 +/- 3.3 vs 33.0 +/- 2.5 ng/24 hr) and PGF2 alpha (13.4 +/- 1.4 vs 27.9 +/- 3.8 ng/24 hr) and an increase in TxB2 (12.1 +/- 3.0 vs 4.6 +/- 0.5 ng/24 hr), and 6-keto PGF1 alpha (56.2 +/- 7.7 vs 27.7 +/- 1.9 ng/24 hr). However, the synthesis of TxB2 and 6-keto PGF1 alpha by renal medullary and cortical slices prepared from CSA treated rats was not different from values obtained for vehicle treatment. In contrast, PGE2 synthesis by cortical slices prepared from the CSA group was increased. A single injection of indomethacin (10 mg/kg) to vehicle and CSA treated rats resulted in a significant reduction in PGs and TxB2 excretion. This, was associated with a further reduction in CCr (0.81 +/- 0.06 vs 1.03 +/- 0.04 ml/min) and an increase in BUN (38.5 +/- 5.2 vs 28.2 +/- 1.4 mg%) only in the CSA group. We suggest that the vasodilating PGs attenuate the renal toxic effects induced by CSA.</td>
      <td>['Animals', 'Cyclosporins', 'In Vitro Techniques', 'Kidney', 'Kidney Cortex', 'Kidney Medulla', 'Male', 'Prostaglandins', 'Rats', 'Rats, Inbred Strains', 'Reference Values', 'Thromboxane B2']</td>
      <td>2735953</td>
      <td>[['B01.050'], ['D04.345.566.235', 'D12.644.641.235'], ['E05.481'], ['A05.810.453'], ['A05.810.453.324'], ['A05.810.453.466'], ['D10.251.355.255.550', 'D23.469.050.175.725'], ['B01.050.150.900.649.313.992.635.505.700'], ['B01.050.050.199.520.760', 'B01.050.150.900.649.313.992.635.505.700.400'], ['E05.978.810'], ['D10.251.355.255.100.825.810', 'D10.251.355.310.166.971.810']]</td>
      <td>['Organisms [B]', 'Chemicals and Drugs [D]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Anatomy [A]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49997</th>
      <td>Impact of pancreaticoduodenal arcade dilation on postoperative outcomes after pancreaticoduodenectomy.</td>
      <td>BACKGROUND: The aim of this study was to investigate the impact of pancreaticoduodenal arcade (PDA) dilation on postoperative outcomes after pancreaticoduodenectomy.METHODS: Consecutive patients submitted to pancreaticoduodenectomy between 2008 and 2016 underwent preoperative multi-detector computed tomography, the images of which were re-reviewed. The patients were categorized according to the grade of PDA dilation into 3 groups (remarkably-dilated, slightly-dilated, and non-dilated).RESULTS: Among the 443 patients, 25 patients (5.6%) were categorized as remarkably-dilated PDA and 24 patients (5.4%) as having slightly-dilated PDA. The patients with remarkably-dilated PDA had undergone pancreaticoduodenectomy with additional surgical maneuvers to restore celiac arterial flow as needed, and had an uneventful postoperative recovery relative to those with non-dilated PDA. In contrast, patients with slightly-dilated PDA underwent only pancreaticoduodenectomy without additional surgical maneuvers, and developed clinically relevant postoperative pancreatic fistula (POPF) more frequently than those with non-dilated PDA (42% vs. 21%, P = 0.021). Moreover, slightly-dilated PDA was shown to be an independent risk factor for clinically relevant POPF (odds ratio = 2.719, P = 0.042).DISCUSSION: For patients with PDA dilation requiring pancreaticoduodenectomy, a preoperative evaluation of the vascular anatomy, intraoperative assessment of the celiac arterial flow, and additional surgical maneuvers might be necessary to reduce the risk of postoperative complications.</td>
      <td>['Adult', 'Aged', 'Aged, 80 and over', 'Dilatation, Pathologic', 'Duodenum', 'Female', 'Humans', 'Male', 'Middle Aged', 'Pancreas', 'Pancreatic Neoplasms', 'Pancreaticoduodenectomy', 'Postoperative Complications', 'Retrospective Studies', 'Tomography, X-Ray Computed', 'Young Adult']</td>
      <td>28919282</td>
      <td>[['M01.060.116'], ['M01.060.116.100'], ['M01.060.116.100.080'], ['C23.300.325'], ['A03.556.124.684.124', 'A03.556.875.249'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['M01.060.116.630'], ['A03.734'], ['C04.588.274.761', 'C04.588.322.475', 'C06.301.761', 'C06.689.667', 'C19.344.421'], ['E04.210.760'], ['C23.550.767'], ['E05.318.372.500.500.500', 'E05.318.372.500.750.750', 'N05.715.360.330.500.500.500', 'N05.715.360.330.500.750.825', 'N06.850.520.450.500.500.500', 'N06.850.520.450.500.750.825'], ['E01.370.350.350.810', 'E01.370.350.600.350.700.810', 'E01.370.350.700.700.810', 'E01.370.350.700.810.810', 'E01.370.350.825.810.810'], ['M01.060.116.815']]</td>
      <td>['Named Groups [M]', 'Diseases [C]', 'Anatomy [A]', 'Organisms [B]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Health Care [N]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49998</th>
      <td>Outcomes of Preterm Infants following Discussions about Withdrawal or Withholding of Life Support.</td>
      <td>OBJECTIVES: To describe the frequency of postnatal discussions about withdrawal or withholding of life-sustaining therapy (WWLST), ensuing WWLST, and outcomes of infants surviving such discussions. We hypothesized that such survivors have poor outcomes.STUDY DESIGN: This retrospective review included registry data from 18 centers of the National Institute of Child Health and Human Development Neonatal Research Network. Infants born at 22-28 weeks of gestation who survived &gt;12 hours during 2011-2013 were included. Regression analysis identified maternal and infant factors associated with WWLST discussions and factors predicting ensuing WWLST. In-hospital and 18- to 26-month outcomes were evaluated.RESULTS: WWLST discussions occurred in 529 (15.4%) of 3434 infants. These were more frequent at 22-24 weeks (27.0%) compared with 27-28 weeks of gestation (5.6%). Factors associated with WWLST discussion were male sex, gestational age (GA) of ?24 weeks, birth weight small for GA, congenital malformations or syndromes, early onset sepsis, severe brain injury, and necrotizing enterocolitis. Rates of WWLST discussion varied by center (6.4%-29.9%) as did WWLST (5.2%-20.7%). Ensuing WWLST occurred in 406 patients; of these, 5 survived to discharge. Of the 123 infants for whom intensive care was continued, 58 (47%) survived to discharge. Survival after WWLST discussion was associated with higher rates of neonatal morbidities and neurodevelopmental impairment compared with babies for whom WWLST discussions did not occur. Significant predictors of ensuing WWLST were maternal age &gt;25 years, necrotizing enterocolitis, and days on a ventilator.CONCLUSIONS: Wide center variations in WWLST discussions occur, especially at ?24 weeks GA. Outcomes of infants surviving after WWLST discussions are poor.TRIAL REGISTRATION: ClinicalTrials.gov: NCT00063063.</td>
      <td>['Decision Making', 'Female', 'Humans', 'Infant', 'Infant Mortality', 'Infant, Newborn', 'Infant, Premature', 'Life Support Care', 'Male', 'Morbidity', 'Outcome Assessment, Health Care', 'Registries', 'Retrospective Studies', 'Survival Rate', 'Withholding Treatment']</td>
      <td>28647272</td>
      <td>[['F02.463.785.373'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['M01.060.703'], ['E05.318.308.985.550.475', 'N01.224.935.698.489', 'N06.850.505.400.975.550.475', 'N06.850.520.308.985.550.475'], ['M01.060.703.520'], ['M01.060.703.520.520'], ['E02.760.440', 'N02.421.585.440'], ['E05.318.308.985.525', 'N01.224.935.597', 'N06.850.505.400.975.525', 'N06.850.520.308.985.525'], ['H01.770.644.145.431', 'N04.761.559.590', 'N05.715.360.575.575'], ['E05.318.308.970', 'N04.452.859.819', 'N05.715.360.300.715.700', 'N06.850.520.308.970'], ['E05.318.372.500.500.500', 'E05.318.372.500.750.750', 'N05.715.360.330.500.500.500', 'N05.715.360.330.500.750.825', 'N06.850.520.450.500.500.500', 'N06.850.520.450.500.750.825'], ['E05.318.308.985.550.900', 'N01.224.935.698.826', 'N06.850.505.400.975.550.900', 'N06.850.520.308.985.550.900'], ['E02.760.952', 'N02.421.585.952']]</td>
      <td>['Psychiatry and Psychology [F]', 'Organisms [B]', 'Named Groups [M]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Health Care [N]', 'Disciplines and Occupations [H]']</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49999</th>
      <td>Molecular subtyping of Borrelia burgdorferi sensu lato isolates from five patients with solitary lymphocytoma.</td>
      <td>Solitary lymphocytoma is a rare cutaneous manifestation of Lyme borreliosis that has been reported almost exclusively from Europe. This suggests that its etiologic agent may be absent or extremely rare on the North American continent. All three species of B. burgdorferi sensu lato known to be associated with human Lyme borreliosis (B. burgdorferi sensu stricto, B. garinii, and B. afzelii have been isolated in Europe, whereas only B. burgdorferi sensu stricto has been found in North America. This suggests that either B. garinii or B. afzelii might be the etiologic agent of borrelial lymphocytoma. To investigate this hypothesis we characterized five strains of B. burgdorferi sensu lato isolated from lymphocytoma lesions of patients residing in Slovenia. The methods used included: large restriction fragment pattern analysis of restriction enzyme MluI-digested genomic DNA, plasmid profiling, protein profiling, ribotyping using 5S, 16S, and 23S rDNA probes, and polymerase chain reaction amplification of the rrf (5S)-rrl (23S) intergenic spacer region. Molecular subtyping showed that four of the five isolates belonged to the species B. afzelii; however, this species is the predominant patient isolate in Slovenia and, therefore, may not represent a preferential association with lymphocytoma. The fifth isolate appeared to be most closely related to the DN127 genomic group of organisms. Further characterization of the isolate revealed that it possessed a unique molecular "fingerprint." The results not only show that borrelial lymphocytoma can be caused by B. afzelii but also demonstrate an association with another genomic group of B. burgdorferi sensu lato that is present in North America as well.</td>
      <td>['Adult', 'Aged', 'Antigens, Surface', 'Bacterial Outer Membrane Proteins', 'Bacterial Vaccines', 'Biopsy', 'Borrelia burgdorferi Group', 'DNA Primers', 'DNA, Bacterial', 'Electrophoresis, Gel, Pulsed-Field', 'Electrophoresis, Polyacrylamide Gel', 'Europe', 'Female', 'Gene Amplification', 'Humans', 'Leukemia, Lymphocytic, Chronic, B-Cell', 'Lipoproteins', 'Lyme Disease', 'Middle Aged', 'Polymerase Chain Reaction', 'Restriction Mapping', 'Skin', 'Skin Neoplasms', 'Sodium Dodecyl Sulfate']</td>
      <td>8980295</td>
      <td>[['M01.060.116'], ['M01.060.116.100'], ['D23.050.301'], ['D12.776.097.120', 'D12.776.543.100'], ['D20.215.894.135'], ['E01.370.225.500.384.100', 'E01.370.225.998.054', 'E01.370.388.100', 'E04.074', 'E05.200.500.384.100', 'E05.200.998.054', 'E05.242.384.100'], ['B03.440.425.410.711.193.150', 'B03.851.595.193.150'], ['D13.695.578.424.450.275', 'D27.720.470.530.600.223.600'], ['D13.444.308.212'], ['E05.196.401.220', 'E05.301.300.220'], ['E05.196.401.402', 'E05.301.300.319'], ['Z01.542'], ['G05.308.250', 'G05.365.590.310', 'G05.558.315'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['C04.557.337.428.080.125', 'C15.604.515.560.080.125', 'C20.683.515.528.080.125'], ['D10.532', 'D12.776.521'], ['C01.150.252.400.536', 'C01.150.252.400.794.352.250', 'C01.920.930.513'], ['M01.060.116.630'], ['E05.393.620.500'], ['E05.393.183.620.650', 'E05.393.712'], ['A17.815'], ['C04.588.805', 'C17.800.882'], ['D02.033.415.220.720', 'D02.886.645.600.055.050.632', 'D10.289.220.720']]</td>
      <td>['Named Groups [M]', 'Chemicals and Drugs [D]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Organisms [B]', 'Geographicals [Z]', 'Phenomena and Processes [G]', 'Diseases [C]', 'Anatomy [A]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>50000 rows × 20 columns</p>
      
          <p>mesh_roots (Series):</p>
          <pre><code>0        [Chemicals and Drugs [D], Organisms [B], Analy...
1        [Named Groups [M], Chemicals and Drugs [D], Ps...
2        [Phenomena and Processes [G], Information Scie...
3        [Chemicals and Drugs [D], Technology, Industry...
4        [Chemicals and Drugs [D], Phenomena and Proces...
                               ...                        
49995    [Named Groups [M], Analytical, Diagnostic and ...
49996    [Organisms [B], Chemicals and Drugs [D], Analy...
49997    [Named Groups [M], Diseases [C], Anatomy [A], ...
49998    [Psychiatry and Psychology [F], Organisms [B],...
49999    [Named Groups [M], Chemicals and Drugs [D], An...
Name: meshroot, Length: 50000, dtype: object</code></pre>
      
          <p>unique_mesh_roots (set):</p>
          <pre><code>{'Technology, Industry, and Agriculture [J]', 'Phenomena and Processes [G]', 'Geographicals [Z]', 'Humanities [K]', 'Chemicals and Drugs [D]', 'Anthropology, Education, Sociology, and Social Phenomena [I]', 'Anatomy [A]', 'Diseases [C]', 'Disciplines and Occupations [H]', 'Information Science [L]', 'Organisms [B]', 'Psychiatry and Psychology [F]', 'Named Groups [M]', 'Health Care [N]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]'}</code></pre>
      
          <p>mesh_roots_list (list):</p>
          <pre><code>['Named Groups [M]', 'Chemicals and Drugs [D]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]', 'Organisms [B]', 'Geographicals [Z]', 'Phenomena and Processes [G]', 'Diseases [C]', 'Anatomy [A]']</code></pre>
      
          <p>root (str):</p>
          <pre><code>Anatomy [A]</code></pre>
      
          <p>mesh_root (str):</p>
          <pre><code>Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]</code></pre>
      
          <p>root_name (str):</p>
          <pre><code>Analytical, Diagnostic and Therapeutic Techniques, and Equipment</code></pre>
      
          <p>letter_id (str):</p>
          <pre><code>E</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('df', 'df', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.09090909090909091, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> pubmed-multilabel-text-classification/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show a dataframe that has the number of articles for each mesh root.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>counts = []
for column in df.columns[6:]:
  counts.append((column, df[column].sum()))
pd.DataFrame(counts, columns=['Mesh Root', 'Number of Articles'])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>counts = []
for column in df.columns[6:]:
  counts.append((column, df[column].sum()))
pd.DataFrame(counts, columns=['Mesh Root', 'Number of Articles'])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>counts = []
for column in df.columns[6:]:
    counts.append((column, df[column].sum()))
__output__ = pd.DataFrame(counts, columns=['Mesh Root', 'Number of Articles'])
</code></pre>
        <p><span onclick="$('#var_output_d2a52054').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d2a52054" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Mesh Root</th>
      <th>Number of Articles</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Anatomy</td>
      <td>23263</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Organisms</td>
      <td>46577</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Diseases</td>
      <td>26453</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Chemicals and Drugs</td>
      <td>31074</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Analytical, Diagnostic and Therapeutic Techniques, and Equipment</td>
      <td>39202</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Psychiatry and Psychology</td>
      <td>8885</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Phenomena and Processes</td>
      <td>33609</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Disciplines and Occupations</td>
      <td>6069</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Anthropology, Education, Sociology, and Social Phenomena</td>
      <td>5595</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Technology, Industry, and Agriculture</td>
      <td>5531</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Information Science</td>
      <td>7503</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Named Groups</td>
      <td>21363</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Health Care</td>
      <td>22919</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Geographicals</td>
      <td>8049</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> counts, column, __output__ </p>
    
          <p>counts (list):</p>
          <pre><code>[('Anatomy', 23263), ('Organisms', 46577), ('Diseases', 26453), ('Chemicals and Drugs', 31074), ('Analytical, Diagnostic and Therapeutic Techniques, and Equipment', 39202), ('Psychiatry and Psychology', 8885), ('Phenomena and Processes', 33609), ('Disciplines and Occupations', 6069), ('Anthropology, Education, Sociology, and Social Phenomena', 5595), ('Technology, Industry, and Agriculture', 5531), ('Information Science', 7503), ('Named Groups', 21363), ('Health Care', 22919), ('Geographicals', 8049)]</code></pre>
      
          <p>column (str):</p>
          <pre><code>Geographicals</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Mesh Root</th>
      <th>Number of Articles</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Anatomy</td>
      <td>23263</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Organisms</td>
      <td>46577</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Diseases</td>
      <td>26453</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Chemicals and Drugs</td>
      <td>31074</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Analytical, Diagnostic and Therapeutic Techniques, and Equipment</td>
      <td>39202</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Psychiatry and Psychology</td>
      <td>8885</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Phenomena and Processes</td>
      <td>33609</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Disciplines and Occupations</td>
      <td>6069</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Anthropology, Education, Sociology, and Social Phenomena</td>
      <td>5595</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Technology, Industry, and Agriculture</td>
      <td>5531</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Information Science</td>
      <td>7503</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Named Groups</td>
      <td>21363</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Health Care</td>
      <td>22919</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Geographicals</td>
      <td>8049</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> pubmed-multilabel-text-classification/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average word count of abstracts rounding to the nearest integer?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>round(df.abstractText.str.split().str.len().mean(),0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>round(df.abstractText.str.split().str.len().mean(),0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = round(df.abstractText.str.split().str.len().mean(), 0)
</code></pre>
        <p><span onclick="$('#var_output_063f5c25').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_063f5c25" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>192.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>192.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>
<h3 style="color:red">Execution process crashed.</h3>
<p>Execution process for episode [pubmed-multilabel-text-classification/notebook_1.ipynb|||turn_3] crashed with EOF error. Retrying...</p>


        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> pubmed-multilabel-text-classification/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average length of their abstract?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.iloc[diseases_healthcare.index].abstractText.str.split().str.len().mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.iloc[diseases_healthcare.index].abstractText.str.split().str.len().mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.iloc[diseases_healthcare.index].abstractText.str.split(
    ).str.len().mean()
</code></pre>
        <p><span onclick="$('#var_output_2173e0ab').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2173e0ab" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>139.05555555555554</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>139.05555555555554</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> pubmed-multilabel-text-classification/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of articles that discuss aging and DNA?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>len(df[(df['meshMajor'].str.contains('DNA')) & (df['meshMajor'].str.contains('Aging'))])/len(df)*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>len(df[(df['meshMajor'].str.contains('DNA')) & (df['meshMajor'].str.contains('Aging'))])/len(df)*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = len(df[df['meshMajor'].str.contains('DNA') & df['meshMajor'].
    str.contains('Aging')]) / len(df) * 100
</code></pre>
        <p><span onclick="$('#var_output_93cf9255').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_93cf9255" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>0.054</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>0.054</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> pubmed-multilabel-text-classification/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the title of the longest abstract?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.iloc[df.abstractText.str.split().str.len().idxmax()][0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.iloc[df.abstractText.str.split().str.len().idxmax()][0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.iloc[df.abstractText.str.split().str.len().idxmax()][0]
</code></pre>
        <p><span onclick="$('#var_output_8d94fe95').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8d94fe95" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>A comparison of once-daily extended-release methylphenidate formulations in children with attention-deficit/hyperactivity disorder in the laboratory school (the Comacs Study).</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>A comparison of once-daily extended-release methylphenidate formulations in children with attention-deficit/hyperactivity disorder in the laboratory school (the Comacs Study).</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> pubmed-multilabel-text-classification/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the titles of the top five longest abstracts discussing information science and gerographcals</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.iloc[df[(df['Information Science']==1) & (df['Geographicals']==1)].abstractText.str.split().str.len().sort_values(ascending=False).head().index].Title</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.iloc[df[(df['Information Science']==1) & (df['Geographicals']==1)].abstractText.str.split().str.len().sort_values(ascending=False).head().index].Title</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.iloc[df[(df['Information Science'] == 1) & (df[
    'Geographicals'] == 1)].abstractText.str.split().str.len().sort_values(
    ascending=False).head().index].Title
</code></pre>
        <p><span onclick="$('#var_output_16fc5cb8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_16fc5cb8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>39796    Towards a HPC-oriented parallel implementation...
36005             Advanced reproductive age and fertility.
7033     Preapproval Information Exchange: Perspectives...
29264    How nursing leadership and management interven...
27872    Knowledge on legislation of abortion and exper...
Name: Title, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>39796    Towards a HPC-oriented parallel implementation...
36005             Advanced reproductive age and fertility.
7033     Preapproval Information Exchange: Perspectives...
29264    How nursing leadership and management interven...
27872    Knowledge on legislation of abortion and exper...
Name: Title, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> pubmed-multilabel-text-classification/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percentage of the articles that discuss one or two topics only?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>topic_columns=df.iloc[:,6:].sum(axis=1)
len(topic_columns[(topic_columns==1) | (topic_columns==2)])/len(df)*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>topic_columns=df.iloc[:,6:].sum(axis=1)
len(topic_columns[(topic_columns==1) | (topic_columns==2)])/len(df)*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>topic_columns = df.iloc[:, 6:].sum(axis=1)
__output__ = len(topic_columns[(topic_columns == 1) | (topic_columns == 2)]
    ) / len(df) * 100
</code></pre>
        <p><span onclick="$('#var_output_ce7f702a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ce7f702a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>1.202</code></pre>
      
        <p><strong>Hyp output variables:</strong> topic_columns, __output__ </p>
    
          <p>topic_columns (Series):</p>
          <pre><code>0         5
1        11
2         6
3         7
4         6
         ..
49995     6
49996     4
49997     6
49998     6
49999     8
Length: 50000, dtype: int64</code></pre>
      
          <p>__output__ (float):</p>
          <pre><code>1.202</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> pubmed-multilabel-text-classification/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many of these articles talk about Phenomena and Processes</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>new_df=df.loc[topic_columns[(topic_columns==1) | (topic_columns==2)].index]
len(new_df[new_df['Phenomena and Processes']==1])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>new_df=df.loc[topic_columns[(topic_columns==1) | (topic_columns==2)].index]
len(new_df[new_df['Phenomena and Processes']==1])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>new_df = df.loc[topic_columns[(topic_columns == 1) | (topic_columns == 2)].
    index]
__output__ = len(new_df[new_df['Phenomena and Processes'] == 1])
</code></pre>
        <p><span onclick="$('#var_output_5f1acd5b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5f1acd5b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>217</code></pre>
      
        <p><strong>Hyp output variables:</strong> new_df, __output__ </p>
    
          <p>new_df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Title</th>
      <th>abstractText</th>
      <th>meshMajor</th>
      <th>pmid</th>
      <th>meshid</th>
      <th>meshroot</th>
      <th>Anatomy</th>
      <th>...</th>
      <th>Disciplines and Occupations</th>
      <th>Anthropology, Education, Sociology, and Social Phenomena</th>
      <th>Technology, Industry, and Agriculture</th>
      <th>Information Science</th>
      <th>Named Groups</th>
      <th>Health Care</th>
      <th>Geographicals</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>42</th>
      <td>[Update on the diagnosis and therapy of blood-transmitted occupational infections].</td>
      <td>The Human Immunodeficiency Virus (HIV) infection, Hepatitis B Virus (HBV) infection and Hepatitis C Virus (HCV) infection are the most important blood borne occupational viral infection. Estimates of the prevalence of HIV infection in Italy is between 0.24 and 0.26%. The implementation of HIV screening strategies in the general population will decrease the proportion of patients with unknown HIV serostatus and the improvement of anti HIV therapie will decrease the proportion of HIV infected patients with detectable viraemia. The increate sensitivity of HBVDNA assays will prompt the definition of cut off levels for the definition of the infectivity of HBsAg positive health workers. The availability of highly effective and well tollerate oral antivirals could increase the proportion of treatable HBsAg positive health workers. The highly elevated success rates in the treatment of acute HCV infection will support strategies aimed at an early identification of occupational HCV infections. The tailoring of anti HCV schedules allows to optimize anti HCV treatment of health workers with chronic hepatitis C and the availability of new anti HCV will open an horizon of success in the treatment of chronic hepatitis C in health workers.</td>
      <td>['Blood-Borne Pathogens', 'Communicable Diseases', 'HIV Infections', 'Hepatitis B', 'Hepatitis C', 'Humans', 'Occupational Diseases']</td>
      <td>21061703</td>
      <td>[['B05.155'], ['C01.221', 'C23.550.291.531'], ['C01.221.250.875', 'C01.221.812.640.400', 'C01.778.640.400', 'C01.925.782.815.616.400', 'C01.925.813.400', 'C20.673.480'], ['C01.221.250.500', 'C01.925.256.430.400', 'C01.925.440.435', 'C06.552.380.705.437'], ['C01.221.250.750', 'C01.925.440.440', 'C01.925.782.350.350', 'C06.552.380.705.440'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['C24']]</td>
      <td>['Organisms [B]', 'Diseases [C]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>119</th>
      <td>How to Map Theory: Reliable Methods Are Fruitless Without Rigorous Theory.</td>
      <td>Good science requires both reliable methods and rigorous theory. Theory allows us to build a unified structure of knowledge, to connect the dots of individual studies and reveal the bigger picture. Some have criticized the proliferation of pet "Theories," but generic "theory" is essential to healthy science, because questions of theory are ultimately those of validity. Although reliable methods and rigorous theory are synergistic, Action Identification suggests psychological tension between them: The more we focus on methodological details, the less we notice the broader connections. Therefore, psychology needs to supplement training in methods (how to design studies and analyze data) with training in theory (how to connect studies and synthesize ideas). This article provides a technique for visually outlining theory: theory mapping. Theory mapping contains five elements, which are illustrated with moral judgment and with cars. Also included are 15 additional theory maps provided by experts in emotion, culture, priming, power, stress, ideology, morality, marketing, decision-making, and more (see all at theorymaps.org ). Theory mapping provides both precision and synthesis, which helps to resolve arguments, prevent redundancies, assess the theoretical contribution of papers, and evaluate the likelihood of surprising effects.</td>
      <td>['Cognition', 'Decision Making', 'Humans', 'Judgment', 'Knowledge', 'Morals', 'Psychological Theory', 'Thinking']</td>
      <td>28873328</td>
      <td>[['F02.463.188'], ['F02.463.785.373'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['F02.463.785.626'], ['K01.468'], ['F01.829.500', 'K01.752.566'], ['F02.739'], ['F02.463.785']]</td>
      <td>['Psychiatry and Psychology [F]', 'Organisms [B]', 'Humanities [K]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>206</th>
      <td>Scatterer reconstruction and parametrization of homogeneous tissue for ultrasound image simulation.</td>
      <td>Numerical simulation of ultrasound images can facilitate the training of sonographers. A realistic appearance of simulated ultrasonic speckle is essential for a plausible ultrasound simulation. An efficient and realistic model for ultrasonic speckle is the convolution of the ultrasound point-spread function with a parametrized distribution of point scatterers. Nevertheless, for a given arbitrary tissue, such scatterer distributions that would generate a realistic image are not known a priori, and currently there is no principled method to extract such scatterer patterns for given target tissues to be simulated. In this paper we propose to solve the inverse problem, in which an underlying scatterer map for a given sample ultrasound image is estimated. From such scatterer maps, it is also shown that a parametrization distribution model can be built, using which other instances of the same tissue can be simulated by feeding into a standard speckle generation method. This enables us to synthesize images of different tissue types from actual ultrasound images to be used in simulations with arbitrary view angles and transducer settings. We show in numerical and physical tissue-mimicking phantoms and actual physical tissue that the appearance of the synthesized images closely match the real images.</td>
      <td>['Computer Simulation', 'Image Processing, Computer-Assisted', 'Models, Biological', 'Phantoms, Imaging', 'Ultrasonography']</td>
      <td>26737745</td>
      <td>[['L01.224.160'], ['L01.224.308'], ['E05.599.395'], ['E07.671'], ['E01.370.350.850']]</td>
      <td>['Information Science [L]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>252</th>
      <td>The mechanism of inhibition by H2 of H2-evolution by hydrogenases.</td>
      <td>By analysing the results of experiments carried out with two FeFe hydrogenases and several "channel mutants" of a NiFe hydrogenase, we demonstrate that whether or not hydrogen evolution is significantly inhibited by H2 is not a consequence of active site chemistry, but rather relates to H2 transport within the enzyme.</td>
      <td>['Hydrogen', 'Hydrogenase', 'Iron-Sulfur Proteins', 'Models, Molecular']</td>
      <td>23792933</td>
      <td>[['D01.268.406', 'D01.362.340'], ['D08.811.682.400'], ['D12.776.157.427.374.375', 'D12.776.556.579.374.375'], ['E05.599.595']]</td>
      <td>['Chemicals and Drugs [D]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>335</th>
      <td>Fixed-interval behavior maintained by conditioned reinforcement.</td>
      <td>The key-pecking of a pigeon was reinforced with grain on an 18-min second-order schedule. During the 18 min, a key peck which completed a 3-min fixed interval produced a stimulus of 0.5-sec duration. The first 3-min fixed interval completed after 18 min resulted in primary reinforcement. Behavior characteristic of fixed-interval schedules was produced on both the 3-min components and the 18-min schedule. This performance was shown to be enhanced whenever the 0.5-sec stimulus was also presented before the presentation of grain.</td>
      <td>['Animals', 'Behavior, Animal', 'Columbidae', 'Conditioning, Psychological', 'Male', 'Reinforcement Schedule', 'Reinforcement, Psychology']</td>
      <td>6056800</td>
      <td>[['B01.050'], ['F01.145.113'], ['B01.050.150.900.248.165.150'], ['F02.463.425.179'], ['F02.463.425.770.644'], ['F02.463.425.770']]</td>
      <td>['Organisms [B]', 'Psychiatry and Psychology [F]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>444</th>
      <td>Synthesis, biological evaluation of 5-carbomethoxymethyl-7-hydroxy-2-pentylchromone, 5-carboethoxymethyl-4',7-dihydroxyflavone and their analogues.</td>
      <td>In this letter, we describe the first synthesis of two recently isolated flavones 5-carbomethoxymethyl-7-hydroxy-2-pentylchromone (3a), 5-carboethoxymethyl-4',7-dihydroxyflavone (3b) and their derivatives (3c-t), evaluated for their antimicrobial, antioxidant and anticancer activities. Most of the synthesized compounds exhibited antimicrobial activity against the tested microbial strains and some of these compounds were found to be more potent as compared to the standard drugs like neomycin and luteolin. Interestingly, some of these synthesized compounds also showed moderate antioxidant property.</td>
      <td>['Anti-Infective Agents', 'Antifungal Agents', 'Antioxidants', 'Chromones', 'Flavones', 'Flavonoids', 'Microbial Viability', 'Molecular Structure', 'Structure-Activity Relationship']</td>
      <td>22677320</td>
      <td>[['D27.505.954.122'], ['D27.505.954.122.136'], ['D27.505.519.217', 'D27.505.696.706.125', 'D27.720.799.047'], ['D03.383.663.283.266', 'D03.633.100.150.266'], ['D03.383.663.283.266.450.260', 'D03.633.100.150.266.450.260'], ['D03.383.663.283.266.450', 'D03.633.100.150.266.450'], ['G06.580'], ['G02.111.570', 'G02.466'], ['G02.111.830', 'G07.690.773.997']]</td>
      <td>['Chemicals and Drugs [D]', 'Phenomena and Processes [G]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>635</th>
      <td>A density functional investigation of the extradiol cleavage mechanism in non-heme iron catechol dioxygenases.</td>
      <td>The mechanism for extradiol cleavage in non-heme iron catechol dioxygenase was modelled theoretically via density functional theory. Based on the Fe(II)-His,His,Glu motif observed in enzymes, an active site model complex, [Fe(acetate)(imidazole)(2)(catecholate)(O(2))](-), was optimized for states with six, four and two unpaired electrons (U6, U4 and U2, respectively). The transfer of the terminal atom of the coordinated dioxygen leading to "ferryl" Fe=O intermediates spontaneously generates an extradiol epoxide. The computed barriers range from 19 kcal mol(-1) on the U6 surface to approximately 25 kcal mol(-1) on the U4 surface, with overall reaction energies of +11.6, 6.3 and 7.1 kcal mol(-1) for U6, U4 and U2, respectively. The calculations for a protonated process reveal the terminal oxygen of O(2) to be the thermodynamically favoured site but subsequent oxygen transfer to the catechol has a barrier of approximately 30-40 kcal mol(-1), depending on the spin state. Instead, protonating the acetate group gives a slightly higher energy species but a subsequent barrier on the U4 surface of only 7 kcal mol(-1) relative to the hydroperoxide complex. The overall exoergicity increases to 13 kcal mol(-1). The favoured proton-assisted pathway does not involve significant radical character and has features reminiscent of a Criegee rearrangement which involves the participation of the aromatic ring pi-orbitals in the formation of the new carbon-oxygen bond. The subsequent collapse of the epoxide, attack by the coordinated hydroxide and final product formation proceeds with an overall exoergicity of approximately 75 kcal mol(-1) on the U4 surface.</td>
      <td>['Catechols', 'Estradiol', 'Heme', 'Nonheme Iron Proteins', 'Oxygenases']</td>
      <td>12761662</td>
      <td>[['D02.455.426.559.389.657.166'], ['D04.210.500.365.415.248', 'D06.472.334.851.437.500'], ['D03.383.129.578.840.500.640.587', 'D03.633.400.909.500.640.587', 'D04.345.783.500.640.587', 'D23.767.727.640.587'], ['D12.776.157.427.374', 'D12.776.556.579.374'], ['D08.811.682.690']]</td>
      <td>['Chemicals and Drugs [D]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>49487</th>
      <td>Ensuring care quality at a time of diminishing resources.</td>
      <td>John Tingle, Reader in Health Law at Nottingham Trent University, discusses the Care Quality Commission's State of Health Care report, in the light of some important clinical negligence trends and reports on major safety failures.</td>
      <td>['Awards and Prizes', "Nurse's Role", 'Quality of Health Care']</td>
      <td>28079425</td>
      <td>[['K01.150'], ['F01.829.316.616.625.450', 'N05.300.100.337'], ['N04.761', 'N05.715']]</td>
      <td>['Humanities [K]', 'Psychiatry and Psychology [F]', 'Health Care [N]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49531</th>
      <td>[Histological and ultrastructural variations after radiofrequency for soft palate in porcines].</td>
      <td>PURPOSE: To investigate the histological and ultrastructural variations after radiofrequency volumetric reduction of the soft palate in an animal model.METHODS: Thirteen porcines were used to evaluate the tissue response to radiofrequency for various time periods. They were divided into two groups. Group 1 was exposed to radiofrequency in the midline of the soft palate with a constant energy of 2.4 KJ. Group 2 served as a control group. The animals in group 1 were sacrificed after 1 hour, 24 hours, 48 hours, 72 hours, 1 week, 2 weeks, 3 weeks, 4 weeks, 6 weeks and 9 weeks, respectively, and after 72 hours, 2 weeks and 4 weeks for the animals in group 2. Then the soft palates from both groups were examined for histological and ultrastructural variations.RESULTS: Interstitial edema, hemorrhage and infiltration with inflammatory cells were observed in the early acute stage after radiofrequency, and then the neovascularization of the forming scar was observed. In the end, the injured tissue was replaced by collagenous fibers. Intact vessels and nerves were observed around the lesions.CONCLUSIONS: After radiofrequency, lesion tissue is replaced by collagenous fibers, and it is focused on the lesion site. These findings may help provide a basis for technological suggestion in regard to clinical treatment.</td>
      <td>['Animals', 'Palate, Soft', 'Swine']</td>
      <td>15619700</td>
      <td>[['B01.050'], ['A14.549.617.780'], ['B01.050.150.900.649.313.500.880']]</td>
      <td>['Organisms [B]', 'Anatomy [A]']</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49546</th>
      <td>[Domestic animals and veterinary medicine in the Old and New Testaments of the Bible and the Apocrypha].</td>
      <td>Referring to an 1865 edition of the Bible, the article deals with domestic animals and veterinary matters in the sacred book of Christianity, singling out donkey, camel, horse, sheep, goat, pig, dog and cat. Comments on early aspects of animal welfare and food hygiene round off the picture.</td>
      <td>['Animals', 'Animals, Domestic', 'Bible', 'Christianity', 'History, 19th Century', 'History, Ancient', 'Veterinary Medicine']</td>
      <td>8457188</td>
      <td>[['B01.050'], ['B01.050.050.116'], ['K01.517.172'], ['K01.844.188'], ['K01.400.504.937'], ['K01.400.470'], ['H02.956']]</td>
      <td>['Organisms [B]', 'Humanities [K]', 'Disciplines and Occupations [H]']</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49589</th>
      <td>A robust GC-MS method for the quantitation of fatty acids in biological systems.</td>
      <td>Fatty acids (FAs) are involved in a wide range of functions in biological systems. It is important to measure the exact amount of fatty acids in biological matrices in order to determine the level of fatty acids and understand the role they play. The ability to quantify fatty acids in various systems, especially plant species and microbes has recently paved the way to the mass production of pharmaceuticals and energy substitutes including biodiesel. This chapter describes an efficient method to quantify the total fatty acids (TFAs) in biological systems using gas chromatography-mass spectrometry (GC-MS) and a commercially available standard mix of fatty acid methyl esters (FAMEs) using a step-by-step methodology to setup a quantitation method using the Agilent Chemstation software.</td>
      <td>['Fatty Acids', 'Gas Chromatography-Mass Spectrometry']</td>
      <td>23963902</td>
      <td>[['D10.251'], ['E05.196.181.349.500', 'E05.196.566.500']]</td>
      <td>['Chemicals and Drugs [D]', 'Analytical, Diagnostic and Therapeutic Techniques, and Equipment [E]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49627</th>
      <td>Telescoping is not time compression: a model of the dating of autobiographical events.</td>
      <td>A model of telescoping is proposed that assumes no systematic errors in dating. Rather, the overestimation of recent occurrences of events is based on the combination of three factors: (1) Retention is greater for recent events; (2) errors in dating, though unbiased, increase linearly with the time since the dated event; and (3) intrusions often occur from events outside the period being asked about, but such intrusions do not come from events that have not yet occurred. In Experiment 1, we found that recall for colloquia fell markedly over a 2-year interval, the magnitude of errors in psychologists' dating of the colloquia increased at a rate of .4 days per day of delay, and the direction of the dating error was toward the middle of the interval. In Experiment 2, the model used the retention function and dating errors from the first study to predict the distribution of the actual dates of colloquia recalled as being within a 5-month period. In Experiment 3, the findings of the first study were replicated with colloquia given by, instead of for, the subjects.</td>
      <td>['Attention', 'Humans', 'Judgment', 'Memory', 'Mental Recall', 'Time Perception']</td>
      <td>2811662</td>
      <td>[['F02.830.104.214'], ['B01.050.150.900.649.313.988.400.112.400.400'], ['F02.463.785.626'], ['F02.463.425.540'], ['F02.463.425.540.641'], ['F02.463.593.857']]</td>
      <td>['Psychiatry and Psychology [F]', 'Organisms [B]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49662</th>
      <td>CCK-A receptors mediate the effect of cholecystokinin on vasopressin but not on cortisol in pigs.</td>
      <td>Bolus intravenous injections of cholecystokinin (CCK) octapeptide induce a rapid rise in plasma vasopressin and a later increase in cortisol in the prepubertal pig. To determine whether these endocrine responses involve CCK-A or CCK-B receptors, this experiment investigated the effect of CCK (1 microgram/kg) in pigs (n = 7) pretreated with the CCK-A antagonist L 364718 (70 microgram/kg) or the CCK-B antagonist L 365260 (10 ng/kg and 10 micrograms/kg). The animals were prepared with jugular vein catheters and given the antagonist vehicle, L 364718, or L 365260 10 min before administration of CCK or saline. Analysis of hormone concentrations in blood samples taken 2, 5, 10, and 20 min after the second injection indicated that an abrupt rise in vasopressin, detectable within 2 min of CCK administration, occurred after vehicle or L 365260 pretreatment but not when CCK was preceded by L 364718. In contrast, the rise in plasma cortisol that was observed approximately 15 min after CCK injection was not prevented by either antagonist. Thus peripherally administered CCK induces vasopressin release by CCK-A receptor activation, in agreement with its inhibitory effect on food intake in this species. However, the effect of CCK on cortisol secretion does not appear to involve either CCK-A or CCK-B receptors.</td>
      <td>['Animals', 'Benzodiazepinones', 'Cholecystokinin', 'Devazepide', 'Female', 'Hydrocortisone', 'Lypressin', 'Male', 'Phenylurea Compounds', 'Receptors, Cholecystokinin', 'Swine', 'Vasopressins']</td>
      <td>1621871</td>
      <td>[['B01.050'], ['D03.633.100.079.080.070'], ['D06.472.317.152', 'D12.644.120'], ['D03.633.100.079.080.070.200'], ['D04.210.500.745.745.654.600', 'D06.472.040.585.353.476', 'D06.472.040.585.478.392'], ['D06.472.699.631.692.781.400', 'D12.644.400.900.400', 'D12.644.456.925.480', 'D12.644.548.691.692.781.400', 'D12.776.631.650.937.400'], ['D02.065.950.681', 'D02.455.426.559.389.703'], ['D12.776.543.750.695.170', 'D12.776.543.750.720.600.270', 'D12.776.543.750.750.360.200', 'D12.776.543.750.750.555.270'], ['B01.050.150.900.649.313.500.880'], ['D06.472.699.631.692.781', 'D12.644.400.900', 'D12.644.456.925', 'D12.644.548.691.692.781', 'D12.776.631.650.937']]</td>
      <td>['Organisms [B]', 'Chemicals and Drugs [D]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49760</th>
      <td>Mismatch repair in the antimutator Escherichia coli mud.</td>
      <td>Antimutators are genetic mutants that produce mutations at reduced rates compared to the wild type strain. They are interesting because they may provide insights into the mechanisms by which spontaneous mutations occur. We have investigated a reported antimutator strain of Escherichia coli termed mud for its possible mechanism. The mud strain exhibits a decrease in both spontaneous mutagenesis and mutability with alkylated agents and base analogs. These types of DNA lesions are known to be the substrates for the E. coli methyl-directed mismatch repair encoded by the mutHLSU system. We investigated whether the putative antimutator effect results from the increased expression or activity of the mutHLSU system. To directly measure the mismatch repair capacity of mud cells, we have transfected them with phage lambda heteroduplexes and scored the fraction of mixed (unrepaired) infective centers. This transfection system has been used routinely to assay mismatch repair capacity in E. coli and other organisms. No difference between mud and wild type cells is observed. From the results of the experiments we conclude that the reported antimutator effect of mud does not result from enhanced mismatch repair capacity. This conclusion is consistent with recently published evidence that the mud effect does not represent a real antimutator effect, but is an artifact due to impaired growth of mud cells under certain selective conditions.</td>
      <td>['Bacteriophage lambda', 'Base Pair Mismatch', 'DNA Repair', 'Escherichia coli', 'Genetic Vectors', 'Mutation', 'Transformation, Genetic']</td>
      <td>12517409</td>
      <td>[['B04.123.150.800.230', 'B04.123.205.230', 'B04.280.090.800.230'], ['G05.365.590.060'], ['G02.111.222', 'G05.219'], ['B03.440.450.425.325.300', 'B03.660.250.150.180.100'], ['G05.360.337'], ['G05.365.590'], ['G05.728.865']]</td>
      <td>['Organisms [B]', 'Phenomena and Processes [G]']</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>601 rows × 20 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>217</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> gameloft-android-games-collection-2022/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Calculate the numeric value of the game sizes in megabytes in a new column called "numeric_size". Replace variable size with NaN.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def string_count_to_numeric(x: str):
    if x[-1] == 'M':
        n = float(x[:-1])
    else:
        n = np.NaN
    return n

df_data['numeric_size'] = df_data['size'].apply(string_count_to_numeric)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def string_count_to_numeric(x: str):
    if x[-1] == 'M':
        n = float(x[:-1])
    else:
        n = np.NaN
    return n

df_data['numeric_size'] = df_data['size'].apply(string_count_to_numeric)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def string_count_to_numeric(x: str):
    if x[-1] == 'M':
        n = float(x[:-1])
    else:
        n = np.NaN
    return n


__output__ = df_data['numeric_size'] = df_data['size'].apply(
    string_count_to_numeric)
</code></pre>
        <p><span onclick="$('#var_output_8f9c179e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8f9c179e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0     177.0
1      46.0
2       NaN
3      31.0
4      71.0
      ...  
35    832.0
36     32.0
37      NaN
38     37.0
39     31.0
Name: size, Length: 40, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_data, __output__ </p>
    
          <p>df_data (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>summary</th>
      <th>installs</th>
      <th>score</th>
      <th>ratings</th>
      <th>reviews</th>
      <th>size</th>
      <th>androidVersion</th>
      <th>genreId</th>
      <th>contentRating</th>
      <th>released</th>
      <th>updated</th>
      <th>version</th>
      <th>appId</th>
      <th>numeric_size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Racing multiplayer online game. Drive cars and motorcycles.</td>
      <td>100000000</td>
      <td>4.474443</td>
      <td>10191799</td>
      <td>280041</td>
      <td>177M</td>
      <td>5.0</td>
      <td>RACING</td>
      <td>Everyone 10+</td>
      <td>2013-08-20</td>
      <td>2022-04-18</td>
      <td>6.2.3b</td>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>177.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Asphalt Nitro</td>
      <td>Car racing game with luxury licensed brands</td>
      <td>100000000</td>
      <td>4.285882</td>
      <td>1743070</td>
      <td>16204</td>
      <td>46M</td>
      <td>4.1</td>
      <td>RACING</td>
      <td>Everyone</td>
      <td>2015-11-05</td>
      <td>2022-03-21</td>
      <td>1.7.5a</td>
      <td>com.gameloft.android.ANMP.GloftAGHM</td>
      <td>46.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Asphalt 9: Legends</td>
      <td>Online multiplayer street auto racing game with high luxury car brands.</td>
      <td>50000000</td>
      <td>4.471972</td>
      <td>2443874</td>
      <td>61954</td>
      <td>Varies with device</td>
      <td>7.0</td>
      <td>RACING</td>
      <td>Everyone 10+</td>
      <td>2018-07-25</td>
      <td>2022-04-28</td>
      <td>3.4.5a</td>
      <td>com.gameloft.android.ANMP.GloftA9HM</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Real Football</td>
      <td>Experience soccer both on and off the pitch with Real Football</td>
      <td>50000000</td>
      <td>3.766698</td>
      <td>970452</td>
      <td>4662</td>
      <td>31M</td>
      <td>4.4</td>
      <td>SPORTS</td>
      <td>Everyone 10+</td>
      <td>2016-09-29</td>
      <td>2021-08-24</td>
      <td>1.7.2</td>
      <td>com.gameloft.android.ANMP.GloftR7HM</td>
      <td>31.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Sniper Fury: Shooting Game</td>
      <td>A 3D sniping game to hunt elite hitmen and shooter assassins. Ready to snipe?</td>
      <td>50000000</td>
      <td>4.324803</td>
      <td>1025668</td>
      <td>20414</td>
      <td>71M</td>
      <td>5.0</td>
      <td>ACTION</td>
      <td>Mature 17+</td>
      <td>2015-12-02</td>
      <td>2022-02-02</td>
      <td>6.2.2a</td>
      <td>com.gameloft.android.ANMP.GloftFWHM</td>
      <td>71.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>N.O.V.A. Legacy</td>
      <td>N.O.V.A. Legacy game; multiplayer FPS experience</td>
      <td>50000000</td>
      <td>3.998916</td>
      <td>1592747</td>
      <td>32576</td>
      <td>45M</td>
      <td>4.0.3</td>
      <td>ACTION</td>
      <td>Everyone 10+</td>
      <td>2017-03-27</td>
      <td>2020-10-15</td>
      <td>5.8.3c</td>
      <td>com.gameloft.android.ANMP.GloftNOHM</td>
      <td>45.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Gangstar Vegas: World of Crime</td>
      <td>RPG crime and mafia online game set in Las Vegas</td>
      <td>100000000</td>
      <td>4.334542</td>
      <td>6556484</td>
      <td>174148</td>
      <td>51M</td>
      <td>5.0</td>
      <td>ACTION</td>
      <td>Mature 17+</td>
      <td>2013-06-19</td>
      <td>2022-03-30</td>
      <td>5.6.0k</td>
      <td>com.gameloft.android.ANMP.GloftGGHM</td>
      <td>51.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Ice Age Village</td>
      <td>Discover what's above and beneath the ice in ICE AGE VILLAGE</td>
      <td>50000000</td>
      <td>4.428929</td>
      <td>1907405</td>
      <td>98467</td>
      <td>53M</td>
      <td>4.1</td>
      <td>CASUAL</td>
      <td>Everyone 10+</td>
      <td>2012-04-05</td>
      <td>2022-04-26</td>
      <td>3.6.1a</td>
      <td>com.gameloft.android.ANMP.GloftIAHM</td>
      <td>53.0</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Order &amp; Chaos 2: 3D MMO RPG</td>
      <td>Fantasy heroes on the road to redemption. MMORPG game.</td>
      <td>10000000</td>
      <td>3.735089</td>
      <td>263719</td>
      <td>10824</td>
      <td>54M</td>
      <td>4.0.3</td>
      <td>ROLE_PLAYING</td>
      <td>Teen</td>
      <td>2015-09-16</td>
      <td>2018-08-13</td>
      <td>3.1.3a</td>
      <td>com.gameloft.android.ANMP.GloftO2HM</td>
      <td>54.0</td>
    </tr>
    <tr>
      <th>35</th>
      <td>War Planet Online: MMO Game</td>
      <td>Be a war lord. Conquer the world. Build an army to dominate</td>
      <td>5000000</td>
      <td>4.239910</td>
      <td>98200</td>
      <td>3461</td>
      <td>832M</td>
      <td>5.0</td>
      <td>STRATEGY</td>
      <td>Everyone 10+</td>
      <td>2017-08-30</td>
      <td>2022-04-21</td>
      <td>4.5.1</td>
      <td>com.gameloft.android.ANMP.GloftW2HM</td>
      <td>832.0</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Paddington Run game</td>
      <td>Infinite run through London with Paddington collecting marmalade and tokens</td>
      <td>1000000</td>
      <td>3.960000</td>
      <td>10353</td>
      <td>249</td>
      <td>32M</td>
      <td>4.1</td>
      <td>ACTION</td>
      <td>Everyone</td>
      <td>2017-10-25</td>
      <td>2020-10-20</td>
      <td>1.2.6a</td>
      <td>com.gameloft.android.ANMP.GloftDTHM</td>
      <td>32.0</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Dungeon Hunter Champions</td>
      <td>Online action RPG fight in live PVP 5v5 battles with customizable teams</td>
      <td>1000000</td>
      <td>3.699357</td>
      <td>47672</td>
      <td>2723</td>
      <td>Varies with device</td>
      <td>4.4</td>
      <td>ROLE_PLAYING</td>
      <td>Teen</td>
      <td>2018-05-02</td>
      <td>2021-02-01</td>
      <td>1.8.36</td>
      <td>com.gameloft.android.ANMP.GloftD6HM</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Order &amp; Chaos Online 3D MMORPG</td>
      <td>Battle Orcs and Demons in a massive multiplayer role-playing adventure</td>
      <td>5000000</td>
      <td>4.347230</td>
      <td>475583</td>
      <td>36629</td>
      <td>37M</td>
      <td>4.1</td>
      <td>ROLE_PLAYING</td>
      <td>Teen</td>
      <td>2011-06-20</td>
      <td>2021-12-15</td>
      <td>4.2.5a</td>
      <td>com.gameloft.android.ANMP.GloftMMHM</td>
      <td>37.0</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Rival Knights</td>
      <td>Adventure challenge game to battle for glory and victory</td>
      <td>5000000</td>
      <td>4.274475</td>
      <td>355751</td>
      <td>11280</td>
      <td>31M</td>
      <td>4.0</td>
      <td>ACTION</td>
      <td>Teen</td>
      <td>2014-06-04</td>
      <td>2021-04-15</td>
      <td>1.2.4b</td>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>31.0</td>
    </tr>
  </tbody>
</table>
<p>40 rows × 15 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0     177.0
1      46.0
2       NaN
3      31.0
4      71.0
      ...  
35    832.0
36     32.0
37      NaN
38     37.0
39     31.0
Name: size, Length: 40, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> gameloft-android-games-collection-2022/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the average size of games with at least 100 million installs and games with less than that. Ignore NaN rows. Show the two groups as rows.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_sizes = df_data[['numeric_size', 'installs']].dropna()
more_than_100 = df_sizes.installs >= 100_000_000
df_sizes.loc[:, 'installs'][more_than_100] = 'more_than_100M'
df_sizes.loc[:, 'installs'][~more_than_100] = 'less_than_100M'
df_sizes.groupby('installs').mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_sizes = df_data[['numeric_size', 'installs']].dropna()
more_than_100 = df_sizes.installs >= 100_000_000
df_sizes.loc[:, 'installs'][more_than_100] = 'more_than_100M'
df_sizes.loc[:, 'installs'][~more_than_100] = 'less_than_100M'
df_sizes.groupby('installs').mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_sizes = df_data[['numeric_size', 'installs']].dropna()
more_than_100 = df_sizes.installs >= 100000000
df_sizes.loc[:, 'installs'][more_than_100] = 'more_than_100M'
df_sizes.loc[:, 'installs'][~more_than_100] = 'less_than_100M'
__output__ = df_sizes.groupby('installs').mean()
</code></pre>
        <p><span onclick="$('#var_output_2766c292').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2766c292" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>numeric_size</th>
    </tr>
    <tr>
      <th>installs</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>less_than_100M</th>
      <td>82.9375</td>
    </tr>
    <tr>
      <th>more_than_100M</th>
      <td>90.8000</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_sizes, more_than_100, __output__ </p>
    
          <p>df_sizes (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>numeric_size</th>
      <th>installs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>177.0</td>
      <td>more_than_100M</td>
    </tr>
    <tr>
      <th>1</th>
      <td>46.0</td>
      <td>more_than_100M</td>
    </tr>
    <tr>
      <th>3</th>
      <td>31.0</td>
      <td>less_than_100M</td>
    </tr>
    <tr>
      <th>4</th>
      <td>71.0</td>
      <td>less_than_100M</td>
    </tr>
    <tr>
      <th>5</th>
      <td>45.0</td>
      <td>less_than_100M</td>
    </tr>
    <tr>
      <th>6</th>
      <td>51.0</td>
      <td>more_than_100M</td>
    </tr>
    <tr>
      <th>7</th>
      <td>66.0</td>
      <td>less_than_100M</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>32</th>
      <td>37.0</td>
      <td>less_than_100M</td>
    </tr>
    <tr>
      <th>33</th>
      <td>53.0</td>
      <td>less_than_100M</td>
    </tr>
    <tr>
      <th>34</th>
      <td>54.0</td>
      <td>less_than_100M</td>
    </tr>
    <tr>
      <th>35</th>
      <td>832.0</td>
      <td>less_than_100M</td>
    </tr>
    <tr>
      <th>36</th>
      <td>32.0</td>
      <td>less_than_100M</td>
    </tr>
    <tr>
      <th>38</th>
      <td>37.0</td>
      <td>less_than_100M</td>
    </tr>
    <tr>
      <th>39</th>
      <td>31.0</td>
      <td>less_than_100M</td>
    </tr>
  </tbody>
</table>
<p>37 rows × 2 columns</p>
      
          <p>more_than_100 (Series):</p>
          <pre><code>0      True
1      True
3     False
4     False
5     False
      ...  
34    False
35    False
36    False
38    False
39    False
Name: installs, Length: 37, dtype: bool</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>numeric_size</th>
    </tr>
    <tr>
      <th>installs</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>less_than_100M</th>
      <td>82.9375</td>
    </tr>
    <tr>
      <th>more_than_100M</th>
      <td>90.8000</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> gameloft-android-games-collection-2022/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the average size of games of each major version of Android.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def get_major_version(x):
    return x.split('.')[0]

df_version = df_data.loc[:, ['numeric_size', 'androidVersion']]
df_version['majorVersion'] = df_version['androidVersion'].apply(get_major_version)
df_version[['numeric_size', 'majorVersion']].groupby('majorVersion').mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def get_major_version(x):
    return x.split('.')[0]

df_version = df_data.loc[:, ['numeric_size', 'androidVersion']]
df_version['majorVersion'] = df_version['androidVersion'].apply(get_major_version)
df_version[['numeric_size', 'majorVersion']].groupby('majorVersion').mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def get_major_version(x):
    return x.split('.')[0]


df_version = df_data.loc[:, ['numeric_size', 'androidVersion']]
df_version['majorVersion'] = df_version['androidVersion'].apply(
    get_major_version)
__output__ = df_version[['numeric_size', 'majorVersion']].groupby(
    'majorVersion').mean()
</code></pre>
        <p><span onclick="$('#var_output_21e1c062').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_21e1c062" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>numeric_size</th>
    </tr>
    <tr>
      <th>majorVersion</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>51.00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>46.32</td>
    </tr>
    <tr>
      <th>5</th>
      <td>163.20</td>
    </tr>
    <tr>
      <th>7</th>
      <td>267.00</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_version, __output__ </p>
    
          <p>df_version (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>numeric_size</th>
      <th>androidVersion</th>
      <th>majorVersion</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>177.0</td>
      <td>5.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>46.0</td>
      <td>4.1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>7.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>31.0</td>
      <td>4.4</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>71.0</td>
      <td>5.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>5</th>
      <td>45.0</td>
      <td>4.0.3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>6</th>
      <td>51.0</td>
      <td>5.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>33</th>
      <td>53.0</td>
      <td>4.1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>34</th>
      <td>54.0</td>
      <td>4.0.3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>35</th>
      <td>832.0</td>
      <td>5.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>36</th>
      <td>32.0</td>
      <td>4.1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>37</th>
      <td>NaN</td>
      <td>4.4</td>
      <td>4</td>
    </tr>
    <tr>
      <th>38</th>
      <td>37.0</td>
      <td>4.1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>39</th>
      <td>31.0</td>
      <td>4.0</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>40 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>numeric_size</th>
    </tr>
    <tr>
      <th>majorVersion</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>51.00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>46.32</td>
    </tr>
    <tr>
      <th>5</th>
      <td>163.20</td>
    </tr>
    <tr>
      <th>7</th>
      <td>267.00</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> gameloft-android-games-collection-2022/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which action games have more than 10 thousand reviews? Show a list of titles.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_reviews = df_data[['title', 'reviews']][(df_data.reviews > 10000) & (df_data.genreId == 'ACTION')]
df_reviews.title.to_list()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_reviews = df_data[['title', 'reviews']][(df_data.reviews > 10000) & (df_data.genreId == 'ACTION')]
df_reviews.title.to_list()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_reviews = df_data[['title', 'reviews']][(df_data.reviews > 10000) & (
    df_data.genreId == 'ACTION')]
__output__ = df_reviews.title.to_list()
</code></pre>
        <p><span onclick="$('#var_output_2bc5670a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2bc5670a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Sniper Fury: Shooting Game', 'N.O.V.A. Legacy', 'Gangstar Vegas: World of Crime', 'Modern Combat 5: mobile FPS', 'Gods of Rome', 'Six-Guns: Gang Showdown', 'Blitz Brigade - Online FPS', 'Rival Knights']</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_reviews, __output__ </p>
    
          <p>df_reviews (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>reviews</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>Sniper Fury: Shooting Game</td>
      <td>20414</td>
    </tr>
    <tr>
      <th>5</th>
      <td>N.O.V.A. Legacy</td>
      <td>32576</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Gangstar Vegas: World of Crime</td>
      <td>174148</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Modern Combat 5: mobile FPS</td>
      <td>104630</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Gods of Rome</td>
      <td>14231</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Six-Guns: Gang Showdown</td>
      <td>94101</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Blitz Brigade - Online FPS</td>
      <td>72208</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Rival Knights</td>
      <td>11280</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 2 columns</p>
      
          <p>__output__ (list):</p>
          <pre><code>['Sniper Fury: Shooting Game', 'N.O.V.A. Legacy', 'Gangstar Vegas: World of Crime', 'Modern Combat 5: mobile FPS', 'Gods of Rome', 'Six-Guns: Gang Showdown', 'Blitz Brigade - Online FPS', 'Rival Knights']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> gameloft-android-games-collection-2022/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many of them are rated for teens?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_content = df_reviews.set_index('title').join(df_data[['title', 'contentRating']].set_index('title'),
                                                on=['title']).reset_index()
df_content[df_content.contentRating == 'Teen'].title.count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_content = df_reviews.set_index('title').join(df_data[['title', 'contentRating']].set_index('title'),
                                                on=['title']).reset_index()
df_content[df_content.contentRating == 'Teen'].title.count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_content = df_reviews.set_index('title').join(df_data[['title',
    'contentRating']].set_index('title'), on=['title']).reset_index()
__output__ = df_content[df_content.contentRating == 'Teen'].title.count()
</code></pre>
        <p><span onclick="$('#var_output_a165493f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a165493f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>3</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_content, __output__ </p>
    
          <p>df_content (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>reviews</th>
      <th>contentRating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Sniper Fury: Shooting Game</td>
      <td>20414</td>
      <td>Mature 17+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>N.O.V.A. Legacy</td>
      <td>32576</td>
      <td>Everyone 10+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Gangstar Vegas: World of Crime</td>
      <td>174148</td>
      <td>Mature 17+</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Modern Combat 5: mobile FPS</td>
      <td>104630</td>
      <td>Mature 17+</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Gods of Rome</td>
      <td>14231</td>
      <td>Teen</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Six-Guns: Gang Showdown</td>
      <td>94101</td>
      <td>Teen</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Blitz Brigade - Online FPS</td>
      <td>72208</td>
      <td>Everyone 10+</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Rival Knights</td>
      <td>11280</td>
      <td>Teen</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 3 columns</p>
      
          <p>__output__ (int64):</p>
          <pre><code>3</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> gameloft-android-games-collection-2022/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the oldest game among those that received updates in 2022?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def convert_to_datetime(x):
    x['updated'] = datetime.strptime(x['updated'], '%Y-%m-%d')
    x['released'] = datetime.strptime(x['released'], '%Y-%m-%d')
    return x

df_date = df_data[['title', 'released', 'updated']].apply(convert_to_datetime, 1)
df_date[df_date.updated.dt.year == 2022].sort_values(by='released').title.iloc[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def convert_to_datetime(x):
    x['updated'] = datetime.strptime(x['updated'], '%Y-%m-%d')
    x['released'] = datetime.strptime(x['released'], '%Y-%m-%d')
    return x

df_date = df_data[['title', 'released', 'updated']].apply(convert_to_datetime, 1)
df_date[df_date.updated.dt.year == 2022].sort_values(by='released').title.iloc[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def convert_to_datetime(x):
    x['updated'] = datetime.strptime(x['updated'], '%Y-%m-%d')
    x['released'] = datetime.strptime(x['released'], '%Y-%m-%d')
    return x


df_date = df_data[['title', 'released', 'updated']].apply(convert_to_datetime,
    1)
__output__ = df_date[df_date.updated.dt.year == 2022].sort_values(by='released'
    ).title.iloc[0]
</code></pre>
        <p><span onclick="$('#var_output_1d054cff').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1d054cff" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Six-Guns: Gang Showdown</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_date, __output__ </p>
    
          <p>df_date (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>released</th>
      <th>updated</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>2013-08-20</td>
      <td>2022-04-18</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Asphalt Nitro</td>
      <td>2015-11-05</td>
      <td>2022-03-21</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Asphalt 9: Legends</td>
      <td>2018-07-25</td>
      <td>2022-04-28</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Real Football</td>
      <td>2016-09-29</td>
      <td>2021-08-24</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Sniper Fury: Shooting Game</td>
      <td>2015-12-02</td>
      <td>2022-02-02</td>
    </tr>
    <tr>
      <th>5</th>
      <td>N.O.V.A. Legacy</td>
      <td>2017-03-27</td>
      <td>2020-10-15</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Gangstar Vegas: World of Crime</td>
      <td>2013-06-19</td>
      <td>2022-03-30</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Ice Age Village</td>
      <td>2012-04-05</td>
      <td>2022-04-26</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Order &amp; Chaos 2: 3D MMO RPG</td>
      <td>2015-09-16</td>
      <td>2018-08-13</td>
    </tr>
    <tr>
      <th>35</th>
      <td>War Planet Online: MMO Game</td>
      <td>2017-08-30</td>
      <td>2022-04-21</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Paddington Run game</td>
      <td>2017-10-25</td>
      <td>2020-10-20</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Dungeon Hunter Champions</td>
      <td>2018-05-02</td>
      <td>2021-02-01</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Order &amp; Chaos Online 3D MMORPG</td>
      <td>2011-06-20</td>
      <td>2021-12-15</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Rival Knights</td>
      <td>2014-06-04</td>
      <td>2021-04-15</td>
    </tr>
  </tbody>
</table>
<p>40 rows × 3 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>Six-Guns: Gang Showdown</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> gameloft-android-games-collection-2022/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average age of games for each score value? Show the age as a column rounded to days and the score values as row indices rounded to the first decimal.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_age_score = df_date.set_index('title').join(df_data[['title', 'score']].set_index('title')).reset_index()

round_to_decimal_1 = lambda x: np.round(x * 10) / 10
df_age_score.score = df_age_score.score.apply(round_to_decimal_1)
df_age_score['age'] = datetime.now() - df_age_score.released
dtemp = df_age_score[['age', 'score']].groupby('score').mean()
dtemp.age = dtemp.age.dt.days
dtemp</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_age_score = df_date.set_index('title').join(df_data[['title', 'score']].set_index('title')).reset_index()

round_to_decimal_1 = lambda x: np.round(x * 10) / 10
df_age_score.score = df_age_score.score.apply(round_to_decimal_1)
df_age_score['age'] = datetime.now() - df_age_score.released
dtemp = df_age_score[['age', 'score']].groupby('score').mean()
dtemp.age = dtemp.age.dt.days
dtemp</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_age_score = df_date.set_index('title').join(df_data[['title', 'score']].
    set_index('title')).reset_index()
round_to_decimal_1 = lambda x: np.round(x * 10) / 10
df_age_score.score = df_age_score.score.apply(round_to_decimal_1)
df_age_score['age'] = datetime.now() - df_age_score.released
dtemp = df_age_score[['age', 'score']].groupby('score').mean()
dtemp.age = dtemp.age.dt.days
__output__ = dtemp
</code></pre>
        <p><span onclick="$('#var_output_69cdfe6a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_69cdfe6a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
    </tr>
    <tr>
      <th>score</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3.7</th>
      <td>2337</td>
    </tr>
    <tr>
      <th>3.8</th>
      <td>2159</td>
    </tr>
    <tr>
      <th>3.9</th>
      <td>3657</td>
    </tr>
    <tr>
      <th>4.0</th>
      <td>2340</td>
    </tr>
    <tr>
      <th>4.1</th>
      <td>2566</td>
    </tr>
    <tr>
      <th>4.2</th>
      <td>2061</td>
    </tr>
    <tr>
      <th>4.3</th>
      <td>3104</td>
    </tr>
    <tr>
      <th>4.4</th>
      <td>3222</td>
    </tr>
    <tr>
      <th>4.5</th>
      <td>2929</td>
    </tr>
    <tr>
      <th>4.6</th>
      <td>2313</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_age_score, dtemp, __output__ </p>
    
          <p>df_age_score (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>released</th>
      <th>updated</th>
      <th>score</th>
      <th>age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>2013-08-20</td>
      <td>2022-04-18</td>
      <td>4.5</td>
      <td>3399 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Asphalt Nitro</td>
      <td>2015-11-05</td>
      <td>2022-03-21</td>
      <td>4.3</td>
      <td>2592 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Asphalt 9: Legends</td>
      <td>2018-07-25</td>
      <td>2022-04-28</td>
      <td>4.5</td>
      <td>1599 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Real Football</td>
      <td>2016-09-29</td>
      <td>2021-08-24</td>
      <td>3.8</td>
      <td>2263 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Sniper Fury: Shooting Game</td>
      <td>2015-12-02</td>
      <td>2022-02-02</td>
      <td>4.3</td>
      <td>2565 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>5</th>
      <td>N.O.V.A. Legacy</td>
      <td>2017-03-27</td>
      <td>2020-10-15</td>
      <td>4.0</td>
      <td>2084 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Gangstar Vegas: World of Crime</td>
      <td>2013-06-19</td>
      <td>2022-03-30</td>
      <td>4.3</td>
      <td>3461 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Ice Age Village</td>
      <td>2012-04-05</td>
      <td>2022-04-26</td>
      <td>4.4</td>
      <td>3901 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Order &amp; Chaos 2: 3D MMO RPG</td>
      <td>2015-09-16</td>
      <td>2018-08-13</td>
      <td>3.7</td>
      <td>2642 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>35</th>
      <td>War Planet Online: MMO Game</td>
      <td>2017-08-30</td>
      <td>2022-04-21</td>
      <td>4.2</td>
      <td>1928 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Paddington Run game</td>
      <td>2017-10-25</td>
      <td>2020-10-20</td>
      <td>4.0</td>
      <td>1872 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Dungeon Hunter Champions</td>
      <td>2018-05-02</td>
      <td>2021-02-01</td>
      <td>3.7</td>
      <td>1683 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Order &amp; Chaos Online 3D MMORPG</td>
      <td>2011-06-20</td>
      <td>2021-12-15</td>
      <td>4.3</td>
      <td>4191 days 12:22:14.950135</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Rival Knights</td>
      <td>2014-06-04</td>
      <td>2021-04-15</td>
      <td>4.3</td>
      <td>3111 days 12:22:14.950135</td>
    </tr>
  </tbody>
</table>
<p>40 rows × 5 columns</p>
      
          <p>dtemp (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
    </tr>
    <tr>
      <th>score</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3.7</th>
      <td>2337</td>
    </tr>
    <tr>
      <th>3.8</th>
      <td>2159</td>
    </tr>
    <tr>
      <th>3.9</th>
      <td>3657</td>
    </tr>
    <tr>
      <th>4.0</th>
      <td>2340</td>
    </tr>
    <tr>
      <th>4.1</th>
      <td>2566</td>
    </tr>
    <tr>
      <th>4.2</th>
      <td>2061</td>
    </tr>
    <tr>
      <th>4.3</th>
      <td>3104</td>
    </tr>
    <tr>
      <th>4.4</th>
      <td>3222</td>
    </tr>
    <tr>
      <th>4.5</th>
      <td>2929</td>
    </tr>
    <tr>
      <th>4.6</th>
      <td>2313</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
    </tr>
    <tr>
      <th>score</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3.7</th>
      <td>2337</td>
    </tr>
    <tr>
      <th>3.8</th>
      <td>2159</td>
    </tr>
    <tr>
      <th>3.9</th>
      <td>3657</td>
    </tr>
    <tr>
      <th>4.0</th>
      <td>2340</td>
    </tr>
    <tr>
      <th>4.1</th>
      <td>2566</td>
    </tr>
    <tr>
      <th>4.2</th>
      <td>2061</td>
    </tr>
    <tr>
      <th>4.3</th>
      <td>3104</td>
    </tr>
    <tr>
      <th>4.4</th>
      <td>3222</td>
    </tr>
    <tr>
      <th>4.5</th>
      <td>2929</td>
    </tr>
    <tr>
      <th>4.6</th>
      <td>2313</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> gameloft-android-games-collection-2022/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the app ID and title for each review. Create a dataframe with appID, title and the individual reviews as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_rev = df_data[['title', 'appId']].set_index("appId").join(df_review_list.copy().set_index('appId')).reset_index()
df_rev.reviews = df_rev.reviews.apply(eval)
df_rev = df_rev.explode('reviews')
df_rev</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_rev = df_data[['title', 'appId']].set_index("appId").join(df_review_list.copy().set_index('appId')).reset_index()
df_rev.reviews = df_rev.reviews.apply(eval)
df_rev = df_rev.explode('reviews')
df_rev</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_rev = df_data[['title', 'appId']].set_index('appId').join(df_review_list
    .copy().set_index('appId')).reset_index()
df_rev.reviews = df_rev.reviews.apply(eval)
df_rev = df_rev.explode('reviews')
__output__ = df_rev
</code></pre>
        <p><span onclick="$('#var_output_5014af69').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5014af69" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>appId</th>
      <th>title</th>
      <th>reviews</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>It's a great game, great racing experience, takes time to master, and lots of fun once you get good, fast cars. The only problem is that getting good cars can be a long process unless you're willing to spend real money, and even then, there's a lot of grinding involved in order to obtain currency and parts that you need to purchase and upgrade new cars. I just wish that they would make it easier to obtain new cars and not make it so difficult to progress in this game. It would be SO much better.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>This game is amazing, but after a while of not playing it I came back to see a big difference in the ui, and it just makes everything slower, and also the way there's character animations now just kinda make it feel a bit more like a pubg ad at the end of races somehow, I don't really know what it is it used to bring me so much nostalgia till the update :( Still fun to play and I'm sure that a lot of other people prefer the new layout but I personally rhink a classic mode or something would help</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Super fun, and I really appreciate them keeping this updated and active despite there being a newer version. Controls are easy to make comfortable, fun and easy to play on both PC and mobile, relatively realistic with stats and physics to my knowledge. An interesting variety of maps and race types, great music. I honestly prefer it to Asphalt 9 because it feels easier to navigate and more user-friendly</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Excellent game, high frame rate, no play limit, and menus are easy to navigate. I highly recommend this game for casual gamers. Just focus on getting a really fast car, and you will have adrenaline speed fun for hours! I wanted to rate this games 5 stars, but I don't like that alot of the cool cars require tokens to get, which are almost impossible to obtain without making an in-app purchase.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Overall, this game is really well designed. The graphics are very realisitic and I love how you made Credits that are just like Coins. Maybe make some different tracks because it's boring just going on the same tracks. Also, can you make an update where you play like a parkour where you have to go over jumps or something. And if you finish top 3 or something you get 500 Credits or maybe a New Car Unlocked. Like I said, I really love this game and I would recommend it.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>It's a a awesome game with an imaginative twist, actual cars with real upgrades makes it that much more enjoyable. So many tracks and bonus features, you can never get bored. The bonus features make it that much more possible to gain position against the feirce composition. Have Fun and don't be afraid to take out the composition.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>This is one game I've been playing for a while. Very addictive lol! I would give it a solid five stars however, I can do without the freezes. Also it would be great if the timer for the boost didn't start before the race begins and stop after the race ends. It's kind of a rip off that the timer starts before the race begins and waiting for other players to join i.e multiplayer and continues after the race ended.</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Just wish there was a better story line and more events. Like sword fighting or trying to win over the maiden. Good game but a total RIP off of knights tale the movie. My favorite movie you have so much more you could do with this game that is why I gave 4 stars instead of 5. But why can't you fight in champion ship jousting. It is a fun and entertaining game and you don't have to blow money to win</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I rly love the game, but I have a problem with championship and frienlyes, i can't click on those two. But the game so far got me addicted. I love that they don't have so many adds and other annoying things, so I guess that this is the main reason that they don't get to mannage the bugs so quickly. Game is great guys. I love swiching gears on the horseð¤£ð¤£ð¤£(csr2)</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Just recently opened the app, and i was forced to download an update, and now, the game is unplayable, it crashes and force closes at the title screen. Help?!</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I remember when this game first came out in 2014, I played it a lot and the community was awesome. FF to today, only one PVP mode left and it's populated by bots. Not a single update in a long time. Awesome, fun game. Just slowly dying. Makes me sad UPDATE Game no longer even works</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Amazing Epic Game!!! The controls are smooth, graphics are really nice, art style is clean and vibrant! All sorts of upgrades available for you and your mount. Really fun and challenging as well. If you like the medieval era then you will get a real kick out of this app. Jump in, win some events grab some loot and come back tomorrow for more fun! Enjoy</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>The game is great, the only real problem that i have with it is the multiple times when i would've had a perfect hit, i would lose and the game would say that i missed the target. if this is fixed then the game would get 5 stars sense everything else is very good.</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I really like the game and how its played but the multiplayer tournaments wont work anymore. I contacted customer service and that was a joke. You WILL have to spend money eventually, especially when you get in the last two levels of tournaments during the normal gameplay. Graphics are great and the game is fun.</td>
    </tr>
  </tbody>
</table>
<p>1600 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_rev, __output__ </p>
    
          <p>df_rev (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>appId</th>
      <th>title</th>
      <th>reviews</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>It's a great game, great racing experience, takes time to master, and lots of fun once you get good, fast cars. The only problem is that getting good cars can be a long process unless you're willing to spend real money, and even then, there's a lot of grinding involved in order to obtain currency and parts that you need to purchase and upgrade new cars. I just wish that they would make it easier to obtain new cars and not make it so difficult to progress in this game. It would be SO much better.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>This game is amazing, but after a while of not playing it I came back to see a big difference in the ui, and it just makes everything slower, and also the way there's character animations now just kinda make it feel a bit more like a pubg ad at the end of races somehow, I don't really know what it is it used to bring me so much nostalgia till the update :( Still fun to play and I'm sure that a lot of other people prefer the new layout but I personally rhink a classic mode or something would help</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Super fun, and I really appreciate them keeping this updated and active despite there being a newer version. Controls are easy to make comfortable, fun and easy to play on both PC and mobile, relatively realistic with stats and physics to my knowledge. An interesting variety of maps and race types, great music. I honestly prefer it to Asphalt 9 because it feels easier to navigate and more user-friendly</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Excellent game, high frame rate, no play limit, and menus are easy to navigate. I highly recommend this game for casual gamers. Just focus on getting a really fast car, and you will have adrenaline speed fun for hours! I wanted to rate this games 5 stars, but I don't like that alot of the cool cars require tokens to get, which are almost impossible to obtain without making an in-app purchase.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Overall, this game is really well designed. The graphics are very realisitic and I love how you made Credits that are just like Coins. Maybe make some different tracks because it's boring just going on the same tracks. Also, can you make an update where you play like a parkour where you have to go over jumps or something. And if you finish top 3 or something you get 500 Credits or maybe a New Car Unlocked. Like I said, I really love this game and I would recommend it.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>It's a a awesome game with an imaginative twist, actual cars with real upgrades makes it that much more enjoyable. So many tracks and bonus features, you can never get bored. The bonus features make it that much more possible to gain position against the feirce composition. Have Fun and don't be afraid to take out the composition.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>This is one game I've been playing for a while. Very addictive lol! I would give it a solid five stars however, I can do without the freezes. Also it would be great if the timer for the boost didn't start before the race begins and stop after the race ends. It's kind of a rip off that the timer starts before the race begins and waiting for other players to join i.e multiplayer and continues after the race ended.</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Just wish there was a better story line and more events. Like sword fighting or trying to win over the maiden. Good game but a total RIP off of knights tale the movie. My favorite movie you have so much more you could do with this game that is why I gave 4 stars instead of 5. But why can't you fight in champion ship jousting. It is a fun and entertaining game and you don't have to blow money to win</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I rly love the game, but I have a problem with championship and frienlyes, i can't click on those two. But the game so far got me addicted. I love that they don't have so many adds and other annoying things, so I guess that this is the main reason that they don't get to mannage the bugs so quickly. Game is great guys. I love swiching gears on the horseð¤£ð¤£ð¤£(csr2)</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Just recently opened the app, and i was forced to download an update, and now, the game is unplayable, it crashes and force closes at the title screen. Help?!</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I remember when this game first came out in 2014, I played it a lot and the community was awesome. FF to today, only one PVP mode left and it's populated by bots. Not a single update in a long time. Awesome, fun game. Just slowly dying. Makes me sad UPDATE Game no longer even works</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Amazing Epic Game!!! The controls are smooth, graphics are really nice, art style is clean and vibrant! All sorts of upgrades available for you and your mount. Really fun and challenging as well. If you like the medieval era then you will get a real kick out of this app. Jump in, win some events grab some loot and come back tomorrow for more fun! Enjoy</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>The game is great, the only real problem that i have with it is the multiple times when i would've had a perfect hit, i would lose and the game would say that i missed the target. if this is fixed then the game would get 5 stars sense everything else is very good.</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I really like the game and how its played but the multiplayer tournaments wont work anymore. I contacted customer service and that was a joke. You WILL have to spend money eventually, especially when you get in the last two levels of tournaments during the normal gameplay. Graphics are great and the game is fun.</td>
    </tr>
  </tbody>
</table>
<p>1600 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>appId</th>
      <th>title</th>
      <th>reviews</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>It's a great game, great racing experience, takes time to master, and lots of fun once you get good, fast cars. The only problem is that getting good cars can be a long process unless you're willing to spend real money, and even then, there's a lot of grinding involved in order to obtain currency and parts that you need to purchase and upgrade new cars. I just wish that they would make it easier to obtain new cars and not make it so difficult to progress in this game. It would be SO much better.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>This game is amazing, but after a while of not playing it I came back to see a big difference in the ui, and it just makes everything slower, and also the way there's character animations now just kinda make it feel a bit more like a pubg ad at the end of races somehow, I don't really know what it is it used to bring me so much nostalgia till the update :( Still fun to play and I'm sure that a lot of other people prefer the new layout but I personally rhink a classic mode or something would help</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Super fun, and I really appreciate them keeping this updated and active despite there being a newer version. Controls are easy to make comfortable, fun and easy to play on both PC and mobile, relatively realistic with stats and physics to my knowledge. An interesting variety of maps and race types, great music. I honestly prefer it to Asphalt 9 because it feels easier to navigate and more user-friendly</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Excellent game, high frame rate, no play limit, and menus are easy to navigate. I highly recommend this game for casual gamers. Just focus on getting a really fast car, and you will have adrenaline speed fun for hours! I wanted to rate this games 5 stars, but I don't like that alot of the cool cars require tokens to get, which are almost impossible to obtain without making an in-app purchase.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Overall, this game is really well designed. The graphics are very realisitic and I love how you made Credits that are just like Coins. Maybe make some different tracks because it's boring just going on the same tracks. Also, can you make an update where you play like a parkour where you have to go over jumps or something. And if you finish top 3 or something you get 500 Credits or maybe a New Car Unlocked. Like I said, I really love this game and I would recommend it.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>It's a a awesome game with an imaginative twist, actual cars with real upgrades makes it that much more enjoyable. So many tracks and bonus features, you can never get bored. The bonus features make it that much more possible to gain position against the feirce composition. Have Fun and don't be afraid to take out the composition.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>This is one game I've been playing for a while. Very addictive lol! I would give it a solid five stars however, I can do without the freezes. Also it would be great if the timer for the boost didn't start before the race begins and stop after the race ends. It's kind of a rip off that the timer starts before the race begins and waiting for other players to join i.e multiplayer and continues after the race ended.</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Just wish there was a better story line and more events. Like sword fighting or trying to win over the maiden. Good game but a total RIP off of knights tale the movie. My favorite movie you have so much more you could do with this game that is why I gave 4 stars instead of 5. But why can't you fight in champion ship jousting. It is a fun and entertaining game and you don't have to blow money to win</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I rly love the game, but I have a problem with championship and frienlyes, i can't click on those two. But the game so far got me addicted. I love that they don't have so many adds and other annoying things, so I guess that this is the main reason that they don't get to mannage the bugs so quickly. Game is great guys. I love swiching gears on the horseð¤£ð¤£ð¤£(csr2)</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Just recently opened the app, and i was forced to download an update, and now, the game is unplayable, it crashes and force closes at the title screen. Help?!</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I remember when this game first came out in 2014, I played it a lot and the community was awesome. FF to today, only one PVP mode left and it's populated by bots. Not a single update in a long time. Awesome, fun game. Just slowly dying. Makes me sad UPDATE Game no longer even works</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Amazing Epic Game!!! The controls are smooth, graphics are really nice, art style is clean and vibrant! All sorts of upgrades available for you and your mount. Really fun and challenging as well. If you like the medieval era then you will get a real kick out of this app. Jump in, win some events grab some loot and come back tomorrow for more fun! Enjoy</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>The game is great, the only real problem that i have with it is the multiple times when i would've had a perfect hit, i would lose and the game would say that i missed the target. if this is fixed then the game would get 5 stars sense everything else is very good.</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I really like the game and how its played but the multiplayer tournaments wont work anymore. I contacted customer service and that was a joke. You WILL have to spend money eventually, especially when you get in the last two levels of tournaments during the normal gameplay. Graphics are great and the game is fun.</td>
    </tr>
  </tbody>
</table>
<p>1600 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> gameloft-android-games-collection-2022/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show how many of the reviews for each game have the words "good", "great" or "fantastic"?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def has_pos_words(x):
    rev = x['reviews']
    x['wordCount'] = 0
    if "good" in rev or "great" in rev or "fantastic" in rev:
        x['wordCount'] = 1
    return x

df_rev = df_rev.apply(has_pos_words, 1)
df_rev[['title', 'wordCount']].groupby('title').sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def has_pos_words(x):
    rev = x['reviews']
    x['wordCount'] = 0
    if "good" in rev or "great" in rev or "fantastic" in rev:
        x['wordCount'] = 1
    return x

df_rev = df_rev.apply(has_pos_words, 1)
df_rev[['title', 'wordCount']].groupby('title').sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def has_pos_words(x):
    rev = x['reviews']
    x['wordCount'] = 0
    if 'good' in rev or 'great' in rev or 'fantastic' in rev:
        x['wordCount'] = 1
    return x


df_rev = df_rev.apply(has_pos_words, 1)
__output__ = df_rev[['title', 'wordCount']].groupby('title').sum()
</code></pre>
        <p><span onclick="$('#var_output_57c175b3').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_57c175b3" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>wordCount</th>
    </tr>
    <tr>
      <th>title</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Asphalt 8 - Car Racing Game</th>
      <td>21</td>
    </tr>
    <tr>
      <th>Asphalt 9: Legends</th>
      <td>20</td>
    </tr>
    <tr>
      <th>Asphalt Nitro</th>
      <td>16</td>
    </tr>
    <tr>
      <th>Blitz Brigade - Online FPS</th>
      <td>19</td>
    </tr>
    <tr>
      <th>Brothers in Arms 3</th>
      <td>10</td>
    </tr>
    <tr>
      <th>City Mania: Town Building Game</th>
      <td>13</td>
    </tr>
    <tr>
      <th>Disney Magic Kingdoms</th>
      <td>10</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Rival Knights</th>
      <td>15</td>
    </tr>
    <tr>
      <th>Six-Guns: Gang Showdown</th>
      <td>16</td>
    </tr>
    <tr>
      <th>Sniper Fury: Shooting Game</th>
      <td>8</td>
    </tr>
    <tr>
      <th>Total Conquest</th>
      <td>13</td>
    </tr>
    <tr>
      <th>War Planet Online: MMO Game</th>
      <td>14</td>
    </tr>
    <tr>
      <th>Wonder Zoo: Animal rescue game</th>
      <td>17</td>
    </tr>
    <tr>
      <th>World at Arms</th>
      <td>11</td>
    </tr>
  </tbody>
</table>
<p>40 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_rev, __output__ </p>
    
          <p>df_rev (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>appId</th>
      <th>title</th>
      <th>reviews</th>
      <th>wordCount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>It's a great game, great racing experience, takes time to master, and lots of fun once you get good, fast cars. The only problem is that getting good cars can be a long process unless you're willing to spend real money, and even then, there's a lot of grinding involved in order to obtain currency and parts that you need to purchase and upgrade new cars. I just wish that they would make it easier to obtain new cars and not make it so difficult to progress in this game. It would be SO much better.</td>
      <td>1</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>This game is amazing, but after a while of not playing it I came back to see a big difference in the ui, and it just makes everything slower, and also the way there's character animations now just kinda make it feel a bit more like a pubg ad at the end of races somehow, I don't really know what it is it used to bring me so much nostalgia till the update :( Still fun to play and I'm sure that a lot of other people prefer the new layout but I personally rhink a classic mode or something would help</td>
      <td>0</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Super fun, and I really appreciate them keeping this updated and active despite there being a newer version. Controls are easy to make comfortable, fun and easy to play on both PC and mobile, relatively realistic with stats and physics to my knowledge. An interesting variety of maps and race types, great music. I honestly prefer it to Asphalt 9 because it feels easier to navigate and more user-friendly</td>
      <td>1</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Excellent game, high frame rate, no play limit, and menus are easy to navigate. I highly recommend this game for casual gamers. Just focus on getting a really fast car, and you will have adrenaline speed fun for hours! I wanted to rate this games 5 stars, but I don't like that alot of the cool cars require tokens to get, which are almost impossible to obtain without making an in-app purchase.</td>
      <td>0</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>Overall, this game is really well designed. The graphics are very realisitic and I love how you made Credits that are just like Coins. Maybe make some different tracks because it's boring just going on the same tracks. Also, can you make an update where you play like a parkour where you have to go over jumps or something. And if you finish top 3 or something you get 500 Credits or maybe a New Car Unlocked. Like I said, I really love this game and I would recommend it.</td>
      <td>0</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>It's a a awesome game with an imaginative twist, actual cars with real upgrades makes it that much more enjoyable. So many tracks and bonus features, you can never get bored. The bonus features make it that much more possible to gain position against the feirce composition. Have Fun and don't be afraid to take out the composition.</td>
      <td>0</td>
    </tr>
    <tr>
      <th>0</th>
      <td>com.gameloft.android.ANMP.GloftA8HM</td>
      <td>Asphalt 8 - Car Racing Game</td>
      <td>This is one game I've been playing for a while. Very addictive lol! I would give it a solid five stars however, I can do without the freezes. Also it would be great if the timer for the boost didn't start before the race begins and stop after the race ends. It's kind of a rip off that the timer starts before the race begins and waiting for other players to join i.e multiplayer and continues after the race ended.</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Just wish there was a better story line and more events. Like sword fighting or trying to win over the maiden. Good game but a total RIP off of knights tale the movie. My favorite movie you have so much more you could do with this game that is why I gave 4 stars instead of 5. But why can't you fight in champion ship jousting. It is a fun and entertaining game and you don't have to blow money to win</td>
      <td>0</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I rly love the game, but I have a problem with championship and frienlyes, i can't click on those two. But the game so far got me addicted. I love that they don't have so many adds and other annoying things, so I guess that this is the main reason that they don't get to mannage the bugs so quickly. Game is great guys. I love swiching gears on the horseð¤£ð¤£ð¤£(csr2)</td>
      <td>1</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Just recently opened the app, and i was forced to download an update, and now, the game is unplayable, it crashes and force closes at the title screen. Help?!</td>
      <td>0</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I remember when this game first came out in 2014, I played it a lot and the community was awesome. FF to today, only one PVP mode left and it's populated by bots. Not a single update in a long time. Awesome, fun game. Just slowly dying. Makes me sad UPDATE Game no longer even works</td>
      <td>0</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>Amazing Epic Game!!! The controls are smooth, graphics are really nice, art style is clean and vibrant! All sorts of upgrades available for you and your mount. Really fun and challenging as well. If you like the medieval era then you will get a real kick out of this app. Jump in, win some events grab some loot and come back tomorrow for more fun! Enjoy</td>
      <td>0</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>The game is great, the only real problem that i have with it is the multiple times when i would've had a perfect hit, i would lose and the game would say that i missed the target. if this is fixed then the game would get 5 stars sense everything else is very good.</td>
      <td>1</td>
    </tr>
    <tr>
      <th>39</th>
      <td>com.gameloft.android.ANMP.GloftOKHM</td>
      <td>Rival Knights</td>
      <td>I really like the game and how its played but the multiplayer tournaments wont work anymore. I contacted customer service and that was a joke. You WILL have to spend money eventually, especially when you get in the last two levels of tournaments during the normal gameplay. Graphics are great and the game is fun.</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>1600 rows × 4 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>wordCount</th>
    </tr>
    <tr>
      <th>title</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Asphalt 8 - Car Racing Game</th>
      <td>21</td>
    </tr>
    <tr>
      <th>Asphalt 9: Legends</th>
      <td>20</td>
    </tr>
    <tr>
      <th>Asphalt Nitro</th>
      <td>16</td>
    </tr>
    <tr>
      <th>Blitz Brigade - Online FPS</th>
      <td>19</td>
    </tr>
    <tr>
      <th>Brothers in Arms 3</th>
      <td>10</td>
    </tr>
    <tr>
      <th>City Mania: Town Building Game</th>
      <td>13</td>
    </tr>
    <tr>
      <th>Disney Magic Kingdoms</th>
      <td>10</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Rival Knights</th>
      <td>15</td>
    </tr>
    <tr>
      <th>Six-Guns: Gang Showdown</th>
      <td>16</td>
    </tr>
    <tr>
      <th>Sniper Fury: Shooting Game</th>
      <td>8</td>
    </tr>
    <tr>
      <th>Total Conquest</th>
      <td>13</td>
    </tr>
    <tr>
      <th>War Planet Online: MMO Game</th>
      <td>14</td>
    </tr>
    <tr>
      <th>Wonder Zoo: Animal rescue game</th>
      <td>17</td>
    </tr>
    <tr>
      <th>World at Arms</th>
      <td>11</td>
    </tr>
  </tbody>
</table>
<p>40 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> gameloft-android-games-collection-2022/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which roleplay games have the word "magic" in their summary? Show a list of names.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_data[df_data.summary.str.contains("adventure") & (df_data.genreId == "ROLE_PLAYING")].title.tolist()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_data[df_data.summary.str.contains("adventure") & (df_data.genreId == "ROLE_PLAYING")].title.tolist()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_data[df_data.summary.str.contains('adventure') & (df_data.
    genreId == 'ROLE_PLAYING')].title.tolist()
</code></pre>
        <p><span onclick="$('#var_output_dbf0690b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_dbf0690b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Dungeon Hunter 5:  Action RPG', 'Order & Chaos Online 3D MMORPG']</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Dungeon Hunter 5:  Action RPG', 'Order & Chaos Online 3D MMORPG']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> indian-summer-over-the-years/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert all datestrings in the table to datetime objects.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>from datetime import datetime

df['Date'] = df['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))
df['sunrise'] = df['sunrise'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))
df['sunset'] = df['sunset'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>from datetime import datetime

df['Date'] = df['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))
df['sunrise'] = df['sunrise'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))
df['sunset'] = df['sunset'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>from datetime import datetime
df['Date'] = df['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))
df['sunrise'] = df['sunrise'].apply(lambda x: datetime.strptime(x,
    '%Y-%m-%d %H:%M:%S'))
__output__ = df['sunset'] = df['sunset'].apply(lambda x: datetime.strptime(
    x, '%Y-%m-%d %H:%M:%S'))
</code></pre>
        <p><span onclick="$('#var_output_ce2eb3b5').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ce2eb3b5" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      2021-04-01 18:39:13
1      2021-04-02 18:39:46
2      2021-04-03 18:40:19
3      2021-04-04 18:40:53
4      2021-04-05 18:41:26
               ...        
6727   2007-06-26 18:53:47
6728   2007-06-27 18:53:56
6729   2007-06-28 18:54:05
6730   2007-06-29 18:54:13
6731   2007-06-30 18:54:19
Name: sunset, Length: 20382, dtype: datetime64[ns]</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>City</th>
      <th>Date</th>
      <th>tempmax</th>
      <th>tempmin</th>
      <th>temp</th>
      <th>feelslikemax</th>
      <th>feelslikemin</th>
      <th>...</th>
      <th>cloudcover</th>
      <th>visibility</th>
      <th>sunrise</th>
      <th>sunset</th>
      <th>moonphase</th>
      <th>conditions</th>
      <th>description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>New Delhi</td>
      <td>2021-04-01</td>
      <td>34.0</td>
      <td>19.0</td>
      <td>27.1</td>
      <td>31.6</td>
      <td>19.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>3.1</td>
      <td>2021-04-01 06:11:12</td>
      <td>2021-04-01 18:39:13</td>
      <td>0.60</td>
      <td>Clear</td>
      <td>Clear conditions throughout the day.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>New Delhi</td>
      <td>2021-04-02</td>
      <td>33.9</td>
      <td>16.0</td>
      <td>25.8</td>
      <td>31.8</td>
      <td>16.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>3.5</td>
      <td>2021-04-02 06:10:04</td>
      <td>2021-04-02 18:39:46</td>
      <td>0.65</td>
      <td>Clear</td>
      <td>Clear conditions throughout the day.</td>
    </tr>
    <tr>
      <th>2</th>
      <td>New Delhi</td>
      <td>2021-04-03</td>
      <td>34.8</td>
      <td>14.6</td>
      <td>26.0</td>
      <td>32.2</td>
      <td>14.6</td>
      <td>...</td>
      <td>1.4</td>
      <td>3.5</td>
      <td>2021-04-03 06:08:55</td>
      <td>2021-04-03 18:40:19</td>
      <td>0.70</td>
      <td>Clear</td>
      <td>Clear conditions throughout the day.</td>
    </tr>
    <tr>
      <th>3</th>
      <td>New Delhi</td>
      <td>2021-04-04</td>
      <td>36.8</td>
      <td>16.9</td>
      <td>27.1</td>
      <td>34.2</td>
      <td>16.9</td>
      <td>...</td>
      <td>2.6</td>
      <td>3.2</td>
      <td>2021-04-04 06:07:47</td>
      <td>2021-04-04 18:40:53</td>
      <td>0.76</td>
      <td>Clear</td>
      <td>Clear conditions throughout the day.</td>
    </tr>
    <tr>
      <th>4</th>
      <td>New Delhi</td>
      <td>2021-04-05</td>
      <td>38.8</td>
      <td>21.0</td>
      <td>29.9</td>
      <td>37.1</td>
      <td>21.0</td>
      <td>...</td>
      <td>38.4</td>
      <td>3.1</td>
      <td>2021-04-05 06:06:39</td>
      <td>2021-04-05 18:41:26</td>
      <td>0.81</td>
      <td>Partially cloudy</td>
      <td>Partly cloudy throughout the day.</td>
    </tr>
    <tr>
      <th>5</th>
      <td>New Delhi</td>
      <td>2021-04-06</td>
      <td>38.0</td>
      <td>22.6</td>
      <td>30.4</td>
      <td>37.2</td>
      <td>22.6</td>
      <td>...</td>
      <td>30.7</td>
      <td>2.4</td>
      <td>2021-04-06 06:05:32</td>
      <td>2021-04-06 18:41:59</td>
      <td>0.86</td>
      <td>Partially cloudy</td>
      <td>Partly cloudy throughout the day.</td>
    </tr>
    <tr>
      <th>6</th>
      <td>New Delhi</td>
      <td>2021-04-07</td>
      <td>36.0</td>
      <td>23.4</td>
      <td>29.6</td>
      <td>34.6</td>
      <td>23.4</td>
      <td>...</td>
      <td>24.1</td>
      <td>2.7</td>
      <td>2021-04-07 06:04:24</td>
      <td>2021-04-07 18:42:33</td>
      <td>0.91</td>
      <td>Partially cloudy</td>
      <td>Partly cloudy throughout the day.</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6725</th>
      <td>Hyderabad</td>
      <td>2007-06-24</td>
      <td>29.1</td>
      <td>24.1</td>
      <td>26.5</td>
      <td>31.4</td>
      <td>24.1</td>
      <td>...</td>
      <td>90.0</td>
      <td>4.8</td>
      <td>2007-06-24 05:43:22</td>
      <td>2007-06-24 18:53:26</td>
      <td>0.34</td>
      <td>Rain, Partially cloudy</td>
      <td>Partly cloudy throughout the day with afternoon rain.</td>
    </tr>
    <tr>
      <th>6726</th>
      <td>Hyderabad</td>
      <td>2007-06-25</td>
      <td>32.1</td>
      <td>24.1</td>
      <td>28.7</td>
      <td>33.6</td>
      <td>24.1</td>
      <td>...</td>
      <td>90.0</td>
      <td>5.6</td>
      <td>2007-06-25 05:43:36</td>
      <td>2007-06-25 18:53:37</td>
      <td>0.38</td>
      <td>Rain, Partially cloudy</td>
      <td>Partly cloudy throughout the day with late afternoon rain.</td>
    </tr>
    <tr>
      <th>6727</th>
      <td>Hyderabad</td>
      <td>2007-06-26</td>
      <td>29.1</td>
      <td>23.1</td>
      <td>26.5</td>
      <td>30.9</td>
      <td>23.1</td>
      <td>...</td>
      <td>97.6</td>
      <td>3.4</td>
      <td>2007-06-26 05:43:51</td>
      <td>2007-06-26 18:53:47</td>
      <td>0.42</td>
      <td>Rain, Overcast</td>
      <td>Cloudy skies throughout the day with afternoon rain.</td>
    </tr>
    <tr>
      <th>6728</th>
      <td>Hyderabad</td>
      <td>2007-06-27</td>
      <td>29.1</td>
      <td>24.1</td>
      <td>26.3</td>
      <td>32.9</td>
      <td>24.1</td>
      <td>...</td>
      <td>93.8</td>
      <td>4.3</td>
      <td>2007-06-27 05:44:07</td>
      <td>2007-06-27 18:53:56</td>
      <td>0.45</td>
      <td>Rain, Overcast</td>
      <td>Cloudy skies throughout the day with rain.</td>
    </tr>
    <tr>
      <th>6729</th>
      <td>Hyderabad</td>
      <td>2007-06-28</td>
      <td>29.1</td>
      <td>25.1</td>
      <td>26.8</td>
      <td>31.4</td>
      <td>25.1</td>
      <td>...</td>
      <td>93.8</td>
      <td>4.6</td>
      <td>2007-06-28 05:44:23</td>
      <td>2007-06-28 18:54:05</td>
      <td>0.48</td>
      <td>Rain, Overcast</td>
      <td>Cloudy skies throughout the day with late afternoon rain.</td>
    </tr>
    <tr>
      <th>6730</th>
      <td>Hyderabad</td>
      <td>2007-06-29</td>
      <td>27.1</td>
      <td>24.1</td>
      <td>26.2</td>
      <td>28.6</td>
      <td>24.1</td>
      <td>...</td>
      <td>98.8</td>
      <td>5.0</td>
      <td>2007-06-29 05:44:39</td>
      <td>2007-06-29 18:54:13</td>
      <td>0.49</td>
      <td>Rain, Overcast</td>
      <td>Cloudy skies throughout the day with rain.</td>
    </tr>
    <tr>
      <th>6731</th>
      <td>Hyderabad</td>
      <td>2007-06-30</td>
      <td>28.1</td>
      <td>24.1</td>
      <td>26.2</td>
      <td>29.3</td>
      <td>24.1</td>
      <td>...</td>
      <td>96.8</td>
      <td>4.5</td>
      <td>2007-06-30 05:44:56</td>
      <td>2007-06-30 18:54:19</td>
      <td>0.50</td>
      <td>Rain, Overcast</td>
      <td>Cloudy skies throughout the day with late afternoon rain.</td>
    </tr>
  </tbody>
</table>
<p>20382 rows × 20 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      2021-04-01 18:39:13
1      2021-04-02 18:39:46
2      2021-04-03 18:40:19
3      2021-04-04 18:40:53
4      2021-04-05 18:41:26
               ...        
6727   2007-06-26 18:53:47
6728   2007-06-27 18:53:56
6729   2007-06-28 18:54:05
6730   2007-06-29 18:54:13
6731   2007-06-30 18:54:19
Name: sunset, Length: 20382, dtype: datetime64[ns]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> indian-summer-over-the-years/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the average sunrise and sunset time for each month in the summer of 2018 at New Delhi? Show months as columns and time as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def add_year_month(x):
    x['month'] = datetime.strftime(x.Date, '%B')
    return x

def reset_time(x):
    x['sunrise'] = x.sunrise.replace(2000, 1, 1)
    x['sunset'] = x.sunset.replace(2000, 1, 1)
    return x

def show_time(x):
    x['sunrise_time'] = datetime.strftime(x.sunrise, '%H:%M:%S')
    x['sunset_time'] = datetime.strftime(x.sunset, '%H:%M:%S')
    return x

df_delhi = df[(df.City == 'New Delhi') & (df.Date > datetime.strptime('2017-12-31', "%Y-%m-%d")) & (
        df.Date < datetime.strptime('2019-01-01', "%Y-%m-%d"))][['Date', 'sunrise', 'sunset']]
df_delhi = df_delhi.apply(add_year_month, 1).apply(reset_time, 1).groupby('month').mean()[['sunrise', 'sunset']]
df_delhi.apply(show_time, 1)[['sunrise_time', 'sunset_time']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def add_year_month(x):
    x['month'] = datetime.strftime(x.Date, '%B')
    return x

def reset_time(x):
    x['sunrise'] = x.sunrise.replace(2000, 1, 1)
    x['sunset'] = x.sunset.replace(2000, 1, 1)
    return x

def show_time(x):
    x['sunrise_time'] = datetime.strftime(x.sunrise, '%H:%M:%S')
    x['sunset_time'] = datetime.strftime(x.sunset, '%H:%M:%S')
    return x

df_delhi = df[(df.City == 'New Delhi') & (df.Date > datetime.strptime('2017-12-31', "%Y-%m-%d")) & (
        df.Date < datetime.strptime('2019-01-01', "%Y-%m-%d"))][['Date', 'sunrise', 'sunset']]
df_delhi = df_delhi.apply(add_year_month, 1).apply(reset_time, 1).groupby('month').mean()[['sunrise', 'sunset']]
df_delhi.apply(show_time, 1)[['sunrise_time', 'sunset_time']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def add_year_month(x):
    x['month'] = datetime.strftime(x.Date, '%B')
    return x


def reset_time(x):
    x['sunrise'] = x.sunrise.replace(2000, 1, 1)
    x['sunset'] = x.sunset.replace(2000, 1, 1)
    return x


def show_time(x):
    x['sunrise_time'] = datetime.strftime(x.sunrise, '%H:%M:%S')
    x['sunset_time'] = datetime.strftime(x.sunset, '%H:%M:%S')
    return x


df_delhi = df[(df.City == 'New Delhi') & (df.Date > datetime.strptime(
    '2017-12-31', '%Y-%m-%d')) & (df.Date < datetime.strptime('2019-01-01',
    '%Y-%m-%d'))][['Date', 'sunrise', 'sunset']]
df_delhi = df_delhi.apply(add_year_month, 1).apply(reset_time, 1).groupby(
    'month').mean()[['sunrise', 'sunset']]
__output__ = df_delhi.apply(show_time, 1)[['sunrise_time', 'sunset_time']]
</code></pre>
        <p><span onclick="$('#var_output_991aa184').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_991aa184" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sunrise_time</th>
      <th>sunset_time</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>April</th>
      <td>2022-12-10 05:55:49</td>
      <td>2022-12-10 18:47:14</td>
    </tr>
    <tr>
      <th>June</th>
      <td>2022-12-10 05:23:43</td>
      <td>2022-12-10 19:19:48</td>
    </tr>
    <tr>
      <th>May</th>
      <td>2022-12-10 05:30:47</td>
      <td>2022-12-10 19:05:15</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_delhi, __output__ </p>
    
          <p>df_delhi (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sunrise</th>
      <th>sunset</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>April</th>
      <td>2000-01-01 05:55:49.300000000</td>
      <td>2000-01-01 18:47:14.266666624</td>
    </tr>
    <tr>
      <th>June</th>
      <td>2000-01-01 05:23:43.766666752</td>
      <td>2000-01-01 19:19:48.466666752</td>
    </tr>
    <tr>
      <th>May</th>
      <td>2000-01-01 05:30:47.870967680</td>
      <td>2000-01-01 19:05:15.129032320</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sunrise_time</th>
      <th>sunset_time</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>April</th>
      <td>2022-12-10 05:55:49</td>
      <td>2022-12-10 18:47:14</td>
    </tr>
    <tr>
      <th>June</th>
      <td>2022-12-10 05:23:43</td>
      <td>2022-12-10 19:19:48</td>
    </tr>
    <tr>
      <th>May</th>
      <td>2022-12-10 05:30:47</td>
      <td>2022-12-10 19:05:15</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> indian-summer-over-the-years/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the average sunrise and sunset times for the year after?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_delhi = df[(df.City == 'New Delhi') & (df.Date > datetime.strptime('2018-12-31', "%Y-%m-%d")) & (
        df.Date < datetime.strptime('2020-01-01', "%Y-%m-%d"))][['Date', 'sunrise', 'sunset']]
df_delhi = df_delhi.apply(add_year_month, 1).apply(reset_time, 1).groupby('month').mean()[['sunrise', 'sunset']]
df_delhi.apply(show_time, 1)[['sunrise_time', 'sunset_time']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_delhi = df[(df.City == 'New Delhi') & (df.Date > datetime.strptime('2018-12-31', "%Y-%m-%d")) & (
        df.Date < datetime.strptime('2020-01-01', "%Y-%m-%d"))][['Date', 'sunrise', 'sunset']]
df_delhi = df_delhi.apply(add_year_month, 1).apply(reset_time, 1).groupby('month').mean()[['sunrise', 'sunset']]
df_delhi.apply(show_time, 1)[['sunrise_time', 'sunset_time']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_delhi = df[(df.City == 'New Delhi') & (df.Date > datetime.strptime(
    '2018-12-31', '%Y-%m-%d')) & (df.Date < datetime.strptime('2020-01-01',
    '%Y-%m-%d'))][['Date', 'sunrise', 'sunset']]
df_delhi = df_delhi.apply(add_year_month, 1).apply(reset_time, 1).groupby(
    'month').mean()[['sunrise', 'sunset']]
__output__ = df_delhi.apply(show_time, 1)[['sunrise_time', 'sunset_time']]
</code></pre>
        <p><span onclick="$('#var_output_35f5cf49').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_35f5cf49" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sunrise_time</th>
      <th>sunset_time</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>April</th>
      <td>2022-12-10 05:56:04</td>
      <td>2022-12-10 18:47:06</td>
    </tr>
    <tr>
      <th>June</th>
      <td>2022-12-10 05:23:43</td>
      <td>2022-12-10 19:19:44</td>
    </tr>
    <tr>
      <th>May</th>
      <td>2022-12-10 05:30:56</td>
      <td>2022-12-10 19:05:07</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_delhi, __output__ </p>
    
          <p>df_delhi (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sunrise</th>
      <th>sunset</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>April</th>
      <td>2000-01-01 05:56:04.733333376</td>
      <td>2000-01-01 18:47:06.400000000</td>
    </tr>
    <tr>
      <th>June</th>
      <td>2000-01-01 05:23:43.100000000</td>
      <td>2000-01-01 19:19:44.866666624</td>
    </tr>
    <tr>
      <th>May</th>
      <td>2000-01-01 05:30:56.548387200</td>
      <td>2000-01-01 19:05:07.258064512</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sunrise_time</th>
      <th>sunset_time</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>April</th>
      <td>2022-12-10 05:56:04</td>
      <td>2022-12-10 18:47:06</td>
    </tr>
    <tr>
      <th>June</th>
      <td>2022-12-10 05:23:43</td>
      <td>2022-12-10 19:19:44</td>
    </tr>
    <tr>
      <th>May</th>
      <td>2022-12-10 05:30:56</td>
      <td>2022-12-10 19:05:07</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> indian-summer-over-the-years/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What were the top 3 hottest cities in terms of average temperature in 2021? Show the cities as a list.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>cities = df[(df.Date > datetime.strptime('2020-12-31', "%Y-%m-%d")) \
            & (df.Date < datetime.strptime('2022-01-01', "%Y-%m-%d"))]\
             [['City', 'temp']].groupby('City').mean()\
             .sort_values('temp', ascending=False).iloc[:3].index.to_list()
cities</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>cities = df[(df.Date > datetime.strptime('2020-12-31', "%Y-%m-%d")) \
            & (df.Date < datetime.strptime('2022-01-01', "%Y-%m-%d"))]\
             [['City', 'temp']].groupby('City').mean()\
             .sort_values('temp', ascending=False).iloc[:3].index.to_list()
cities</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>cities = df[(df.Date > datetime.strptime('2020-12-31', '%Y-%m-%d')) & (df.
    Date < datetime.strptime('2022-01-01', '%Y-%m-%d'))][['City', 'temp']
    ].groupby('City').mean().sort_values('temp', ascending=False).iloc[:3
    ].index.to_list()
__output__ = cities
</code></pre>
        <p><span onclick="$('#var_output_35adfc71').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_35adfc71" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Ahmedabad', 'Jaipur', 'Bhopal']</code></pre>
      
        <p><strong>Hyp output variables:</strong> cities, __output__ </p>
    
          <p>cities (list):</p>
          <pre><code>['Ahmedabad', 'Jaipur', 'Bhopal']</code></pre>
      
          <p>__output__ (list):</p>
          <pre><code>['Ahmedabad', 'Jaipur', 'Bhopal']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> indian-summer-over-the-years/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What did the temperature feel like on average in those cities? Show the temperature for each city.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.City.str.contains('|'.join(cities))][['City', 'feelslike']].groupby('City').mean().sort_values('feelslike',
                                                                                                     ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.City.str.contains('|'.join(cities))][['City', 'feelslike']].groupby('City').mean().sort_values('feelslike',
                                                                                                     ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.City.str.contains('|'.join(cities))][['City', 'feelslike']
    ].groupby('City').mean().sort_values('feelslike', ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_213cb047').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_213cb047" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feelslike</th>
    </tr>
    <tr>
      <th>City</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Ahmedabad</th>
      <td>36.126766</td>
    </tr>
    <tr>
      <th>Jaipur</th>
      <td>32.830537</td>
    </tr>
    <tr>
      <th>Bhopal</th>
      <td>32.309969</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feelslike</th>
    </tr>
    <tr>
      <th>City</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Ahmedabad</th>
      <td>36.126766</td>
    </tr>
    <tr>
      <th>Jaipur</th>
      <td>32.830537</td>
    </tr>
    <tr>
      <th>Bhopal</th>
      <td>32.309969</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> indian-summer-over-the-years/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which city was windiest in terms of median wind speed in 2019?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>windiest_city = df[df.Date.dt.year == 2019][
    ['City', 'windspeed']].groupby('City').median().sort_values('windspeed', ascending=False).iloc[0].name
windiest_city</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>windiest_city = df[df.Date.dt.year == 2019][
    ['City', 'windspeed']].groupby('City').median().sort_values('windspeed', ascending=False).iloc[0].name
windiest_city</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>windiest_city = df[df.Date.dt.year == 2019][['City', 'windspeed']].groupby(
    'City').median().sort_values('windspeed', ascending=False).iloc[0].name
__output__ = windiest_city
</code></pre>
        <p><span onclick="$('#var_output_e3eb7cdd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e3eb7cdd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Bhopal</code></pre>
      
        <p><strong>Hyp output variables:</strong> windiest_city, __output__ </p>
    
          <p>windiest_city (str):</p>
          <pre><code>Bhopal</code></pre>
      
          <p>__output__ (str):</p>
          <pre><code>Bhopal</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> indian-summer-over-the-years/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the average wind speed in that city in each year?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_y = df[df.City == windiest_city][['windspeed', 'Date']]
df_y['Year'] = df_y.Date.apply(lambda x: datetime.strftime(x, '%Y'))
df_y[['Year', 'windspeed']].groupby('Year').mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_y = df[df.City == windiest_city][['windspeed', 'Date']]
df_y['Year'] = df_y.Date.apply(lambda x: datetime.strftime(x, '%Y'))
df_y[['Year', 'windspeed']].groupby('Year').mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_y = df[df.City == windiest_city][['windspeed', 'Date']]
df_y['Year'] = df_y.Date.apply(lambda x: datetime.strftime(x, '%Y'))
__output__ = df_y[['Year', 'windspeed']].groupby('Year').mean()
</code></pre>
        <p><span onclick="$('#var_output_cc67cdf6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_cc67cdf6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>windspeed</th>
    </tr>
    <tr>
      <th>Year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2007</th>
      <td>28.518681</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>29.002198</td>
    </tr>
    <tr>
      <th>2009</th>
      <td>26.671429</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>29.120879</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>26.298901</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>24.958242</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>24.857143</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>25.163736</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>28.843956</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>31.170330</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>27.019780</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>27.261538</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>23.849451</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>26.734066</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_y, __output__ </p>
    
          <p>df_y (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>windspeed</th>
      <th>Date</th>
      <th>Year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>910</th>
      <td>22.3</td>
      <td>2021-04-01</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>911</th>
      <td>22.3</td>
      <td>2021-04-02</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>912</th>
      <td>11.2</td>
      <td>2021-04-03</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>913</th>
      <td>14.8</td>
      <td>2021-04-04</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>914</th>
      <td>18.3</td>
      <td>2021-04-05</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>915</th>
      <td>22.2</td>
      <td>2021-04-06</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>916</th>
      <td>29.5</td>
      <td>2021-04-07</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>5633</th>
      <td>22.3</td>
      <td>2007-06-24</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>5634</th>
      <td>27.7</td>
      <td>2007-06-25</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>5635</th>
      <td>27.7</td>
      <td>2007-06-26</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>5636</th>
      <td>37.1</td>
      <td>2007-06-27</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>5637</th>
      <td>33.5</td>
      <td>2007-06-28</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>5638</th>
      <td>9.4</td>
      <td>2007-06-29</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>5639</th>
      <td>25.9</td>
      <td>2007-06-30</td>
      <td>2007</td>
    </tr>
  </tbody>
</table>
<p>1274 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>windspeed</th>
    </tr>
    <tr>
      <th>Year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2007</th>
      <td>28.518681</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>29.002198</td>
    </tr>
    <tr>
      <th>2009</th>
      <td>26.671429</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>29.120879</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>26.298901</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>24.958242</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>24.857143</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>25.163736</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>28.843956</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>31.170330</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>27.019780</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>27.261538</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>23.849451</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>26.734066</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> indian-summer-over-the-years/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the least visible city in terms of average monthly visibility in each year?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_w = df.loc[:, ['visibility', 'Date', 'City']]
df_w['year'] = df_w['Date'].apply(lambda x: datetime.strftime(x, '%Y'))
df_w[['year', 'visibility', 'City']].sort_values('visibility').groupby('year').first()[['City']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_w = df.loc[:, ['visibility', 'Date', 'City']]
df_w['year'] = df_w['Date'].apply(lambda x: datetime.strftime(x, '%Y'))
df_w[['year', 'visibility', 'City']].sort_values('visibility').groupby('year').first()[['City']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_w = df.loc[:, ['visibility', 'Date', 'City']]
df_w['year'] = df_w['Date'].apply(lambda x: datetime.strftime(x, '%Y'))
__output__ = df_w[['year', 'visibility', 'City']].sort_values('visibility'
    ).groupby('year').first()[['City']]
</code></pre>
        <p><span onclick="$('#var_output_5ab43a08').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5ab43a08" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>City</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2007</th>
      <td>New Delhi</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>Jaipur</td>
    </tr>
    <tr>
      <th>2009</th>
      <td>Jaipur</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>New Delhi</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>Mumbai</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>New Delhi</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>Bhopal</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>New Delhi</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>Mumbai</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>Mumbai</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>Mumbai</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>New Delhi</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>Jaipur</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>Lucknow</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>Jaipur</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_w, __output__ </p>
    
          <p>df_w (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>visibility</th>
      <th>Date</th>
      <th>City</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.1</td>
      <td>2021-04-01</td>
      <td>New Delhi</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3.5</td>
      <td>2021-04-02</td>
      <td>New Delhi</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.5</td>
      <td>2021-04-03</td>
      <td>New Delhi</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.2</td>
      <td>2021-04-04</td>
      <td>New Delhi</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3.1</td>
      <td>2021-04-05</td>
      <td>New Delhi</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2.4</td>
      <td>2021-04-06</td>
      <td>New Delhi</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2.7</td>
      <td>2021-04-07</td>
      <td>New Delhi</td>
      <td>2021</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6725</th>
      <td>4.8</td>
      <td>2007-06-24</td>
      <td>Hyderabad</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>6726</th>
      <td>5.6</td>
      <td>2007-06-25</td>
      <td>Hyderabad</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>6727</th>
      <td>3.4</td>
      <td>2007-06-26</td>
      <td>Hyderabad</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>6728</th>
      <td>4.3</td>
      <td>2007-06-27</td>
      <td>Hyderabad</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>6729</th>
      <td>4.6</td>
      <td>2007-06-28</td>
      <td>Hyderabad</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>6730</th>
      <td>5.0</td>
      <td>2007-06-29</td>
      <td>Hyderabad</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>6731</th>
      <td>4.5</td>
      <td>2007-06-30</td>
      <td>Hyderabad</td>
      <td>2007</td>
    </tr>
  </tbody>
</table>
<p>20382 rows × 4 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>City</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2007</th>
      <td>New Delhi</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>Jaipur</td>
    </tr>
    <tr>
      <th>2009</th>
      <td>Jaipur</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>New Delhi</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>Mumbai</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>New Delhi</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>Bhopal</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>New Delhi</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>Mumbai</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>Mumbai</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>Mumbai</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>New Delhi</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>Jaipur</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>Lucknow</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>Jaipur</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> indian-summer-over-the-years/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which city had the most clear days in the summer of 2019?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df.Date.dt.year == 2019) & (df.conditions == 'Clear')][
    ['City', 'conditions']].groupby('City').count().sort_values('conditions').tail(1).index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df.Date.dt.year == 2019) & (df.conditions == 'Clear')][
    ['City', 'conditions']].groupby('City').count().sort_values('conditions').tail(1).index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df.Date.dt.year == 2019) & (df.conditions == 'Clear')][[
    'City', 'conditions']].groupby('City').count().sort_values('conditions'
    ).tail(1).index[0]
</code></pre>
        <p><span onclick="$('#var_output_c6bf4af8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c6bf4af8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Indore</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Indore</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> indian-summer-over-the-years/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many cloudy or partially cloudy days did each city experience in the summer of 2019?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df.Date.dt.year == 2019) & (df.conditions.str.contains('cloudy|Cloudy'))][
    ['City', 'conditions']].groupby('City').count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df.Date.dt.year == 2019) & (df.conditions.str.contains('cloudy|Cloudy'))][
    ['City', 'conditions']].groupby('City').count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df.Date.dt.year == 2019) & df.conditions.str.contains(
    'cloudy|Cloudy')][['City', 'conditions']].groupby('City').count()
</code></pre>
        <p><span onclick="$('#var_output_7ba9f47c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7ba9f47c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>conditions</th>
    </tr>
    <tr>
      <th>City</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bengaluru</th>
      <td>85</td>
    </tr>
    <tr>
      <th>Bhopal</th>
      <td>45</td>
    </tr>
    <tr>
      <th>Chennai</th>
      <td>88</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>182</td>
    </tr>
    <tr>
      <th>Indore</th>
      <td>34</td>
    </tr>
    <tr>
      <th>Jaipur</th>
      <td>71</td>
    </tr>
    <tr>
      <th>Kanpur</th>
      <td>36</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>88</td>
    </tr>
    <tr>
      <th>Lucknow</th>
      <td>37</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>69</td>
    </tr>
    <tr>
      <th>New Delhi</th>
      <td>46</td>
    </tr>
    <tr>
      <th>Patna</th>
      <td>50</td>
    </tr>
    <tr>
      <th>Pune</th>
      <td>46</td>
    </tr>
    <tr>
      <th>Surat</th>
      <td>40</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>conditions</th>
    </tr>
    <tr>
      <th>City</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bengaluru</th>
      <td>85</td>
    </tr>
    <tr>
      <th>Bhopal</th>
      <td>45</td>
    </tr>
    <tr>
      <th>Chennai</th>
      <td>88</td>
    </tr>
    <tr>
      <th>Hyderabad</th>
      <td>182</td>
    </tr>
    <tr>
      <th>Indore</th>
      <td>34</td>
    </tr>
    <tr>
      <th>Jaipur</th>
      <td>71</td>
    </tr>
    <tr>
      <th>Kanpur</th>
      <td>36</td>
    </tr>
    <tr>
      <th>Kolkata</th>
      <td>88</td>
    </tr>
    <tr>
      <th>Lucknow</th>
      <td>37</td>
    </tr>
    <tr>
      <th>Mumbai</th>
      <td>69</td>
    </tr>
    <tr>
      <th>New Delhi</th>
      <td>46</td>
    </tr>
    <tr>
      <th>Patna</th>
      <td>50</td>
    </tr>
    <tr>
      <th>Pune</th>
      <td>46</td>
    </tr>
    <tr>
      <th>Surat</th>
      <td>40</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rafael-nadal/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the most popular hashtag for each source? Show the tag and the number of mentions as seperate columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_y = df.loc[:, ['source', 'hashtags']].dropna()
df_y.hashtags = df_y.hashtags.apply(eval)
df_t = df_y[['source', 'hashtags']].explode('hashtags').groupby('source')
df_c = df_t.apply(lambda x: x.value_counts().idxmax()[-1])
df_c1 = df_t.apply(lambda x: x.value_counts().max())
pd.DataFrame({'Tag': df_c, 'Count': df_c1})</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_y = df.loc[:, ['source', 'hashtags']].dropna()
df_y.hashtags = df_y.hashtags.apply(eval)
df_t = df_y[['source', 'hashtags']].explode('hashtags').groupby('source')
df_c = df_t.apply(lambda x: x.value_counts().idxmax()[-1])
df_c1 = df_t.apply(lambda x: x.value_counts().max())
pd.DataFrame({'Tag': df_c, 'Count': df_c1})</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_y = df.loc[:, ['source', 'hashtags']].dropna()
df_y.hashtags = df_y.hashtags.apply(eval)
df_t = df_y[['source', 'hashtags']].explode('hashtags').groupby('source')
df_c = df_t.apply(lambda x: x.value_counts().idxmax()[-1])
df_c1 = df_t.apply(lambda x: x.value_counts().max())
__output__ = pd.DataFrame({'Tag': df_c, 'Count': df_c1})
</code></pre>
        <p><span onclick="$('#var_output_2ff9a670').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2ff9a670" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Tag</th>
      <th>Count</th>
    </tr>
    <tr>
      <th>source</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>50trends India</th>
      <td>RafaelNadal𓃵</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Ai News Room</th>
      <td>RafaelNadal𓃵</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Bot Sentinel</th>
      <td>RAFAELNADAL𓃵</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Buffer</th>
      <td>RafaelNadal𓃵</td>
      <td>2</td>
    </tr>
    <tr>
      <th>HubSpot</th>
      <td>RafaelNadal𓃵</td>
      <td>1</td>
    </tr>
    <tr>
      <th>IFTTT</th>
      <td>RafaelNadal𓃵</td>
      <td>2</td>
    </tr>
    <tr>
      <th>PostLo</th>
      <td>ShameOnBJP</td>
      <td>7</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Twitter for  iPhone</th>
      <td>FrenchOpen</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Twitter for Advertisers</th>
      <td>RafaelNadal𓃵</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Twitter for Android</th>
      <td>RafaelNadal𓃵</td>
      <td>2808</td>
    </tr>
    <tr>
      <th>Twitter for Mac</th>
      <td>RafaelNadal𓃵</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Twitter for iPad</th>
      <td>RafaelNadal𓃵</td>
      <td>97</td>
    </tr>
    <tr>
      <th>Twitter for iPhone</th>
      <td>RafaelNadal𓃵</td>
      <td>2573</td>
    </tr>
    <tr>
      <th>dailyindia</th>
      <td>India</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>19 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_y, df_c, df_c1, __output__ </p>
    
          <p>df_y (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>source</th>
      <th>hashtags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Twitter Web App</td>
      <td>[dappcensus, Airdrop, BNB, giveaway, Ethereum]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Twitter for iPhone</td>
      <td>[Djokovic]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Twitter for iPhone</td>
      <td>[VamosRafa, RafaelNadal𓃵]</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Twitter Web App</td>
      <td>[dappcensus, Airdrop, BNB, giveaway, Ethereum]</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Twitter for iPhone</td>
      <td>[RafaelNadal𓃵]</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Twitter for Android</td>
      <td>[Rafa]</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Twitter for iPhone</td>
      <td>[VamosRafa, RafaelNadal𓃵]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>8746</th>
      <td>Twitter for iPhone</td>
      <td>[RolandGarros, VamosRafa, RafaelNadal𓃵]</td>
    </tr>
    <tr>
      <th>8748</th>
      <td>Twitter Web App</td>
      <td>[RafaelNadal𓃵, JohnnyDepp]</td>
    </tr>
    <tr>
      <th>8750</th>
      <td>Twitter for iPhone</td>
      <td>[RolandGarros, Fernandez, Stephens, Alcaraz]</td>
    </tr>
    <tr>
      <th>8752</th>
      <td>Twitter for iPhone</td>
      <td>[VamosRafa]</td>
    </tr>
    <tr>
      <th>8754</th>
      <td>Twitter Web App</td>
      <td>[FrenchOpen, RolandGarros, RafaelNadal𓃵, NovakDjokovic, Tennis, ATP]</td>
    </tr>
    <tr>
      <th>8755</th>
      <td>Twitter for Android</td>
      <td>[VamosRafa, RafaelNadal𓃵, DjokovicNadal, NovakDjokovic]</td>
    </tr>
    <tr>
      <th>8758</th>
      <td>Twitter for Android</td>
      <td>[latestnews, RafaelNadal𓃵]</td>
    </tr>
  </tbody>
</table>
<p>6987 rows × 2 columns</p>
      
          <p>df_c (Series):</p>
          <pre><code>source
50trends India         RafaelNadal𓃵
Ai News Room           RafaelNadal𓃵
Bot Sentinel           RAFAELNADAL𓃵
Buffer                 RafaelNadal𓃵
HubSpot                RafaelNadal𓃵
                           ...     
Twitter for Android    RafaelNadal𓃵
Twitter for Mac        RafaelNadal𓃵
Twitter for iPad       RafaelNadal𓃵
Twitter for iPhone     RafaelNadal𓃵
dailyindia                    India
Length: 19, dtype: object</code></pre>
      
          <p>df_c1 (Series):</p>
          <pre><code>source
50trends India            1
Ai News Room              1
Bot Sentinel              1
Buffer                    2
HubSpot                   1
                       ... 
Twitter for Android    2808
Twitter for Mac           5
Twitter for iPad         97
Twitter for iPhone     2573
dailyindia                1
Length: 19, dtype: int64</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Tag</th>
      <th>Count</th>
    </tr>
    <tr>
      <th>source</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>50trends India</th>
      <td>RafaelNadal𓃵</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Ai News Room</th>
      <td>RafaelNadal𓃵</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Bot Sentinel</th>
      <td>RAFAELNADAL𓃵</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Buffer</th>
      <td>RafaelNadal𓃵</td>
      <td>2</td>
    </tr>
    <tr>
      <th>HubSpot</th>
      <td>RafaelNadal𓃵</td>
      <td>1</td>
    </tr>
    <tr>
      <th>IFTTT</th>
      <td>RafaelNadal𓃵</td>
      <td>2</td>
    </tr>
    <tr>
      <th>PostLo</th>
      <td>ShameOnBJP</td>
      <td>7</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Twitter for  iPhone</th>
      <td>FrenchOpen</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Twitter for Advertisers</th>
      <td>RafaelNadal𓃵</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Twitter for Android</th>
      <td>RafaelNadal𓃵</td>
      <td>2808</td>
    </tr>
    <tr>
      <th>Twitter for Mac</th>
      <td>RafaelNadal𓃵</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Twitter for iPad</th>
      <td>RafaelNadal𓃵</td>
      <td>97</td>
    </tr>
    <tr>
      <th>Twitter for iPhone</th>
      <td>RafaelNadal𓃵</td>
      <td>2573</td>
    </tr>
    <tr>
      <th>dailyindia</th>
      <td>India</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>19 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.2, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rafael-nadal/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # In how many tweets are there mentions?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pattern = r'\B@(?!(?:[a-z0-9.]*_){2})(?!(?:[a-z0-9_]*\.){2})[._a-z0-9]{3,24}\b'
find_mentions = lambda x: [mention[1:] for mention in re.findall(pattern, x)]
mentions = df.text.apply(find_mentions).apply(lambda x: x if x else None)
len(mentions.dropna())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pattern = r'\B@(?!(?:[a-z0-9.]*_){2})(?!(?:[a-z0-9_]*\.){2})[._a-z0-9]{3,24}\b'
find_mentions = lambda x: [mention[1:] for mention in re.findall(pattern, x)]
mentions = df.text.apply(find_mentions).apply(lambda x: x if x else None)
len(mentions.dropna())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>pattern = (
    '\\B@(?!(?:[a-z0-9.]*_){2})(?!(?:[a-z0-9_]*\\.){2})[._a-z0-9]{3,24}\\b')
find_mentions = lambda x: [mention[1:] for mention in re.findall(pattern, x)]
mentions = df.text.apply(find_mentions).apply(lambda x: x if x else None)
__output__ = len(mentions.dropna())
</code></pre>
        <p><span onclick="$('#var_output_9b985a6c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9b985a6c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>1161</code></pre>
      
        <p><strong>Hyp output variables:</strong> pattern, mentions, __output__ </p>
    
          <p>pattern (str):</p>
          <pre><code>\B@(?!(?:[a-z0-9.]*_){2})(?!(?:[a-z0-9_]*\.){2})[._a-z0-9]{3,24}\b</code></pre>
      
          <p>mentions (Series):</p>
          <pre><code>0                [linhair8, lamairdrop2]
1                                   None
2                                   None
3             [loknathray173, ranak3178]
4       [neeteshb, 87vintage, nadalprop]
                      ...               
8754                                None
8755                                None
8756                                None
8757           [toisports, rolandgarros]
8758                                None
Name: text, Length: 8759, dtype: object</code></pre>
      
          <p>__output__ (int):</p>
          <pre><code>1161</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rafael-nadal/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many of tweets have both hashtags and mentions?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>hashtags = df.loc[mentions.dropna().index].hashtags.dropna().apply(eval).apply(lambda x: x if x else None)
len(hashtags.dropna())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>hashtags = df.loc[mentions.dropna().index].hashtags.dropna().apply(eval).apply(lambda x: x if x else None)
len(hashtags.dropna())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>hashtags = df.loc[mentions.dropna().index].hashtags.dropna().apply(eval).apply(
    lambda x: x if x else None)
__output__ = len(hashtags.dropna())
</code></pre>
        <p><span onclick="$('#var_output_57cd50dc').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_57cd50dc" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>752</code></pre>
      
        <p><strong>Hyp output variables:</strong> hashtags, __output__ </p>
    
          <p>hashtags (Series):</p>
          <pre><code>0          [dappcensus, Airdrop, BNB, giveaway, Ethereum]
4                                              [Djokovic]
7          [dappcensus, Airdrop, BNB, giveaway, Ethereum]
16                                  [RafaelNadal𓃵, GOAT𓃵]
23                                         [RafaelNadal𓃵]
                              ...                        
8733    [NHLPlayoffs, NoQuitInNY, TakeWarning, Game7, ...
8740                                       [RafaelNadal𓃵]
8745                            [VamosRafa, RafaelNadal𓃵]
8748                           [RafaelNadal𓃵, JohnnyDepp]
8752                                          [VamosRafa]
Name: hashtags, Length: 752, dtype: object</code></pre>
      
          <p>__output__ (int):</p>
          <pre><code>752</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rafael-nadal/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What hashtag appeared in the most tweets?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>hashtag_set = df.hashtags.dropna().apply(eval).apply(set)
Counter(hashtag_set.explode()).most_common(1)[0][0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>hashtag_set = df.hashtags.dropna().apply(eval).apply(set)
Counter(hashtag_set.explode()).most_common(1)[0][0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>hashtag_set = df.hashtags.dropna().apply(eval).apply(set)
__output__ = Counter(hashtag_set.explode()).most_common(1)[0][0]
</code></pre>
        <p><span onclick="$('#var_output_b639b4ba').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b639b4ba" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>RafaelNadal𓃵</code></pre>
      
        <p><strong>Hyp output variables:</strong> hashtag_set, __output__ </p>
    
          <p>hashtag_set (Series):</p>
          <pre><code>0          {giveaway, Airdrop, dappcensus, BNB, Ethereum}
4                                              {Djokovic}
5                               {RafaelNadal𓃵, VamosRafa}
7          {giveaway, Airdrop, dappcensus, BNB, Ethereum}
8                                          {RafaelNadal𓃵}
                              ...                        
8750         {Fernandez, Stephens, Alcaraz, RolandGarros}
8752                                          {VamosRafa}
8754    {RafaelNadal𓃵, ATP, Tennis, NovakDjokovic, Fre...
8755    {RafaelNadal𓃵, DjokovicNadal, VamosRafa, Novak...
8758                           {RafaelNadal𓃵, latestnews}
Name: hashtags, Length: 6987, dtype: object</code></pre>
      
          <p>__output__ (str):</p>
          <pre><code>RafaelNadal𓃵</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rafael-nadal/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Who is mentioned the most and how many times was he mentioned? Show the result as a tuple.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>mentions_set = mentions.dropna().apply(set)
Counter(mentions_set.explode()).most_common(1)[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>mentions_set = mentions.dropna().apply(set)
Counter(mentions_set.explode()).most_common(1)[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>mentions_set = mentions.dropna().apply(set)
__output__ = Counter(mentions_set.explode()).most_common(1)[0]
</code></pre>
        <p><span onclick="$('#var_output_da5b73b2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_da5b73b2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (tuple):</p>
          <pre><code>('rolandgarros', 588)</code></pre>
      
        <p><strong>Hyp output variables:</strong> mentions_set, __output__ </p>
    
          <p>mentions_set (Series):</p>
          <pre><code>0                {lamairdrop2, linhair8}
3             {loknathray173, ranak3178}
4       {neeteshb, 87vintage, nadalprop}
7                         {quanairdrop1}
10                        {trickyboy555}
                      ...               
8743                      {rolandgarros}
8745                   {corinnedubreuil}
8748                   {corinnedubreuil}
8752                   {corinnedubreuil}
8757           {rolandgarros, toisports}
Name: text, Length: 1161, dtype: object</code></pre>
      
          <p>__output__ (tuple):</p>
          <pre><code>('rolandgarros', 588)</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rafael-nadal/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the median time difference between posting a tweet and creating profile?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_t = df.loc[:, ['date', 'user_created']]

df_t['timediff'] = df_t.date.apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\
    - df_t.user_created.apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))
df_t.timediff.median()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_t = df.loc[:, ['date', 'user_created']]

df_t['timediff'] = df_t.date.apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\
    - df_t.user_created.apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))
df_t.timediff.median()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_t = df.loc[:, ['date', 'user_created']]
df_t['timediff'] = df_t.date.apply(lambda x: datetime.strptime(x,
    '%Y-%m-%d %H:%M:%S')) - df_t.user_created.apply(lambda x: datetime.
    strptime(x, '%Y-%m-%d %H:%M:%S'))
__output__ = df_t.timediff.median()
</code></pre>
        <p><span onclick="$('#var_output_70004424').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_70004424" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Timedelta):</p>
          <pre><code>3034 days 17:04:24</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_t, __output__ </p>
    
          <p>df_t (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>user_created</th>
      <th>timediff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2022-06-08 17:02:44</td>
      <td>2021-11-26 07:07:47</td>
      <td>194 days 09:54:57</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2022-06-08 16:52:04</td>
      <td>2009-03-22 16:29:58</td>
      <td>4826 days 00:22:06</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2022-06-08 16:43:24</td>
      <td>2019-05-17 16:33:12</td>
      <td>1118 days 00:10:12</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2022-06-08 16:39:26</td>
      <td>2020-08-28 08:56:58</td>
      <td>649 days 07:42:28</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2022-06-08 16:35:21</td>
      <td>2012-06-08 09:23:24</td>
      <td>3652 days 07:11:57</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2022-06-08 16:20:39</td>
      <td>2013-12-25 20:42:16</td>
      <td>3086 days 19:38:23</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2022-06-08 16:09:55</td>
      <td>2013-12-25 20:42:16</td>
      <td>3086 days 19:27:39</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>8752</th>
      <td>2022-05-31 05:49:07</td>
      <td>2021-04-11 00:37:54</td>
      <td>415 days 05:11:13</td>
    </tr>
    <tr>
      <th>8753</th>
      <td>2022-05-31 04:41:21</td>
      <td>2009-04-29 19:18:11</td>
      <td>4779 days 09:23:10</td>
    </tr>
    <tr>
      <th>8754</th>
      <td>2022-05-31 03:52:03</td>
      <td>2008-12-17 13:25:46</td>
      <td>4912 days 14:26:17</td>
    </tr>
    <tr>
      <th>8755</th>
      <td>2022-05-31 02:48:44</td>
      <td>2018-10-24 09:44:29</td>
      <td>1314 days 17:04:15</td>
    </tr>
    <tr>
      <th>8756</th>
      <td>2022-05-31 02:21:39</td>
      <td>2020-03-09 18:34:15</td>
      <td>812 days 07:47:24</td>
    </tr>
    <tr>
      <th>8757</th>
      <td>2022-05-31 02:18:41</td>
      <td>2020-03-09 18:34:15</td>
      <td>812 days 07:44:26</td>
    </tr>
    <tr>
      <th>8758</th>
      <td>2022-05-31 01:53:19</td>
      <td>2015-05-27 05:34:06</td>
      <td>2560 days 20:19:13</td>
    </tr>
  </tbody>
</table>
<p>8759 rows × 3 columns</p>
      
          <p>__output__ (Timedelta):</p>
          <pre><code>3034 days 17:04:24</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rafael-nadal/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For which user was this duration the shortest?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_t = df_t.join(df.loc[:, ['user_name']])

df_t.sort_values('timediff').iloc[0]['user_name']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_t = df_t.join(df.loc[:, ['user_name']])

df_t.sort_values('timediff').iloc[0]['user_name']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_t = df_t.join(df.loc[:, ['user_name']])
__output__ = df_t.sort_values('timediff').iloc[0]['user_name']
</code></pre>
        <p><span onclick="$('#var_output_70d3b109').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_70d3b109" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>myrtle oconnor</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_t, __output__ </p>
    
          <p>df_t (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>user_created</th>
      <th>timediff</th>
      <th>user_name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2022-06-08 17:02:44</td>
      <td>2021-11-26 07:07:47</td>
      <td>194 days 09:54:57</td>
      <td>Nong Nhat Minh</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2022-06-08 16:52:04</td>
      <td>2009-03-22 16:29:58</td>
      <td>4826 days 00:22:06</td>
      <td>Peter Ndoro</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2022-06-08 16:43:24</td>
      <td>2019-05-17 16:33:12</td>
      <td>1118 days 00:10:12</td>
      <td>Gurpreet Singh</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2022-06-08 16:39:26</td>
      <td>2020-08-28 08:56:58</td>
      <td>649 days 07:42:28</td>
      <td>💯 Earning Tips💰💰</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2022-06-08 16:35:21</td>
      <td>2012-06-08 09:23:24</td>
      <td>3652 days 07:11:57</td>
      <td>ahs</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2022-06-08 16:20:39</td>
      <td>2013-12-25 20:42:16</td>
      <td>3086 days 19:38:23</td>
      <td>TroubleFault</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2022-06-08 16:09:55</td>
      <td>2013-12-25 20:42:16</td>
      <td>3086 days 19:27:39</td>
      <td>TroubleFault</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>8752</th>
      <td>2022-05-31 05:49:07</td>
      <td>2021-04-11 00:37:54</td>
      <td>415 days 05:11:13</td>
      <td>DQ-Poa</td>
    </tr>
    <tr>
      <th>8753</th>
      <td>2022-05-31 04:41:21</td>
      <td>2009-04-29 19:18:11</td>
      <td>4779 days 09:23:10</td>
      <td>Nadal King Of Courts 🇩🇰</td>
    </tr>
    <tr>
      <th>8754</th>
      <td>2022-05-31 03:52:03</td>
      <td>2008-12-17 13:25:46</td>
      <td>4912 days 14:26:17</td>
      <td>myKhel.com</td>
    </tr>
    <tr>
      <th>8755</th>
      <td>2022-05-31 02:48:44</td>
      <td>2018-10-24 09:44:29</td>
      <td>1314 days 17:04:15</td>
      <td>Deepu☀️</td>
    </tr>
    <tr>
      <th>8756</th>
      <td>2022-05-31 02:21:39</td>
      <td>2020-03-09 18:34:15</td>
      <td>812 days 07:47:24</td>
      <td>Leslie Geddes</td>
    </tr>
    <tr>
      <th>8757</th>
      <td>2022-05-31 02:18:41</td>
      <td>2020-03-09 18:34:15</td>
      <td>812 days 07:44:26</td>
      <td>Leslie Geddes</td>
    </tr>
    <tr>
      <th>8758</th>
      <td>2022-05-31 01:53:19</td>
      <td>2015-05-27 05:34:06</td>
      <td>2560 days 20:19:13</td>
      <td>Pragativadi</td>
    </tr>
  </tbody>
</table>
<p>8759 rows × 4 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>myrtle oconnor</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rafael-nadal/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the median number of followers of unverified users and verified ones.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_user = df[['user_followers', 'user_verified']]
df_user.groupby('user_verified').median()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_user = df[['user_followers', 'user_verified']]
df_user.groupby('user_verified').median()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_user = df[['user_followers', 'user_verified']]
__output__ = df_user.groupby('user_verified').median()
</code></pre>
        <p><span onclick="$('#var_output_11b6f5ab').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_11b6f5ab" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_followers</th>
    </tr>
    <tr>
      <th>user_verified</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>False</th>
      <td>232.0</td>
    </tr>
    <tr>
      <th>True</th>
      <td>22837.0</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_user, __output__ </p>
    
          <p>df_user (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_followers</th>
      <th>user_verified</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>20</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>279853</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>61</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>115</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>35</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5982</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>5982</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>8752</th>
      <td>181</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8753</th>
      <td>584</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8754</th>
      <td>10882</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8755</th>
      <td>11</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8756</th>
      <td>16</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8757</th>
      <td>16</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8758</th>
      <td>22314</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>8759 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_followers</th>
    </tr>
    <tr>
      <th>user_verified</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>False</th>
      <td>232.0</td>
    </tr>
    <tr>
      <th>True</th>
      <td>22837.0</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rafael-nadal/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most popular source among verified users?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.user_verified].source.value_counts().index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.user_verified].source.value_counts().index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.user_verified].source.value_counts().index[0]
</code></pre>
        <p><span onclick="$('#var_output_5757bcfc').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5757bcfc" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Twitter for iPhone</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Twitter for iPhone</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rafael-nadal/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the longest tweet in terms of wordcount? Show the contents of that tweet.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_word = df.loc[:, ['text']]
df_word['word_count'] = df_word.text.apply(lambda x: len(re.findall(r'\w+', x)))
df_word.sort_values('word_count', ascending=False).head(1).text.values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_word = df.loc[:, ['text']]
df_word['word_count'] = df_word.text.apply(lambda x: len(re.findall(r'\w+', x)))
df_word.sort_values('word_count', ascending=False).head(1).text.values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_word = df.loc[:, ['text']]
df_word['word_count'] = df_word.text.apply(lambda x: len(re.findall('\\w+', x))
    )
__output__ = df_word.sort_values('word_count', ascending=False).head(1
    ).text.values[0]
</code></pre>
        <p><span onclick="$('#var_output_e1414d35').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e1414d35" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>It's Close to 23:00hrs I better call it night since I've been awake all night watching My #RafaelNadal𓃵 Play n Beat DJ in d #FrenchOpen n then Directly to Work n Back 
Stay Warm n Safe Sleep Well 
@allforunited 
PS- will hv loads of notifications tomorrow 4 d SO's I'm in today😉 https://t.co/jrO1MclJ46</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_word, __output__ </p>
    
          <p>df_word (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>word_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>@DappCensus Nice project. @linhair8 @LongAirdrop @lamairdrop2 \n#dappcensus #Airdrop #BNB #giveaway #Ethereum #Ukraine #RafaelNadal𓃵 #RafaelNadal #r4today #BTSAtWhiteHouse</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The champions are being born everyday. They are fans one day and then they are your biggest rivals in competition #RafaelNadal𓃵  #RogerFederer https://t.co/02xnWuHymu</td>
      <td>26</td>
    </tr>
    <tr>
      <th>2</th>
      <td>@DappCensus 🤩\n Successful in 2022\nBig profitable\n@Baljit577 @Gaggu37084638\n@Seepu84 @Gumnam_199\n@AfzalWind786\n\n#dappcensus #Airdrop #BNB #giveaway #Ethereum #Ukraine #RafaelNadal𓃵 #RafaelNadal #r4today #BTSAtWhiteHouse</td>
      <td>21</td>
    </tr>
    <tr>
      <th>3</th>
      <td>@DappCensus This is very huge and great project and team is wonderful thnku so much for this great opportunity 🚀🚀 \n@loknathray173 @ranak3178\n@BipulRo50180205\n\n#dappcensus #Airdrop #BNB #giveaway #Ethereum #Ukraine #RafaelNadal𓃵 #RafaelNadal #r4today #BTSAtWhiteHouse</td>
      <td>32</td>
    </tr>
    <tr>
      <th>4</th>
      <td>@neeteshb @RajKumarMUFC @87vintage @nadalprop With 50% GS on his surface 2 GS per year #Djokovic able to win 12 #RafaelNadal𓃵 winning 14 on his favourite surface which is 1 in year \nWhat would have happened if there were 2 GS  on clay</td>
      <td>42</td>
    </tr>
    <tr>
      <th>5</th>
      <td>In case you forgot where to find it @Eastwoo87166350 📍\n\n#VamosRafa #RafaelNadal𓃵 https://t.co/iQ7kadWts5</td>
      <td>15</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Thanks for exposing one of your burner accounts, but this is cheating @Eastwoo87166350\n\nGo back to the other thread where you were threatening to harass me forever just because I like Rafa Nadal \n\nYou were doing great work promoting the hashtags there \n\n#VamosRafa #RafaelNadal𓃵 https://t.co/uive7hFeem</td>
      <td>48</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>8752</th>
      <td>We know, champ, we know. And we’re gonna be right there, by your side, until the last point and beyond #VamosRafa #RafaelNadal𓃵 [📷: @corinnedubreuil ] https://t.co/TRALwMrFQG</td>
      <td>28</td>
    </tr>
    <tr>
      <th>8753</th>
      <td>Good morning everyone. \nThanks for your positive vibes 🆒\nToday is the day. It will be one tough match, but we can guarantee you one thing #RafaelNadal𓃵 WE WILL CHEER WHILE YOU FIGHT TO THE END - THAT IS FOR SURE 💪🏼🇪🇸♥️#vamos #believe #fight #youvegotthis #tonitaughtyou https://t.co/O6czTJ5rgR</td>
      <td>48</td>
    </tr>
    <tr>
      <th>8754</th>
      <td>Who'll win the big battle beyond the baseline tonight? #FrenchOpen #RolandGarros #RafaelNadal𓃵 #NovakDjokovic #Tennis #ATP</td>
      <td>16</td>
    </tr>
    <tr>
      <th>8755</th>
      <td>Blockbuster QF so excited\n#VamosRafa #RafaelNadal𓃵 #DjokovicNadal #NovakDjokovic https://t.co/lNC3ArZ9d0</td>
      <td>12</td>
    </tr>
    <tr>
      <th>8756</th>
      <td>@RafaelNadal Vamos Rafa! Gracias for all the joy you bring to us- an honour to cheer you on always and no matter what.  Incomparable! Most thrilling, humble and best player on this planet. Ever🇪🇸💪❤️👑🔥🍀#VamosRafa #RafaelNadal𓃵</td>
      <td>36</td>
    </tr>
    <tr>
      <th>8757</th>
      <td>@toisports @RafaelNadal @DjokerNole @rolandgarros Night or Day, Hot or Cold - Vamos Rafa siempre! An honour to cheer you on Always and no matter what! #RafaelNadal𓃵 👑🇪🇸💪❤️🔥🍀</td>
      <td>25</td>
    </tr>
    <tr>
      <th>8758</th>
      <td>Rafael Nadal's French Open Quarter-Final With Novak Djokovic Gets Night Session\n\n#latestnews #RafaelNadal𓃵 #NovakDjokovic #FrenchOpen #SportsNews \n\nhttps://t.co/9hZB2lxUJf</td>
      <td>22</td>
    </tr>
  </tbody>
</table>
<p>8759 rows × 2 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>It's Close to 23:00hrs I better call it night since I've been awake all night watching My #RafaelNadal𓃵 Play n Beat DJ in d #FrenchOpen n then Directly to Work n Back 
Stay Warm n Safe Sleep Well 
@allforunited 
PS- will hv loads of notifications tomorrow 4 d SO's I'm in today😉 https://t.co/jrO1MclJ46</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> toronto-bus-delay-2022/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the mean delay on route 35 for each month? Sort the months in chronological order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_35 = df[df.Route=='35'][['Date', 'Min Delay']]
df_35['month'] = df.Date.apply(lambda x: datetime.strftime(datetime.strptime(x, '%d-%b-%y'), "%B"))
df_35[['Min Delay', 'month']].groupby('month').mean().loc[['January', 'February', 'March', 'April', 'May'], :]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_35 = df[df.Route=='35'][['Date', 'Min Delay']]
df_35['month'] = df.Date.apply(lambda x: datetime.strftime(datetime.strptime(x, '%d-%b-%y'), "%B"))
df_35[['Min Delay', 'month']].groupby('month').mean().loc[['January', 'February', 'March', 'April', 'May'], :]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_35 = df[df.Route == '35'][['Date', 'Min Delay']]
df_35['month'] = df.Date.apply(lambda x: datetime.strftime(datetime.
    strptime(x, '%d-%b-%y'), '%B'))
__output__ = df_35[['Min Delay', 'month']].groupby('month').mean().loc[[
    'January', 'February', 'March', 'April', 'May'], :]
</code></pre>
        <p><span onclick="$('#var_output_23150591').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_23150591" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>January</th>
      <td>11.172414</td>
    </tr>
    <tr>
      <th>February</th>
      <td>13.621951</td>
    </tr>
    <tr>
      <th>March</th>
      <td>10.741573</td>
    </tr>
    <tr>
      <th>April</th>
      <td>11.608108</td>
    </tr>
    <tr>
      <th>May</th>
      <td>9.523077</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_35, __output__ </p>
    
          <p>df_35 (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Min Delay</th>
      <th>month</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>27</th>
      <td>1-Jan-22</td>
      <td>10</td>
      <td>January</td>
    </tr>
    <tr>
      <th>155</th>
      <td>2-Jan-22</td>
      <td>30</td>
      <td>January</td>
    </tr>
    <tr>
      <th>224</th>
      <td>2-Jan-22</td>
      <td>8</td>
      <td>January</td>
    </tr>
    <tr>
      <th>237</th>
      <td>2-Jan-22</td>
      <td>8</td>
      <td>January</td>
    </tr>
    <tr>
      <th>248</th>
      <td>2-Jan-22</td>
      <td>8</td>
      <td>January</td>
    </tr>
    <tr>
      <th>255</th>
      <td>2-Jan-22</td>
      <td>8</td>
      <td>January</td>
    </tr>
    <tr>
      <th>359</th>
      <td>3-Jan-22</td>
      <td>79</td>
      <td>January</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>27190</th>
      <td>30-Jun-22</td>
      <td>8</td>
      <td>June</td>
    </tr>
    <tr>
      <th>27197</th>
      <td>30-Jun-22</td>
      <td>9</td>
      <td>June</td>
    </tr>
    <tr>
      <th>27198</th>
      <td>30-Jun-22</td>
      <td>9</td>
      <td>June</td>
    </tr>
    <tr>
      <th>27227</th>
      <td>30-Jun-22</td>
      <td>18</td>
      <td>June</td>
    </tr>
    <tr>
      <th>27262</th>
      <td>30-Jun-22</td>
      <td>10</td>
      <td>June</td>
    </tr>
    <tr>
      <th>27287</th>
      <td>30-Jun-22</td>
      <td>10</td>
      <td>June</td>
    </tr>
    <tr>
      <th>27341</th>
      <td>30-Jun-22</td>
      <td>9</td>
      <td>June</td>
    </tr>
  </tbody>
</table>
<p>593 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>January</th>
      <td>11.172414</td>
    </tr>
    <tr>
      <th>February</th>
      <td>13.621951</td>
    </tr>
    <tr>
      <th>March</th>
      <td>10.741573</td>
    </tr>
    <tr>
      <th>April</th>
      <td>11.608108</td>
    </tr>
    <tr>
      <th>May</th>
      <td>9.523077</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> toronto-bus-delay-2022/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What were the top 10 most delayed routes in terms of total delay?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>route = df.groupby(df['Route'])['Min Delay'].sum().reset_index()
route_10_del = route.sort_values(by = ['Min Delay'], ascending = False).head(10).set_index('Route')
route_10_del</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>route = df.groupby(df['Route'])['Min Delay'].sum().reset_index()
route_10_del = route.sort_values(by = ['Min Delay'], ascending = False).head(10).set_index('Route')
route_10_del</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>route = df.groupby(df['Route'])['Min Delay'].sum().reset_index()
route_10_del = route.sort_values(by=['Min Delay'], ascending=False).head(10
    ).set_index('Route')
__output__ = route_10_del
</code></pre>
        <p><span onclick="$('#var_output_92b0b353').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_92b0b353" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Route</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>52</th>
      <td>15459</td>
    </tr>
    <tr>
      <th>36</th>
      <td>12728</td>
    </tr>
    <tr>
      <th>32</th>
      <td>12408</td>
    </tr>
    <tr>
      <th>97</th>
      <td>11088</td>
    </tr>
    <tr>
      <th>29</th>
      <td>11075</td>
    </tr>
    <tr>
      <th>96</th>
      <td>10246</td>
    </tr>
    <tr>
      <th>54</th>
      <td>8769</td>
    </tr>
    <tr>
      <th>47</th>
      <td>8504</td>
    </tr>
    <tr>
      <th>63</th>
      <td>8465</td>
    </tr>
    <tr>
      <th>14</th>
      <td>8384</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> route, route_10_del, __output__ </p>
    
          <p>route (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Route</th>
      <th>Min Delay</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>214</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10</td>
      <td>1138</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100</td>
      <td>3266</td>
    </tr>
    <tr>
      <th>3</th>
      <td>101</td>
      <td>477</td>
    </tr>
    <tr>
      <th>4</th>
      <td>102</td>
      <td>6427</td>
    </tr>
    <tr>
      <th>5</th>
      <td>104</td>
      <td>2680</td>
    </tr>
    <tr>
      <th>6</th>
      <td>105</td>
      <td>1235</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>216</th>
      <td>99</td>
      <td>217</td>
    </tr>
    <tr>
      <th>217</th>
      <td>995</td>
      <td>902</td>
    </tr>
    <tr>
      <th>218</th>
      <td>996</td>
      <td>2017</td>
    </tr>
    <tr>
      <th>219</th>
      <td>999</td>
      <td>63</td>
    </tr>
    <tr>
      <th>220</th>
      <td>A242</td>
      <td>0</td>
    </tr>
    <tr>
      <th>221</th>
      <td>OTC</td>
      <td>26</td>
    </tr>
    <tr>
      <th>222</th>
      <td>RAD</td>
      <td>12</td>
    </tr>
  </tbody>
</table>
<p>223 rows × 2 columns</p>
      
          <p>route_10_del (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Route</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>52</th>
      <td>15459</td>
    </tr>
    <tr>
      <th>36</th>
      <td>12728</td>
    </tr>
    <tr>
      <th>32</th>
      <td>12408</td>
    </tr>
    <tr>
      <th>97</th>
      <td>11088</td>
    </tr>
    <tr>
      <th>29</th>
      <td>11075</td>
    </tr>
    <tr>
      <th>96</th>
      <td>10246</td>
    </tr>
    <tr>
      <th>54</th>
      <td>8769</td>
    </tr>
    <tr>
      <th>47</th>
      <td>8504</td>
    </tr>
    <tr>
      <th>63</th>
      <td>8465</td>
    </tr>
    <tr>
      <th>14</th>
      <td>8384</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Route</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>52</th>
      <td>15459</td>
    </tr>
    <tr>
      <th>36</th>
      <td>12728</td>
    </tr>
    <tr>
      <th>32</th>
      <td>12408</td>
    </tr>
    <tr>
      <th>97</th>
      <td>11088</td>
    </tr>
    <tr>
      <th>29</th>
      <td>11075</td>
    </tr>
    <tr>
      <th>96</th>
      <td>10246</td>
    </tr>
    <tr>
      <th>54</th>
      <td>8769</td>
    </tr>
    <tr>
      <th>47</th>
      <td>8504</td>
    </tr>
    <tr>
      <th>63</th>
      <td>8465</td>
    </tr>
    <tr>
      <th>14</th>
      <td>8384</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> toronto-bus-delay-2022/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the total delay for each type of incident on route 54? Sort in descending order of the delay.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_54 = df.loc[df['Route'] == '54']
df_54_del = df.groupby(['Incident'])['Min Delay'].sum().reset_index().sort_values(by = ['Min Delay'], ascending = False)
df_54_del</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_54 = df.loc[df['Route'] == '54']
df_54_del = df.groupby(['Incident'])['Min Delay'].sum().reset_index().sort_values(by = ['Min Delay'], ascending = False)
df_54_del</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_54 = df.loc[df['Route'] == '54']
df_54_del = df.groupby(['Incident'])['Min Delay'].sum().reset_index(
    ).sort_values(by=['Min Delay'], ascending=False)
__output__ = df_54_del
</code></pre>
        <p><span onclick="$('#var_output_b21d7c2a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b21d7c2a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Incident</th>
      <th>Min Delay</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>Diversion</td>
      <td>157108</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Operations - Operator</td>
      <td>130990</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Mechanical</td>
      <td>105045</td>
    </tr>
    <tr>
      <th>5</th>
      <td>General Delay</td>
      <td>40714</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Road Blocked - NON-TTC Collision</td>
      <td>23692</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Security</td>
      <td>21881</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Collision - TTC</td>
      <td>21371</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Utilized Off Route</td>
      <td>13231</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Emergency Services</td>
      <td>12856</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Held By</td>
      <td>9724</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Cleaning - Unsanitary</td>
      <td>8519</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Investigation</td>
      <td>4808</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Vision</td>
      <td>4288</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Cleaning - Disinfection</td>
      <td>527</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Late Entering Service</td>
      <td>428</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_54, df_54_del, __output__ </p>
    
          <p>df_54 (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Route</th>
      <th>Time</th>
      <th>Day</th>
      <th>Location</th>
      <th>Incident</th>
      <th>Min Delay</th>
      <th>Min Gap</th>
      <th>Direction</th>
      <th>Vehicle</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>48</th>
      <td>1-Jan-22</td>
      <td>54</td>
      <td>10:21</td>
      <td>Saturday</td>
      <td>LAWRENCE RT STATION</td>
      <td>Operations - Operator</td>
      <td>16</td>
      <td>32</td>
      <td>E</td>
      <td>8689</td>
    </tr>
    <tr>
      <th>331</th>
      <td>3-Jan-22</td>
      <td>54</td>
      <td>06:33</td>
      <td>Monday</td>
      <td>LAWRENCE AND KENNEDY</td>
      <td>Mechanical</td>
      <td>5</td>
      <td>10</td>
      <td>W</td>
      <td>8736</td>
    </tr>
    <tr>
      <th>335</th>
      <td>3-Jan-22</td>
      <td>54</td>
      <td>06:37</td>
      <td>Monday</td>
      <td>LAWRENCE AND DON MILLS</td>
      <td>Mechanical</td>
      <td>5</td>
      <td>10</td>
      <td>E</td>
      <td>8625</td>
    </tr>
    <tr>
      <th>357</th>
      <td>3-Jan-22</td>
      <td>54</td>
      <td>07:33</td>
      <td>Monday</td>
      <td>LAWRENCE AND KENNEDY</td>
      <td>Mechanical</td>
      <td>5</td>
      <td>10</td>
      <td>W</td>
      <td>8736</td>
    </tr>
    <tr>
      <th>370</th>
      <td>3-Jan-22</td>
      <td>54</td>
      <td>08:50</td>
      <td>Monday</td>
      <td>STARSPRAY LOOP AND LAW</td>
      <td>Collision - TTC</td>
      <td>10</td>
      <td>20</td>
      <td>W</td>
      <td>8692</td>
    </tr>
    <tr>
      <th>474</th>
      <td>3-Jan-22</td>
      <td>54</td>
      <td>15:46</td>
      <td>Monday</td>
      <td>EGLINTON STATION</td>
      <td>Operations - Operator</td>
      <td>11</td>
      <td>22</td>
      <td>NaN</td>
      <td>0</td>
    </tr>
    <tr>
      <th>515</th>
      <td>3-Jan-22</td>
      <td>54</td>
      <td>17:44</td>
      <td>Monday</td>
      <td>LAWRENCE AND RAILSIDE</td>
      <td>Mechanical</td>
      <td>0</td>
      <td>0</td>
      <td>E</td>
      <td>8742</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>27049</th>
      <td>29-Jun-22</td>
      <td>54</td>
      <td>14:43</td>
      <td>Wednesday</td>
      <td>LAWRENCE AND WARDEN</td>
      <td>Operations - Operator</td>
      <td>14</td>
      <td>28</td>
      <td>W</td>
      <td>8625</td>
    </tr>
    <tr>
      <th>27055</th>
      <td>29-Jun-22</td>
      <td>54</td>
      <td>14:56</td>
      <td>Wednesday</td>
      <td>LAWRENCE AND WARDEN</td>
      <td>Operations - Operator</td>
      <td>5</td>
      <td>11</td>
      <td>W</td>
      <td>8722</td>
    </tr>
    <tr>
      <th>27066</th>
      <td>29-Jun-22</td>
      <td>54</td>
      <td>16:08</td>
      <td>Wednesday</td>
      <td>LAWRENCE EAST STATION</td>
      <td>Operations - Operator</td>
      <td>6</td>
      <td>11</td>
      <td>E</td>
      <td>8861</td>
    </tr>
    <tr>
      <th>27148</th>
      <td>29-Jun-22</td>
      <td>54</td>
      <td>01:36</td>
      <td>Wednesday</td>
      <td>LESLIE AND EGLINTON</td>
      <td>Mechanical</td>
      <td>20</td>
      <td>40</td>
      <td>E</td>
      <td>8669</td>
    </tr>
    <tr>
      <th>27231</th>
      <td>30-Jun-22</td>
      <td>54</td>
      <td>14:07</td>
      <td>Thursday</td>
      <td>EGLINTON STATION</td>
      <td>Operations - Operator</td>
      <td>10</td>
      <td>21</td>
      <td>NaN</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27309</th>
      <td>30-Jun-22</td>
      <td>54</td>
      <td>18:11</td>
      <td>Thursday</td>
      <td>LAWRENCE EAST STATION</td>
      <td>Operations - Operator</td>
      <td>11</td>
      <td>22</td>
      <td>NaN</td>
      <td>8821</td>
    </tr>
    <tr>
      <th>27312</th>
      <td>30-Jun-22</td>
      <td>54</td>
      <td>18:16</td>
      <td>Thursday</td>
      <td>ORTON PARK AND BRIMORT</td>
      <td>Road Blocked - NON-TTC Collision</td>
      <td>235</td>
      <td>246</td>
      <td>N</td>
      <td>8669</td>
    </tr>
  </tbody>
</table>
<p>562 rows × 10 columns</p>
      
          <p>df_54_del (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Incident</th>
      <th>Min Delay</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>Diversion</td>
      <td>157108</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Operations - Operator</td>
      <td>130990</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Mechanical</td>
      <td>105045</td>
    </tr>
    <tr>
      <th>5</th>
      <td>General Delay</td>
      <td>40714</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Road Blocked - NON-TTC Collision</td>
      <td>23692</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Security</td>
      <td>21881</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Collision - TTC</td>
      <td>21371</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Utilized Off Route</td>
      <td>13231</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Emergency Services</td>
      <td>12856</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Held By</td>
      <td>9724</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Cleaning - Unsanitary</td>
      <td>8519</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Investigation</td>
      <td>4808</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Vision</td>
      <td>4288</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Cleaning - Disinfection</td>
      <td>527</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Late Entering Service</td>
      <td>428</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Incident</th>
      <th>Min Delay</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>Diversion</td>
      <td>157108</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Operations - Operator</td>
      <td>130990</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Mechanical</td>
      <td>105045</td>
    </tr>
    <tr>
      <th>5</th>
      <td>General Delay</td>
      <td>40714</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Road Blocked - NON-TTC Collision</td>
      <td>23692</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Security</td>
      <td>21881</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Collision - TTC</td>
      <td>21371</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Utilized Off Route</td>
      <td>13231</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Emergency Services</td>
      <td>12856</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Held By</td>
      <td>9724</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Cleaning - Unsanitary</td>
      <td>8519</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Investigation</td>
      <td>4808</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Vision</td>
      <td>4288</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Cleaning - Disinfection</td>
      <td>527</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Late Entering Service</td>
      <td>428</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> toronto-bus-delay-2022/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a column of datetime objects by combining the contents of Date and Time columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def convert_time(x):
    datestring = ' '.join([x.Date, x.Time])
    x['date_time'] = datetime.strptime(datestring, '%d-%b-%y %H:%M')
    return x

df = df.apply(convert_time, 1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def convert_time(x):
    datestring = ' '.join([x.Date, x.Time])
    x['date_time'] = datetime.strptime(datestring, '%d-%b-%y %H:%M')
    return x

df = df.apply(convert_time, 1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def convert_time(x):
    datestring = ' '.join([x.Date, x.Time])
    x['date_time'] = datetime.strptime(datestring, '%d-%b-%y %H:%M')
    return x


__output__ = df = df.apply(convert_time, 1)
</code></pre>
        <p><span onclick="$('#var_output_e82e37a2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e82e37a2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Route</th>
      <th>Time</th>
      <th>Day</th>
      <th>Location</th>
      <th>Incident</th>
      <th>Min Delay</th>
      <th>Min Gap</th>
      <th>Direction</th>
      <th>Vehicle</th>
      <th>date_time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:00</td>
      <td>Saturday</td>
      <td>YONGE AND DUNDAS</td>
      <td>General Delay</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>8531</td>
      <td>2022-01-01 02:00:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1-Jan-22</td>
      <td>325</td>
      <td>02:00</td>
      <td>Saturday</td>
      <td>OVERLEA AND THORCLIFFE</td>
      <td>Diversion</td>
      <td>131</td>
      <td>161</td>
      <td>W</td>
      <td>8658</td>
      <td>2022-01-01 02:00:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:00</td>
      <td>Saturday</td>
      <td>YONGE AND STEELES</td>
      <td>Operations - Operator</td>
      <td>17</td>
      <td>20</td>
      <td>S</td>
      <td>0</td>
      <td>2022-01-01 02:00:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:07</td>
      <td>Saturday</td>
      <td>YONGE AND STEELES</td>
      <td>Operations - Operator</td>
      <td>4</td>
      <td>11</td>
      <td>S</td>
      <td>0</td>
      <td>2022-01-01 02:07:00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:13</td>
      <td>Saturday</td>
      <td>YONGE AND STEELES</td>
      <td>Operations - Operator</td>
      <td>4</td>
      <td>8</td>
      <td>S</td>
      <td>0</td>
      <td>2022-01-01 02:13:00</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1-Jan-22</td>
      <td>363</td>
      <td>02:16</td>
      <td>Saturday</td>
      <td>KING AND SHAW</td>
      <td>Operations - Operator</td>
      <td>30</td>
      <td>60</td>
      <td>NaN</td>
      <td>0</td>
      <td>2022-01-01 02:16:00</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1-Jan-22</td>
      <td>96</td>
      <td>02:18</td>
      <td>Saturday</td>
      <td>HUMBERLINE LOOP</td>
      <td>Security</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>3536</td>
      <td>2022-01-01 02:18:00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>27344</th>
      <td>30-Jun-22</td>
      <td>927</td>
      <td>00:30</td>
      <td>Thursday</td>
      <td>STEELES AND AND MARTIN</td>
      <td>Emergency Services</td>
      <td>30</td>
      <td>30</td>
      <td>E</td>
      <td>3637</td>
      <td>2022-06-30 00:30:00</td>
    </tr>
    <tr>
      <th>27345</th>
      <td>30-Jun-22</td>
      <td>32</td>
      <td>00:31</td>
      <td>Thursday</td>
      <td>EGLINTON AND RONALD AV</td>
      <td>Mechanical</td>
      <td>14</td>
      <td>28</td>
      <td>W</td>
      <td>1094</td>
      <td>2022-06-30 00:31:00</td>
    </tr>
    <tr>
      <th>27346</th>
      <td>30-Jun-22</td>
      <td>123</td>
      <td>00:45</td>
      <td>Thursday</td>
      <td>SHERWAY GARDENS RD</td>
      <td>Operations - Operator</td>
      <td>27</td>
      <td>54</td>
      <td>E</td>
      <td>8088</td>
      <td>2022-06-30 00:45:00</td>
    </tr>
    <tr>
      <th>27347</th>
      <td>30-Jun-22</td>
      <td>102</td>
      <td>01:08</td>
      <td>Thursday</td>
      <td>WARDEN AND DANFORTH</td>
      <td>Operations - Operator</td>
      <td>30</td>
      <td>60</td>
      <td>S</td>
      <td>3416</td>
      <td>2022-06-30 01:08:00</td>
    </tr>
    <tr>
      <th>27348</th>
      <td>30-Jun-22</td>
      <td>66</td>
      <td>01:15</td>
      <td>Thursday</td>
      <td>UNKNOWN</td>
      <td>Operations - Operator</td>
      <td>30</td>
      <td>30</td>
      <td>NaN</td>
      <td>0</td>
      <td>2022-06-30 01:15:00</td>
    </tr>
    <tr>
      <th>27349</th>
      <td>30-Jun-22</td>
      <td>32</td>
      <td>01:33</td>
      <td>Thursday</td>
      <td>RENFORTH STATION</td>
      <td>Cleaning - Unsanitary</td>
      <td>18</td>
      <td>36</td>
      <td>E</td>
      <td>1202</td>
      <td>2022-06-30 01:33:00</td>
    </tr>
    <tr>
      <th>27350</th>
      <td>30-Jun-22</td>
      <td>32</td>
      <td>01:55</td>
      <td>Thursday</td>
      <td>EGLINTON AND DUPLEX</td>
      <td>Cleaning - Unsanitary</td>
      <td>8</td>
      <td>16</td>
      <td>W</td>
      <td>1265</td>
      <td>2022-06-30 01:55:00</td>
    </tr>
  </tbody>
</table>
<p>27351 rows × 11 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Route</th>
      <th>Time</th>
      <th>Day</th>
      <th>Location</th>
      <th>Incident</th>
      <th>Min Delay</th>
      <th>Min Gap</th>
      <th>Direction</th>
      <th>Vehicle</th>
      <th>date_time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:00</td>
      <td>Saturday</td>
      <td>YONGE AND DUNDAS</td>
      <td>General Delay</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>8531</td>
      <td>2022-01-01 02:00:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1-Jan-22</td>
      <td>325</td>
      <td>02:00</td>
      <td>Saturday</td>
      <td>OVERLEA AND THORCLIFFE</td>
      <td>Diversion</td>
      <td>131</td>
      <td>161</td>
      <td>W</td>
      <td>8658</td>
      <td>2022-01-01 02:00:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:00</td>
      <td>Saturday</td>
      <td>YONGE AND STEELES</td>
      <td>Operations - Operator</td>
      <td>17</td>
      <td>20</td>
      <td>S</td>
      <td>0</td>
      <td>2022-01-01 02:00:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:07</td>
      <td>Saturday</td>
      <td>YONGE AND STEELES</td>
      <td>Operations - Operator</td>
      <td>4</td>
      <td>11</td>
      <td>S</td>
      <td>0</td>
      <td>2022-01-01 02:07:00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:13</td>
      <td>Saturday</td>
      <td>YONGE AND STEELES</td>
      <td>Operations - Operator</td>
      <td>4</td>
      <td>8</td>
      <td>S</td>
      <td>0</td>
      <td>2022-01-01 02:13:00</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1-Jan-22</td>
      <td>363</td>
      <td>02:16</td>
      <td>Saturday</td>
      <td>KING AND SHAW</td>
      <td>Operations - Operator</td>
      <td>30</td>
      <td>60</td>
      <td>NaN</td>
      <td>0</td>
      <td>2022-01-01 02:16:00</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1-Jan-22</td>
      <td>96</td>
      <td>02:18</td>
      <td>Saturday</td>
      <td>HUMBERLINE LOOP</td>
      <td>Security</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>3536</td>
      <td>2022-01-01 02:18:00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>27344</th>
      <td>30-Jun-22</td>
      <td>927</td>
      <td>00:30</td>
      <td>Thursday</td>
      <td>STEELES AND AND MARTIN</td>
      <td>Emergency Services</td>
      <td>30</td>
      <td>30</td>
      <td>E</td>
      <td>3637</td>
      <td>2022-06-30 00:30:00</td>
    </tr>
    <tr>
      <th>27345</th>
      <td>30-Jun-22</td>
      <td>32</td>
      <td>00:31</td>
      <td>Thursday</td>
      <td>EGLINTON AND RONALD AV</td>
      <td>Mechanical</td>
      <td>14</td>
      <td>28</td>
      <td>W</td>
      <td>1094</td>
      <td>2022-06-30 00:31:00</td>
    </tr>
    <tr>
      <th>27346</th>
      <td>30-Jun-22</td>
      <td>123</td>
      <td>00:45</td>
      <td>Thursday</td>
      <td>SHERWAY GARDENS RD</td>
      <td>Operations - Operator</td>
      <td>27</td>
      <td>54</td>
      <td>E</td>
      <td>8088</td>
      <td>2022-06-30 00:45:00</td>
    </tr>
    <tr>
      <th>27347</th>
      <td>30-Jun-22</td>
      <td>102</td>
      <td>01:08</td>
      <td>Thursday</td>
      <td>WARDEN AND DANFORTH</td>
      <td>Operations - Operator</td>
      <td>30</td>
      <td>60</td>
      <td>S</td>
      <td>3416</td>
      <td>2022-06-30 01:08:00</td>
    </tr>
    <tr>
      <th>27348</th>
      <td>30-Jun-22</td>
      <td>66</td>
      <td>01:15</td>
      <td>Thursday</td>
      <td>UNKNOWN</td>
      <td>Operations - Operator</td>
      <td>30</td>
      <td>30</td>
      <td>NaN</td>
      <td>0</td>
      <td>2022-06-30 01:15:00</td>
    </tr>
    <tr>
      <th>27349</th>
      <td>30-Jun-22</td>
      <td>32</td>
      <td>01:33</td>
      <td>Thursday</td>
      <td>RENFORTH STATION</td>
      <td>Cleaning - Unsanitary</td>
      <td>18</td>
      <td>36</td>
      <td>E</td>
      <td>1202</td>
      <td>2022-06-30 01:33:00</td>
    </tr>
    <tr>
      <th>27350</th>
      <td>30-Jun-22</td>
      <td>32</td>
      <td>01:55</td>
      <td>Thursday</td>
      <td>EGLINTON AND DUPLEX</td>
      <td>Cleaning - Unsanitary</td>
      <td>8</td>
      <td>16</td>
      <td>W</td>
      <td>1265</td>
      <td>2022-06-30 01:55:00</td>
    </tr>
  </tbody>
</table>
<p>27351 rows × 11 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Route</th>
      <th>Time</th>
      <th>Day</th>
      <th>Location</th>
      <th>Incident</th>
      <th>Min Delay</th>
      <th>Min Gap</th>
      <th>Direction</th>
      <th>Vehicle</th>
      <th>date_time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:00</td>
      <td>Saturday</td>
      <td>YONGE AND DUNDAS</td>
      <td>General Delay</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>8531</td>
      <td>2022-01-01 02:00:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1-Jan-22</td>
      <td>325</td>
      <td>02:00</td>
      <td>Saturday</td>
      <td>OVERLEA AND THORCLIFFE</td>
      <td>Diversion</td>
      <td>131</td>
      <td>161</td>
      <td>W</td>
      <td>8658</td>
      <td>2022-01-01 02:00:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:00</td>
      <td>Saturday</td>
      <td>YONGE AND STEELES</td>
      <td>Operations - Operator</td>
      <td>17</td>
      <td>20</td>
      <td>S</td>
      <td>0</td>
      <td>2022-01-01 02:00:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:07</td>
      <td>Saturday</td>
      <td>YONGE AND STEELES</td>
      <td>Operations - Operator</td>
      <td>4</td>
      <td>11</td>
      <td>S</td>
      <td>0</td>
      <td>2022-01-01 02:07:00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1-Jan-22</td>
      <td>320</td>
      <td>02:13</td>
      <td>Saturday</td>
      <td>YONGE AND STEELES</td>
      <td>Operations - Operator</td>
      <td>4</td>
      <td>8</td>
      <td>S</td>
      <td>0</td>
      <td>2022-01-01 02:13:00</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1-Jan-22</td>
      <td>363</td>
      <td>02:16</td>
      <td>Saturday</td>
      <td>KING AND SHAW</td>
      <td>Operations - Operator</td>
      <td>30</td>
      <td>60</td>
      <td>NaN</td>
      <td>0</td>
      <td>2022-01-01 02:16:00</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1-Jan-22</td>
      <td>96</td>
      <td>02:18</td>
      <td>Saturday</td>
      <td>HUMBERLINE LOOP</td>
      <td>Security</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>3536</td>
      <td>2022-01-01 02:18:00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>27344</th>
      <td>30-Jun-22</td>
      <td>927</td>
      <td>00:30</td>
      <td>Thursday</td>
      <td>STEELES AND AND MARTIN</td>
      <td>Emergency Services</td>
      <td>30</td>
      <td>30</td>
      <td>E</td>
      <td>3637</td>
      <td>2022-06-30 00:30:00</td>
    </tr>
    <tr>
      <th>27345</th>
      <td>30-Jun-22</td>
      <td>32</td>
      <td>00:31</td>
      <td>Thursday</td>
      <td>EGLINTON AND RONALD AV</td>
      <td>Mechanical</td>
      <td>14</td>
      <td>28</td>
      <td>W</td>
      <td>1094</td>
      <td>2022-06-30 00:31:00</td>
    </tr>
    <tr>
      <th>27346</th>
      <td>30-Jun-22</td>
      <td>123</td>
      <td>00:45</td>
      <td>Thursday</td>
      <td>SHERWAY GARDENS RD</td>
      <td>Operations - Operator</td>
      <td>27</td>
      <td>54</td>
      <td>E</td>
      <td>8088</td>
      <td>2022-06-30 00:45:00</td>
    </tr>
    <tr>
      <th>27347</th>
      <td>30-Jun-22</td>
      <td>102</td>
      <td>01:08</td>
      <td>Thursday</td>
      <td>WARDEN AND DANFORTH</td>
      <td>Operations - Operator</td>
      <td>30</td>
      <td>60</td>
      <td>S</td>
      <td>3416</td>
      <td>2022-06-30 01:08:00</td>
    </tr>
    <tr>
      <th>27348</th>
      <td>30-Jun-22</td>
      <td>66</td>
      <td>01:15</td>
      <td>Thursday</td>
      <td>UNKNOWN</td>
      <td>Operations - Operator</td>
      <td>30</td>
      <td>30</td>
      <td>NaN</td>
      <td>0</td>
      <td>2022-06-30 01:15:00</td>
    </tr>
    <tr>
      <th>27349</th>
      <td>30-Jun-22</td>
      <td>32</td>
      <td>01:33</td>
      <td>Thursday</td>
      <td>RENFORTH STATION</td>
      <td>Cleaning - Unsanitary</td>
      <td>18</td>
      <td>36</td>
      <td>E</td>
      <td>1202</td>
      <td>2022-06-30 01:33:00</td>
    </tr>
    <tr>
      <th>27350</th>
      <td>30-Jun-22</td>
      <td>32</td>
      <td>01:55</td>
      <td>Thursday</td>
      <td>EGLINTON AND DUPLEX</td>
      <td>Cleaning - Unsanitary</td>
      <td>8</td>
      <td>16</td>
      <td>W</td>
      <td>1265</td>
      <td>2022-06-30 01:55:00</td>
    </tr>
  </tbody>
</table>
<p>27351 rows × 11 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> toronto-bus-delay-2022/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the average delays caused by each incident in January? Sort in descending order of the delay.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_jan = df[df.date_time.dt.month == 1]
df_jan = df_jan[['Incident', 'Min Delay']].groupby('Incident').mean()
df_jan = df_jan.sort_values('Min Delay', ascending=False)
df_jan</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_jan = df[df.date_time.dt.month == 1]
df_jan = df_jan[['Incident', 'Min Delay']].groupby('Incident').mean()
df_jan = df_jan.sort_values('Min Delay', ascending=False)
df_jan</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_jan = df[df.date_time.dt.month == 1]
df_jan = df_jan[['Incident', 'Min Delay']].groupby('Incident').mean()
df_jan = df_jan.sort_values('Min Delay', ascending=False)
__output__ = df_jan
</code></pre>
        <p><span onclick="$('#var_output_c3ccab3c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c3ccab3c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Incident</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Cleaning - Disinfection</th>
      <td>245.500000</td>
    </tr>
    <tr>
      <th>Diversion</th>
      <td>109.545752</td>
    </tr>
    <tr>
      <th>Road Blocked - NON-TTC Collision</th>
      <td>49.714286</td>
    </tr>
    <tr>
      <th>General Delay</th>
      <td>45.653979</td>
    </tr>
    <tr>
      <th>Held By</th>
      <td>33.500000</td>
    </tr>
    <tr>
      <th>Cleaning - Unsanitary</th>
      <td>15.592593</td>
    </tr>
    <tr>
      <th>Late Entering Service</th>
      <td>14.000000</td>
    </tr>
    <tr>
      <th>Mechanical</th>
      <td>13.492843</td>
    </tr>
    <tr>
      <th>Vision</th>
      <td>13.218182</td>
    </tr>
    <tr>
      <th>Operations - Operator</th>
      <td>13.193694</td>
    </tr>
    <tr>
      <th>Security</th>
      <td>13.018957</td>
    </tr>
    <tr>
      <th>Utilized Off Route</th>
      <td>11.853503</td>
    </tr>
    <tr>
      <th>Investigation</th>
      <td>11.169231</td>
    </tr>
    <tr>
      <th>Collision - TTC</th>
      <td>10.347518</td>
    </tr>
    <tr>
      <th>Emergency Services</th>
      <td>9.074074</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_jan, __output__ </p>
    
          <p>df_jan (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Incident</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Cleaning - Disinfection</th>
      <td>245.500000</td>
    </tr>
    <tr>
      <th>Diversion</th>
      <td>109.545752</td>
    </tr>
    <tr>
      <th>Road Blocked - NON-TTC Collision</th>
      <td>49.714286</td>
    </tr>
    <tr>
      <th>General Delay</th>
      <td>45.653979</td>
    </tr>
    <tr>
      <th>Held By</th>
      <td>33.500000</td>
    </tr>
    <tr>
      <th>Cleaning - Unsanitary</th>
      <td>15.592593</td>
    </tr>
    <tr>
      <th>Late Entering Service</th>
      <td>14.000000</td>
    </tr>
    <tr>
      <th>Mechanical</th>
      <td>13.492843</td>
    </tr>
    <tr>
      <th>Vision</th>
      <td>13.218182</td>
    </tr>
    <tr>
      <th>Operations - Operator</th>
      <td>13.193694</td>
    </tr>
    <tr>
      <th>Security</th>
      <td>13.018957</td>
    </tr>
    <tr>
      <th>Utilized Off Route</th>
      <td>11.853503</td>
    </tr>
    <tr>
      <th>Investigation</th>
      <td>11.169231</td>
    </tr>
    <tr>
      <th>Collision - TTC</th>
      <td>10.347518</td>
    </tr>
    <tr>
      <th>Emergency Services</th>
      <td>9.074074</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Incident</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Cleaning - Disinfection</th>
      <td>245.500000</td>
    </tr>
    <tr>
      <th>Diversion</th>
      <td>109.545752</td>
    </tr>
    <tr>
      <th>Road Blocked - NON-TTC Collision</th>
      <td>49.714286</td>
    </tr>
    <tr>
      <th>General Delay</th>
      <td>45.653979</td>
    </tr>
    <tr>
      <th>Held By</th>
      <td>33.500000</td>
    </tr>
    <tr>
      <th>Cleaning - Unsanitary</th>
      <td>15.592593</td>
    </tr>
    <tr>
      <th>Late Entering Service</th>
      <td>14.000000</td>
    </tr>
    <tr>
      <th>Mechanical</th>
      <td>13.492843</td>
    </tr>
    <tr>
      <th>Vision</th>
      <td>13.218182</td>
    </tr>
    <tr>
      <th>Operations - Operator</th>
      <td>13.193694</td>
    </tr>
    <tr>
      <th>Security</th>
      <td>13.018957</td>
    </tr>
    <tr>
      <th>Utilized Off Route</th>
      <td>11.853503</td>
    </tr>
    <tr>
      <th>Investigation</th>
      <td>11.169231</td>
    </tr>
    <tr>
      <th>Collision - TTC</th>
      <td>10.347518</td>
    </tr>
    <tr>
      <th>Emergency Services</th>
      <td>9.074074</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> toronto-bus-delay-2022/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What were those delays in May? Sort in descending order of the delay.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_may = df[df.date_time.dt.month == 5]
df_may = df_may[['Incident', 'Min Delay']].groupby('Incident').mean().sort_values('Min Delay', ascending=False)
df_may</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_may = df[df.date_time.dt.month == 5]
df_may = df_may[['Incident', 'Min Delay']].groupby('Incident').mean().sort_values('Min Delay', ascending=False)
df_may</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_may = df[df.date_time.dt.month == 5]
df_may = df_may[['Incident', 'Min Delay']].groupby('Incident').mean(
    ).sort_values('Min Delay', ascending=False)
__output__ = df_may
</code></pre>
        <p><span onclick="$('#var_output_5f7dc0f1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5f7dc0f1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Incident</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Diversion</th>
      <td>143.646465</td>
    </tr>
    <tr>
      <th>Road Blocked - NON-TTC Collision</th>
      <td>88.101695</td>
    </tr>
    <tr>
      <th>General Delay</th>
      <td>23.233696</td>
    </tr>
    <tr>
      <th>Held By</th>
      <td>18.500000</td>
    </tr>
    <tr>
      <th>Security</th>
      <td>16.493421</td>
    </tr>
    <tr>
      <th>Cleaning - Unsanitary</th>
      <td>15.649573</td>
    </tr>
    <tr>
      <th>Vision</th>
      <td>14.666667</td>
    </tr>
    <tr>
      <th>Operations - Operator</th>
      <td>14.397829</td>
    </tr>
    <tr>
      <th>Mechanical</th>
      <td>12.854647</td>
    </tr>
    <tr>
      <th>Emergency Services</th>
      <td>12.578475</td>
    </tr>
    <tr>
      <th>Collision - TTC</th>
      <td>11.949219</td>
    </tr>
    <tr>
      <th>Utilized Off Route</th>
      <td>11.625000</td>
    </tr>
    <tr>
      <th>Late Entering Service</th>
      <td>11.600000</td>
    </tr>
    <tr>
      <th>Investigation</th>
      <td>11.071429</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_may, __output__ </p>
    
          <p>df_may (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Incident</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Diversion</th>
      <td>143.646465</td>
    </tr>
    <tr>
      <th>Road Blocked - NON-TTC Collision</th>
      <td>88.101695</td>
    </tr>
    <tr>
      <th>General Delay</th>
      <td>23.233696</td>
    </tr>
    <tr>
      <th>Held By</th>
      <td>18.500000</td>
    </tr>
    <tr>
      <th>Security</th>
      <td>16.493421</td>
    </tr>
    <tr>
      <th>Cleaning - Unsanitary</th>
      <td>15.649573</td>
    </tr>
    <tr>
      <th>Vision</th>
      <td>14.666667</td>
    </tr>
    <tr>
      <th>Operations - Operator</th>
      <td>14.397829</td>
    </tr>
    <tr>
      <th>Mechanical</th>
      <td>12.854647</td>
    </tr>
    <tr>
      <th>Emergency Services</th>
      <td>12.578475</td>
    </tr>
    <tr>
      <th>Collision - TTC</th>
      <td>11.949219</td>
    </tr>
    <tr>
      <th>Utilized Off Route</th>
      <td>11.625000</td>
    </tr>
    <tr>
      <th>Late Entering Service</th>
      <td>11.600000</td>
    </tr>
    <tr>
      <th>Investigation</th>
      <td>11.071429</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Incident</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Diversion</th>
      <td>143.646465</td>
    </tr>
    <tr>
      <th>Road Blocked - NON-TTC Collision</th>
      <td>88.101695</td>
    </tr>
    <tr>
      <th>General Delay</th>
      <td>23.233696</td>
    </tr>
    <tr>
      <th>Held By</th>
      <td>18.500000</td>
    </tr>
    <tr>
      <th>Security</th>
      <td>16.493421</td>
    </tr>
    <tr>
      <th>Cleaning - Unsanitary</th>
      <td>15.649573</td>
    </tr>
    <tr>
      <th>Vision</th>
      <td>14.666667</td>
    </tr>
    <tr>
      <th>Operations - Operator</th>
      <td>14.397829</td>
    </tr>
    <tr>
      <th>Mechanical</th>
      <td>12.854647</td>
    </tr>
    <tr>
      <th>Emergency Services</th>
      <td>12.578475</td>
    </tr>
    <tr>
      <th>Collision - TTC</th>
      <td>11.949219</td>
    </tr>
    <tr>
      <th>Utilized Off Route</th>
      <td>11.625000</td>
    </tr>
    <tr>
      <th>Late Entering Service</th>
      <td>11.600000</td>
    </tr>
    <tr>
      <th>Investigation</th>
      <td>11.071429</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> toronto-bus-delay-2022/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the percent change in average delay between the May and January data for each type of incident not related to cleaning?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pct = 100*(df_may[~df_may.index.str.contains('Cleaning')] - df_jan[~df_jan.index.str.contains('Cleaning')])
pct/df_jan[~df_jan.index.str.contains('Cleaning')]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pct = 100*(df_may[~df_may.index.str.contains('Cleaning')] - df_jan[~df_jan.index.str.contains('Cleaning')])
pct/df_jan[~df_jan.index.str.contains('Cleaning')]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>pct = 100 * (df_may[~df_may.index.str.contains('Cleaning')] - df_jan[~
    df_jan.index.str.contains('Cleaning')])
__output__ = pct / df_jan[~df_jan.index.str.contains('Cleaning')]
</code></pre>
        <p><span onclick="$('#var_output_dc757f23').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_dc757f23" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Incident</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Collision - TTC</th>
      <td>15.479085</td>
    </tr>
    <tr>
      <th>Diversion</th>
      <td>31.129197</td>
    </tr>
    <tr>
      <th>Emergency Services</th>
      <td>38.619932</td>
    </tr>
    <tr>
      <th>General Delay</th>
      <td>-49.109155</td>
    </tr>
    <tr>
      <th>Held By</th>
      <td>-44.776119</td>
    </tr>
    <tr>
      <th>Investigation</th>
      <td>-0.875640</td>
    </tr>
    <tr>
      <th>Late Entering Service</th>
      <td>-17.142857</td>
    </tr>
    <tr>
      <th>Mechanical</th>
      <td>-4.729885</td>
    </tr>
    <tr>
      <th>Operations - Operator</th>
      <td>9.126596</td>
    </tr>
    <tr>
      <th>Road Blocked - NON-TTC Collision</th>
      <td>77.216053</td>
    </tr>
    <tr>
      <th>Security</th>
      <td>26.687726</td>
    </tr>
    <tr>
      <th>Utilized Off Route</th>
      <td>-1.927727</td>
    </tr>
    <tr>
      <th>Vision</th>
      <td>10.958276</td>
    </tr>
  </tbody>
</table>
<p>13 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> pct, __output__ </p>
    
          <p>pct (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Incident</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Collision - TTC</th>
      <td>160.170102</td>
    </tr>
    <tr>
      <th>Diversion</th>
      <td>3410.071301</td>
    </tr>
    <tr>
      <th>Emergency Services</th>
      <td>350.440126</td>
    </tr>
    <tr>
      <th>General Delay</th>
      <td>-2242.028359</td>
    </tr>
    <tr>
      <th>Held By</th>
      <td>-1500.000000</td>
    </tr>
    <tr>
      <th>Investigation</th>
      <td>-9.780220</td>
    </tr>
    <tr>
      <th>Late Entering Service</th>
      <td>-240.000000</td>
    </tr>
    <tr>
      <th>Mechanical</th>
      <td>-63.819599</td>
    </tr>
    <tr>
      <th>Operations - Operator</th>
      <td>120.413517</td>
    </tr>
    <tr>
      <th>Road Blocked - NON-TTC Collision</th>
      <td>3838.740920</td>
    </tr>
    <tr>
      <th>Security</th>
      <td>347.446371</td>
    </tr>
    <tr>
      <th>Utilized Off Route</th>
      <td>-22.850318</td>
    </tr>
    <tr>
      <th>Vision</th>
      <td>144.848485</td>
    </tr>
  </tbody>
</table>
<p>13 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Incident</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Collision - TTC</th>
      <td>15.479085</td>
    </tr>
    <tr>
      <th>Diversion</th>
      <td>31.129197</td>
    </tr>
    <tr>
      <th>Emergency Services</th>
      <td>38.619932</td>
    </tr>
    <tr>
      <th>General Delay</th>
      <td>-49.109155</td>
    </tr>
    <tr>
      <th>Held By</th>
      <td>-44.776119</td>
    </tr>
    <tr>
      <th>Investigation</th>
      <td>-0.875640</td>
    </tr>
    <tr>
      <th>Late Entering Service</th>
      <td>-17.142857</td>
    </tr>
    <tr>
      <th>Mechanical</th>
      <td>-4.729885</td>
    </tr>
    <tr>
      <th>Operations - Operator</th>
      <td>9.126596</td>
    </tr>
    <tr>
      <th>Road Blocked - NON-TTC Collision</th>
      <td>77.216053</td>
    </tr>
    <tr>
      <th>Security</th>
      <td>26.687726</td>
    </tr>
    <tr>
      <th>Utilized Off Route</th>
      <td>-1.927727</td>
    </tr>
    <tr>
      <th>Vision</th>
      <td>10.958276</td>
    </tr>
  </tbody>
</table>
<p>13 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> toronto-bus-delay-2022/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the total delay in hours for each day of the week? Sort in chronological order starting from Saturday.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>Day = df.groupby(df['Day'])[['Min Delay']].sum()/60
Day.loc[['Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>Day = df.groupby(df['Day'])[['Min Delay']].sum()/60
Day.loc[['Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>Day = df.groupby(df['Day'])[['Min Delay']].sum() / 60
__output__ = Day.loc[['Saturday', 'Sunday', 'Monday', 'Tuesday',
    'Wednesday', 'Thursday', 'Friday']]
</code></pre>
        <p><span onclick="$('#var_output_59c53f32').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_59c53f32" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Day</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Saturday</th>
      <td>1331.683333</td>
    </tr>
    <tr>
      <th>Sunday</th>
      <td>946.616667</td>
    </tr>
    <tr>
      <th>Monday</th>
      <td>1379.416667</td>
    </tr>
    <tr>
      <th>Tuesday</th>
      <td>1214.800000</td>
    </tr>
    <tr>
      <th>Wednesday</th>
      <td>1520.683333</td>
    </tr>
    <tr>
      <th>Thursday</th>
      <td>1422.600000</td>
    </tr>
    <tr>
      <th>Friday</th>
      <td>1437.233333</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> Day, __output__ </p>
    
          <p>Day (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Day</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Friday</th>
      <td>1437.233333</td>
    </tr>
    <tr>
      <th>Monday</th>
      <td>1379.416667</td>
    </tr>
    <tr>
      <th>Saturday</th>
      <td>1331.683333</td>
    </tr>
    <tr>
      <th>Sunday</th>
      <td>946.616667</td>
    </tr>
    <tr>
      <th>Thursday</th>
      <td>1422.600000</td>
    </tr>
    <tr>
      <th>Tuesday</th>
      <td>1214.800000</td>
    </tr>
    <tr>
      <th>Wednesday</th>
      <td>1520.683333</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>Day</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Saturday</th>
      <td>1331.683333</td>
    </tr>
    <tr>
      <th>Sunday</th>
      <td>946.616667</td>
    </tr>
    <tr>
      <th>Monday</th>
      <td>1379.416667</td>
    </tr>
    <tr>
      <th>Tuesday</th>
      <td>1214.800000</td>
    </tr>
    <tr>
      <th>Wednesday</th>
      <td>1520.683333</td>
    </tr>
    <tr>
      <th>Thursday</th>
      <td>1422.600000</td>
    </tr>
    <tr>
      <th>Friday</th>
      <td>1437.233333</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> toronto-bus-delay-2022/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What were the top 5 vehichles that encountered the most total delay due to mechanical problems? Show a list of vehicle numbers.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.Incident.str.contains('Mechanical')][['Min Delay', 'Vehicle']].groupby('Vehicle').sum().sort_values('Min Delay')\
    .tail(5).index.to_list()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.Incident.str.contains('Mechanical')][['Min Delay', 'Vehicle']].groupby('Vehicle').sum().sort_values('Min Delay')\
    .tail(5).index.to_list()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.Incident.str.contains('Mechanical')][['Min Delay',
    'Vehicle']].groupby('Vehicle').sum().sort_values('Min Delay').tail(5
    ).index.to_list()
</code></pre>
        <p><span onclick="$('#var_output_cf250dbb').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_cf250dbb" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>[8374, 3336, 8346, 8338, 0]</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>[8374, 3336, 8346, 8338, 0]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> toronto-bus-delay-2022/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What location had the most total delay due to diversion?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.Incident.str.contains('Diversion')][['Location', 'Min Delay']].groupby('Location').sum().sort_values('Min '
                                                                                                           'Delay')\
    .tail(1).index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.Incident.str.contains('Diversion')][['Location', 'Min Delay']].groupby('Location').sum().sort_values('Min '
                                                                                                           'Delay')\
    .tail(1).index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.Incident.str.contains('Diversion')][['Location',
    'Min Delay']].groupby('Location').sum().sort_values('Min Delay').tail(1
    ).index[0]
</code></pre>
        <p><span onclick="$('#var_output_3c676c88').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3c676c88" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>BATHURST AND ROSELAWN</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>BATHURST AND ROSELAWN</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> toronto-bus-delay-2022/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the mean delay for each hour of the day? Show the min delay as a column in chronological order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_t = df.loc[:, ['Time', 'Min Delay', 'date_time']]
df_t['hour_of_day'] = df_t.date_time.dt.hour
df_t[['Min Delay', 'hour_of_day']].groupby('hour_of_day').mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_t = df.loc[:, ['Time', 'Min Delay', 'date_time']]
df_t['hour_of_day'] = df_t.date_time.dt.hour
df_t[['Min Delay', 'hour_of_day']].groupby('hour_of_day').mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_t = df.loc[:, ['Time', 'Min Delay', 'date_time']]
df_t['hour_of_day'] = df_t.date_time.dt.hour
__output__ = df_t[['Min Delay', 'hour_of_day']].groupby('hour_of_day').mean()
</code></pre>
        <p><span onclick="$('#var_output_0f47416d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0f47416d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>hour_of_day</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>21.389662</td>
    </tr>
    <tr>
      <th>1</th>
      <td>23.700873</td>
    </tr>
    <tr>
      <th>2</th>
      <td>24.593886</td>
    </tr>
    <tr>
      <th>3</th>
      <td>26.323432</td>
    </tr>
    <tr>
      <th>4</th>
      <td>19.764172</td>
    </tr>
    <tr>
      <th>5</th>
      <td>21.876886</td>
    </tr>
    <tr>
      <th>6</th>
      <td>17.883692</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>17</th>
      <td>17.232750</td>
    </tr>
    <tr>
      <th>18</th>
      <td>18.058228</td>
    </tr>
    <tr>
      <th>19</th>
      <td>25.021016</td>
    </tr>
    <tr>
      <th>20</th>
      <td>24.183801</td>
    </tr>
    <tr>
      <th>21</th>
      <td>20.775661</td>
    </tr>
    <tr>
      <th>22</th>
      <td>25.318508</td>
    </tr>
    <tr>
      <th>23</th>
      <td>23.792393</td>
    </tr>
  </tbody>
</table>
<p>24 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_t, __output__ </p>
    
          <p>df_t (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>Min Delay</th>
      <th>date_time</th>
      <th>hour_of_day</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>02:00</td>
      <td>0</td>
      <td>2022-01-01 02:00:00</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>02:00</td>
      <td>131</td>
      <td>2022-01-01 02:00:00</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>02:00</td>
      <td>17</td>
      <td>2022-01-01 02:00:00</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>02:07</td>
      <td>4</td>
      <td>2022-01-01 02:07:00</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>02:13</td>
      <td>4</td>
      <td>2022-01-01 02:13:00</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>02:16</td>
      <td>30</td>
      <td>2022-01-01 02:16:00</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>02:18</td>
      <td>0</td>
      <td>2022-01-01 02:18:00</td>
      <td>2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>27344</th>
      <td>00:30</td>
      <td>30</td>
      <td>2022-06-30 00:30:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27345</th>
      <td>00:31</td>
      <td>14</td>
      <td>2022-06-30 00:31:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27346</th>
      <td>00:45</td>
      <td>27</td>
      <td>2022-06-30 00:45:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27347</th>
      <td>01:08</td>
      <td>30</td>
      <td>2022-06-30 01:08:00</td>
      <td>1</td>
    </tr>
    <tr>
      <th>27348</th>
      <td>01:15</td>
      <td>30</td>
      <td>2022-06-30 01:15:00</td>
      <td>1</td>
    </tr>
    <tr>
      <th>27349</th>
      <td>01:33</td>
      <td>18</td>
      <td>2022-06-30 01:33:00</td>
      <td>1</td>
    </tr>
    <tr>
      <th>27350</th>
      <td>01:55</td>
      <td>8</td>
      <td>2022-06-30 01:55:00</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>27351 rows × 4 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Min Delay</th>
    </tr>
    <tr>
      <th>hour_of_day</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>21.389662</td>
    </tr>
    <tr>
      <th>1</th>
      <td>23.700873</td>
    </tr>
    <tr>
      <th>2</th>
      <td>24.593886</td>
    </tr>
    <tr>
      <th>3</th>
      <td>26.323432</td>
    </tr>
    <tr>
      <th>4</th>
      <td>19.764172</td>
    </tr>
    <tr>
      <th>5</th>
      <td>21.876886</td>
    </tr>
    <tr>
      <th>6</th>
      <td>17.883692</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>17</th>
      <td>17.232750</td>
    </tr>
    <tr>
      <th>18</th>
      <td>18.058228</td>
    </tr>
    <tr>
      <th>19</th>
      <td>25.021016</td>
    </tr>
    <tr>
      <th>20</th>
      <td>24.183801</td>
    </tr>
    <tr>
      <th>21</th>
      <td>20.775661</td>
    </tr>
    <tr>
      <th>22</th>
      <td>25.318508</td>
    </tr>
    <tr>
      <th>23</th>
      <td>23.792393</td>
    </tr>
  </tbody>
</table>
<p>24 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> anime-list-2022/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 3 anime themes in terms of number of ratings?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def string_count_to_numeric(x: str):
    n = 0
    if x[-1] == 'M':
        n = float(x[:-1]) * 1e6
    elif x[-1] == 'K':
        n = float(x[:-1]) * 1e3
    else:
        n = float(x)
    return n

def split_fn(x: str):
    x = x.split(',')
    x.sort()
    return x

df_theme = df[['theme', 'rated_by']]
df_theme.rated_by = df_theme.rated_by.apply(string_count_to_numeric)
df['numeric_ratings'] = df_theme.rated_by
df_theme.theme = df_theme.theme.apply(split_fn)
df_theme = df_theme.explode(column=['theme'])
df_theme.groupby('theme').sum().sort_values(by='rated_by', ascending=False).head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def string_count_to_numeric(x: str):
    n = 0
    if x[-1] == 'M':
        n = float(x[:-1]) * 1e6
    elif x[-1] == 'K':
        n = float(x[:-1]) * 1e3
    else:
        n = float(x)
    return n

def split_fn(x: str):
    x = x.split(',')
    x.sort()
    return x

df_theme = df[['theme', 'rated_by']]
df_theme.rated_by = df_theme.rated_by.apply(string_count_to_numeric)
df['numeric_ratings'] = df_theme.rated_by
df_theme.theme = df_theme.theme.apply(split_fn)
df_theme = df_theme.explode(column=['theme'])
df_theme.groupby('theme').sum().sort_values(by='rated_by', ascending=False).head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def string_count_to_numeric(x: str):
    n = 0
    if x[-1] == 'M':
        n = float(x[:-1]) * 1000000.0
    elif x[-1] == 'K':
        n = float(x[:-1]) * 1000.0
    else:
        n = float(x)
    return n


def split_fn(x: str):
    x = x.split(',')
    x.sort()
    return x


df_theme = df[['theme', 'rated_by']]
df_theme.rated_by = df_theme.rated_by.apply(string_count_to_numeric)
df['numeric_ratings'] = df_theme.rated_by
df_theme.theme = df_theme.theme.apply(split_fn)
df_theme = df_theme.explode(column=['theme'])
__output__ = df_theme.groupby('theme').sum().sort_values(by='rated_by',
    ascending=False).head(3)
</code></pre>
        <p><span onclick="$('#var_output_1234f8c0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1234f8c0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rated_by</th>
    </tr>
    <tr>
      <th>theme</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>School</th>
      <td>51080150.0</td>
    </tr>
    <tr>
      <th>School</th>
      <td>45072482.0</td>
    </tr>
    <tr>
      <th>Shounen</th>
      <td>35061376.0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, df_theme, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>studio</th>
      <th>theme</th>
      <th>tags</th>
      <th>source</th>
      <th>rating</th>
      <th>year</th>
      <th>synopsis</th>
      <th>demographic</th>
      <th>status</th>
      <th>eps</th>
      <th>eps_avg_duration_in_min</th>
      <th>rated_by</th>
      <th>numeric_ratings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Shingeki no Kyojin</td>
      <td>Wit Studio</td>
      <td>Gore, Military, Survival</td>
      <td>Action, Drama</td>
      <td>Manga</td>
      <td>8.53</td>
      <td>2013.0</td>
      <td>Centuries ago, mankind was slaughtered to near extinction by monstrous humanoid creatures called Titans, forcing humans to hide in fear behind enormous concentric walls. What makes these giants truly terrifying is that their taste for human flesh is not born out of hunger but what appears to be out of pleasure. To ensure their survival, the remnants of humanity began living within defensive barriers, resulting in one hundred years without a single titan encounter. However, that fragile calm is soon shattered when a colossal Titan manages to breach the supposedly impregnable outer wall, reigniting the fight for survival against the man-eating abominations.\r\n\r\nAfter witnessing a horrific personal loss at the hands of the invading creatures, Eren Yeager dedicates his life to their eradication by enlisting into the Survey Corps, an elite military unit that combats the merciless humanoids outside the protection of the walls. Eren, his adopted sister Mikasa Ackerman, and his childhood friend Armin Arlert join the brutal war against the Titans and race to discover a way of defeating them before the last walls are breached.\r\n\r\n[Written by MAL Rewrite]\n\n\n\n\n\nStudioWit Studio\n\nSourceManga\n\nThemesGoreMilitarySurvival\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Finished</td>
      <td>25.0</td>
      <td>24.0</td>
      <td>3.4M</td>
      <td>3400000.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Death Note</td>
      <td>Madhouse</td>
      <td>Psychological</td>
      <td>Supernatural, Suspense</td>
      <td>Manga</td>
      <td>8.63</td>
      <td>2006.0</td>
      <td>Brutal murders, petty thefts, and senseless violence pollute the human world. In contrast, the realm of death gods is a humdrum, unchanging gambling den. The ingenious 17-year-old Japanese student Light Yagami and sadistic god of death Ryuk share one belief: their worlds are rotten.\r\n\r\nFor his own amusement, Ryuk drops his "Death Note" into the human world. Light stumbles upon it, deeming the first of its rules ridiculous: the human whose name is written in this note shall die. However, the temptation is too great, and Light experiments by writing a felon's name, which disturbingly enacts his first murder.\r\n\r\nAware of the terrifying godlike power that has fallen into his hands, Light—under the alias "Kira"—follows his wicked sense of justice with the ultimate goal of cleansing the world of all evil-doers. The meticulous mastermind detective L is already on his trail, but as Light's brilliance rivals L's, the grand chase for Kira turns into an intense battle of wits that can only end when one of them is dead.\r\n\r\n[Written by MAL Rewrite]\r\n\n\n\n\n\n\nStudioMadhouse\n\nSourceManga\n\nThemePsychological\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Finished</td>
      <td>37.0</td>
      <td>23.0</td>
      <td>3.4M</td>
      <td>3400000.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Fullmetal Alchemist: Brotherhood</td>
      <td>Bones</td>
      <td>Military</td>
      <td>Action, Adventure, Drama, Fantasy</td>
      <td>Manga</td>
      <td>9.14</td>
      <td>2009.0</td>
      <td>After a horrific alchemy experiment goes wrong in the Elric household, brothers Edward and Alphonse are left in a catastrophic new reality. Ignoring the alchemical principle banning human transmutation, the boys attempted to bring their recently deceased mother back to life. Instead, they suffered brutal personal loss: Alphonse's body disintegrated while Edward lost a leg and then sacrificed an arm to keep Alphonse's soul in the physical realm by binding it to a hulking suit of armor.\r\n\r\nThe brothers are rescued by their neighbor Pinako Rockbell and her granddaughter Winry. Known as a bio-mechanical engineering prodigy, Winry creates prosthetic limbs for Edward by utilizing "automail," a tough, versatile metal used in robots and combat armor. After years of training, the Elric brothers set off on a quest to restore their bodies by locating the Philosopher's Stone—a powerful gem that allows an alchemist to defy the traditional laws of Equivalent Exchange.\r\n\r\nAs Edward becomes an infamous alchemist and gains the nickname "Fullmetal," the boys' journey embroils them in a growing conspiracy that threatens the fate of the world.\r\n\r\n[Written by MAL Rewrite]\n\n\n\n\n\nStudioBones\n\nSourceManga\n\nThemeMilitary\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Finished</td>
      <td>64.0</td>
      <td>24.0</td>
      <td>2.9M</td>
      <td>2900000.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Boku no Hero Academia</td>
      <td>Bones</td>
      <td>School, Super Power</td>
      <td>Action</td>
      <td>Manga</td>
      <td>7.95</td>
      <td>2016.0</td>
      <td>The appearance of "quirks," newly discovered super powers, has been steadily increasing over the years, with 80 percent of humanity possessing various abilities from manipulation of elements to shapeshifting. This leaves the remainder of the world completely powerless, and Izuku Midoriya is one such individual.\r\n\r\nSince he was a child, the ambitious middle schooler has wanted nothing more than to be a hero. Izuku's unfair fate leaves him admiring heroes and taking notes on them whenever he can. But it seems that his persistence has borne some fruit: Izuku meets the number one hero and his personal idol, All Might. All Might's quirk is a unique ability that can be inherited, and he has chosen Izuku to be his successor!\r\n\r\nEnduring many months of grueling training, Izuku enrolls in UA High, a prestigious high school famous for its excellent hero training program, and this year's freshmen look especially promising. With his bizarre but talented classmates and the looming threat of a villainous organization, Izuku will soon learn what it really means to be a hero.\r\n\r\n[Written by MAL Rewrite]\n\n\n\n\n\nStudioBones\n\nSourceManga\n\nThemesSchoolSuper Power\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Finished</td>
      <td>13.0</td>
      <td>24.0</td>
      <td>2.6M</td>
      <td>2600000.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Naruto</td>
      <td>Studio Pierrot</td>
      <td>Martial Arts</td>
      <td>Action, Adventure, Fantasy</td>
      <td>Manga</td>
      <td>7.97</td>
      <td>2002.0</td>
      <td>Moments prior to Naruto Uzumaki's birth, a huge demon known as the Kyuubi, the Nine-Tailed Fox, attacked Konohagakure, the Hidden Leaf Village, and wreaked havoc. In order to put an end to the Kyuubi's rampage, the leader of the village, the Fourth Hokage, sacrificed his life and sealed the monstrous beast inside the newborn Naruto.\r\n\r\nNow, Naruto is a hyperactive and knuckle-headed ninja still living in Konohagakure. Shunned because of the Kyuubi inside him, Naruto struggles to find his place in the village, while his burning desire to become the Hokage of Konohagakure leads him not only to some great new friends, but also some deadly foes.\r\n\r\n[Written by MAL Rewrite]\n\n\n\n\n\nStudioStudio Pierrot\n\nSourceManga\n\nThemeMartial Arts\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Finished</td>
      <td>220.0</td>
      <td>23.0</td>
      <td>2.5M</td>
      <td>2500000.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Kimetsu no Yaiba</td>
      <td>ufotable</td>
      <td>Historical</td>
      <td>Action, Fantasy</td>
      <td>Manga</td>
      <td>8.55</td>
      <td>2019.0</td>
      <td>Ever since the death of his father, the burden of supporting the family has fallen upon Tanjirou Kamado's shoulders. Though living impoverished on a remote mountain, the Kamado family are able to enjoy a relatively peaceful and happy life. One day, Tanjirou decides to go down to the local village to make a little money selling charcoal. On his way back, night falls, forcing Tanjirou to take shelter in the house of a strange man, who warns him of the existence of flesh-eating demons that lurk in the woods at night.\r\n\r\nWhen he finally arrives back home the next day, he is met with a horrifying sight—his whole family has been slaughtered. Worse still, the sole survivor is his sister Nezuko, who has been turned into a bloodthirsty demon. Consumed by rage and hatred, Tanjirou swears to avenge his family and stay by his only remaining sibling. Alongside the mysterious group calling themselves the Demon Slayer Corps, Tanjirou will do whatever it takes to slay the demons and protect the remnants of his beloved sister's humanity.\r\n\r\n[Written by MAL Rewrite]\n\n\n\n\n\nStudioufotable\n\nSourceManga\n\nThemeHistorical\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Finished</td>
      <td>26.0</td>
      <td>23.0</td>
      <td>2.4M</td>
      <td>2400000.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Hunter x Hunter (2011)</td>
      <td>Madhouse</td>
      <td>Shounen</td>
      <td>Action, Adventure, Fantasy</td>
      <td>Manga</td>
      <td>9.05</td>
      <td>2011.0</td>
      <td>Hunters devote themselves to accomplishing hazardous tasks, all from traversing the world's uncharted territories to locating rare items and monsters. Before becoming a Hunter, one must pass the Hunter Examination—a high-risk selection process in which most applicants end up handicapped or worse, deceased.\r\n\r\nAmbitious participants who challenge the notorious exam carry their own reason. What drives 12-year-old Gon Freecss is finding Ging, his father and a Hunter himself. Believing that he will meet his father by becoming a Hunter, Gon takes the first step to walk the same path.\r\n\r\nDuring the Hunter Examination, Gon befriends the medical student Leorio Paladiknight, the vindictive Kurapika, and ex-assassin Killua Zoldyck. While their motives vastly differ from each other, they band together for a common goal and begin to venture into a perilous world.\r\n\r\n[Written by MAL Rewrite]\r\n\r\n\n\n\n\n\n\nStudioMadhouse\n\nSourceManga\n\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Finished</td>
      <td>148.0</td>
      <td>23.0</td>
      <td>2.3M</td>
      <td>2300000.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2998</th>
      <td>Gushi Nainai</td>
      <td>Unknown</td>
      <td>Kids</td>
      <td>Adventure, Fantasy</td>
      <td>Original</td>
      <td>NaN</td>
      <td>2017.0</td>
      <td>NaN</td>
      <td>Kids</td>
      <td>Finished</td>
      <td>26.0</td>
      <td>22.0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2999</th>
      <td>Hou Wang Chuan</td>
      <td>Unknown</td>
      <td>Kids</td>
      <td>Adventure, Fantasy</td>
      <td>Original</td>
      <td>NaN</td>
      <td>2010.0</td>
      <td>NaN</td>
      <td>Kids</td>
      <td>Finished</td>
      <td>52.0</td>
      <td>22.0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3000</th>
      <td>Kaixin Chaoren: Baoxiao Xing Xingqiu</td>
      <td>Unknown</td>
      <td>Kids</td>
      <td>Comedy, Sci-Fi</td>
      <td>Original</td>
      <td>NaN</td>
      <td>2016.0</td>
      <td>NaN</td>
      <td>Kids</td>
      <td>Finished</td>
      <td>52.0</td>
      <td>4.0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3001</th>
      <td>Shaonian Shiye: Yongzhe Chuang Jiangnan</td>
      <td>Unknown</td>
      <td>Historical</td>
      <td>NaN</td>
      <td>Original</td>
      <td>NaN</td>
      <td>2013.0</td>
      <td>NaN</td>
      <td>Kids</td>
      <td>Finished</td>
      <td>26.0</td>
      <td>15.0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3002</th>
      <td>Shentan Si Dou Xing</td>
      <td>Unknown</td>
      <td>Anthropomorphic</td>
      <td>Adventure, Fantasy</td>
      <td>Original</td>
      <td>NaN</td>
      <td>2013.0</td>
      <td>NaN</td>
      <td>Kids</td>
      <td>Finished</td>
      <td>52.0</td>
      <td>10.0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3003</th>
      <td>Taoqi Huaxue</td>
      <td>Unknown</td>
      <td>Educational</td>
      <td>NaN</td>
      <td>Original</td>
      <td>NaN</td>
      <td>2017.0</td>
      <td>NaN</td>
      <td>Kids</td>
      <td>Finished</td>
      <td>50.0</td>
      <td>4.0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3004</th>
      <td>Tobot V</td>
      <td>Unknown</td>
      <td>Mecha</td>
      <td>Sci-Fi</td>
      <td>Original</td>
      <td>NaN</td>
      <td>2018.0</td>
      <td>NaN</td>
      <td>Kids</td>
      <td>Finished</td>
      <td>52.0</td>
      <td>11.0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>3005 rows × 14 columns</p>
      
          <p>df_theme (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>theme</th>
      <th>rated_by</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Military</td>
      <td>3400000.0</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Survival</td>
      <td>3400000.0</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Gore</td>
      <td>3400000.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Psychological</td>
      <td>3400000.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Military</td>
      <td>2900000.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Super Power</td>
      <td>2600000.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>School</td>
      <td>2600000.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2998</th>
      <td>Kids</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2999</th>
      <td>Kids</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3000</th>
      <td>Kids</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3001</th>
      <td>Historical</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3002</th>
      <td>Anthropomorphic</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3003</th>
      <td>Educational</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3004</th>
      <td>Mecha</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>3896 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rated_by</th>
    </tr>
    <tr>
      <th>theme</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>School</th>
      <td>51080150.0</td>
    </tr>
    <tr>
      <th>School</th>
      <td>45072482.0</td>
    </tr>
    <tr>
      <th>Shounen</th>
      <td>35061376.0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> anime-list-2022/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which Studio averages the highest rating for original anime?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_studio = df[['studio', 'source', 'rating']]
df_studio = df_studio[df_studio.source == 'Original'][['studio', 'rating']].dropna()
df_studio.groupby('studio').mean().sort_values(by='rating', ascending=False).iloc[0].name</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_studio = df[['studio', 'source', 'rating']]
df_studio = df_studio[df_studio.source == 'Original'][['studio', 'rating']].dropna()
df_studio.groupby('studio').mean().sort_values(by='rating', ascending=False).iloc[0].name</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_studio = df[['studio', 'source', 'rating']]
df_studio = df_studio[df_studio.source == 'Original'][['studio', 'rating']
    ].dropna()
__output__ = df_studio.groupby('studio').mean().sort_values(by='rating',
    ascending=False).iloc[0].name
</code></pre>
        <p><span onclick="$('#var_output_dbe9df57').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_dbe9df57" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Manglobe</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_studio, __output__ </p>
    
          <p>df_studio (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>studio</th>
      <th>rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>41</th>
      <td>Manglobe</td>
      <td>8.50</td>
    </tr>
    <tr>
      <th>239</th>
      <td>Toei Animation</td>
      <td>7.63</td>
    </tr>
    <tr>
      <th>277</th>
      <td>Toei Animation</td>
      <td>7.15</td>
    </tr>
    <tr>
      <th>284</th>
      <td>Manglobe</td>
      <td>7.49</td>
    </tr>
    <tr>
      <th>327</th>
      <td>Bones</td>
      <td>7.20</td>
    </tr>
    <tr>
      <th>331</th>
      <td>Sunrise</td>
      <td>7.18</td>
    </tr>
    <tr>
      <th>363</th>
      <td>Toei Animation</td>
      <td>6.94</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>Unknown</td>
      <td>6.19</td>
    </tr>
    <tr>
      <th>1951</th>
      <td>Unknown</td>
      <td>5.47</td>
    </tr>
    <tr>
      <th>1971</th>
      <td>Unknown</td>
      <td>5.88</td>
    </tr>
    <tr>
      <th>1989</th>
      <td>Unknown</td>
      <td>5.62</td>
    </tr>
    <tr>
      <th>2001</th>
      <td>Unknown</td>
      <td>5.82</td>
    </tr>
    <tr>
      <th>2040</th>
      <td>Unknown</td>
      <td>5.97</td>
    </tr>
    <tr>
      <th>2069</th>
      <td>Unknown</td>
      <td>5.79</td>
    </tr>
  </tbody>
</table>
<p>242 rows × 2 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>Manglobe</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> anime-list-2022/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the highest rated anime in each theme with more than ten thousand ratings.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_rating = df[['name', 'numeric_ratings', 'rating', 'theme']]
df_rating = df_rating[df_rating.numeric_ratings > 10000]
df_rating.theme = df_rating.theme.apply(lambda x: x.split(', '))
df_rating = df_rating.sort_values(by='numeric_ratings', ascending=False)
df_rating = df_rating.explode(column='theme')
df_rating.groupby('theme').first()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_rating = df[['name', 'numeric_ratings', 'rating', 'theme']]
df_rating = df_rating[df_rating.numeric_ratings > 10000]
df_rating.theme = df_rating.theme.apply(lambda x: x.split(', '))
df_rating = df_rating.sort_values(by='numeric_ratings', ascending=False)
df_rating = df_rating.explode(column='theme')
df_rating.groupby('theme').first()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_rating = df[['name', 'numeric_ratings', 'rating', 'theme']]
df_rating = df_rating[df_rating.numeric_ratings > 10000]
df_rating.theme = df_rating.theme.apply(lambda x: x.split(', '))
df_rating = df_rating.sort_values(by='numeric_ratings', ascending=False)
df_rating = df_rating.explode(column='theme')
__output__ = df_rating.groupby('theme').first()
</code></pre>
        <p><span onclick="$('#var_output_b0a4dbbb').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b0a4dbbb" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>numeric_ratings</th>
      <th>rating</th>
    </tr>
    <tr>
      <th>theme</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adult Cast</th>
      <td>Black Lagoon</td>
      <td>863000.0</td>
      <td>8.03</td>
    </tr>
    <tr>
      <th>Anthropomorphic</th>
      <td>Beastars</td>
      <td>718000.0</td>
      <td>7.89</td>
    </tr>
    <tr>
      <th>CGDCT</th>
      <td>Non Non Biyori</td>
      <td>382000.0</td>
      <td>7.95</td>
    </tr>
    <tr>
      <th>Childcare</th>
      <td>3-gatsu no Lion</td>
      <td>598000.0</td>
      <td>8.40</td>
    </tr>
    <tr>
      <th>Combat Sports</th>
      <td>Hajime no Ippo</td>
      <td>474000.0</td>
      <td>8.74</td>
    </tr>
    <tr>
      <th>Crossdressing</th>
      <td>Ouran Koukou Host Club</td>
      <td>1000000.0</td>
      <td>8.16</td>
    </tr>
    <tr>
      <th>Delinquents</th>
      <td>Tokyo Revengers</td>
      <td>906000.0</td>
      <td>8.15</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Survival</th>
      <td>Shingeki no Kyojin</td>
      <td>3400000.0</td>
      <td>8.53</td>
    </tr>
    <tr>
      <th>Team Sports</th>
      <td>Haikyuu!!</td>
      <td>1700000.0</td>
      <td>8.45</td>
    </tr>
    <tr>
      <th>Time Travel</th>
      <td>Boku dake ga Inai Machi</td>
      <td>1800000.0</td>
      <td>8.32</td>
    </tr>
    <tr>
      <th>Vampire</th>
      <td>JoJo no Kimyou na Bouken (TV)</td>
      <td>1400000.0</td>
      <td>7.92</td>
    </tr>
    <tr>
      <th>Video Game</th>
      <td>100-man no Inochi no Ue ni Ore wa Tatteiru</td>
      <td>225000.0</td>
      <td>6.49</td>
    </tr>
    <tr>
      <th>Visual Arts</th>
      <td>Blue Period</td>
      <td>328000.0</td>
      <td>7.86</td>
    </tr>
    <tr>
      <th>Workplace</th>
      <td>Great Teacher Onizuka</td>
      <td>715000.0</td>
      <td>8.69</td>
    </tr>
  </tbody>
</table>
<p>55 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_rating, __output__ </p>
    
          <p>df_rating (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>numeric_ratings</th>
      <th>rating</th>
      <th>theme</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Shingeki no Kyojin</td>
      <td>3400000.0</td>
      <td>8.53</td>
      <td>Gore</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Shingeki no Kyojin</td>
      <td>3400000.0</td>
      <td>8.53</td>
      <td>Military</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Shingeki no Kyojin</td>
      <td>3400000.0</td>
      <td>8.53</td>
      <td>Survival</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Death Note</td>
      <td>3400000.0</td>
      <td>8.63</td>
      <td>Psychological</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Fullmetal Alchemist: Brotherhood</td>
      <td>2900000.0</td>
      <td>9.14</td>
      <td>Military</td>
    </tr>
    <tr>
      <th>887</th>
      <td>One Punch Man</td>
      <td>2800000.0</td>
      <td>8.51</td>
      <td>Parody</td>
    </tr>
    <tr>
      <th>887</th>
      <td>One Punch Man</td>
      <td>2800000.0</td>
      <td>8.51</td>
      <td>Super Power</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>615</th>
      <td>Karakurizoushi Ayatsuri Sakon</td>
      <td>11000.0</td>
      <td>7.38</td>
      <td>Shounen</td>
    </tr>
    <tr>
      <th>616</th>
      <td>B'T X</td>
      <td>11000.0</td>
      <td>7.03</td>
      <td>Mecha</td>
    </tr>
    <tr>
      <th>617</th>
      <td>Stratos 4</td>
      <td>11000.0</td>
      <td>6.66</td>
      <td>Military</td>
    </tr>
    <tr>
      <th>618</th>
      <td>Viewtiful Joe</td>
      <td>11000.0</td>
      <td>6.74</td>
      <td>Shounen</td>
    </tr>
    <tr>
      <th>619</th>
      <td>Kaiketsu Zorro</td>
      <td>11000.0</td>
      <td>7.22</td>
      <td>Historical</td>
    </tr>
    <tr>
      <th>620</th>
      <td>Zoids Fuzors</td>
      <td>11000.0</td>
      <td>6.38</td>
      <td>Mecha</td>
    </tr>
    <tr>
      <th>612</th>
      <td>Hyakujuu-Ou GoLion</td>
      <td>11000.0</td>
      <td>6.82</td>
      <td>Mecha</td>
    </tr>
  </tbody>
</table>
<p>1898 rows × 4 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>numeric_ratings</th>
      <th>rating</th>
    </tr>
    <tr>
      <th>theme</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adult Cast</th>
      <td>Black Lagoon</td>
      <td>863000.0</td>
      <td>8.03</td>
    </tr>
    <tr>
      <th>Anthropomorphic</th>
      <td>Beastars</td>
      <td>718000.0</td>
      <td>7.89</td>
    </tr>
    <tr>
      <th>CGDCT</th>
      <td>Non Non Biyori</td>
      <td>382000.0</td>
      <td>7.95</td>
    </tr>
    <tr>
      <th>Childcare</th>
      <td>3-gatsu no Lion</td>
      <td>598000.0</td>
      <td>8.40</td>
    </tr>
    <tr>
      <th>Combat Sports</th>
      <td>Hajime no Ippo</td>
      <td>474000.0</td>
      <td>8.74</td>
    </tr>
    <tr>
      <th>Crossdressing</th>
      <td>Ouran Koukou Host Club</td>
      <td>1000000.0</td>
      <td>8.16</td>
    </tr>
    <tr>
      <th>Delinquents</th>
      <td>Tokyo Revengers</td>
      <td>906000.0</td>
      <td>8.15</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Survival</th>
      <td>Shingeki no Kyojin</td>
      <td>3400000.0</td>
      <td>8.53</td>
    </tr>
    <tr>
      <th>Team Sports</th>
      <td>Haikyuu!!</td>
      <td>1700000.0</td>
      <td>8.45</td>
    </tr>
    <tr>
      <th>Time Travel</th>
      <td>Boku dake ga Inai Machi</td>
      <td>1800000.0</td>
      <td>8.32</td>
    </tr>
    <tr>
      <th>Vampire</th>
      <td>JoJo no Kimyou na Bouken (TV)</td>
      <td>1400000.0</td>
      <td>7.92</td>
    </tr>
    <tr>
      <th>Video Game</th>
      <td>100-man no Inochi no Ue ni Ore wa Tatteiru</td>
      <td>225000.0</td>
      <td>6.49</td>
    </tr>
    <tr>
      <th>Visual Arts</th>
      <td>Blue Period</td>
      <td>328000.0</td>
      <td>7.86</td>
    </tr>
    <tr>
      <th>Workplace</th>
      <td>Great Teacher Onizuka</td>
      <td>715000.0</td>
      <td>8.69</td>
    </tr>
  </tbody>
</table>
<p>55 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> anime-list-2022/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the oldest manga based anime still on air?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df.status == 'Airing') & (df.source == 'Manga')].sort_values(by='year').iloc[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df.status == 'Airing') & (df.source == 'Manga')].sort_values(by='year').iloc[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df.status == 'Airing') & (df.source == 'Manga')].sort_values(
    by='year').iloc[0]
</code></pre>
        <p><span onclick="$('#var_output_f3f91f58').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f3f91f58" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>name                                                        Crayon Shin-chan
studio                                                     Shin-Ei Animation
theme                                                                 School
tags                                          Comedy, Slice, of, Life, Ecchi
source                                                                 Manga
rating                                                                  7.74
year                                                                  1992.0
synopsis                   There is no such thing as an uneventful day in...
demographic                                                           Seinen
status                                                                Airing
eps                                                                      NaN
eps_avg_duration_in_min                                                 21.0
rated_by                                                                 71K
numeric_ratings                                                      71000.0
Name: 1083, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>name                                                        Crayon Shin-chan
studio                                                     Shin-Ei Animation
theme                                                                 School
tags                                          Comedy, Slice, of, Life, Ecchi
source                                                                 Manga
rating                                                                  7.74
year                                                                  1992.0
synopsis                   There is no such thing as an uneventful day in...
demographic                                                           Seinen
status                                                                Airing
eps                                                                      NaN
eps_avg_duration_in_min                                                 21.0
rated_by                                                                 71K
numeric_ratings                                                      71000.0
Name: 1083, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> anime-list-2022/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common tag associated with each theme?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_tag = df[['theme', 'tags']].dropna()
df_tag.theme = df_tag.theme.apply(split_fn)
df_tag.tags = df_tag.tags.apply(split_fn)
df_tag = df_tag.explode(column=['theme']).explode('tags')
df_tag.groupby('theme').agg(pd.Series.mode)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_tag = df[['theme', 'tags']].dropna()
df_tag.theme = df_tag.theme.apply(split_fn)
df_tag.tags = df_tag.tags.apply(split_fn)
df_tag = df_tag.explode(column=['theme']).explode('tags')
df_tag.groupby('theme').agg(pd.Series.mode)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_tag = df[['theme', 'tags']].dropna()
df_tag.theme = df_tag.theme.apply(split_fn)
df_tag.tags = df_tag.tags.apply(split_fn)
df_tag = df_tag.explode(column=['theme']).explode('tags')
__output__ = df_tag.groupby('theme').agg(pd.Series.mode)
</code></pre>
        <p><span onclick="$('#var_output_fdbe0db9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_fdbe0db9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tags</th>
    </tr>
    <tr>
      <th>theme</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CGDCT</th>
      <td>[ Girls,  Life,  Love,  Slice,  of, Fantasy]</td>
    </tr>
    <tr>
      <th>Childcare</th>
      <td>[ Life,  Slice,  of, Fantasy]</td>
    </tr>
    <tr>
      <th>Delinquents</th>
      <td>[ Comedy,  Supernatural, Action]</td>
    </tr>
    <tr>
      <th>Detective</th>
      <td>[ Sci-Fi, Action]</td>
    </tr>
    <tr>
      <th>Educational</th>
      <td>Comedy</td>
    </tr>
    <tr>
      <th>Gag Humor</th>
      <td>Comedy</td>
    </tr>
    <tr>
      <th>Gore</th>
      <td>Action</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Survival</th>
      <td>[ Comedy, Adventure]</td>
    </tr>
    <tr>
      <th>Team Sports</th>
      <td>Sports</td>
    </tr>
    <tr>
      <th>Time Travel</th>
      <td>Comedy</td>
    </tr>
    <tr>
      <th>Vampire</th>
      <td>Supernatural</td>
    </tr>
    <tr>
      <th>Video Game</th>
      <td>[ Comedy,  Fantasy,  Sci-Fi, Adventure, Comedy]</td>
    </tr>
    <tr>
      <th>Visual Arts</th>
      <td>[ Drama,  Life,  Romance,  Slice,  of, Comedy]</td>
    </tr>
    <tr>
      <th>Workplace</th>
      <td>Comedy</td>
    </tr>
  </tbody>
</table>
<p>101 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_tag, __output__ </p>
    
          <p>df_tag (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>theme</th>
      <th>tags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Military</td>
      <td>Drama</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Military</td>
      <td>Action</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Survival</td>
      <td>Drama</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Survival</td>
      <td>Action</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Gore</td>
      <td>Drama</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Gore</td>
      <td>Action</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Psychological</td>
      <td>Suspense</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2999</th>
      <td>Kids</td>
      <td>Fantasy</td>
    </tr>
    <tr>
      <th>2999</th>
      <td>Kids</td>
      <td>Adventure</td>
    </tr>
    <tr>
      <th>3000</th>
      <td>Kids</td>
      <td>Sci-Fi</td>
    </tr>
    <tr>
      <th>3000</th>
      <td>Kids</td>
      <td>Comedy</td>
    </tr>
    <tr>
      <th>3002</th>
      <td>Anthropomorphic</td>
      <td>Fantasy</td>
    </tr>
    <tr>
      <th>3002</th>
      <td>Anthropomorphic</td>
      <td>Adventure</td>
    </tr>
    <tr>
      <th>3004</th>
      <td>Mecha</td>
      <td>Sci-Fi</td>
    </tr>
  </tbody>
</table>
<p>8759 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tags</th>
    </tr>
    <tr>
      <th>theme</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CGDCT</th>
      <td>[ Girls,  Life,  Love,  Slice,  of, Fantasy]</td>
    </tr>
    <tr>
      <th>Childcare</th>
      <td>[ Life,  Slice,  of, Fantasy]</td>
    </tr>
    <tr>
      <th>Delinquents</th>
      <td>[ Comedy,  Supernatural, Action]</td>
    </tr>
    <tr>
      <th>Detective</th>
      <td>[ Sci-Fi, Action]</td>
    </tr>
    <tr>
      <th>Educational</th>
      <td>Comedy</td>
    </tr>
    <tr>
      <th>Gag Humor</th>
      <td>Comedy</td>
    </tr>
    <tr>
      <th>Gore</th>
      <td>Action</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Survival</th>
      <td>[ Comedy, Adventure]</td>
    </tr>
    <tr>
      <th>Team Sports</th>
      <td>Sports</td>
    </tr>
    <tr>
      <th>Time Travel</th>
      <td>Comedy</td>
    </tr>
    <tr>
      <th>Vampire</th>
      <td>Supernatural</td>
    </tr>
    <tr>
      <th>Video Game</th>
      <td>[ Comedy,  Fantasy,  Sci-Fi, Adventure, Comedy]</td>
    </tr>
    <tr>
      <th>Visual Arts</th>
      <td>[ Drama,  Life,  Romance,  Slice,  of, Comedy]</td>
    </tr>
    <tr>
      <th>Workplace</th>
      <td>Comedy</td>
    </tr>
  </tbody>
</table>
<p>101 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> anime-list-2022/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the average total duration of anime series based on their source.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_dur = df[['source', 'eps', 'eps_avg_duration_in_min']].dropna()
df_dur['average_total_duration'] = df.eps * df.eps_avg_duration_in_min
df_dur[['source', 'average_total_duration']].groupby('source').mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_dur = df[['source', 'eps', 'eps_avg_duration_in_min']].dropna()
df_dur['average_total_duration'] = df.eps * df.eps_avg_duration_in_min
df_dur[['source', 'average_total_duration']].groupby('source').mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_dur = df[['source', 'eps', 'eps_avg_duration_in_min']].dropna()
df_dur['average_total_duration'] = df.eps * df.eps_avg_duration_in_min
__output__ = df_dur[['source', 'average_total_duration']].groupby('source'
    ).mean()
</code></pre>
        <p><span onclick="$('#var_output_2c7a07fd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2c7a07fd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>average_total_duration</th>
    </tr>
    <tr>
      <th>source</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4-koma manga</th>
      <td>214.569231</td>
    </tr>
    <tr>
      <th>Book</th>
      <td>818.478261</td>
    </tr>
    <tr>
      <th>Card game</th>
      <td>1075.000000</td>
    </tr>
    <tr>
      <th>Game</th>
      <td>1065.123711</td>
    </tr>
    <tr>
      <th>Light novel</th>
      <td>498.300000</td>
    </tr>
    <tr>
      <th>Manga</th>
      <td>729.333035</td>
    </tr>
    <tr>
      <th>Mixed media</th>
      <td>314.200000</td>
    </tr>
    <tr>
      <th>Music</th>
      <td>90.000000</td>
    </tr>
    <tr>
      <th>Novel</th>
      <td>769.222222</td>
    </tr>
    <tr>
      <th>Original</th>
      <td>770.458738</td>
    </tr>
    <tr>
      <th>Other</th>
      <td>697.975309</td>
    </tr>
    <tr>
      <th>Picture book</th>
      <td>276.680851</td>
    </tr>
    <tr>
      <th>Radio</th>
      <td>500.000000</td>
    </tr>
    <tr>
      <th>Visual novel</th>
      <td>303.812500</td>
    </tr>
    <tr>
      <th>Web manga</th>
      <td>219.461538</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_dur, __output__ </p>
    
          <p>df_dur (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>source</th>
      <th>eps</th>
      <th>eps_avg_duration_in_min</th>
      <th>average_total_duration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Manga</td>
      <td>25.0</td>
      <td>24.0</td>
      <td>600.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Manga</td>
      <td>37.0</td>
      <td>23.0</td>
      <td>851.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Manga</td>
      <td>64.0</td>
      <td>24.0</td>
      <td>1536.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Manga</td>
      <td>13.0</td>
      <td>24.0</td>
      <td>312.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Manga</td>
      <td>220.0</td>
      <td>23.0</td>
      <td>5060.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Manga</td>
      <td>26.0</td>
      <td>23.0</td>
      <td>598.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Manga</td>
      <td>148.0</td>
      <td>23.0</td>
      <td>3404.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2998</th>
      <td>Original</td>
      <td>26.0</td>
      <td>22.0</td>
      <td>572.0</td>
    </tr>
    <tr>
      <th>2999</th>
      <td>Original</td>
      <td>52.0</td>
      <td>22.0</td>
      <td>1144.0</td>
    </tr>
    <tr>
      <th>3000</th>
      <td>Original</td>
      <td>52.0</td>
      <td>4.0</td>
      <td>208.0</td>
    </tr>
    <tr>
      <th>3001</th>
      <td>Original</td>
      <td>26.0</td>
      <td>15.0</td>
      <td>390.0</td>
    </tr>
    <tr>
      <th>3002</th>
      <td>Original</td>
      <td>52.0</td>
      <td>10.0</td>
      <td>520.0</td>
    </tr>
    <tr>
      <th>3003</th>
      <td>Original</td>
      <td>50.0</td>
      <td>4.0</td>
      <td>200.0</td>
    </tr>
    <tr>
      <th>3004</th>
      <td>Original</td>
      <td>52.0</td>
      <td>11.0</td>
      <td>572.0</td>
    </tr>
  </tbody>
</table>
<p>2402 rows × 4 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>average_total_duration</th>
    </tr>
    <tr>
      <th>source</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4-koma manga</th>
      <td>214.569231</td>
    </tr>
    <tr>
      <th>Book</th>
      <td>818.478261</td>
    </tr>
    <tr>
      <th>Card game</th>
      <td>1075.000000</td>
    </tr>
    <tr>
      <th>Game</th>
      <td>1065.123711</td>
    </tr>
    <tr>
      <th>Light novel</th>
      <td>498.300000</td>
    </tr>
    <tr>
      <th>Manga</th>
      <td>729.333035</td>
    </tr>
    <tr>
      <th>Mixed media</th>
      <td>314.200000</td>
    </tr>
    <tr>
      <th>Music</th>
      <td>90.000000</td>
    </tr>
    <tr>
      <th>Novel</th>
      <td>769.222222</td>
    </tr>
    <tr>
      <th>Original</th>
      <td>770.458738</td>
    </tr>
    <tr>
      <th>Other</th>
      <td>697.975309</td>
    </tr>
    <tr>
      <th>Picture book</th>
      <td>276.680851</td>
    </tr>
    <tr>
      <th>Radio</th>
      <td>500.000000</td>
    </tr>
    <tr>
      <th>Visual novel</th>
      <td>303.812500</td>
    </tr>
    <tr>
      <th>Web manga</th>
      <td>219.461538</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> anime-list-2022/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the most popular studios in terms of number of ratings for each demographic?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_dem = df[['studio', 'demographic', 'numeric_ratings']]
df_dem = df_dem.groupby(['demographic', 'studio']).sum().sort_values('numeric_ratings', ascending=False)
df_dem.reset_index().groupby('demographic').first()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_dem = df[['studio', 'demographic', 'numeric_ratings']]
df_dem = df_dem.groupby(['demographic', 'studio']).sum().sort_values('numeric_ratings', ascending=False)
df_dem.reset_index().groupby('demographic').first()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_dem = df[['studio', 'demographic', 'numeric_ratings']]
df_dem = df_dem.groupby(['demographic', 'studio']).sum().sort_values(
    'numeric_ratings', ascending=False)
__output__ = df_dem.reset_index().groupby('demographic').first()
</code></pre>
        <p><span onclick="$('#var_output_36c07018').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_36c07018" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>studio</th>
      <th>numeric_ratings</th>
    </tr>
    <tr>
      <th>demographic</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Josei</th>
      <td>Madhouse</td>
      <td>1032000.0</td>
    </tr>
    <tr>
      <th>Kids</th>
      <td>OLM</td>
      <td>1680859.0</td>
    </tr>
    <tr>
      <th>Seinen</th>
      <td>Madhouse</td>
      <td>10278900.0</td>
    </tr>
    <tr>
      <th>Shoujo</th>
      <td>Brain's Base</td>
      <td>3296000.0</td>
    </tr>
    <tr>
      <th>Shounen</th>
      <td>Bones</td>
      <td>20615200.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_dem, __output__ </p>
    
          <p>df_dem (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>numeric_ratings</th>
    </tr>
    <tr>
      <th>demographic</th>
      <th>studio</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="5" valign="top">Shounen</th>
      <th>Bones</th>
      <td>20615200.0</td>
    </tr>
    <tr>
      <th>A-1 Pictures</th>
      <td>15065100.0</td>
    </tr>
    <tr>
      <th>Wit Studio</th>
      <td>12058000.0</td>
    </tr>
    <tr>
      <th>Studio Pierrot</th>
      <td>10980440.0</td>
    </tr>
    <tr>
      <th>Madhouse</th>
      <td>10698000.0</td>
    </tr>
    <tr>
      <th>Seinen</th>
      <th>Madhouse</th>
      <td>10278900.0</td>
    </tr>
    <tr>
      <th>Shounen</th>
      <th>Production I.G</th>
      <td>8971000.0</td>
    </tr>
    <tr>
      <th>...</th>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th rowspan="6" valign="top">Kids</th>
      <th>Milky Cartoon</th>
      <td>183.0</td>
    </tr>
    <tr>
      <th>Directions</th>
      <td>164.0</td>
    </tr>
    <tr>
      <th>Robot Communications</th>
      <td>159.0</td>
    </tr>
    <tr>
      <th>TUBA</th>
      <td>86.0</td>
    </tr>
    <tr>
      <th>CMAY Animation</th>
      <td>55.0</td>
    </tr>
    <tr>
      <th>Creative Power Entertaining</th>
      <td>47.0</td>
    </tr>
    <tr>
      <th>Shounen</th>
      <th>Staple Entertainment</th>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>458 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>studio</th>
      <th>numeric_ratings</th>
    </tr>
    <tr>
      <th>demographic</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Josei</th>
      <td>Madhouse</td>
      <td>1032000.0</td>
    </tr>
    <tr>
      <th>Kids</th>
      <td>OLM</td>
      <td>1680859.0</td>
    </tr>
    <tr>
      <th>Seinen</th>
      <td>Madhouse</td>
      <td>10278900.0</td>
    </tr>
    <tr>
      <th>Shoujo</th>
      <td>Brain's Base</td>
      <td>3296000.0</td>
    </tr>
    <tr>
      <th>Shounen</th>
      <td>Bones</td>
      <td>20615200.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> anime-list-2022/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the highest rated anime for each theme.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_anim = df[['theme', 'name', 'rating']].dropna()
df_anim.theme = df_anim.theme.apply(split_fn)
df_anim.sort_values(by='rating', ascending=False).explode('theme').groupby('theme').first()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_anim = df[['theme', 'name', 'rating']].dropna()
df_anim.theme = df_anim.theme.apply(split_fn)
df_anim.sort_values(by='rating', ascending=False).explode('theme').groupby('theme').first()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_anim = df[['theme', 'name', 'rating']].dropna()
df_anim.theme = df_anim.theme.apply(split_fn)
__output__ = df_anim.sort_values(by='rating', ascending=False).explode('theme'
    ).groupby('theme').first()
</code></pre>
        <p><span onclick="$('#var_output_8e133331').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8e133331" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>rating</th>
    </tr>
    <tr>
      <th>theme</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CGDCT</th>
      <td>Konohana Kitan</td>
      <td>7.51</td>
    </tr>
    <tr>
      <th>Childcare</th>
      <td>Udon no Kuni no Kiniro Kemari</td>
      <td>7.75</td>
    </tr>
    <tr>
      <th>Delinquents</th>
      <td>Beelzebub</td>
      <td>7.87</td>
    </tr>
    <tr>
      <th>Detective</th>
      <td>Koukaku Kidoutai: Stand Alone Complex 2nd GIG</td>
      <td>8.52</td>
    </tr>
    <tr>
      <th>Educational</th>
      <td>Hataraku Saibou (TV)</td>
      <td>7.57</td>
    </tr>
    <tr>
      <th>Gag Humor</th>
      <td>Kakushigoto (TV)</td>
      <td>8.00</td>
    </tr>
    <tr>
      <th>Gore</th>
      <td>Gungrave</td>
      <td>7.84</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Survival</th>
      <td>Dr. Stone</td>
      <td>8.30</td>
    </tr>
    <tr>
      <th>Team Sports</th>
      <td>Major S5</td>
      <td>8.42</td>
    </tr>
    <tr>
      <th>Time Travel</th>
      <td>Generator Gawl</td>
      <td>6.89</td>
    </tr>
    <tr>
      <th>Vampire</th>
      <td>JoJo no Kimyou na Bouken (TV)</td>
      <td>7.92</td>
    </tr>
    <tr>
      <th>Video Game</th>
      <td>.hack//Tasogare no Udewa Densetsu</td>
      <td>6.57</td>
    </tr>
    <tr>
      <th>Visual Arts</th>
      <td>Paradise Kiss</td>
      <td>7.85</td>
    </tr>
    <tr>
      <th>Workplace</th>
      <td>Working!!!</td>
      <td>7.98</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_anim, __output__ </p>
    
          <p>df_anim (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>theme</th>
      <th>name</th>
      <th>rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[ Military,  Survival, Gore]</td>
      <td>Shingeki no Kyojin</td>
      <td>8.53</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[Psychological]</td>
      <td>Death Note</td>
      <td>8.63</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[Military]</td>
      <td>Fullmetal Alchemist: Brotherhood</td>
      <td>9.14</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[ Super Power, School]</td>
      <td>Boku no Hero Academia</td>
      <td>7.95</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[Martial Arts]</td>
      <td>Naruto</td>
      <td>7.97</td>
    </tr>
    <tr>
      <th>5</th>
      <td>[Historical]</td>
      <td>Kimetsu no Yaiba</td>
      <td>8.55</td>
    </tr>
    <tr>
      <th>6</th>
      <td>[Shounen]</td>
      <td>Hunter x Hunter (2011)</td>
      <td>9.05</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1978</th>
      <td>[Racing]</td>
      <td>Porong Porong Pororo 5</td>
      <td>5.70</td>
    </tr>
    <tr>
      <th>1980</th>
      <td>[Kids]</td>
      <td>Porong Porong Pororo 3</td>
      <td>5.68</td>
    </tr>
    <tr>
      <th>1989</th>
      <td>[Kids]</td>
      <td>Xiong Chumo</td>
      <td>5.62</td>
    </tr>
    <tr>
      <th>2001</th>
      <td>[Racing]</td>
      <td>Lei Su Deng Shandian Chong Xian</td>
      <td>5.82</td>
    </tr>
    <tr>
      <th>2040</th>
      <td>[Strategy Game]</td>
      <td>Huoli Shaonian Wang 3</td>
      <td>5.97</td>
    </tr>
    <tr>
      <th>2057</th>
      <td>[Kids]</td>
      <td>Xiao Liyu Lixian Ji</td>
      <td>6.08</td>
    </tr>
    <tr>
      <th>2069</th>
      <td>[Racing]</td>
      <td>Kkoma Bus Tayo</td>
      <td>5.79</td>
    </tr>
  </tbody>
</table>
<p>1812 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>rating</th>
    </tr>
    <tr>
      <th>theme</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CGDCT</th>
      <td>Konohana Kitan</td>
      <td>7.51</td>
    </tr>
    <tr>
      <th>Childcare</th>
      <td>Udon no Kuni no Kiniro Kemari</td>
      <td>7.75</td>
    </tr>
    <tr>
      <th>Delinquents</th>
      <td>Beelzebub</td>
      <td>7.87</td>
    </tr>
    <tr>
      <th>Detective</th>
      <td>Koukaku Kidoutai: Stand Alone Complex 2nd GIG</td>
      <td>8.52</td>
    </tr>
    <tr>
      <th>Educational</th>
      <td>Hataraku Saibou (TV)</td>
      <td>7.57</td>
    </tr>
    <tr>
      <th>Gag Humor</th>
      <td>Kakushigoto (TV)</td>
      <td>8.00</td>
    </tr>
    <tr>
      <th>Gore</th>
      <td>Gungrave</td>
      <td>7.84</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Survival</th>
      <td>Dr. Stone</td>
      <td>8.30</td>
    </tr>
    <tr>
      <th>Team Sports</th>
      <td>Major S5</td>
      <td>8.42</td>
    </tr>
    <tr>
      <th>Time Travel</th>
      <td>Generator Gawl</td>
      <td>6.89</td>
    </tr>
    <tr>
      <th>Vampire</th>
      <td>JoJo no Kimyou na Bouken (TV)</td>
      <td>7.92</td>
    </tr>
    <tr>
      <th>Video Game</th>
      <td>.hack//Tasogare no Udewa Densetsu</td>
      <td>6.57</td>
    </tr>
    <tr>
      <th>Visual Arts</th>
      <td>Paradise Kiss</td>
      <td>7.85</td>
    </tr>
    <tr>
      <th>Workplace</th>
      <td>Working!!!</td>
      <td>7.98</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> anime-list-2022/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 3 highest rated anime still on air?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>
df_airing = df[df.status == 'Airing']
df_airing[['name', 'rating']].sort_values(by='rating', ascending=False).head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_airing = df[df.status == 'Airing']
df_airing[['name', 'rating']].sort_values(by='rating', ascending=False).head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_airing = df[df.status == 'Airing']
__output__ = df_airing[['name', 'rating']].sort_values(by='rating',
    ascending=False).head(3)
</code></pre>
        <p><span onclick="$('#var_output_590d4d0a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_590d4d0a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>119</th>
      <td>Spy x Family</td>
      <td>9.09</td>
    </tr>
    <tr>
      <th>927</th>
      <td>Kaguya-sama wa Kokurasetai: Ultra Romantic</td>
      <td>8.97</td>
    </tr>
    <tr>
      <th>1167</th>
      <td>Kingdom 4th Season</td>
      <td>8.69</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_airing, __output__ </p>
    
          <p>df_airing (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>studio</th>
      <th>theme</th>
      <th>tags</th>
      <th>source</th>
      <th>rating</th>
      <th>year</th>
      <th>synopsis</th>
      <th>demographic</th>
      <th>status</th>
      <th>eps</th>
      <th>eps_avg_duration_in_min</th>
      <th>rated_by</th>
      <th>numeric_ratings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14</th>
      <td>One Piece</td>
      <td>Toei Animation</td>
      <td>Shounen</td>
      <td>Action, Adventure, Fantasy</td>
      <td>Manga</td>
      <td>8.63</td>
      <td>1999.0</td>
      <td>Gol D. Roger was known as the "Pirate King," the strongest and most infamous being to have sailed the Grand Line. The capture and execution of Roger by the World Government brought a change throughout the world. His last words before his death revealed the existence of the greatest treasure in the world, One Piece. It was this revelation that brought about the Grand Age of Pirates, men who dreamed of finding One Piece—which promises an unlimited amount of riches and fame—and quite possibly the pinnacle of glory and the title of the Pirate King.\r\n\r\nEnter Monkey D. Luffy, a 17-year-old boy who defies your standard definition of a pirate. Rather than the popular persona of a wicked, hardened, toothless pirate ransacking villages for fun, Luffy's reason for being a pirate is one of pure wonder: the thought of an exciting adventure that leads him to intriguing people and ultimately, the promised treasure. Following in the footsteps of his childhood hero, Luffy and his crew travel across the Grand Line, experiencing crazy adventures, unveiling dark mysteries and battling strong enemies, all in order to reach the most coveted of all fortunes—One Piece.\r\n\r\n[Written by MAL Rewrite] \n\n\n\n\n\nStudioToei Animation\n\nSourceManga\n\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>24.0</td>
      <td>1.8M</td>
      <td>1800000.0</td>
    </tr>
    <tr>
      <th>77</th>
      <td>Boruto: Naruto Next Generations</td>
      <td>Studio Pierrot</td>
      <td>Martial Arts</td>
      <td>Action, Adventure, Fantasy</td>
      <td>Manga</td>
      <td>5.86</td>
      <td>2017.0</td>
      <td>Following the successful end of the Fourth Shinobi World War, Konohagakure has been enjoying a period of peace, prosperity, and extraordinary technological advancement. This is all due to the efforts of the Allied Shinobi Forces and the village's Seventh Hokage, Naruto Uzumaki. Now resembling a modern metropolis, Konohagakure has changed, particularly the life of a shinobi. Under the watchful eye of Naruto and his old comrades, a new generation of shinobi has stepped up to learn the ways of the ninja.\r\n\r\nBoruto Uzumaki is often the center of attention as the son of the Seventh Hokage. Despite having inherited Naruto's boisterous and stubborn demeanor, Boruto is considered a prodigy and is able to unleash his potential with the help of supportive friends and family. Unfortunately, this has only worsened his arrogance and his desire to surpass Naruto which, along with his father's busy lifestyle, has strained their relationship. However, a sinister force brewing within the village may threaten Boruto's carefree life.\r\n\r\nNew friends and familiar faces join Boruto as a new story begins in Boruto: Naruto Next Generations.\r\n\r\n[Written by MAL Rewrite]\n\n\n\n\n\nStudioStudio Pierrot\n\nSourceManga\n\nThemeMartial Arts\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>23.0</td>
      <td>741K</td>
      <td>741000.0</td>
    </tr>
    <tr>
      <th>119</th>
      <td>Spy x Family</td>
      <td>CloverWorks</td>
      <td>Childcare</td>
      <td>Action, Comedy</td>
      <td>Manga</td>
      <td>9.09</td>
      <td>2022.0</td>
      <td>For the agent known as "Twilight," no order is too tall if it is for the sake of peace. Operating as Westalis' master spy, Twilight works tirelessly to prevent extremists from sparking a war with neighboring country Ostania. For his latest mission, he must investigate Ostanian politician Donovan Desmond by infiltrating his son's school: the prestigious Eden Academy. Thus, the agent faces the most difficult task of his career: get married, have a child, and play family.\r\n\r\nTwilight, or "Loid Forger," quickly adopts the unassuming orphan Anya to play the role of a six-year-old daughter and prospective Eden Academy student. For a wife, he comes across Yor Briar, an absent-minded office worker who needs a pretend partner of her own to impress her friends. However, Loid is not the only one with a hidden nature. Yor moonlights as the lethal assassin "Thorn Princess." For her, marrying Loid creates the perfect cover. Meanwhile, Anya is not the ordinary girl she appears to be; she is an esper, the product of secret experiments that allow her to read minds. Although she uncovers their true identities, Anya is thrilled that her new parents are cool secret agents! She would never tell them, of course. That would ruin the fun.\r\n\r\nUnder the guise of "The Forgers," the spy, the assassin, and the esper must act as a family while carrying out their own agendas. Although these liars and misfits are only playing parts, they soon find that family is about far more than blood relations. \r\n\r\n[Written by MAL Rewrite]\n\n\n\n\n\nStudiosCloverWorksWit Studio\n\nSourceManga\n\nThemeChildcare\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Airing</td>
      <td>12.0</td>
      <td>24.0</td>
      <td>511K</td>
      <td>511000.0</td>
    </tr>
    <tr>
      <th>167</th>
      <td>Detective Conan</td>
      <td>TMS Entertainment</td>
      <td>Detective</td>
      <td>Adventure, Comedy, Mystery</td>
      <td>Manga</td>
      <td>8.16</td>
      <td>1996.0</td>
      <td>Shinichi Kudou, a high school student of astounding talent in detective work, is well known for having solved several challenging cases. One day, when Shinichi spots two suspicious men and decides to follow them, he inadvertently becomes witness to a disturbing illegal activity. Unfortunately, he is caught in the act, so the men dose him with an experimental drug formulated by their criminal organization, leaving him to his death. However, to his own astonishment, Shinichi lives to see another day, but now in the body of a seven-year-old child.\r\n\r\nPerfectly preserving his original intelligence, he hides his real identity from everyone, including his childhood friend Ran Mouri and her father, private detective Kogorou Mouri. To this end, he takes on the alias of Conan Edogawa, inspired by the mystery writers Arthur Conan Doyle and Ranpo Edogawa.\r\n\r\nDetective Conan follows Shinichi who, as Conan, starts secretly solving the senior Mouri's cases from behind the scenes with his still exceptional sleuthing skills, while covertly investigating the organization responsible for his current state, hoping to reverse the drug's effects someday.\r\n\r\n[Written by MAL Rewrite]\n\n\n\n\n\nStudioTMS Entertainment\n\nSourceManga\n\nThemeDetective\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>25.0</td>
      <td>305K</td>
      <td>305000.0</td>
    </tr>
    <tr>
      <th>213</th>
      <td>Komi-san wa, Comyushou desu. 2nd Season</td>
      <td>OLM</td>
      <td>Romantic Subtext, School</td>
      <td>Comedy, Drama, Slice, of, Life</td>
      <td>Manga</td>
      <td>8.32</td>
      <td>2022.0</td>
      <td>Second season of Komi-san wa, Comyushou desu..\n\n\n\n\n\nStudioOLM\n\nSourceManga\n\nThemesRomantic SubtextSchool\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>23.0</td>
      <td>221K</td>
      <td>221000.0</td>
    </tr>
    <tr>
      <th>257</th>
      <td>Aharen-san wa Hakarenai</td>
      <td>Felix Film</td>
      <td>Iyashikei, School</td>
      <td>Comedy</td>
      <td>Manga</td>
      <td>7.49</td>
      <td>2022.0</td>
      <td>Beginning his first year of high school, all Matsuboshi Raidou wants is to make friends—starting with the cute, tiny, and soft-spoken Reina Aharen, who sits right next to him in class. Unbeknownst to Raidou, Reina shares the same sentiment, but she has a problem. Awkward and timid, Reina is incapable of determining how chummy she has to be when approaching a person.\r\n\r\nDue to Reina's complete inability to gauge personal space, the two struggle to spark their unlikely friendship, as even the simplest tasks like talking seem impossible for them. But despite the countless yet pointless challenges that hinder the pair, the overly imaginative Raidou will do whatever it takes to befriend the indecipherable Reina.\r\n\r\n[Written by MAL Rewrite]\r\n\n\n\n\n\n\nStudioFelix Film\n\nSourceManga\n\nThemesIyashikeiSchool\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>23.0</td>
      <td>164K</td>
      <td>164000.0</td>
    </tr>
    <tr>
      <th>307</th>
      <td>Tomodachi Game</td>
      <td>Okuruto Noboru</td>
      <td>High Stakes Game, Psychological, Strategy Game</td>
      <td>NaN</td>
      <td>Manga</td>
      <td>7.23</td>
      <td>2022.0</td>
      <td>Yuuichi Katagiri has battled financial hardships his whole life but has learned to stay content and positive thanks to his close circle of friends. To keep a promise he made to them, Yuuichi saves up enough money to join them on the school trip. But when the gathered money mysteriously goes missing, suspicion falls on two of Yuuichi's friends: Shiho Sawaragi and Makoto Shibe, who were in charge of collecting the payments. Although innocent, Shiho and Makoto take responsibility for the failure to protect the money when no one else comes forward.\r\n\r\nA few days later, Yuuichi and his friends receive mysterious letters which trick each of them into meeting up. Upon arrival, they are ambushed and knocked unconscious. They wake up in a mysterious room in the presence of "Manabu-kun," a character from a controversial children's show that stopped airing due to its malicious content. He informs the group that one of them indirectly gathered them together in order to settle a large debt. They are to play a "friendship game": a series of games that will test the strength of their bond and trust in each other. As the group's faith wavers due to the growing number of secrets and betrayals, Yuuichi must figure out who of his "friends" he can actually trust and ultimately discover the identity of the traitor. \r\n\r\n[Written by MAL Rewrite]\n\n\n\n\n\nStudioOkuruto Noboru\n\nSourceManga\n\nThemesHigh Stakes GamePsychologicalStrategy Game\nDemographicShounen</td>
      <td>Shounen</td>
      <td>Airing</td>
      <td>12.0</td>
      <td>22.0</td>
      <td>115K</td>
      <td>115000.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2244</th>
      <td>Onigiri ni Naritai Cogimyun</td>
      <td>Unknown</td>
      <td>School</td>
      <td>Fantasy</td>
      <td>Other</td>
      <td>NaN</td>
      <td>2020.0</td>
      <td>A prequel to Cogimyun covering her life at flour school before she runs her grandfather's apartment complex. Episodes air within the "Millenia Girl" live action program and then get released for a limited time later in the day on Sanrio's official YouTube channel.\n\n\n\n\n\nStudioUnknown\n\nSourceOther\n\nThemeSchool\nDemographicKids</td>
      <td>Kids</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>190</td>
      <td>190.0</td>
    </tr>
    <tr>
      <th>2252</th>
      <td>Reizouko no Tsukenosuke!</td>
      <td>Unknown</td>
      <td>Parody</td>
      <td>Comedy</td>
      <td>Original</td>
      <td>NaN</td>
      <td>2018.0</td>
      <td>A gag anime about foods in a refrigerator. The anime airs within the Oha Suta children's morning TV program and will receive a simultaneous manga serialization by Kazumata Oguri.\n\n\n\n\n\nStudioUnknown\n\nSourceOriginal\n\nThemeParody\nDemographicKids</td>
      <td>Kids</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>188</td>
      <td>188.0</td>
    </tr>
    <tr>
      <th>2291</th>
      <td>Origami Ninja Koyankinte</td>
      <td>Directions</td>
      <td>Kids</td>
      <td>Comedy</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2020.0</td>
      <td>Koyan, the Origami Ninja, came to Earth from his planet Origamio to find the magical stone "Hapiton" that has the ability to make people happy. On the way, he was joined by childhood friend Namin anda new friend Lublin. One day, a villain called Evilrun appeared. Evilrun has a black hole in her stomach and tries to inhale anything. Every time an event happens, Evilrun gets in the way of Koyan and friends. But what Evilrun's aim is remains a mystery...\n\n\n\n\n\nStudioDirections\n\nSource\n\nDemographicKids</td>
      <td>Kids</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>164</td>
      <td>164.0</td>
    </tr>
    <tr>
      <th>2298</th>
      <td>Baby-Hamitang</td>
      <td>Robot Communications</td>
      <td>Educational</td>
      <td>NaN</td>
      <td>Original</td>
      <td>NaN</td>
      <td>2022.0</td>
      <td>The episodes will present topics from the list of 17 Sustainable Development Goals (SDG) such as global warming, food waste, and gender equality, in an easy-to-understand manner. Baby Hamitang will then solve the issues.\r\n\r\n(Source: ANN)\n\n\n\n\n\nStudioRobot Communications\n\nSourceOriginal\n\nThemeEducational\nDemographicKids</td>
      <td>Kids</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>159</td>
      <td>159.0</td>
    </tr>
    <tr>
      <th>2311</th>
      <td>Pororo Donghwanala</td>
      <td>Unknown</td>
      <td>Kids</td>
      <td>Adventure, Fantasy</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2020.0</td>
      <td>NaN</td>
      <td>Kids</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>9.0</td>
      <td>154</td>
      <td>154.0</td>
    </tr>
    <tr>
      <th>2319</th>
      <td>Papan Ga Panda!</td>
      <td>Unknown</td>
      <td>Music</td>
      <td>NaN</td>
      <td>Original</td>
      <td>NaN</td>
      <td>2012.0</td>
      <td>A series of shorts broadcasted on Kids Station. The star a Panda (with other animals present) as they do quick skits usually revolving around singing, dancing, and exercise.\n\n\n\n\n\nStudioUnknown\n\nSourceOriginal\n\nThemeMusic\nDemographicKids</td>
      <td>Kids</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>148</td>
      <td>148.0</td>
    </tr>
    <tr>
      <th>2484</th>
      <td>Dawang Riji</td>
      <td>Unknown</td>
      <td>Kids</td>
      <td>Slice, of, Life</td>
      <td>Original</td>
      <td>NaN</td>
      <td>2020.0</td>
      <td>NaN</td>
      <td>Kids</td>
      <td>Airing</td>
      <td>NaN</td>
      <td>24.0</td>
      <td>48</td>
      <td>48.0</td>
    </tr>
  </tbody>
</table>
<p>66 rows × 14 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>119</th>
      <td>Spy x Family</td>
      <td>9.09</td>
    </tr>
    <tr>
      <th>927</th>
      <td>Kaguya-sama wa Kokurasetai: Ultra Romantic</td>
      <td>8.97</td>
    </tr>
    <tr>
      <th>1167</th>
      <td>Kingdom 4th Season</td>
      <td>8.69</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> anime-list-2022/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the average rating of each studio that released anime rated by more than a million viewers.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.numeric_ratings >= 1e6][['studio', 'rating']].groupby('studio').mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.numeric_ratings >= 1e6][['studio', 'rating']].groupby('studio').mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.numeric_ratings >= 1000000.0][['studio', 'rating']].groupby(
    'studio').mean()
</code></pre>
        <p><span onclick="$('#var_output_ca19f575').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ca19f575" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rating</th>
    </tr>
    <tr>
      <th>studio</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>A-1 Pictures</th>
      <td>8.068750</td>
    </tr>
    <tr>
      <th>Arms</th>
      <td>7.510000</td>
    </tr>
    <tr>
      <th>Bones</th>
      <td>8.127273</td>
    </tr>
    <tr>
      <th>CloverWorks</th>
      <td>8.550000</td>
    </tr>
    <tr>
      <th>David Production</th>
      <td>7.903333</td>
    </tr>
    <tr>
      <th>J.C.Staff</th>
      <td>7.947500</td>
    </tr>
    <tr>
      <th>Lerche</th>
      <td>8.305000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Studio Pierrot</th>
      <td>7.833333</td>
    </tr>
    <tr>
      <th>TMS Entertainment</th>
      <td>8.300000</td>
    </tr>
    <tr>
      <th>Toei Animation</th>
      <td>8.390000</td>
    </tr>
    <tr>
      <th>White Fox</th>
      <td>7.470000</td>
    </tr>
    <tr>
      <th>Wit Studio</th>
      <td>8.491667</td>
    </tr>
    <tr>
      <th>asread.</th>
      <td>7.450000</td>
    </tr>
    <tr>
      <th>ufotable</th>
      <td>8.550000</td>
    </tr>
  </tbody>
</table>
<p>19 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rating</th>
    </tr>
    <tr>
      <th>studio</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>A-1 Pictures</th>
      <td>8.068750</td>
    </tr>
    <tr>
      <th>Arms</th>
      <td>7.510000</td>
    </tr>
    <tr>
      <th>Bones</th>
      <td>8.127273</td>
    </tr>
    <tr>
      <th>CloverWorks</th>
      <td>8.550000</td>
    </tr>
    <tr>
      <th>David Production</th>
      <td>7.903333</td>
    </tr>
    <tr>
      <th>J.C.Staff</th>
      <td>7.947500</td>
    </tr>
    <tr>
      <th>Lerche</th>
      <td>8.305000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Studio Pierrot</th>
      <td>7.833333</td>
    </tr>
    <tr>
      <th>TMS Entertainment</th>
      <td>8.300000</td>
    </tr>
    <tr>
      <th>Toei Animation</th>
      <td>8.390000</td>
    </tr>
    <tr>
      <th>White Fox</th>
      <td>7.470000</td>
    </tr>
    <tr>
      <th>Wit Studio</th>
      <td>8.491667</td>
    </tr>
    <tr>
      <th>asread.</th>
      <td>7.450000</td>
    </tr>
    <tr>
      <th>ufotable</th>
      <td>8.550000</td>
    </tr>
  </tbody>
</table>
<p>19 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> anime-list-2022/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which two themes occur together the most?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>themes = df.theme.apply(split_fn)
themes = themes[themes.apply(lambda x: len(x) > 1)]
themes.apply(lambda x: list(itertools.combinations(x, 2))).explode().value_counts().index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>themes = df.theme.apply(split_fn)
themes = themes[themes.apply(lambda x: len(x) > 1)]
themes.apply(lambda x: list(itertools.combinations(x, 2))).explode().value_counts().index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>themes = df.theme.apply(split_fn)
themes = themes[themes.apply(lambda x: len(x) > 1)]
__output__ = themes.apply(lambda x: list(itertools.combinations(x, 2))
    ).explode().value_counts().index[0]
</code></pre>
        <p><span onclick="$('#var_output_c197f8f9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c197f8f9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (tuple):</p>
          <pre><code>(' School', 'Harem')</code></pre>
      
        <p><strong>Hyp output variables:</strong> themes, __output__ </p>
    
          <p>themes (Series):</p>
          <pre><code>0          [ Military,  Survival, Gore]
3                [ Super Power, School]
7          [ Military,  Survival, Gore]
8                [ Super Power, School]
10         [ Military,  Survival, Gore]
                     ...               
2584        [ Martial Arts, Historical]
2783            [ Military, Historical]
2857              [ School, Historical]
2942        [ Martial Arts, Historical]
2993    [ Educational, Anthropomorphic]
Name: theme, Length: 639, dtype: object</code></pre>
      
          <p>__output__ (tuple):</p>
          <pre><code>(' School', 'Harem')</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> nasa-nearest-earth-objects/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the estimated minimum and maximum diameter of the most luminous hazardous object?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_hazard = df[df.hazardous]
df_non_hazard = df[~df.hazardous]
df_hazard.sort_values(by='absolute_magnitude', ascending=False)[['est_diameter_min', 'est_diameter_max']].iloc[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_hazard = df[df.hazardous]
df_non_hazard = df[~df.hazardous]
df_hazard.sort_values(by='absolute_magnitude', ascending=False)[['est_diameter_min', 'est_diameter_max']].iloc[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_hazard = df[df.hazardous]
df_non_hazard = df[~df.hazardous]
__output__ = df_hazard.sort_values(by='absolute_magnitude', ascending=False)[[
    'est_diameter_min', 'est_diameter_max']].iloc[0]
</code></pre>
        <p><span onclick="$('#var_output_f1e4f410').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f1e4f410" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>est_diameter_min    0.088015
est_diameter_max    0.196807
Name: 10044, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_hazard, df_non_hazard, __output__ </p>
    
          <p>df_hazard (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>name</th>
      <th>est_diameter_min</th>
      <th>est_diameter_max</th>
      <th>relative_velocity</th>
      <th>miss_distance</th>
      <th>orbiting_body</th>
      <th>sentry_object</th>
      <th>absolute_magnitude</th>
      <th>hazardous</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2277475</td>
      <td>277475 (2005 WK4)</td>
      <td>0.265800</td>
      <td>0.594347</td>
      <td>73588.726663</td>
      <td>6.143813e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>20.00</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3667127</td>
      <td>(2014 GE35)</td>
      <td>0.255009</td>
      <td>0.570217</td>
      <td>42737.733765</td>
      <td>4.627557e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>20.09</td>
      <td>True</td>
    </tr>
    <tr>
      <th>10</th>
      <td>54049873</td>
      <td>(2020 OT6)</td>
      <td>0.252671</td>
      <td>0.564989</td>
      <td>58430.697200</td>
      <td>3.833750e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>20.11</td>
      <td>True</td>
    </tr>
    <tr>
      <th>23</th>
      <td>2506491</td>
      <td>506491 (2003 UW29)</td>
      <td>0.201630</td>
      <td>0.450858</td>
      <td>115899.180498</td>
      <td>1.510102e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>20.60</td>
      <td>True</td>
    </tr>
    <tr>
      <th>27</th>
      <td>3781344</td>
      <td>(2017 RV)</td>
      <td>0.110804</td>
      <td>0.247765</td>
      <td>48655.305132</td>
      <td>3.279775e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>21.90</td>
      <td>True</td>
    </tr>
    <tr>
      <th>32</th>
      <td>2020425</td>
      <td>20425 (1998 VD35)</td>
      <td>0.221083</td>
      <td>0.494356</td>
      <td>40625.288951</td>
      <td>1.489180e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>20.40</td>
      <td>True</td>
    </tr>
    <tr>
      <th>39</th>
      <td>2003362</td>
      <td>3362 Khufu (1984 QA)</td>
      <td>0.581507</td>
      <td>1.300289</td>
      <td>37279.210933</td>
      <td>3.253063e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>18.30</td>
      <td>True</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>90770</th>
      <td>3441093</td>
      <td>(2008 XB1)</td>
      <td>0.175612</td>
      <td>0.392681</td>
      <td>66430.853885</td>
      <td>3.740546e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>20.90</td>
      <td>True</td>
    </tr>
    <tr>
      <th>90779</th>
      <td>2003361</td>
      <td>3361 Orpheus (1982 HR)</td>
      <td>0.352010</td>
      <td>0.787118</td>
      <td>28698.357306</td>
      <td>6.905495e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>19.39</td>
      <td>True</td>
    </tr>
    <tr>
      <th>90782</th>
      <td>3776295</td>
      <td>(2017 NH)</td>
      <td>0.133216</td>
      <td>0.297879</td>
      <td>67595.756852</td>
      <td>5.681059e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>21.50</td>
      <td>True</td>
    </tr>
    <tr>
      <th>90794</th>
      <td>54235530</td>
      <td>(2022 AY1)</td>
      <td>0.104847</td>
      <td>0.234444</td>
      <td>51149.696785</td>
      <td>5.450002e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>22.02</td>
      <td>True</td>
    </tr>
    <tr>
      <th>90811</th>
      <td>2138404</td>
      <td>138404 (2000 HA24)</td>
      <td>0.356907</td>
      <td>0.798068</td>
      <td>33008.617883</td>
      <td>7.189835e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>19.36</td>
      <td>True</td>
    </tr>
    <tr>
      <th>90812</th>
      <td>2377732</td>
      <td>377732 (2005 XJ8)</td>
      <td>1.034082</td>
      <td>2.312278</td>
      <td>53362.798148</td>
      <td>4.756627e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>17.05</td>
      <td>True</td>
    </tr>
    <tr>
      <th>90818</th>
      <td>3836727</td>
      <td>(2018 XR)</td>
      <td>0.508809</td>
      <td>1.137732</td>
      <td>71465.448580</td>
      <td>8.894222e+06</td>
      <td>Earth</td>
      <td>False</td>
      <td>18.59</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>8840 rows × 10 columns</p>
      
          <p>df_non_hazard (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>name</th>
      <th>est_diameter_min</th>
      <th>est_diameter_max</th>
      <th>relative_velocity</th>
      <th>miss_distance</th>
      <th>orbiting_body</th>
      <th>sentry_object</th>
      <th>absolute_magnitude</th>
      <th>hazardous</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2162635</td>
      <td>162635 (2000 SS164)</td>
      <td>1.198271</td>
      <td>2.679415</td>
      <td>13569.249224</td>
      <td>5.483974e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>16.73</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2512244</td>
      <td>512244 (2015 YE18)</td>
      <td>0.722030</td>
      <td>1.614507</td>
      <td>114258.692129</td>
      <td>4.979872e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>17.83</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3596030</td>
      <td>(2012 BV13)</td>
      <td>0.096506</td>
      <td>0.215794</td>
      <td>24764.303138</td>
      <td>2.543497e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>22.20</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>54138696</td>
      <td>(2021 GY23)</td>
      <td>0.036354</td>
      <td>0.081291</td>
      <td>34297.587778</td>
      <td>4.058569e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>24.32</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>54189957</td>
      <td>(2021 PY40)</td>
      <td>0.171615</td>
      <td>0.383743</td>
      <td>27529.472307</td>
      <td>2.906912e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>20.95</td>
      <td>False</td>
    </tr>
    <tr>
      <th>7</th>
      <td>54230078</td>
      <td>(2021 XD6)</td>
      <td>0.005328</td>
      <td>0.011914</td>
      <td>57544.470083</td>
      <td>5.511502e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>28.49</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8</th>
      <td>2088213</td>
      <td>88213 (2001 AF2)</td>
      <td>0.350393</td>
      <td>0.783502</td>
      <td>56625.210122</td>
      <td>6.903598e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>19.40</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>90829</th>
      <td>3587872</td>
      <td>(2011 WA)</td>
      <td>0.123184</td>
      <td>0.275448</td>
      <td>80671.310009</td>
      <td>6.897365e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>21.67</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90830</th>
      <td>3678630</td>
      <td>(2014 OL339)</td>
      <td>0.069913</td>
      <td>0.156329</td>
      <td>38102.469622</td>
      <td>4.667988e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>22.90</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90831</th>
      <td>3763337</td>
      <td>(2016 VX1)</td>
      <td>0.026580</td>
      <td>0.059435</td>
      <td>52078.886692</td>
      <td>1.230039e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>25.00</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90832</th>
      <td>3837603</td>
      <td>(2019 AD3)</td>
      <td>0.016771</td>
      <td>0.037501</td>
      <td>46114.605073</td>
      <td>5.432121e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>26.00</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90833</th>
      <td>54017201</td>
      <td>(2020 JP3)</td>
      <td>0.031956</td>
      <td>0.071456</td>
      <td>7566.807732</td>
      <td>2.840077e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>24.60</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90834</th>
      <td>54115824</td>
      <td>(2021 CN5)</td>
      <td>0.007321</td>
      <td>0.016370</td>
      <td>69199.154484</td>
      <td>6.869206e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>27.80</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90835</th>
      <td>54205447</td>
      <td>(2021 TW7)</td>
      <td>0.039862</td>
      <td>0.089133</td>
      <td>27024.455553</td>
      <td>5.977213e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>24.12</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>81996 rows × 10 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>est_diameter_min    0.088015
est_diameter_max    0.196807
Name: 10044, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> nasa-nearest-earth-objects/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How much less luminous in terms of absolute magnitude are hazardous objects compared to non-hazardouus ones? Show in percentage.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>f"{df_non_hazard.absolute_magnitude.mean() - df_hazard.absolute_magnitude.mean() / df_hazard.absolute_magnitude.mean()}"</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>f"{df_non_hazard.absolute_magnitude.mean() - df_hazard.absolute_magnitude.mean() / df_hazard.absolute_magnitude.mean()}"</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = (
    f'{df_non_hazard.absolute_magnitude.mean() - df_hazard.absolute_magnitude.mean() / df_hazard.absolute_magnitude.mean()}'
    )
</code></pre>
        <p><span onclick="$('#var_output_9f54efd0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9f54efd0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>22.87419885116347</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>22.87419885116347</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> nasa-nearest-earth-objects/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What percentage of objects with above average absolute magnitude are hazardous?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_bel_avg_mag = df[(df.absolute_magnitude > df.absolute_magnitude.mean())]
100 * len(df_bel_avg_mag[df.hazardous]) / len(df_bel_avg_mag)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_bel_avg_mag = df[(df.absolute_magnitude > df.absolute_magnitude.mean())]
100 * len(df_bel_avg_mag[df.hazardous]) / len(df_bel_avg_mag)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_bel_avg_mag = df[df.absolute_magnitude > df.absolute_magnitude.mean()]
__output__ = 100 * len(df_bel_avg_mag[df.hazardous]) / len(df_bel_avg_mag)
</code></pre>
        <p><span onclick="$('#var_output_56145ae9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_56145ae9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>0.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_bel_avg_mag, __output__ </p>
    
          <p>df_bel_avg_mag (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>name</th>
      <th>est_diameter_min</th>
      <th>est_diameter_max</th>
      <th>relative_velocity</th>
      <th>miss_distance</th>
      <th>orbiting_body</th>
      <th>sentry_object</th>
      <th>absolute_magnitude</th>
      <th>hazardous</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>54138696</td>
      <td>(2021 GY23)</td>
      <td>0.036354</td>
      <td>0.081291</td>
      <td>34297.587778</td>
      <td>4.058569e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>24.32</td>
      <td>False</td>
    </tr>
    <tr>
      <th>7</th>
      <td>54230078</td>
      <td>(2021 XD6)</td>
      <td>0.005328</td>
      <td>0.011914</td>
      <td>57544.470083</td>
      <td>5.511502e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>28.49</td>
      <td>False</td>
    </tr>
    <tr>
      <th>13</th>
      <td>54235433</td>
      <td>(2022 AM)</td>
      <td>0.006145</td>
      <td>0.013742</td>
      <td>24323.046145</td>
      <td>2.461759e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>28.18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>16</th>
      <td>3739154</td>
      <td>(2016 AF2)</td>
      <td>0.006991</td>
      <td>0.015633</td>
      <td>75486.090854</td>
      <td>7.138706e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>27.90</td>
      <td>False</td>
    </tr>
    <tr>
      <th>17</th>
      <td>3795026</td>
      <td>(2017 YU3)</td>
      <td>0.044112</td>
      <td>0.098637</td>
      <td>70770.591144</td>
      <td>2.771724e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>23.90</td>
      <td>False</td>
    </tr>
    <tr>
      <th>18</th>
      <td>3797456</td>
      <td>(2018 AN2)</td>
      <td>0.029144</td>
      <td>0.065169</td>
      <td>42111.044076</td>
      <td>3.942128e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>24.80</td>
      <td>False</td>
    </tr>
    <tr>
      <th>20</th>
      <td>3835974</td>
      <td>(2018 VK1)</td>
      <td>0.009785</td>
      <td>0.021880</td>
      <td>49452.240578</td>
      <td>5.766709e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>27.17</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>90827</th>
      <td>54087420</td>
      <td>(2020 VL)</td>
      <td>0.024692</td>
      <td>0.055213</td>
      <td>14655.044804</td>
      <td>1.766750e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>25.16</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90828</th>
      <td>3363723</td>
      <td>(2006 XW4)</td>
      <td>0.036691</td>
      <td>0.082043</td>
      <td>26172.119254</td>
      <td>2.249368e+06</td>
      <td>Earth</td>
      <td>False</td>
      <td>24.30</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90831</th>
      <td>3763337</td>
      <td>(2016 VX1)</td>
      <td>0.026580</td>
      <td>0.059435</td>
      <td>52078.886692</td>
      <td>1.230039e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>25.00</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90832</th>
      <td>3837603</td>
      <td>(2019 AD3)</td>
      <td>0.016771</td>
      <td>0.037501</td>
      <td>46114.605073</td>
      <td>5.432121e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>26.00</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90833</th>
      <td>54017201</td>
      <td>(2020 JP3)</td>
      <td>0.031956</td>
      <td>0.071456</td>
      <td>7566.807732</td>
      <td>2.840077e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>24.60</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90834</th>
      <td>54115824</td>
      <td>(2021 CN5)</td>
      <td>0.007321</td>
      <td>0.016370</td>
      <td>69199.154484</td>
      <td>6.869206e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>27.80</td>
      <td>False</td>
    </tr>
    <tr>
      <th>90835</th>
      <td>54205447</td>
      <td>(2021 TW7)</td>
      <td>0.039862</td>
      <td>0.089133</td>
      <td>27024.455553</td>
      <td>5.977213e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>24.12</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>47193 rows × 10 columns</p>
      
          <p>__output__ (float):</p>
          <pre><code>0.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> nasa-nearest-earth-objects/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many times larger are hazardous objects compared to non-hazardous ones in terms of average maximum diameter?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_hazard.est_diameter_max.mean() / df_non_hazard.est_diameter_max.mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_hazard.est_diameter_max.mean() / df_non_hazard.est_diameter_max.mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_hazard.est_diameter_max.mean(
    ) / df_non_hazard.est_diameter_max.mean()
</code></pre>
        <p><span onclick="$('#var_output_b360001c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b360001c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>2.6871388377643437</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>2.6871388377643437</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> nasa-nearest-earth-objects/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the probability that an object is hazardous given it has above average relative velocity and below average absolute magnitude</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>len(df[(df.absolute_magnitude < df.absolute_magnitude.mean()) & (df.relative_velocity > df.relative_velocity.mean())
       & df.hazardous]) / len(df)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>len(df[(df.absolute_magnitude < df.absolute_magnitude.mean()) & (df.relative_velocity > df.relative_velocity.mean())
       & df.hazardous]) / len(df)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = len(df[(df.absolute_magnitude < df.absolute_magnitude.mean()) &
    (df.relative_velocity > df.relative_velocity.mean()) & df.hazardous]
    ) / len(df)
</code></pre>
        <p><span onclick="$('#var_output_e568da6d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e568da6d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>0.0648421330749923</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>0.0648421330749923</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> nasa-nearest-earth-objects/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the top 3 roundest objects?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['min_max_diff'] = df.est_diameter_max - df.est_diameter_min
df[['name', 'min_max_diff']].sort_values('min_max_diff').head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['min_max_diff'] = df.est_diameter_max - df.est_diameter_min
df[['name', 'min_max_diff']].sort_values('min_max_diff').head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['min_max_diff'] = df.est_diameter_max - df.est_diameter_min
__output__ = df[['name', 'min_max_diff']].sort_values('min_max_diff').head(3)
</code></pre>
        <p><span onclick="$('#var_output_75f3b089').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_75f3b089" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>min_max_diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>24949</th>
      <td>(2008 TS26)</td>
      <td>0.000753</td>
    </tr>
    <tr>
      <th>88408</th>
      <td>(2021 BO)</td>
      <td>0.000844</td>
    </tr>
    <tr>
      <th>75986</th>
      <td>(2021 BO)</td>
      <td>0.000844</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>name</th>
      <th>est_diameter_min</th>
      <th>est_diameter_max</th>
      <th>relative_velocity</th>
      <th>miss_distance</th>
      <th>orbiting_body</th>
      <th>sentry_object</th>
      <th>absolute_magnitude</th>
      <th>hazardous</th>
      <th>min_max_diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2162635</td>
      <td>162635 (2000 SS164)</td>
      <td>1.198271</td>
      <td>2.679415</td>
      <td>13569.249224</td>
      <td>5.483974e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>16.73</td>
      <td>False</td>
      <td>1.481144</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2277475</td>
      <td>277475 (2005 WK4)</td>
      <td>0.265800</td>
      <td>0.594347</td>
      <td>73588.726663</td>
      <td>6.143813e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>20.00</td>
      <td>True</td>
      <td>0.328547</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2512244</td>
      <td>512244 (2015 YE18)</td>
      <td>0.722030</td>
      <td>1.614507</td>
      <td>114258.692129</td>
      <td>4.979872e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>17.83</td>
      <td>False</td>
      <td>0.892478</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3596030</td>
      <td>(2012 BV13)</td>
      <td>0.096506</td>
      <td>0.215794</td>
      <td>24764.303138</td>
      <td>2.543497e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>22.20</td>
      <td>False</td>
      <td>0.119288</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3667127</td>
      <td>(2014 GE35)</td>
      <td>0.255009</td>
      <td>0.570217</td>
      <td>42737.733765</td>
      <td>4.627557e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>20.09</td>
      <td>True</td>
      <td>0.315208</td>
    </tr>
    <tr>
      <th>5</th>
      <td>54138696</td>
      <td>(2021 GY23)</td>
      <td>0.036354</td>
      <td>0.081291</td>
      <td>34297.587778</td>
      <td>4.058569e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>24.32</td>
      <td>False</td>
      <td>0.044936</td>
    </tr>
    <tr>
      <th>6</th>
      <td>54189957</td>
      <td>(2021 PY40)</td>
      <td>0.171615</td>
      <td>0.383743</td>
      <td>27529.472307</td>
      <td>2.906912e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>20.95</td>
      <td>False</td>
      <td>0.212128</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>90829</th>
      <td>3587872</td>
      <td>(2011 WA)</td>
      <td>0.123184</td>
      <td>0.275448</td>
      <td>80671.310009</td>
      <td>6.897365e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>21.67</td>
      <td>False</td>
      <td>0.152264</td>
    </tr>
    <tr>
      <th>90830</th>
      <td>3678630</td>
      <td>(2014 OL339)</td>
      <td>0.069913</td>
      <td>0.156329</td>
      <td>38102.469622</td>
      <td>4.667988e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>22.90</td>
      <td>False</td>
      <td>0.086417</td>
    </tr>
    <tr>
      <th>90831</th>
      <td>3763337</td>
      <td>(2016 VX1)</td>
      <td>0.026580</td>
      <td>0.059435</td>
      <td>52078.886692</td>
      <td>1.230039e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>25.00</td>
      <td>False</td>
      <td>0.032855</td>
    </tr>
    <tr>
      <th>90832</th>
      <td>3837603</td>
      <td>(2019 AD3)</td>
      <td>0.016771</td>
      <td>0.037501</td>
      <td>46114.605073</td>
      <td>5.432121e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>26.00</td>
      <td>False</td>
      <td>0.020730</td>
    </tr>
    <tr>
      <th>90833</th>
      <td>54017201</td>
      <td>(2020 JP3)</td>
      <td>0.031956</td>
      <td>0.071456</td>
      <td>7566.807732</td>
      <td>2.840077e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>24.60</td>
      <td>False</td>
      <td>0.039500</td>
    </tr>
    <tr>
      <th>90834</th>
      <td>54115824</td>
      <td>(2021 CN5)</td>
      <td>0.007321</td>
      <td>0.016370</td>
      <td>69199.154484</td>
      <td>6.869206e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>27.80</td>
      <td>False</td>
      <td>0.009049</td>
    </tr>
    <tr>
      <th>90835</th>
      <td>54205447</td>
      <td>(2021 TW7)</td>
      <td>0.039862</td>
      <td>0.089133</td>
      <td>27024.455553</td>
      <td>5.977213e+07</td>
      <td>Earth</td>
      <td>False</td>
      <td>24.12</td>
      <td>False</td>
      <td>0.049272</td>
    </tr>
  </tbody>
</table>
<p>90836 rows × 11 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>min_max_diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>24949</th>
      <td>(2008 TS26)</td>
      <td>0.000753</td>
    </tr>
    <tr>
      <th>88408</th>
      <td>(2021 BO)</td>
      <td>0.000844</td>
    </tr>
    <tr>
      <th>75986</th>
      <td>(2021 BO)</td>
      <td>0.000844</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> nasa-nearest-earth-objects/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many times faster is the fastest object compared to the slowest?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_sorted = df[['id', 'relative_velocity']]
df_sorted = df_sorted.groupby('id').max()
df_sorted = df_sorted.sort_values('relative_velocity', ascending=False)
df_sorted['relative_velocity'].iloc[0] / df_sorted['relative_velocity'].iloc[-1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_sorted = df[['id', 'relative_velocity']]
df_sorted = df_sorted.groupby('id').max()
df_sorted = df_sorted.sort_values('relative_velocity', ascending=False)
df_sorted['relative_velocity'].iloc[0] / df_sorted['relative_velocity'].iloc[-1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_sorted = df[['id', 'relative_velocity']]
df_sorted = df_sorted.groupby('id').max()
df_sorted = df_sorted.sort_values('relative_velocity', ascending=False)
__output__ = df_sorted['relative_velocity'].iloc[0] / df_sorted[
    'relative_velocity'].iloc[-1]
</code></pre>
        <p><span onclick="$('#var_output_a85c464f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a85c464f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>226.6145958624145</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_sorted, __output__ </p>
    
          <p>df_sorted (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>relative_velocity</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3840692</th>
      <td>236990.128088</td>
    </tr>
    <tr>
      <th>3843840</th>
      <td>228242.243467</td>
    </tr>
    <tr>
      <th>3989287</th>
      <td>207168.668693</td>
    </tr>
    <tr>
      <th>3799259</th>
      <td>194056.414989</td>
    </tr>
    <tr>
      <th>3824084</th>
      <td>193386.975218</td>
    </tr>
    <tr>
      <th>3655362</th>
      <td>191176.458196</td>
    </tr>
    <tr>
      <th>3266180</th>
      <td>187221.073334</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>3645309</th>
      <td>2133.937928</td>
    </tr>
    <tr>
      <th>54097977</th>
      <td>2128.708726</td>
    </tr>
    <tr>
      <th>3836753</th>
      <td>2046.488665</td>
    </tr>
    <tr>
      <th>54245576</th>
      <td>1905.204352</td>
    </tr>
    <tr>
      <th>54132046</th>
      <td>1752.856483</td>
    </tr>
    <tr>
      <th>54105115</th>
      <td>1464.207053</td>
    </tr>
    <tr>
      <th>2250162</th>
      <td>1045.784925</td>
    </tr>
  </tbody>
</table>
<p>27423 rows × 1 columns</p>
      
          <p>__output__ (float64):</p>
          <pre><code>226.6145958624145</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> nasa-nearest-earth-objects/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which numeric column is least skewed?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>skdf = df[['id', 'est_diameter_min', 'est_diameter_max', 'relative_velocity', 'miss_distance', 'absolute_magnitude']]
skdf = skdf.groupby('id').mean().skew(axis=0)
skdf.apply(abs).sort_values().index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>skdf = df[['id', 'est_diameter_min', 'est_diameter_max', 'relative_velocity', 'miss_distance', 'absolute_magnitude']]
skdf = skdf.groupby('id').mean().skew(axis=0)
skdf.apply(abs).sort_values().index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>skdf = df[['id', 'est_diameter_min', 'est_diameter_max',
    'relative_velocity', 'miss_distance', 'absolute_magnitude']]
skdf = skdf.groupby('id').mean().skew(axis=0)
__output__ = skdf.apply(abs).sort_values().index[0]
</code></pre>
        <p><span onclick="$('#var_output_535d77a1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_535d77a1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>miss_distance</code></pre>
      
        <p><strong>Hyp output variables:</strong> skdf, __output__ </p>
    
          <p>skdf (Series):</p>
          <pre><code>est_diameter_min      48.614178
est_diameter_max      48.614178
relative_velocity      1.033366
miss_distance         -0.016289
absolute_magnitude    -0.204530
dtype: float64</code></pre>
      
          <p>__output__ (str):</p>
          <pre><code>miss_distance</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> nasa-nearest-earth-objects/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which are the top 3 hazardous object with above average velocity had the closest miss distance?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_hazard[df_hazard.relative_velocity > (df.relative_velocity.mean())]\
    .sort_values('miss_distance', ascending=False)\
    .head(3)[['name', 'relative_velocity', 'miss_distance']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_hazard[df_hazard.relative_velocity > (df.relative_velocity.mean())]\
    .sort_values('miss_distance', ascending=False)\
    .head(3)[['name', 'relative_velocity', 'miss_distance']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_hazard[df_hazard.relative_velocity > df.relative_velocity.
    mean()].sort_values('miss_distance', ascending=False).head(3)[['name',
    'relative_velocity', 'miss_distance']]
</code></pre>
        <p><span onclick="$('#var_output_76bd434b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_76bd434b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>relative_velocity</th>
      <th>miss_distance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>48158</th>
      <td>434188 (2003 AD23)</td>
      <td>91847.754688</td>
      <td>7.478335e+07</td>
    </tr>
    <tr>
      <th>62853</th>
      <td>(2010 DO)</td>
      <td>69573.352182</td>
      <td>7.478247e+07</td>
    </tr>
    <tr>
      <th>44329</th>
      <td>297418 (2000 SP43)</td>
      <td>106802.283952</td>
      <td>7.478231e+07</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>relative_velocity</th>
      <th>miss_distance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>48158</th>
      <td>434188 (2003 AD23)</td>
      <td>91847.754688</td>
      <td>7.478335e+07</td>
    </tr>
    <tr>
      <th>62853</th>
      <td>(2010 DO)</td>
      <td>69573.352182</td>
      <td>7.478247e+07</td>
    </tr>
    <tr>
      <th>44329</th>
      <td>297418 (2000 SP43)</td>
      <td>106802.283952</td>
      <td>7.478231e+07</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> nasa-nearest-earth-objects/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the top 3 hazardous object with above average relative velocity and maximum estimated diameter that has flown by Earth the most?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_hazard[(df_hazard.relative_velocity > (df.relative_velocity.mean()))
          & (df_hazard.est_diameter_max > (df.est_diameter_max.mean()))]\
    .rename({'name':'number_of_fly_bys'}, axis=1)\
    .number_of_fly_bys.value_counts().head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_hazard[(df_hazard.relative_velocity > (df.relative_velocity.mean()))
          & (df_hazard.est_diameter_max > (df.est_diameter_max.mean()))]\
    .rename({'name':'number_of_fly_bys'}, axis=1)\
    .number_of_fly_bys.value_counts().head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_hazard[(df_hazard.relative_velocity > df.relative_velocity.
    mean()) & (df_hazard.est_diameter_max > df.est_diameter_max.mean())
    ].rename({'name': 'number_of_fly_bys'}, axis=1
    ).number_of_fly_bys.value_counts().head(3)
</code></pre>
        <p><span onclick="$('#var_output_6b90cbdb').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6b90cbdb" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>418849 (2008 WM64)    34
255071 (2005 UH6)     17
455176 (1999 VF22)    15
Name: number_of_fly_bys, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>418849 (2008 WM64)    34
255071 (2005 UH6)     17
455176 (1999 VF22)    15
Name: number_of_fly_bys, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-200-youtubers-cleaned/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What topic in the comedy video category gets the highest average engagement?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['Main_Video_Category'] == 'Comedy'][['Main_topic', 'Engagement_Rate']].groupby(['Main_topic']).mean().sort_values(
    'Engagement_Rate', ascending=False).iloc[0].name</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['Main_Video_Category'] == 'Comedy'][['Main_topic', 'Engagement_Rate']].groupby(['Main_topic']).mean().sort_values(
    'Engagement_Rate', ascending=False).iloc[0].name</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['Main_Video_Category'] == 'Comedy'][['Main_topic',
    'Engagement_Rate']].groupby(['Main_topic']).mean().sort_values(
    'Engagement_Rate', ascending=False).iloc[0].name
</code></pre>
        <p><span onclick="$('#var_output_bff486d2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bff486d2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Music</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Music</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-200-youtubers-cleaned/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 5 categories with the most geographically diverse channel selection?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Category', 'Country']].dropna().groupby('Category').nunique().sort_values('Country', ascending=False).head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Category', 'Country']].dropna().groupby('Category').nunique().sort_values('Country', ascending=False).head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Category', 'Country']].dropna().groupby('Category').nunique(
    ).sort_values('Country', ascending=False).head(5)
</code></pre>
        <p><span onclick="$('#var_output_618d6f96').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_618d6f96" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
    </tr>
    <tr>
      <th>Category</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Gaming &amp; Apps</th>
      <td>14</td>
    </tr>
    <tr>
      <th>Music</th>
      <td>14</td>
    </tr>
    <tr>
      <th>None</th>
      <td>7</td>
    </tr>
    <tr>
      <th>Beauty &amp; Fashion</th>
      <td>3</td>
    </tr>
    <tr>
      <th>LifeStyle</th>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
    </tr>
    <tr>
      <th>Category</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Gaming &amp; Apps</th>
      <td>14</td>
    </tr>
    <tr>
      <th>Music</th>
      <td>14</td>
    </tr>
    <tr>
      <th>None</th>
      <td>7</td>
    </tr>
    <tr>
      <th>Beauty &amp; Fashion</th>
      <td>3</td>
    </tr>
    <tr>
      <th>LifeStyle</th>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-200-youtubers-cleaned/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the average number of followers for channels according to the number of topics they are associated with.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>get_num_topics = lambda x: len(x.split(',')) if type(x) is str else 0

df['num_topics'] = df.More_topics.apply(get_num_topics)
df[['num_topics', 'followers']].groupby('num_topics').mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>get_num_topics = lambda x: len(x.split(',')) if type(x) is str else 0

df['num_topics'] = df.More_topics.apply(get_num_topics)
df[['num_topics', 'followers']].groupby('num_topics').mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>get_num_topics = lambda x: len(x.split(',')) if type(x) is str else 0
df['num_topics'] = df.More_topics.apply(get_num_topics)
__output__ = df[['num_topics', 'followers']].groupby('num_topics').mean()
</code></pre>
        <p><span onclick="$('#var_output_bd2b506d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bd2b506d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>followers</th>
    </tr>
    <tr>
      <th>num_topics</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.610000e+07</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3.372500e+07</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.003191e+07</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.692619e+07</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4.706977e+07</td>
    </tr>
    <tr>
      <th>5</th>
      <td>3.645556e+07</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3.130000e+07</td>
    </tr>
    <tr>
      <th>8</th>
      <td>2.540000e+07</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Channel_Name</th>
      <th>Category</th>
      <th>Main_Video_Category</th>
      <th>username</th>
      <th>followers</th>
      <th>Main_topic</th>
      <th>...</th>
      <th>Avg._7_Day</th>
      <th>Avg._14_Day</th>
      <th>Avg._30_day</th>
      <th>Avg._60_day</th>
      <th>Comments_Avg</th>
      <th>Youtube_Link</th>
      <th>num_topics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>IN</td>
      <td>T-Series</td>
      <td>Gaming &amp; Apps</td>
      <td>Music</td>
      <td>T-Series</td>
      <td>220000000</td>
      <td>Music of Asia</td>
      <td>...</td>
      <td>1.809830e+06</td>
      <td>2.306178e+06</td>
      <td>1.676330e+06</td>
      <td>2.295416e+06</td>
      <td>4493.984146</td>
      <td>UCq-Fj5jknLsUf-MWSy4_brA</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>US</td>
      <td>ABCkidTV - Nursery Rhymes</td>
      <td>Gaming &amp; Apps</td>
      <td>Education</td>
      <td>ABCkidTV - Nursery Rhymes</td>
      <td>138000000</td>
      <td>Movies</td>
      <td>...</td>
      <td>4.891832e+06</td>
      <td>7.052576e+06</td>
      <td>1.265433e+07</td>
      <td>1.572284e+07</td>
      <td>146.700252</td>
      <td>UCbCmjCuTUZos6Inko4u57UQ</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>IN</td>
      <td>SET India</td>
      <td>Gaming &amp; Apps</td>
      <td>Shows</td>
      <td>SET India</td>
      <td>137000000</td>
      <td>Movies</td>
      <td>...</td>
      <td>2.801276e+05</td>
      <td>3.437881e+05</td>
      <td>3.536019e+05</td>
      <td>3.220336e+05</td>
      <td>76.244316</td>
      <td>UCpEhnqL0y41EpW2TvWAHD7Q</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>US</td>
      <td>PewDiePie</td>
      <td>Gaming &amp; Apps</td>
      <td>Gaming</td>
      <td>PewDiePie</td>
      <td>111000000</td>
      <td>Lifestyle</td>
      <td>...</td>
      <td>3.497395e+06</td>
      <td>3.094440e+06</td>
      <td>3.620274e+06</td>
      <td>4.454120e+06</td>
      <td>35839.781347</td>
      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>US</td>
      <td>MrBeast</td>
      <td>Gaming &amp; Apps</td>
      <td>Entertainment</td>
      <td>MrBeast</td>
      <td>98100000</td>
      <td>Lifestyle</td>
      <td>...</td>
      <td>2.994102e+07</td>
      <td>2.994102e+07</td>
      <td>2.994102e+07</td>
      <td>5.343473e+07</td>
      <td>113432.373684</td>
      <td>UCX6OQ3DkcsbYNE6H8uQQuVA</td>
      <td>3</td>
    </tr>
    <tr>
      <th>5</th>
      <td>US</td>
      <td>Like Nastya</td>
      <td>NaN</td>
      <td>People &amp; Blogs</td>
      <td>Like Nastya</td>
      <td>97300000</td>
      <td>Hobby</td>
      <td>...</td>
      <td>5.829929e+06</td>
      <td>9.480138e+06</td>
      <td>1.375691e+07</td>
      <td>2.210875e+07</td>
      <td>0.292490</td>
      <td>UCJplp5SjeGSdVdwsfb9Q7lQ</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>US</td>
      <td>✿ Kids Diana Show</td>
      <td>Gaming &amp; Apps</td>
      <td>Entertainment</td>
      <td>✿ Kids Diana Show</td>
      <td>97200000</td>
      <td>Lifestyle</td>
      <td>...</td>
      <td>7.539490e+06</td>
      <td>9.148088e+06</td>
      <td>1.434739e+07</td>
      <td>2.346710e+07</td>
      <td>0.000000</td>
      <td>UCk8GzjMOrta8yxDcKfylJYw</td>
      <td>2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>650</th>
      <td>US</td>
      <td>ZHC</td>
      <td>Gaming &amp; Apps</td>
      <td>Howto &amp; Style</td>
      <td>ZHC</td>
      <td>24200000</td>
      <td>Technology</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.778361e+06</td>
      <td>49103.751634</td>
      <td>UClQubH2NeMmGLTLgNdLBwXg</td>
      <td>3</td>
    </tr>
    <tr>
      <th>651</th>
      <td>US</td>
      <td>David Guetta</td>
      <td>Gaming &amp; Apps</td>
      <td>Music</td>
      <td>David Guetta</td>
      <td>24200000</td>
      <td>Electronic music</td>
      <td>...</td>
      <td>NaN</td>
      <td>7.385900e+04</td>
      <td>1.505350e+05</td>
      <td>1.144851e+06</td>
      <td>1386.875000</td>
      <td>UC1l7wYrva1qCH-wgqcHaaRg</td>
      <td>4</td>
    </tr>
    <tr>
      <th>652</th>
      <td>NaN</td>
      <td>1theK (원더케이)</td>
      <td>Music</td>
      <td>Music</td>
      <td>1theK (원더케이)</td>
      <td>24100000</td>
      <td>Pop music</td>
      <td>...</td>
      <td>1.508900e+05</td>
      <td>1.141193e+05</td>
      <td>1.361403e+05</td>
      <td>8.631710e+04</td>
      <td>810.979818</td>
      <td>UCweOkPb1wVVH0Q0Tlj4a5Pw</td>
      <td>3</td>
    </tr>
    <tr>
      <th>653</th>
      <td>US</td>
      <td>Post Malone</td>
      <td>Gaming &amp; Apps</td>
      <td>Music</td>
      <td>Post Malone</td>
      <td>24000000</td>
      <td>Music</td>
      <td>...</td>
      <td>NaN</td>
      <td>1.066810e+05</td>
      <td>1.860830e+06</td>
      <td>1.310594e+06</td>
      <td>11098.637931</td>
      <td>UCeLHszkByNZtPKcaVXOCOQQ</td>
      <td>3</td>
    </tr>
    <tr>
      <th>654</th>
      <td>IN</td>
      <td>Amit Bhadana</td>
      <td>NaN</td>
      <td>Entertainment</td>
      <td>Amit Bhadana</td>
      <td>24000000</td>
      <td>Entertainment</td>
      <td>...</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>100248.500000</td>
      <td>UC_vcKmg67vjMP7ciLnSxSHQ</td>
      <td>3</td>
    </tr>
    <tr>
      <th>655</th>
      <td>US</td>
      <td>James Charles</td>
      <td>Gaming &amp; Apps</td>
      <td>Entertainment</td>
      <td>James Charles</td>
      <td>24000000</td>
      <td>Lifestyle</td>
      <td>...</td>
      <td>6.875610e+05</td>
      <td>6.216617e+05</td>
      <td>6.195134e+05</td>
      <td>8.354377e+05</td>
      <td>38414.745174</td>
      <td>UCucot-Zp428OwkyRm2I7v2Q</td>
      <td>1</td>
    </tr>
    <tr>
      <th>656</th>
      <td>US</td>
      <td>Netflix</td>
      <td>None</td>
      <td>Entertainment</td>
      <td>Netflix</td>
      <td>24000000</td>
      <td>TV shows</td>
      <td>...</td>
      <td>2.734545e+05</td>
      <td>2.780231e+05</td>
      <td>6.761672e+05</td>
      <td>1.004604e+06</td>
      <td>1311.491067</td>
      <td>UCWOA1ZGywLbqmigxE4Qlvuw</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>200 rows × 23 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>followers</th>
    </tr>
    <tr>
      <th>num_topics</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.610000e+07</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3.372500e+07</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.003191e+07</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.692619e+07</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4.706977e+07</td>
    </tr>
    <tr>
      <th>5</th>
      <td>3.645556e+07</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3.130000e+07</td>
    </tr>
    <tr>
      <th>8</th>
      <td>2.540000e+07</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-200-youtubers-cleaned/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many channels have more than 500 million likes but averages no comments?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_0_commnets = df[df.Comments_Avg == 0][['Channel_Name', 'Likes']]
df_0_commnets[df_0_commnets.Likes > 1e8].count()[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_0_commnets = df[df.Comments_Avg == 0][['Channel_Name', 'Likes']]
df_0_commnets[df_0_commnets.Likes > 1e8].count()[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_0_commnets = df[df.Comments_Avg == 0][['Channel_Name', 'Likes']]
__output__ = df_0_commnets[df_0_commnets.Likes > 100000000.0].count()[0]
</code></pre>
        <p><span onclick="$('#var_output_e6deb16c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e6deb16c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int64):</p>
          <pre><code>2</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_0_commnets, __output__ </p>
    
          <p>df_0_commnets (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Channel_Name</th>
      <th>Likes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>✿ Kids Diana Show</td>
      <td>2.351904e+08</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Vlad and Niki</td>
      <td>1.462454e+08</td>
    </tr>
    <tr>
      <th>59</th>
      <td>Like Nastya Show</td>
      <td>3.926915e+07</td>
    </tr>
    <tr>
      <th>68</th>
      <td>Маша и Медведь</td>
      <td>2.375138e+07</td>
    </tr>
    <tr>
      <th>81</th>
      <td>Toys and Colors</td>
      <td>5.098859e+07</td>
    </tr>
    <tr>
      <th>536</th>
      <td>shfa2 - شفا</td>
      <td>3.313906e+07</td>
    </tr>
    <tr>
      <th>572</th>
      <td>Galinha Pintadinha</td>
      <td>5.334350e+07</td>
    </tr>
    <tr>
      <th>574</th>
      <td>CVS 3D Rhymes</td>
      <td>6.457219e+07</td>
    </tr>
    <tr>
      <th>597</th>
      <td>قناة طيور الجنة | toyoraljanahtv</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>617</th>
      <td>Bounce Patrol - Kids Songs</td>
      <td>2.977614e+07</td>
    </tr>
    <tr>
      <th>627</th>
      <td>Diana and Roma ESP</td>
      <td>1.825927e+07</td>
    </tr>
    <tr>
      <th>630</th>
      <td>व्लाद और निकिता</td>
      <td>2.902166e+07</td>
    </tr>
    <tr>
      <th>634</th>
      <td>Vlad và Nikita</td>
      <td>3.801597e+07</td>
    </tr>
    <tr>
      <th>646</th>
      <td>Las Ratitas</td>
      <td>2.573465e+07</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 2 columns</p>
      
          <p>__output__ (int64):</p>
          <pre><code>2</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-200-youtubers-cleaned/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which category has the most channels with a 60 day engagement rate above the median rate?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>median = df.Engagement_Rate_60days.median()
df[df.Engagement_Rate_60days > median][['Category']].value_counts().index[0][0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>median = df.Engagement_Rate_60days.median()
df[df.Engagement_Rate_60days > median][['Category']].value_counts().index[0][0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>median = df.Engagement_Rate_60days.median()
__output__ = df[df.Engagement_Rate_60days > median][['Category']].value_counts(
    ).index[0][0]
</code></pre>
        <p><span onclick="$('#var_output_95a8219e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_95a8219e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Gaming & Apps</code></pre>
      
        <p><strong>Hyp output variables:</strong> median, __output__ </p>
    
          <p>median (float):</p>
          <pre><code>0.025570568652035747</code></pre>
      
          <p>__output__ (str):</p>
          <pre><code>Gaming & Apps</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-200-youtubers-cleaned/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 3 countries in terms of the views accumulated from their creators?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Country', 'Views']].groupby('Country').mean().sort_values('Views', ascending=False).head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Country', 'Views']].groupby('Country').mean().sort_values('Views', ascending=False).head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Country', 'Views']].groupby('Country').mean().sort_values(
    'Views', ascending=False).head(3)
</code></pre>
        <p><span onclick="$('#var_output_948e3d14').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_948e3d14" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Views</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>PH</th>
      <td>3.622977e+10</td>
    </tr>
    <tr>
      <th>RU</th>
      <td>3.041799e+10</td>
    </tr>
    <tr>
      <th>TH</th>
      <td>2.659563e+10</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Views</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>PH</th>
      <td>3.622977e+10</td>
    </tr>
    <tr>
      <th>RU</th>
      <td>3.041799e+10</td>
    </tr>
    <tr>
      <th>TH</th>
      <td>2.659563e+10</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-200-youtubers-cleaned/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which channels among the top 25% most followed channels have a boost index within the first quartile</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df.Boost_Index < df.Boost_Index.quantile(0.25))
   & (df.followers > df.followers.quantile(0.75))][['Channel_Name',
                                                   'Boost_Index',
                                                   'followers']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df.Boost_Index < df.Boost_Index.quantile(0.25))
   & (df.followers > df.followers.quantile(0.75))][['Channel_Name',
                                                   'Boost_Index',
                                                   'followers']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df.Boost_Index < df.Boost_Index.quantile(0.25)) & (df.
    followers > df.followers.quantile(0.75))][['Channel_Name',
    'Boost_Index', 'followers']]
</code></pre>
        <p><span onclick="$('#var_output_1e1fe5c5').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1e1fe5c5" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Channel_Name</th>
      <th>Boost_Index</th>
      <th>followers</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20</th>
      <td>Justin Bieber</td>
      <td>46</td>
      <td>69400000</td>
    </tr>
    <tr>
      <th>34</th>
      <td>EminemMusic</td>
      <td>27</td>
      <td>52600000</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Ariana Grande</td>
      <td>33</td>
      <td>51500000</td>
    </tr>
    <tr>
      <th>46</th>
      <td>Billie Eilish</td>
      <td>16</td>
      <td>45900000</td>
    </tr>
    <tr>
      <th>53</th>
      <td>HolaSoyGerman.</td>
      <td>59</td>
      <td>43300000</td>
    </tr>
    <tr>
      <th>55</th>
      <td>Katy Perry</td>
      <td>57</td>
      <td>43000000</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Channel_Name</th>
      <th>Boost_Index</th>
      <th>followers</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20</th>
      <td>Justin Bieber</td>
      <td>46</td>
      <td>69400000</td>
    </tr>
    <tr>
      <th>34</th>
      <td>EminemMusic</td>
      <td>27</td>
      <td>52600000</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Ariana Grande</td>
      <td>33</td>
      <td>51500000</td>
    </tr>
    <tr>
      <th>46</th>
      <td>Billie Eilish</td>
      <td>16</td>
      <td>45900000</td>
    </tr>
    <tr>
      <th>53</th>
      <td>HolaSoyGerman.</td>
      <td>59</td>
      <td>43300000</td>
    </tr>
    <tr>
      <th>55</th>
      <td>Katy Perry</td>
      <td>57</td>
      <td>43000000</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-200-youtubers-cleaned/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 5 topic pairs that occur together the most?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def split_fn(x: str):
    try:
        x = x.split(',')
    except:
        print(x)
    x.sort()
    return x

topics = df.More_topics.dropna().apply(split_fn)
topics = topics[topics.apply(lambda x: len(x) > 1)]
topics.apply(lambda x: list(itertools.combinations(x, 2))).explode().value_counts().index[:5].to_list()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def split_fn(x: str):
    try:
        x = x.split(',')
    except:
        print(x)
    x.sort()
    return x

topics = df.More_topics.dropna().apply(split_fn)
topics = topics[topics.apply(lambda x: len(x) > 1)]
topics.apply(lambda x: list(itertools.combinations(x, 2))).explode().value_counts().index[:5].to_list()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def split_fn(x: str):
    try:
        x = x.split(',')
    except:
        print(x)
    x.sort()
    return x


topics = df.More_topics.dropna().apply(split_fn)
topics = topics[topics.apply(lambda x: len(x) > 1)]
__output__ = topics.apply(lambda x: list(itertools.combinations(x, 2))
    ).explode().value_counts().index[:5].to_list()
</code></pre>
        <p><span onclick="$('#var_output_cc476e15').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_cc476e15" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>[('Entertainment', 'Movies'), ('Music', 'Pop music'), ('Entertainment', 'Music'), ('Movies', 'Music'), ('Hip hop music', 'Music')]</code></pre>
      
        <p><strong>Hyp output variables:</strong> topics, __output__ </p>
    
          <p>topics (Series):</p>
          <pre><code>0          [Entertainment, Movies, Music, Music of Asia]
1                         [Entertainment, Movies, Music]
2               [Entertainment, Movies, Music, TV shows]
3      [Action game, Action-adventure game, Gaming, L...
4                 [Entertainment, Lifestyle, Technology]
                             ...                        
651    [Electronic music, Hip hop music, Music, Pop m...
652                    [Music, Music of Asia, Pop music]
653                    [Hip hop music, Music, Pop music]
654                       [Entertainment, Movies, Music]
656                    [Entertainment, Movies, TV shows]
Name: More_topics, Length: 187, dtype: object</code></pre>
      
          <p>__output__ (list):</p>
          <pre><code>[('Entertainment', 'Movies'), ('Music', 'Pop music'), ('Entertainment', 'Music'), ('Movies', 'Music'), ('Hip hop music', 'Music')]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-200-youtubers-cleaned/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which channels are associated with both 'Entertainment' and 'Movies'?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_ch = df[['Channel_Name', 'More_topics']].dropna()
df_ch.More_topics = df_ch.More_topics.apply(split_fn)
df_ch[df_ch.More_topics.apply(lambda x: 'Entertainment' in x and 'Movies' in x)]['Channel_Name']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_ch = df[['Channel_Name', 'More_topics']].dropna()
df_ch.More_topics = df_ch.More_topics.apply(split_fn)
df_ch[df_ch.More_topics.apply(lambda x: 'Entertainment' in x and 'Movies' in x)]['Channel_Name']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_ch = df[['Channel_Name', 'More_topics']].dropna()
df_ch.More_topics = df_ch.More_topics.apply(split_fn)
__output__ = df_ch[df_ch.More_topics.apply(lambda x: 'Entertainment' in x and
    'Movies' in x)]['Channel_Name']
</code></pre>
        <p><span onclick="$('#var_output_e31b4730').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e31b4730" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0                                      T-Series
1                     ABCkidTV - Nursery Rhymes
2                                     SET India
19                          Goldmines Telefilms
21                                       SAB TV
                         ...                   
640                                    Nick Jr.
647                               WatchMojo.com
648    Super JoJo - Nursery Rhymes & Kids Songs
654                                Amit Bhadana
656                                     Netflix
Name: Channel_Name, Length: 69, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_ch, __output__ </p>
    
          <p>df_ch (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Channel_Name</th>
      <th>More_topics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>T-Series</td>
      <td>[Entertainment, Movies, Music, Music of Asia]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ABCkidTV - Nursery Rhymes</td>
      <td>[Entertainment, Movies, Music]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SET India</td>
      <td>[Entertainment, Movies, Music, TV shows]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>PewDiePie</td>
      <td>[Action game, Action-adventure game, Gaming, Lifestyle]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>MrBeast</td>
      <td>[Entertainment, Lifestyle, Technology]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Like Nastya</td>
      <td>[Hobby, Lifestyle]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>✿ Kids Diana Show</td>
      <td>[Hobby, Lifestyle]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>650</th>
      <td>ZHC</td>
      <td>[Hobby, Lifestyle, Technology]</td>
    </tr>
    <tr>
      <th>651</th>
      <td>David Guetta</td>
      <td>[Electronic music, Hip hop music, Music, Pop music]</td>
    </tr>
    <tr>
      <th>652</th>
      <td>1theK (원더케이)</td>
      <td>[Music, Music of Asia, Pop music]</td>
    </tr>
    <tr>
      <th>653</th>
      <td>Post Malone</td>
      <td>[Hip hop music, Music, Pop music]</td>
    </tr>
    <tr>
      <th>654</th>
      <td>Amit Bhadana</td>
      <td>[Entertainment, Movies, Music]</td>
    </tr>
    <tr>
      <th>655</th>
      <td>James Charles</td>
      <td>[Lifestyle]</td>
    </tr>
    <tr>
      <th>656</th>
      <td>Netflix</td>
      <td>[Entertainment, Movies, TV shows]</td>
    </tr>
  </tbody>
</table>
<p>199 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0                                      T-Series
1                     ABCkidTV - Nursery Rhymes
2                                     SET India
19                          Goldmines Telefilms
21                                       SAB TV
                         ...                   
640                                    Nick Jr.
647                               WatchMojo.com
648    Super JoJo - Nursery Rhymes & Kids Songs
654                                Amit Bhadana
656                                     Netflix
Name: Channel_Name, Length: 69, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-200-youtubers-cleaned/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which channels had the highest percentage growth in monthly viewership in this month? List top 3.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_30_day_viewership, df_60_day_viewership  = df['Avg._30_day'], df['Avg._60_day']
df_30_day_viewership_prev = (2 * df_60_day_viewership - df_30_day_viewership)
df['growth_percentage'] = 100 * (df_30_day_viewership - df_30_day_viewership_prev) / df_30_day_viewership_prev
df[['Channel_Name', 'growth_percentage']].sort_values('growth_percentage', ascending=False).head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_30_day_viewership, df_60_day_viewership  = df['Avg._30_day'], df['Avg._60_day']
df_30_day_viewership_prev = (2 * df_60_day_viewership - df_30_day_viewership)
df['growth_percentage'] = 100 * (df_30_day_viewership - df_30_day_viewership_prev) / df_30_day_viewership_prev
df[['Channel_Name', 'growth_percentage']].sort_values('growth_percentage', ascending=False).head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_30_day_viewership, df_60_day_viewership = df['Avg._30_day'], df[
    'Avg._60_day']
df_30_day_viewership_prev = 2 * df_60_day_viewership - df_30_day_viewership
df['growth_percentage'] = 100 * (df_30_day_viewership -
    df_30_day_viewership_prev) / df_30_day_viewership_prev
__output__ = df[['Channel_Name', 'growth_percentage']].sort_values(
    'growth_percentage', ascending=False).head(3)
</code></pre>
        <p><span onclick="$('#var_output_4da7ddd7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4da7ddd7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Channel_Name</th>
      <th>growth_percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>577</th>
      <td>Rajshri</td>
      <td>7490.917332</td>
    </tr>
    <tr>
      <th>601</th>
      <td>The Late Late Show with James Corden</td>
      <td>304.722810</td>
    </tr>
    <tr>
      <th>652</th>
      <td>1theK (원더케이)</td>
      <td>273.049689</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, df_30_day_viewership, df_60_day_viewership, df_30_day_viewership_prev, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Channel_Name</th>
      <th>Category</th>
      <th>Main_Video_Category</th>
      <th>username</th>
      <th>followers</th>
      <th>Main_topic</th>
      <th>...</th>
      <th>Avg._14_Day</th>
      <th>Avg._30_day</th>
      <th>Avg._60_day</th>
      <th>Comments_Avg</th>
      <th>Youtube_Link</th>
      <th>num_topics</th>
      <th>growth_percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>IN</td>
      <td>T-Series</td>
      <td>Gaming &amp; Apps</td>
      <td>Music</td>
      <td>T-Series</td>
      <td>220000000</td>
      <td>Music of Asia</td>
      <td>...</td>
      <td>2.306178e+06</td>
      <td>1.676330e+06</td>
      <td>2.295416e+06</td>
      <td>4493.984146</td>
      <td>UCq-Fj5jknLsUf-MWSy4_brA</td>
      <td>4</td>
      <td>-42.483155</td>
    </tr>
    <tr>
      <th>1</th>
      <td>US</td>
      <td>ABCkidTV - Nursery Rhymes</td>
      <td>Gaming &amp; Apps</td>
      <td>Education</td>
      <td>ABCkidTV - Nursery Rhymes</td>
      <td>138000000</td>
      <td>Movies</td>
      <td>...</td>
      <td>7.052576e+06</td>
      <td>1.265433e+07</td>
      <td>1.572284e+07</td>
      <td>146.700252</td>
      <td>UCbCmjCuTUZos6Inko4u57UQ</td>
      <td>3</td>
      <td>-32.658787</td>
    </tr>
    <tr>
      <th>2</th>
      <td>IN</td>
      <td>SET India</td>
      <td>Gaming &amp; Apps</td>
      <td>Shows</td>
      <td>SET India</td>
      <td>137000000</td>
      <td>Movies</td>
      <td>...</td>
      <td>3.437881e+05</td>
      <td>3.536019e+05</td>
      <td>3.220336e+05</td>
      <td>76.244316</td>
      <td>UCpEhnqL0y41EpW2TvWAHD7Q</td>
      <td>4</td>
      <td>21.736325</td>
    </tr>
    <tr>
      <th>3</th>
      <td>US</td>
      <td>PewDiePie</td>
      <td>Gaming &amp; Apps</td>
      <td>Gaming</td>
      <td>PewDiePie</td>
      <td>111000000</td>
      <td>Lifestyle</td>
      <td>...</td>
      <td>3.094440e+06</td>
      <td>3.620274e+06</td>
      <td>4.454120e+06</td>
      <td>35839.781347</td>
      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>
      <td>4</td>
      <td>-31.537501</td>
    </tr>
    <tr>
      <th>4</th>
      <td>US</td>
      <td>MrBeast</td>
      <td>Gaming &amp; Apps</td>
      <td>Entertainment</td>
      <td>MrBeast</td>
      <td>98100000</td>
      <td>Lifestyle</td>
      <td>...</td>
      <td>2.994102e+07</td>
      <td>2.994102e+07</td>
      <td>5.343473e+07</td>
      <td>113432.373684</td>
      <td>UCX6OQ3DkcsbYNE6H8uQQuVA</td>
      <td>3</td>
      <td>-61.079389</td>
    </tr>
    <tr>
      <th>5</th>
      <td>US</td>
      <td>Like Nastya</td>
      <td>NaN</td>
      <td>People &amp; Blogs</td>
      <td>Like Nastya</td>
      <td>97300000</td>
      <td>Hobby</td>
      <td>...</td>
      <td>9.480138e+06</td>
      <td>1.375691e+07</td>
      <td>2.210875e+07</td>
      <td>0.292490</td>
      <td>UCJplp5SjeGSdVdwsfb9Q7lQ</td>
      <td>2</td>
      <td>-54.837035</td>
    </tr>
    <tr>
      <th>6</th>
      <td>US</td>
      <td>✿ Kids Diana Show</td>
      <td>Gaming &amp; Apps</td>
      <td>Entertainment</td>
      <td>✿ Kids Diana Show</td>
      <td>97200000</td>
      <td>Lifestyle</td>
      <td>...</td>
      <td>9.148088e+06</td>
      <td>1.434739e+07</td>
      <td>2.346710e+07</td>
      <td>0.000000</td>
      <td>UCk8GzjMOrta8yxDcKfylJYw</td>
      <td>2</td>
      <td>-55.971787</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>650</th>
      <td>US</td>
      <td>ZHC</td>
      <td>Gaming &amp; Apps</td>
      <td>Howto &amp; Style</td>
      <td>ZHC</td>
      <td>24200000</td>
      <td>Technology</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.778361e+06</td>
      <td>49103.751634</td>
      <td>UClQubH2NeMmGLTLgNdLBwXg</td>
      <td>3</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>651</th>
      <td>US</td>
      <td>David Guetta</td>
      <td>Gaming &amp; Apps</td>
      <td>Music</td>
      <td>David Guetta</td>
      <td>24200000</td>
      <td>Electronic music</td>
      <td>...</td>
      <td>7.385900e+04</td>
      <td>1.505350e+05</td>
      <td>1.144851e+06</td>
      <td>1386.875000</td>
      <td>UC1l7wYrva1qCH-wgqcHaaRg</td>
      <td>4</td>
      <td>-92.962918</td>
    </tr>
    <tr>
      <th>652</th>
      <td>NaN</td>
      <td>1theK (원더케이)</td>
      <td>Music</td>
      <td>Music</td>
      <td>1theK (원더케이)</td>
      <td>24100000</td>
      <td>Pop music</td>
      <td>...</td>
      <td>1.141193e+05</td>
      <td>1.361403e+05</td>
      <td>8.631710e+04</td>
      <td>810.979818</td>
      <td>UCweOkPb1wVVH0Q0Tlj4a5Pw</td>
      <td>3</td>
      <td>273.049689</td>
    </tr>
    <tr>
      <th>653</th>
      <td>US</td>
      <td>Post Malone</td>
      <td>Gaming &amp; Apps</td>
      <td>Music</td>
      <td>Post Malone</td>
      <td>24000000</td>
      <td>Music</td>
      <td>...</td>
      <td>1.066810e+05</td>
      <td>1.860830e+06</td>
      <td>1.310594e+06</td>
      <td>11098.637931</td>
      <td>UCeLHszkByNZtPKcaVXOCOQQ</td>
      <td>3</td>
      <td>144.730998</td>
    </tr>
    <tr>
      <th>654</th>
      <td>IN</td>
      <td>Amit Bhadana</td>
      <td>NaN</td>
      <td>Entertainment</td>
      <td>Amit Bhadana</td>
      <td>24000000</td>
      <td>Entertainment</td>
      <td>...</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000e+00</td>
      <td>100248.500000</td>
      <td>UC_vcKmg67vjMP7ciLnSxSHQ</td>
      <td>3</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>655</th>
      <td>US</td>
      <td>James Charles</td>
      <td>Gaming &amp; Apps</td>
      <td>Entertainment</td>
      <td>James Charles</td>
      <td>24000000</td>
      <td>Lifestyle</td>
      <td>...</td>
      <td>6.216617e+05</td>
      <td>6.195134e+05</td>
      <td>8.354377e+05</td>
      <td>38414.745174</td>
      <td>UCucot-Zp428OwkyRm2I7v2Q</td>
      <td>1</td>
      <td>-41.075154</td>
    </tr>
    <tr>
      <th>656</th>
      <td>US</td>
      <td>Netflix</td>
      <td>None</td>
      <td>Entertainment</td>
      <td>Netflix</td>
      <td>24000000</td>
      <td>TV shows</td>
      <td>...</td>
      <td>2.780231e+05</td>
      <td>6.761672e+05</td>
      <td>1.004604e+06</td>
      <td>1311.491067</td>
      <td>UCWOA1ZGywLbqmigxE4Qlvuw</td>
      <td>3</td>
      <td>-49.276331</td>
    </tr>
  </tbody>
</table>
<p>200 rows × 24 columns</p>
      
          <p>df_30_day_viewership (Series):</p>
          <pre><code>0      1.676330e+06
1      1.265433e+07
2      3.536019e+05
3      3.620274e+06
4      2.994102e+07
           ...     
652    1.361403e+05
653    1.860830e+06
654    0.000000e+00
655    6.195134e+05
656    6.761672e+05
Name: Avg._30_day, Length: 200, dtype: float64</code></pre>
      
          <p>df_60_day_viewership (Series):</p>
          <pre><code>0      2.295416e+06
1      1.572284e+07
2      3.220336e+05
3      4.454120e+06
4      5.343473e+07
           ...     
652    8.631710e+04
653    1.310594e+06
654    0.000000e+00
655    8.354377e+05
656    1.004604e+06
Name: Avg._60_day, Length: 200, dtype: float64</code></pre>
      
          <p>df_30_day_viewership_prev (Series):</p>
          <pre><code>0      2.914502e+06
1      1.879136e+07
2      2.904654e+05
3      5.287966e+06
4      7.692844e+07
           ...     
652    3.649388e+04
653    7.603575e+05
654    0.000000e+00
655    1.051362e+06
656    1.333041e+06
Length: 200, dtype: float64</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Channel_Name</th>
      <th>growth_percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>577</th>
      <td>Rajshri</td>
      <td>7490.917332</td>
    </tr>
    <tr>
      <th>601</th>
      <td>The Late Late Show with James Corden</td>
      <td>304.722810</td>
    </tr>
    <tr>
      <th>652</th>
      <td>1theK (원더케이)</td>
      <td>273.049689</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.2, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bollywood-movies-boxoffice-collection-2022/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total gross of Hollywood movies in India?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.MovieType == 'Hollywood'].IndiaGross.sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.MovieType == 'Hollywood'].IndiaGross.sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.MovieType == 'Hollywood'].IndiaGross.sum()
</code></pre>
        <p><span onclick="$('#var_output_7909fef1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7909fef1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>514.23</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>514.23</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bollywood-movies-boxoffice-collection-2022/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the release dates to datetime objects.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>convert_to_datetime = lambda datestring: datetime.strptime(datestring, "%d-%b-%y")
df.ReleasedDate = df.ReleasedDate.apply(convert_to_datetime)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>convert_to_datetime = lambda datestring: datetime.strptime(datestring, "%d-%b-%y")
df.ReleasedDate = df.ReleasedDate.apply(convert_to_datetime)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>convert_to_datetime = lambda datestring: datetime.strptime(datestring,
    '%d-%b-%y')
__output__ = df.ReleasedDate = df.ReleasedDate.apply(convert_to_datetime)
</code></pre>
        <p><span onclick="$('#var_output_f912ac3d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f912ac3d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0    2022-06-24
1    2022-06-17
2    2022-06-17
3    2022-06-17
4    2022-06-17
        ...    
95   2021-11-25
96   2021-11-25
97   2021-11-19
98   2021-11-19
99   2021-11-19
Name: ReleasedDate, Length: 100, dtype: datetime64[ns]</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>Worldwide</th>
      <th>IndiaNet</th>
      <th>IndiaGross</th>
      <th>Overseas</th>
      <th>Budget</th>
      <th>Verdict</th>
      <th>MovieType</th>
      <th>ReleasedDate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>JugJugg Jeeyo</td>
      <td>74.5000</td>
      <td>50.2400</td>
      <td>54.5000</td>
      <td>20.00</td>
      <td>100</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2022-06-24</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Virata Parvam</td>
      <td>4.2000</td>
      <td>5.1200</td>
      <td>2.9000</td>
      <td>1.30</td>
      <td>1</td>
      <td>None</td>
      <td>Tollywood</td>
      <td>2022-06-17</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Naadi Dosh</td>
      <td>8.1500</td>
      <td>7.8700</td>
      <td>8.1500</td>
      <td>0.00</td>
      <td>1</td>
      <td>None</td>
      <td>Gollywood</td>
      <td>2022-06-17</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Veetla Vishesham</td>
      <td>9.6000</td>
      <td>7.4000</td>
      <td>8.6000</td>
      <td>1.00</td>
      <td>1</td>
      <td>None</td>
      <td>Kollywood</td>
      <td>2022-06-17</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Nikamma</td>
      <td>0.8000</td>
      <td>2.1900</td>
      <td>0.6000</td>
      <td>0.20</td>
      <td>1</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2022-06-17</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Jurassic World: Dominion</td>
      <td>4000.0000</td>
      <td>62.8100</td>
      <td>56.6000</td>
      <td>2700.00</td>
      <td>1</td>
      <td>None</td>
      <td>Hollywood</td>
      <td>2022-06-10</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Ante Sundaraniki</td>
      <td>31.5000</td>
      <td>21.2300</td>
      <td>23.3700</td>
      <td>8.13</td>
      <td>1</td>
      <td>None</td>
      <td>Tollywood</td>
      <td>2022-06-10</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>93</th>
      <td>Marakkar: Lion of the Arabian Sea</td>
      <td>45.4000</td>
      <td>21.0500</td>
      <td>22.4000</td>
      <td>23.00</td>
      <td>100</td>
      <td>None</td>
      <td>Mollywood</td>
      <td>2021-12-02</td>
    </tr>
    <tr>
      <th>94</th>
      <td>Antim: The Final Truth</td>
      <td>58.5000</td>
      <td>39.5700</td>
      <td>46.8000</td>
      <td>11.70</td>
      <td>35</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-26</td>
    </tr>
    <tr>
      <th>95</th>
      <td>Maanaadu</td>
      <td>75.0000</td>
      <td>52.1800</td>
      <td>59.5000</td>
      <td>15.50</td>
      <td>30</td>
      <td>None</td>
      <td>Kollywood</td>
      <td>2021-11-25</td>
    </tr>
    <tr>
      <th>96</th>
      <td>Satyameva Jayate 2</td>
      <td>15.0000</td>
      <td>14.1600</td>
      <td>12.4000</td>
      <td>2.60</td>
      <td>60</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-25</td>
    </tr>
    <tr>
      <th>97</th>
      <td>Bunty Aur Babli 2</td>
      <td>20.5000</td>
      <td>11.9000</td>
      <td>14.0000</td>
      <td>6.50</td>
      <td>30</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-19</td>
    </tr>
    <tr>
      <th>98</th>
      <td>Shubh Raatri</td>
      <td>0.0001</td>
      <td>0.0001</td>
      <td>0.0001</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2021-11-19</td>
    </tr>
    <tr>
      <th>99</th>
      <td>Ghostbusters: Afterlife</td>
      <td>0.2300</td>
      <td>0.2000</td>
      <td>0.2300</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Hollywood</td>
      <td>2021-11-19</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 9 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0    2022-06-24
1    2022-06-17
2    2022-06-17
3    2022-06-17
4    2022-06-17
        ...    
95   2021-11-25
96   2021-11-25
97   2021-11-19
98   2021-11-19
99   2021-11-19
Name: ReleasedDate, Length: 100, dtype: datetime64[ns]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bollywood-movies-boxoffice-collection-2022/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the number of movies released for each month since November 2021 to June 2022. List the months in chronological order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['month'] = df.ReleasedDate.apply(lambda x: x.strftime("%B, %Y"))
df_t = df[df.ReleasedDate.apply(
    lambda date: datetime.fromisoformat('2021-10-30') <= date <= datetime.fromisoformat('2022-07-01'))]
df_counts = df_t[['month']].value_counts()
months = df_t.month.unique()
months = list(map(lambda x: datetime.strptime(x, "%B, %Y"), months))
months.sort()
months = list(map(lambda x: x.strftime("%B, %Y"), months))
df_counts[months]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['month'] = df.ReleasedDate.apply(lambda x: x.strftime("%B, %Y"))
df_t = df[df.ReleasedDate.apply(
    lambda date: datetime.fromisoformat('2021-10-30') <= date <= datetime.fromisoformat('2022-07-01'))]
df_counts = df_t[['month']].value_counts()
months = df_t.month.unique()
months = list(map(lambda x: datetime.strptime(x, "%B, %Y"), months))
months.sort()
months = list(map(lambda x: x.strftime("%B, %Y"), months))
df_counts[months]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['month'] = df.ReleasedDate.apply(lambda x: x.strftime('%B, %Y'))
df_t = df[df.ReleasedDate.apply(lambda date: datetime.fromisoformat(
    '2021-10-30') <= date <= datetime.fromisoformat('2022-07-01'))]
df_counts = df_t[['month']].value_counts()
months = df_t.month.unique()
months = list(map(lambda x: datetime.strptime(x, '%B, %Y'), months))
__tmp_5 = months.sort()
months = list(map(lambda x: x.strftime('%B, %Y'), months))
__output__ = df_counts[months]
</code></pre>
        <p><span onclick="$('#var_output_620af179').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_620af179" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>month         
November, 2021     6
December, 2021    10
January, 2022      3
February, 2022    24
March, 2022       13
April, 2022       15
May, 2022         17
June, 2022        12
dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, df_t, df_counts, months, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>Worldwide</th>
      <th>IndiaNet</th>
      <th>IndiaGross</th>
      <th>Overseas</th>
      <th>Budget</th>
      <th>Verdict</th>
      <th>MovieType</th>
      <th>ReleasedDate</th>
      <th>month</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>JugJugg Jeeyo</td>
      <td>74.5000</td>
      <td>50.2400</td>
      <td>54.5000</td>
      <td>20.00</td>
      <td>100</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2022-06-24</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Virata Parvam</td>
      <td>4.2000</td>
      <td>5.1200</td>
      <td>2.9000</td>
      <td>1.30</td>
      <td>1</td>
      <td>None</td>
      <td>Tollywood</td>
      <td>2022-06-17</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Naadi Dosh</td>
      <td>8.1500</td>
      <td>7.8700</td>
      <td>8.1500</td>
      <td>0.00</td>
      <td>1</td>
      <td>None</td>
      <td>Gollywood</td>
      <td>2022-06-17</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Veetla Vishesham</td>
      <td>9.6000</td>
      <td>7.4000</td>
      <td>8.6000</td>
      <td>1.00</td>
      <td>1</td>
      <td>None</td>
      <td>Kollywood</td>
      <td>2022-06-17</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Nikamma</td>
      <td>0.8000</td>
      <td>2.1900</td>
      <td>0.6000</td>
      <td>0.20</td>
      <td>1</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2022-06-17</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Jurassic World: Dominion</td>
      <td>4000.0000</td>
      <td>62.8100</td>
      <td>56.6000</td>
      <td>2700.00</td>
      <td>1</td>
      <td>None</td>
      <td>Hollywood</td>
      <td>2022-06-10</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Ante Sundaraniki</td>
      <td>31.5000</td>
      <td>21.2300</td>
      <td>23.3700</td>
      <td>8.13</td>
      <td>1</td>
      <td>None</td>
      <td>Tollywood</td>
      <td>2022-06-10</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>93</th>
      <td>Marakkar: Lion of the Arabian Sea</td>
      <td>45.4000</td>
      <td>21.0500</td>
      <td>22.4000</td>
      <td>23.00</td>
      <td>100</td>
      <td>None</td>
      <td>Mollywood</td>
      <td>2021-12-02</td>
      <td>December, 2021</td>
    </tr>
    <tr>
      <th>94</th>
      <td>Antim: The Final Truth</td>
      <td>58.5000</td>
      <td>39.5700</td>
      <td>46.8000</td>
      <td>11.70</td>
      <td>35</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-26</td>
      <td>November, 2021</td>
    </tr>
    <tr>
      <th>95</th>
      <td>Maanaadu</td>
      <td>75.0000</td>
      <td>52.1800</td>
      <td>59.5000</td>
      <td>15.50</td>
      <td>30</td>
      <td>None</td>
      <td>Kollywood</td>
      <td>2021-11-25</td>
      <td>November, 2021</td>
    </tr>
    <tr>
      <th>96</th>
      <td>Satyameva Jayate 2</td>
      <td>15.0000</td>
      <td>14.1600</td>
      <td>12.4000</td>
      <td>2.60</td>
      <td>60</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-25</td>
      <td>November, 2021</td>
    </tr>
    <tr>
      <th>97</th>
      <td>Bunty Aur Babli 2</td>
      <td>20.5000</td>
      <td>11.9000</td>
      <td>14.0000</td>
      <td>6.50</td>
      <td>30</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-19</td>
      <td>November, 2021</td>
    </tr>
    <tr>
      <th>98</th>
      <td>Shubh Raatri</td>
      <td>0.0001</td>
      <td>0.0001</td>
      <td>0.0001</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2021-11-19</td>
      <td>November, 2021</td>
    </tr>
    <tr>
      <th>99</th>
      <td>Ghostbusters: Afterlife</td>
      <td>0.2300</td>
      <td>0.2000</td>
      <td>0.2300</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Hollywood</td>
      <td>2021-11-19</td>
      <td>November, 2021</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 10 columns</p>
      
          <p>df_t (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>Worldwide</th>
      <th>IndiaNet</th>
      <th>IndiaGross</th>
      <th>Overseas</th>
      <th>Budget</th>
      <th>Verdict</th>
      <th>MovieType</th>
      <th>ReleasedDate</th>
      <th>month</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>JugJugg Jeeyo</td>
      <td>74.5000</td>
      <td>50.2400</td>
      <td>54.5000</td>
      <td>20.00</td>
      <td>100</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2022-06-24</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Virata Parvam</td>
      <td>4.2000</td>
      <td>5.1200</td>
      <td>2.9000</td>
      <td>1.30</td>
      <td>1</td>
      <td>None</td>
      <td>Tollywood</td>
      <td>2022-06-17</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Naadi Dosh</td>
      <td>8.1500</td>
      <td>7.8700</td>
      <td>8.1500</td>
      <td>0.00</td>
      <td>1</td>
      <td>None</td>
      <td>Gollywood</td>
      <td>2022-06-17</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Veetla Vishesham</td>
      <td>9.6000</td>
      <td>7.4000</td>
      <td>8.6000</td>
      <td>1.00</td>
      <td>1</td>
      <td>None</td>
      <td>Kollywood</td>
      <td>2022-06-17</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Nikamma</td>
      <td>0.8000</td>
      <td>2.1900</td>
      <td>0.6000</td>
      <td>0.20</td>
      <td>1</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2022-06-17</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Jurassic World: Dominion</td>
      <td>4000.0000</td>
      <td>62.8100</td>
      <td>56.6000</td>
      <td>2700.00</td>
      <td>1</td>
      <td>None</td>
      <td>Hollywood</td>
      <td>2022-06-10</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Ante Sundaraniki</td>
      <td>31.5000</td>
      <td>21.2300</td>
      <td>23.3700</td>
      <td>8.13</td>
      <td>1</td>
      <td>None</td>
      <td>Tollywood</td>
      <td>2022-06-10</td>
      <td>June, 2022</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>93</th>
      <td>Marakkar: Lion of the Arabian Sea</td>
      <td>45.4000</td>
      <td>21.0500</td>
      <td>22.4000</td>
      <td>23.00</td>
      <td>100</td>
      <td>None</td>
      <td>Mollywood</td>
      <td>2021-12-02</td>
      <td>December, 2021</td>
    </tr>
    <tr>
      <th>94</th>
      <td>Antim: The Final Truth</td>
      <td>58.5000</td>
      <td>39.5700</td>
      <td>46.8000</td>
      <td>11.70</td>
      <td>35</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-26</td>
      <td>November, 2021</td>
    </tr>
    <tr>
      <th>95</th>
      <td>Maanaadu</td>
      <td>75.0000</td>
      <td>52.1800</td>
      <td>59.5000</td>
      <td>15.50</td>
      <td>30</td>
      <td>None</td>
      <td>Kollywood</td>
      <td>2021-11-25</td>
      <td>November, 2021</td>
    </tr>
    <tr>
      <th>96</th>
      <td>Satyameva Jayate 2</td>
      <td>15.0000</td>
      <td>14.1600</td>
      <td>12.4000</td>
      <td>2.60</td>
      <td>60</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-25</td>
      <td>November, 2021</td>
    </tr>
    <tr>
      <th>97</th>
      <td>Bunty Aur Babli 2</td>
      <td>20.5000</td>
      <td>11.9000</td>
      <td>14.0000</td>
      <td>6.50</td>
      <td>30</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-19</td>
      <td>November, 2021</td>
    </tr>
    <tr>
      <th>98</th>
      <td>Shubh Raatri</td>
      <td>0.0001</td>
      <td>0.0001</td>
      <td>0.0001</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2021-11-19</td>
      <td>November, 2021</td>
    </tr>
    <tr>
      <th>99</th>
      <td>Ghostbusters: Afterlife</td>
      <td>0.2300</td>
      <td>0.2000</td>
      <td>0.2300</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Hollywood</td>
      <td>2021-11-19</td>
      <td>November, 2021</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 10 columns</p>
      
          <p>df_counts (Series):</p>
          <pre><code>month         
February, 2022    24
May, 2022         17
April, 2022       15
March, 2022       13
June, 2022        12
December, 2021    10
November, 2021     6
January, 2022      3
dtype: int64</code></pre>
      
          <p>months (list):</p>
          <pre><code>['November, 2021', 'December, 2021', 'January, 2022', 'February, 2022', 'March, 2022', 'April, 2022', 'May, 2022', 'June, 2022']</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>month         
November, 2021     6
December, 2021    10
January, 2022      3
February, 2022    24
March, 2022       13
April, 2022       15
May, 2022         17
June, 2022        12
dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.16666666666666666, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bollywood-movies-boxoffice-collection-2022/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the worldwide gross of the films released for each month since November, 2021 to June 2022. List  the months in chronological order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_t[['month', 'Worldwide']].groupby('month').sum().T</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_t[['month', 'Worldwide']].groupby('month').sum().T</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_t[['month', 'Worldwide']].groupby('month').sum().T
</code></pre>
        <p><span onclick="$('#var_output_4519d392').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4519d392" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>month</th>
      <th>April, 2022</th>
      <th>December, 2021</th>
      <th>February, 2022</th>
      <th>January, 2022</th>
      <th>June, 2022</th>
      <th>March, 2022</th>
      <th>May, 2022</th>
      <th>November, 2021</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Worldwide</th>
      <td>1748.13</td>
      <td>10988.6</td>
      <td>1812.99</td>
      <td>114.12</td>
      <td>4763.05</td>
      <td>3849.25</td>
      <td>7730.75</td>
      <td>169.2301</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 8 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>month</th>
      <th>April, 2022</th>
      <th>December, 2021</th>
      <th>February, 2022</th>
      <th>January, 2022</th>
      <th>June, 2022</th>
      <th>March, 2022</th>
      <th>May, 2022</th>
      <th>November, 2021</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Worldwide</th>
      <td>1748.13</td>
      <td>10988.6</td>
      <td>1812.99</td>
      <td>114.12</td>
      <td>4763.05</td>
      <td>3849.25</td>
      <td>7730.75</td>
      <td>169.2301</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 8 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bollywood-movies-boxoffice-collection-2022/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 3 movies that are considered a disaster but made the most profit? List them according to profit in ascending order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_disasters = df[df.Verdict == 'Disaster'].dropna()
df_disasters['Profit'] = df_disasters['Worldwide'] - df['Budget']
df_disasters[['Movie', 'Profit']].sort_values("Profit").tail(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_disasters = df[df.Verdict == 'Disaster'].dropna()
df_disasters['Profit'] = df_disasters['Worldwide'] - df['Budget']
df_disasters[['Movie', 'Profit']].sort_values("Profit").tail(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_disasters = df[df.Verdict == 'Disaster'].dropna()
df_disasters['Profit'] = df_disasters['Worldwide'] - df['Budget']
__output__ = df_disasters[['Movie', 'Profit']].sort_values('Profit').tail(3)
</code></pre>
        <p><span onclick="$('#var_output_5a7640c9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5a7640c9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>Profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>39</th>
      <td>Ghani</td>
      <td>6.7</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Anek</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Jayeshbhai Jordaar</td>
      <td>16.5</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_disasters, __output__ </p>
    
          <p>df_disasters (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>Worldwide</th>
      <th>IndiaNet</th>
      <th>IndiaGross</th>
      <th>Overseas</th>
      <th>Budget</th>
      <th>Verdict</th>
      <th>MovieType</th>
      <th>ReleasedDate</th>
      <th>month</th>
      <th>Profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>11</th>
      <td>Samrat Prithviraj</td>
      <td>85.0000</td>
      <td>66.0000</td>
      <td>77.0000</td>
      <td>8.00</td>
      <td>220</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2022-06-03</td>
      <td>June, 2022</td>
      <td>-135.0000</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Anek</td>
      <td>9.0000</td>
      <td>9.0500</td>
      <td>7.3000</td>
      <td>1.70</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2022-05-27</td>
      <td>May, 2022</td>
      <td>8.0000</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Jayeshbhai Jordaar</td>
      <td>17.5000</td>
      <td>17.9100</td>
      <td>14.0500</td>
      <td>3.45</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2022-05-13</td>
      <td>May, 2022</td>
      <td>16.5000</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Heropanti 2</td>
      <td>28.0000</td>
      <td>21.5000</td>
      <td>25.3000</td>
      <td>2.70</td>
      <td>80</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2022-04-29</td>
      <td>April, 2022</td>
      <td>-52.0000</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Acharya</td>
      <td>73.5000</td>
      <td>56.1400</td>
      <td>62.2500</td>
      <td>11.25</td>
      <td>140</td>
      <td>Disaster</td>
      <td>Tollywood</td>
      <td>2022-04-29</td>
      <td>April, 2022</td>
      <td>-66.5000</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Main Te Bapu</td>
      <td>0.7000</td>
      <td>0.6000</td>
      <td>0.7000</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Pollywood</td>
      <td>2022-04-22</td>
      <td>April, 2022</td>
      <td>-0.3000</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Jersey</td>
      <td>26.0000</td>
      <td>20.5400</td>
      <td>22.5000</td>
      <td>3.50</td>
      <td>60</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2022-04-22</td>
      <td>April, 2022</td>
      <td>-34.0000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>60</th>
      <td>Upacharapoorvam Gunda Jayan</td>
      <td>0.6300</td>
      <td>0.5500</td>
      <td>0.6300</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Mollywood</td>
      <td>2022-02-25</td>
      <td>February, 2022</td>
      <td>-0.3700</td>
    </tr>
    <tr>
      <th>71</th>
      <td>Badhaai Do</td>
      <td>23.0000</td>
      <td>19.8100</td>
      <td>20.0000</td>
      <td>3.00</td>
      <td>30</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2022-02-11</td>
      <td>February, 2022</td>
      <td>-7.0000</td>
    </tr>
    <tr>
      <th>72</th>
      <td>Kallan D`Souza</td>
      <td>0.1700</td>
      <td>0.1500</td>
      <td>0.1700</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Mollywood</td>
      <td>2022-02-11</td>
      <td>February, 2022</td>
      <td>-0.8300</td>
    </tr>
    <tr>
      <th>75</th>
      <td>Archana 31 Not Out</td>
      <td>0.1000</td>
      <td>0.1900</td>
      <td>0.1000</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Mollywood</td>
      <td>2022-02-11</td>
      <td>February, 2022</td>
      <td>-0.9000</td>
    </tr>
    <tr>
      <th>86</th>
      <td>83</td>
      <td>193.0000</td>
      <td>107.3100</td>
      <td>129.0000</td>
      <td>64.00</td>
      <td>220</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2021-12-24</td>
      <td>December, 2021</td>
      <td>-27.0000</td>
    </tr>
    <tr>
      <th>98</th>
      <td>Shubh Raatri</td>
      <td>0.0001</td>
      <td>0.0001</td>
      <td>0.0001</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2021-11-19</td>
      <td>November, 2021</td>
      <td>-0.9999</td>
    </tr>
    <tr>
      <th>99</th>
      <td>Ghostbusters: Afterlife</td>
      <td>0.2300</td>
      <td>0.2000</td>
      <td>0.2300</td>
      <td>0.00</td>
      <td>1</td>
      <td>Disaster</td>
      <td>Hollywood</td>
      <td>2021-11-19</td>
      <td>November, 2021</td>
      <td>-0.7700</td>
    </tr>
  </tbody>
</table>
<p>18 rows × 11 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>Profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>39</th>
      <td>Ghani</td>
      <td>6.7</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Anek</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Jayeshbhai Jordaar</td>
      <td>16.5</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bollywood-movies-boxoffice-collection-2022/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Among the all time hit movies, what percentage of worldwide gross was from India?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_all_time_blockbusters = df[df.Verdict == 'All Time Blockbuster'].dropna()
df_all_time_blockbusters['Indian Gross(%)'] = 100 * (df_all_time_blockbusters['IndiaGross']) \
                                              /df_all_time_blockbusters['Worldwide']
df_all_time_blockbusters[['Movie', 'Indian Gross(%)']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_all_time_blockbusters = df[df.Verdict == 'All Time Blockbuster'].dropna()
df_all_time_blockbusters['Indian Gross(%)'] = 100 * (df_all_time_blockbusters['IndiaGross']) \
                                              /df_all_time_blockbusters['Worldwide']
df_all_time_blockbusters[['Movie', 'Indian Gross(%)']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_all_time_blockbusters = df[df.Verdict == 'All Time Blockbuster'].dropna()
df_all_time_blockbusters['Indian Gross(%)'] = 100 * df_all_time_blockbusters[
    'IndiaGross'] / df_all_time_blockbusters['Worldwide']
__output__ = df_all_time_blockbusters[['Movie', 'Indian Gross(%)']]
</code></pre>
        <p><span onclick="$('#var_output_726cd116').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_726cd116" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>Indian Gross(%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>Vikram</td>
      <td>69.265823</td>
    </tr>
    <tr>
      <th>37</th>
      <td>KGF Chapter 2</td>
      <td>82.903894</td>
    </tr>
    <tr>
      <th>48</th>
      <td>The Kashmir Files</td>
      <td>86.510264</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_all_time_blockbusters, __output__ </p>
    
          <p>df_all_time_blockbusters (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>Worldwide</th>
      <th>IndiaNet</th>
      <th>IndiaGross</th>
      <th>Overseas</th>
      <th>Budget</th>
      <th>Verdict</th>
      <th>MovieType</th>
      <th>ReleasedDate</th>
      <th>month</th>
      <th>Indian Gross(%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>Vikram</td>
      <td>395.0</td>
      <td>236.11</td>
      <td>273.60</td>
      <td>121.40</td>
      <td>120</td>
      <td>All Time Blockbuster</td>
      <td>Kollywood</td>
      <td>2022-06-03</td>
      <td>June, 2022</td>
      <td>69.265823</td>
    </tr>
    <tr>
      <th>37</th>
      <td>KGF Chapter 2</td>
      <td>1207.0</td>
      <td>859.55</td>
      <td>1000.65</td>
      <td>206.35</td>
      <td>100</td>
      <td>All Time Blockbuster</td>
      <td>Sandalwood</td>
      <td>2022-04-14</td>
      <td>April, 2022</td>
      <td>82.903894</td>
    </tr>
    <tr>
      <th>48</th>
      <td>The Kashmir Files</td>
      <td>341.0</td>
      <td>252.25</td>
      <td>295.00</td>
      <td>46.00</td>
      <td>20</td>
      <td>All Time Blockbuster</td>
      <td>Bollywood</td>
      <td>2022-03-11</td>
      <td>March, 2022</td>
      <td>86.510264</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 11 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>Indian Gross(%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>Vikram</td>
      <td>69.265823</td>
    </tr>
    <tr>
      <th>37</th>
      <td>KGF Chapter 2</td>
      <td>82.903894</td>
    </tr>
    <tr>
      <th>48</th>
      <td>The Kashmir Files</td>
      <td>86.510264</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bollywood-movies-boxoffice-collection-2022/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the mean budget for each movie type?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Movie', 'MovieType', 'Budget']].groupby('MovieType').mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Movie', 'MovieType', 'Budget']].groupby('MovieType').mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Movie', 'MovieType', 'Budget']].groupby('MovieType').mean()
</code></pre>
        <p><span onclick="$('#var_output_f48a77a2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f48a77a2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Budget</th>
    </tr>
    <tr>
      <th>MovieType</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bengali Tollywood</th>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>Bollywood</th>
      <td>57.961538</td>
    </tr>
    <tr>
      <th>Gollywood</th>
      <td>2.333333</td>
    </tr>
    <tr>
      <th>Hollywood</th>
      <td>557.714286</td>
    </tr>
    <tr>
      <th>Indian</th>
      <td>350.000000</td>
    </tr>
    <tr>
      <th>Kollywood</th>
      <td>43.153846</td>
    </tr>
    <tr>
      <th>Marathi Film</th>
      <td>5.857143</td>
    </tr>
    <tr>
      <th>Mollywood</th>
      <td>19.000000</td>
    </tr>
    <tr>
      <th>Pollywood</th>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>Sandalwood</th>
      <td>19.555556</td>
    </tr>
    <tr>
      <th>Tollywood</th>
      <td>62.157895</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Budget</th>
    </tr>
    <tr>
      <th>MovieType</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bengali Tollywood</th>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>Bollywood</th>
      <td>57.961538</td>
    </tr>
    <tr>
      <th>Gollywood</th>
      <td>2.333333</td>
    </tr>
    <tr>
      <th>Hollywood</th>
      <td>557.714286</td>
    </tr>
    <tr>
      <th>Indian</th>
      <td>350.000000</td>
    </tr>
    <tr>
      <th>Kollywood</th>
      <td>43.153846</td>
    </tr>
    <tr>
      <th>Marathi Film</th>
      <td>5.857143</td>
    </tr>
    <tr>
      <th>Mollywood</th>
      <td>19.000000</td>
    </tr>
    <tr>
      <th>Pollywood</th>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>Sandalwood</th>
      <td>19.555556</td>
    </tr>
    <tr>
      <th>Tollywood</th>
      <td>62.157895</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> bollywood-movies-boxoffice-collection-2022/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the top 5 movies with the highest percentage return on investment.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_roi = df[df.Budget>1]
df_roi['ROI'] = 100*(df_roi.Worldwide - df_roi.Budget)/df_roi.Budget
df_roi[['Movie', 'ROI']].sort_values('ROI', ascending=False).head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_roi = df[df.Budget>1]
df_roi['ROI'] = 100*(df_roi.Worldwide - df_roi.Budget)/df_roi.Budget
df_roi[['Movie', 'ROI']].sort_values('ROI', ascending=False).head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_roi = df[df.Budget > 1]
df_roi['ROI'] = 100 * (df_roi.Worldwide - df_roi.Budget) / df_roi.Budget
__output__ = df_roi[['Movie', 'ROI']].sort_values('ROI', ascending=False).head(
    5)
</code></pre>
        <p><span onclick="$('#var_output_2a3bad4f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2a3bad4f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>ROI</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>48</th>
      <td>The Kashmir Files</td>
      <td>1605.000000</td>
    </tr>
    <tr>
      <th>37</th>
      <td>KGF Chapter 2</td>
      <td>1107.000000</td>
    </tr>
    <tr>
      <th>82</th>
      <td>Hridayam</td>
      <td>658.571429</td>
    </tr>
    <tr>
      <th>88</th>
      <td>Spider-Man: No Way Home</td>
      <td>578.000000</td>
    </tr>
    <tr>
      <th>8</th>
      <td>777 Charlie</td>
      <td>504.000000</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_roi, __output__ </p>
    
          <p>df_roi (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>Worldwide</th>
      <th>IndiaNet</th>
      <th>IndiaGross</th>
      <th>Overseas</th>
      <th>Budget</th>
      <th>Verdict</th>
      <th>MovieType</th>
      <th>ReleasedDate</th>
      <th>month</th>
      <th>ROI</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>JugJugg Jeeyo</td>
      <td>74.50</td>
      <td>50.24</td>
      <td>54.50</td>
      <td>20.0</td>
      <td>100</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2022-06-24</td>
      <td>June, 2022</td>
      <td>-25.500000</td>
    </tr>
    <tr>
      <th>8</th>
      <td>777 Charlie</td>
      <td>90.60</td>
      <td>75.76</td>
      <td>85.00</td>
      <td>5.6</td>
      <td>15</td>
      <td>None</td>
      <td>Sandalwood</td>
      <td>2022-06-10</td>
      <td>June, 2022</td>
      <td>504.000000</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Vikram</td>
      <td>395.00</td>
      <td>236.11</td>
      <td>273.60</td>
      <td>121.4</td>
      <td>120</td>
      <td>All Time Blockbuster</td>
      <td>Kollywood</td>
      <td>2022-06-03</td>
      <td>June, 2022</td>
      <td>229.166667</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Major</td>
      <td>58.20</td>
      <td>41.03</td>
      <td>45.20</td>
      <td>13.0</td>
      <td>30</td>
      <td>SuperHit</td>
      <td>Bollywood</td>
      <td>2022-06-03</td>
      <td>June, 2022</td>
      <td>94.000000</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Samrat Prithviraj</td>
      <td>85.00</td>
      <td>66.00</td>
      <td>77.00</td>
      <td>8.0</td>
      <td>220</td>
      <td>Disaster</td>
      <td>Bollywood</td>
      <td>2022-06-03</td>
      <td>June, 2022</td>
      <td>-61.363636</td>
    </tr>
    <tr>
      <th>12</th>
      <td>F3: Fun and Frustration</td>
      <td>90.00</td>
      <td>67.34</td>
      <td>75.10</td>
      <td>14.9</td>
      <td>70</td>
      <td>Average</td>
      <td>Tollywood</td>
      <td>2022-05-27</td>
      <td>May, 2022</td>
      <td>28.571429</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Sarsenapati Hambirrao</td>
      <td>17.65</td>
      <td>15.09</td>
      <td>17.65</td>
      <td>0.0</td>
      <td>10</td>
      <td>Hit</td>
      <td>Marathi Film</td>
      <td>2022-05-27</td>
      <td>May, 2022</td>
      <td>76.500000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>91</th>
      <td>Pandu</td>
      <td>5.90</td>
      <td>5.50</td>
      <td>5.90</td>
      <td>0.0</td>
      <td>4</td>
      <td>None</td>
      <td>Marathi Film</td>
      <td>2021-12-03</td>
      <td>December, 2021</td>
      <td>47.500000</td>
    </tr>
    <tr>
      <th>92</th>
      <td>Akhanda</td>
      <td>117.00</td>
      <td>89.00</td>
      <td>103.30</td>
      <td>13.7</td>
      <td>40</td>
      <td>SuperHit</td>
      <td>Tollywood</td>
      <td>2021-12-02</td>
      <td>December, 2021</td>
      <td>192.500000</td>
    </tr>
    <tr>
      <th>93</th>
      <td>Marakkar: Lion of the Arabian Sea</td>
      <td>45.40</td>
      <td>21.05</td>
      <td>22.40</td>
      <td>23.0</td>
      <td>100</td>
      <td>None</td>
      <td>Mollywood</td>
      <td>2021-12-02</td>
      <td>December, 2021</td>
      <td>-54.600000</td>
    </tr>
    <tr>
      <th>94</th>
      <td>Antim: The Final Truth</td>
      <td>58.50</td>
      <td>39.57</td>
      <td>46.80</td>
      <td>11.7</td>
      <td>35</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-26</td>
      <td>November, 2021</td>
      <td>67.142857</td>
    </tr>
    <tr>
      <th>95</th>
      <td>Maanaadu</td>
      <td>75.00</td>
      <td>52.18</td>
      <td>59.50</td>
      <td>15.5</td>
      <td>30</td>
      <td>None</td>
      <td>Kollywood</td>
      <td>2021-11-25</td>
      <td>November, 2021</td>
      <td>150.000000</td>
    </tr>
    <tr>
      <th>96</th>
      <td>Satyameva Jayate 2</td>
      <td>15.00</td>
      <td>14.16</td>
      <td>12.40</td>
      <td>2.6</td>
      <td>60</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-25</td>
      <td>November, 2021</td>
      <td>-75.000000</td>
    </tr>
    <tr>
      <th>97</th>
      <td>Bunty Aur Babli 2</td>
      <td>20.50</td>
      <td>11.90</td>
      <td>14.00</td>
      <td>6.5</td>
      <td>30</td>
      <td>None</td>
      <td>Bollywood</td>
      <td>2021-11-19</td>
      <td>November, 2021</td>
      <td>-31.666667</td>
    </tr>
  </tbody>
</table>
<p>52 rows × 11 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Movie</th>
      <th>ROI</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>48</th>
      <td>The Kashmir Files</td>
      <td>1605.000000</td>
    </tr>
    <tr>
      <th>37</th>
      <td>KGF Chapter 2</td>
      <td>1107.000000</td>
    </tr>
    <tr>
      <th>82</th>
      <td>Hridayam</td>
      <td>658.571429</td>
    </tr>
    <tr>
      <th>88</th>
      <td>Spider-Man: No Way Home</td>
      <td>578.000000</td>
    </tr>
    <tr>
      <th>8</th>
      <td>777 Charlie</td>
      <td>504.000000</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ecommerce-fashion-dataset/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the list price and selling price of each item to numeric values.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def convert_mrp_string(x):
    if type(x) != str:
        return np.NaN
    if x == 'Nan':
        return np.NaN
    return float(x.split('\n')[1])

df.MRP = df.MRP.apply(convert_mrp_string)
df.SellPrice = df.SellPrice.apply(lambda x: x if type(x) != str else float(x))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def convert_mrp_string(x):
    if type(x) != str:
        return np.NaN
    if x == 'Nan':
        return np.NaN
    return float(x.split('\n')[1])

df.MRP = df.MRP.apply(convert_mrp_string)
df.SellPrice = df.SellPrice.apply(lambda x: x if type(x) != str else float(x))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def convert_mrp_string(x):
    if type(x) != str:
        return np.NaN
    if x == 'Nan':
        return np.NaN
    return float(x.split('\n')[1])


df.MRP = df.MRP.apply(convert_mrp_string)
__output__ = df.SellPrice = df.SellPrice.apply(lambda x: x if type(x) !=
    str else float(x))
</code></pre>
        <p><span onclick="$('#var_output_fc0389e3').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_fc0389e3" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      849.0
1     2449.0
2      599.0
3     1379.0
4      849.0
       ...  
21    8950.0
22       NaN
23     643.0
24    2799.0
25    1899.0
Name: SellPrice, Length: 30758, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BrandName</th>
      <th>Deatils</th>
      <th>Sizes</th>
      <th>MRP</th>
      <th>SellPrice</th>
      <th>Discount</th>
      <th>Category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>life</td>
      <td>solid cotton blend collar neck womens a-line dress - indigo</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>50% off</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>1</th>
      <td>only</td>
      <td>polyester peter pan collar womens blouson dress - yellow</td>
      <td>Size:34,36,38,40</td>
      <td>3499.0</td>
      <td>2449.0</td>
      <td>30% off</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fratini</td>
      <td>solid polyester blend wide neck womens regular top - off white</td>
      <td>Size:Large,X-Large,XX-Large</td>
      <td>1199.0</td>
      <td>599.0</td>
      <td>50% off</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>3</th>
      <td>zink london</td>
      <td>stripes polyester sweetheart neck womens dress - black</td>
      <td>Size:Large,Medium,Small,X-Large</td>
      <td>2299.0</td>
      <td>1379.0</td>
      <td>40% off</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>4</th>
      <td>life</td>
      <td>regular fit regular length denim womens jeans - stone</td>
      <td>Size:26,28,30,32,34,36</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>50% off</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>5</th>
      <td>kraus</td>
      <td>wide ankle length cotton womens jeans - light blue</td>
      <td>Size:26,28,30,32,34</td>
      <td>1795.0</td>
      <td>1615.0</td>
      <td>10% off</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>6</th>
      <td>life</td>
      <td>printed cotton blend collared womens regular dress - white</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1299.0</td>
      <td>649.0</td>
      <td>50% off</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19</th>
      <td>swarovski</td>
      <td>constella stylish crystal white pierced earrings</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>8950.0</td>
      <td>Nan</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>20</th>
      <td>shaya by caratlane</td>
      <td>the wing woman clover charm necklace</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>1250.0</td>
      <td>Nan</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>21</th>
      <td>swarovski</td>
      <td>crystal stylish womens rodhium earrings</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>8950.0</td>
      <td>Nan</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Nan</td>
      <td>Nan</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Nan</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>23</th>
      <td>jewelz</td>
      <td>ethnic gold plated jhumki earrings</td>
      <td>Nan</td>
      <td>1839.0</td>
      <td>643.0</td>
      <td>65% off</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>24</th>
      <td>estelle</td>
      <td>womens gold plated double line fancy white and gold pearl necklace</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>2799.0</td>
      <td>Nan</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>25</th>
      <td>estelle</td>
      <td>womens gold plated bridge designer mangalsutra necklaces</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>1899.0</td>
      <td>Nan</td>
      <td>Jewellery-Women</td>
    </tr>
  </tbody>
</table>
<p>30758 rows × 7 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      849.0
1     2449.0
2      599.0
3     1379.0
4      849.0
       ...  
21    8950.0
22       NaN
23     643.0
24    2799.0
25    1899.0
Name: SellPrice, Length: 30758, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ecommerce-fashion-dataset/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the discounts on each item to decimal values.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.Discount = df.Discount.apply(lambda x: float(x.split('%')[0]) / 100)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.Discount = df.Discount.apply(lambda x: float(x.split('%')[0]) / 100)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.Discount = df.Discount.apply(lambda x: float(x.split('%')[0
    ]) / 100)
</code></pre>
        <p><span onclick="$('#var_output_8853e942').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8853e942" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0     0.50
1     0.30
2     0.50
3     0.40
4     0.50
      ... 
21     NaN
22     NaN
23    0.65
24     NaN
25     NaN
Name: Discount, Length: 30758, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BrandName</th>
      <th>Deatils</th>
      <th>Sizes</th>
      <th>MRP</th>
      <th>SellPrice</th>
      <th>Discount</th>
      <th>Category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>life</td>
      <td>solid cotton blend collar neck womens a-line dress - indigo</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>1</th>
      <td>only</td>
      <td>polyester peter pan collar womens blouson dress - yellow</td>
      <td>Size:34,36,38,40</td>
      <td>3499.0</td>
      <td>2449.0</td>
      <td>0.30</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fratini</td>
      <td>solid polyester blend wide neck womens regular top - off white</td>
      <td>Size:Large,X-Large,XX-Large</td>
      <td>1199.0</td>
      <td>599.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>3</th>
      <td>zink london</td>
      <td>stripes polyester sweetheart neck womens dress - black</td>
      <td>Size:Large,Medium,Small,X-Large</td>
      <td>2299.0</td>
      <td>1379.0</td>
      <td>0.40</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>4</th>
      <td>life</td>
      <td>regular fit regular length denim womens jeans - stone</td>
      <td>Size:26,28,30,32,34,36</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>5</th>
      <td>kraus</td>
      <td>wide ankle length cotton womens jeans - light blue</td>
      <td>Size:26,28,30,32,34</td>
      <td>1795.0</td>
      <td>1615.0</td>
      <td>0.10</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>6</th>
      <td>life</td>
      <td>printed cotton blend collared womens regular dress - white</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1299.0</td>
      <td>649.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19</th>
      <td>swarovski</td>
      <td>constella stylish crystal white pierced earrings</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>8950.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>20</th>
      <td>shaya by caratlane</td>
      <td>the wing woman clover charm necklace</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>1250.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>21</th>
      <td>swarovski</td>
      <td>crystal stylish womens rodhium earrings</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>8950.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Nan</td>
      <td>Nan</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>23</th>
      <td>jewelz</td>
      <td>ethnic gold plated jhumki earrings</td>
      <td>Nan</td>
      <td>1839.0</td>
      <td>643.0</td>
      <td>0.65</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>24</th>
      <td>estelle</td>
      <td>womens gold plated double line fancy white and gold pearl necklace</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>2799.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
    </tr>
    <tr>
      <th>25</th>
      <td>estelle</td>
      <td>womens gold plated bridge designer mangalsutra necklaces</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>1899.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
    </tr>
  </tbody>
</table>
<p>30758 rows × 7 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0     0.50
1     0.30
2     0.50
3     0.40
4     0.50
      ... 
21     NaN
22     NaN
23    0.65
24     NaN
25     NaN
Name: Discount, Length: 30758, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ecommerce-fashion-dataset/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the median number of sizes offered?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['SizeVariations'] = df.Sizes.apply(lambda x: x.strip().replace('Size:', '').split(','))
df.SizeVariations.apply(len).median()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['SizeVariations'] = df.Sizes.apply(lambda x: x.strip().replace('Size:', '').split(','))
df.SizeVariations.apply(len).median()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['SizeVariations'] = df.Sizes.apply(lambda x: x.strip().replace('Size:',
    '').split(','))
__output__ = df.SizeVariations.apply(len).median()
</code></pre>
        <p><span onclick="$('#var_output_a6e37aad').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a6e37aad" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float):</p>
          <pre><code>4.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BrandName</th>
      <th>Deatils</th>
      <th>Sizes</th>
      <th>MRP</th>
      <th>SellPrice</th>
      <th>Discount</th>
      <th>Category</th>
      <th>SizeVariations</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>life</td>
      <td>solid cotton blend collar neck womens a-line dress - indigo</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large, X-Small]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>only</td>
      <td>polyester peter pan collar womens blouson dress - yellow</td>
      <td>Size:34,36,38,40</td>
      <td>3499.0</td>
      <td>2449.0</td>
      <td>0.30</td>
      <td>Westernwear-Women</td>
      <td>[34, 36, 38, 40]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fratini</td>
      <td>solid polyester blend wide neck womens regular top - off white</td>
      <td>Size:Large,X-Large,XX-Large</td>
      <td>1199.0</td>
      <td>599.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, X-Large, XX-Large]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>zink london</td>
      <td>stripes polyester sweetheart neck womens dress - black</td>
      <td>Size:Large,Medium,Small,X-Large</td>
      <td>2299.0</td>
      <td>1379.0</td>
      <td>0.40</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>life</td>
      <td>regular fit regular length denim womens jeans - stone</td>
      <td>Size:26,28,30,32,34,36</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[26, 28, 30, 32, 34, 36]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>kraus</td>
      <td>wide ankle length cotton womens jeans - light blue</td>
      <td>Size:26,28,30,32,34</td>
      <td>1795.0</td>
      <td>1615.0</td>
      <td>0.10</td>
      <td>Westernwear-Women</td>
      <td>[26, 28, 30, 32, 34]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>life</td>
      <td>printed cotton blend collared womens regular dress - white</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1299.0</td>
      <td>649.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large, X-Small]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19</th>
      <td>swarovski</td>
      <td>constella stylish crystal white pierced earrings</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>8950.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
    </tr>
    <tr>
      <th>20</th>
      <td>shaya by caratlane</td>
      <td>the wing woman clover charm necklace</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>1250.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
    </tr>
    <tr>
      <th>21</th>
      <td>swarovski</td>
      <td>crystal stylish womens rodhium earrings</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>8950.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Nan</td>
      <td>Nan</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
    </tr>
    <tr>
      <th>23</th>
      <td>jewelz</td>
      <td>ethnic gold plated jhumki earrings</td>
      <td>Nan</td>
      <td>1839.0</td>
      <td>643.0</td>
      <td>0.65</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
    </tr>
    <tr>
      <th>24</th>
      <td>estelle</td>
      <td>womens gold plated double line fancy white and gold pearl necklace</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>2799.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
    </tr>
    <tr>
      <th>25</th>
      <td>estelle</td>
      <td>womens gold plated bridge designer mangalsutra necklaces</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>1899.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
    </tr>
  </tbody>
</table>
<p>30758 rows × 8 columns</p>
      
          <p>__output__ (float):</p>
          <pre><code>4.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ecommerce-fashion-dataset/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Find the color of each item and save in a new column.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['color'] = df.Deatils.apply(lambda x: x.split(' - ')[-1].strip())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['color'] = df.Deatils.apply(lambda x: x.split(' - ')[-1].strip())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df['color'] = df.Deatils.apply(lambda x: x.split(' - ')[-1].
    strip())
</code></pre>
        <p><span onclick="$('#var_output_03112089').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_03112089" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0                                                indigo
1                                                yellow
2                                             off white
3                                                 black
4                                                 stone
                            ...                        
21              crystal stylish womens rodhium earrings
22                                                  Nan
23                   ethnic gold plated jhumki earrings
24    womens gold plated double line fancy white and...
25    womens gold plated bridge designer mangalsutra...
Name: Deatils, Length: 30758, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BrandName</th>
      <th>Deatils</th>
      <th>Sizes</th>
      <th>MRP</th>
      <th>SellPrice</th>
      <th>Discount</th>
      <th>Category</th>
      <th>SizeVariations</th>
      <th>color</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>life</td>
      <td>solid cotton blend collar neck womens a-line dress - indigo</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large, X-Small]</td>
      <td>indigo</td>
    </tr>
    <tr>
      <th>1</th>
      <td>only</td>
      <td>polyester peter pan collar womens blouson dress - yellow</td>
      <td>Size:34,36,38,40</td>
      <td>3499.0</td>
      <td>2449.0</td>
      <td>0.30</td>
      <td>Westernwear-Women</td>
      <td>[34, 36, 38, 40]</td>
      <td>yellow</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fratini</td>
      <td>solid polyester blend wide neck womens regular top - off white</td>
      <td>Size:Large,X-Large,XX-Large</td>
      <td>1199.0</td>
      <td>599.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, X-Large, XX-Large]</td>
      <td>off white</td>
    </tr>
    <tr>
      <th>3</th>
      <td>zink london</td>
      <td>stripes polyester sweetheart neck womens dress - black</td>
      <td>Size:Large,Medium,Small,X-Large</td>
      <td>2299.0</td>
      <td>1379.0</td>
      <td>0.40</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large]</td>
      <td>black</td>
    </tr>
    <tr>
      <th>4</th>
      <td>life</td>
      <td>regular fit regular length denim womens jeans - stone</td>
      <td>Size:26,28,30,32,34,36</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[26, 28, 30, 32, 34, 36]</td>
      <td>stone</td>
    </tr>
    <tr>
      <th>5</th>
      <td>kraus</td>
      <td>wide ankle length cotton womens jeans - light blue</td>
      <td>Size:26,28,30,32,34</td>
      <td>1795.0</td>
      <td>1615.0</td>
      <td>0.10</td>
      <td>Westernwear-Women</td>
      <td>[26, 28, 30, 32, 34]</td>
      <td>light blue</td>
    </tr>
    <tr>
      <th>6</th>
      <td>life</td>
      <td>printed cotton blend collared womens regular dress - white</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1299.0</td>
      <td>649.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large, X-Small]</td>
      <td>white</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19</th>
      <td>swarovski</td>
      <td>constella stylish crystal white pierced earrings</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>8950.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>constella stylish crystal white pierced earrings</td>
    </tr>
    <tr>
      <th>20</th>
      <td>shaya by caratlane</td>
      <td>the wing woman clover charm necklace</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>1250.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>the wing woman clover charm necklace</td>
    </tr>
    <tr>
      <th>21</th>
      <td>swarovski</td>
      <td>crystal stylish womens rodhium earrings</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>8950.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>crystal stylish womens rodhium earrings</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Nan</td>
      <td>Nan</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>Nan</td>
    </tr>
    <tr>
      <th>23</th>
      <td>jewelz</td>
      <td>ethnic gold plated jhumki earrings</td>
      <td>Nan</td>
      <td>1839.0</td>
      <td>643.0</td>
      <td>0.65</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>ethnic gold plated jhumki earrings</td>
    </tr>
    <tr>
      <th>24</th>
      <td>estelle</td>
      <td>womens gold plated double line fancy white and gold pearl necklace</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>2799.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>womens gold plated double line fancy white and gold pearl necklace</td>
    </tr>
    <tr>
      <th>25</th>
      <td>estelle</td>
      <td>womens gold plated bridge designer mangalsutra necklaces</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>1899.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>womens gold plated bridge designer mangalsutra necklaces</td>
    </tr>
  </tbody>
</table>
<p>30758 rows × 9 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0                                                indigo
1                                                yellow
2                                             off white
3                                                 black
4                                                 stone
                            ...                        
21              crystal stylish womens rodhium earrings
22                                                  Nan
23                   ethnic gold plated jhumki earrings
24    womens gold plated double line fancy white and...
25    womens gold plated bridge designer mangalsutra...
Name: Deatils, Length: 30758, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ecommerce-fashion-dataset/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the median discount in each category? Show Percentage.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Category', 'Discount']].groupby('Category').median() * 100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Category', 'Discount']].groupby('Category').median() * 100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Category', 'Discount']].groupby('Category').median() * 100
</code></pre>
        <p><span onclick="$('#var_output_b0f75973').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b0f75973" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Discount</th>
    </tr>
    <tr>
      <th>Category</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Footwear-Women</th>
      <td>40.0</td>
    </tr>
    <tr>
      <th>Fragrance-Women</th>
      <td>20.0</td>
    </tr>
    <tr>
      <th>Indianwear-Women</th>
      <td>50.0</td>
    </tr>
    <tr>
      <th>Jewellery-Women</th>
      <td>50.0</td>
    </tr>
    <tr>
      <th>Lingerie&amp;Nightwear-Women</th>
      <td>50.0</td>
    </tr>
    <tr>
      <th>Watches-Women</th>
      <td>30.0</td>
    </tr>
    <tr>
      <th>Westernwear-Women</th>
      <td>50.0</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Discount</th>
    </tr>
    <tr>
      <th>Category</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Footwear-Women</th>
      <td>40.0</td>
    </tr>
    <tr>
      <th>Fragrance-Women</th>
      <td>20.0</td>
    </tr>
    <tr>
      <th>Indianwear-Women</th>
      <td>50.0</td>
    </tr>
    <tr>
      <th>Jewellery-Women</th>
      <td>50.0</td>
    </tr>
    <tr>
      <th>Lingerie&amp;Nightwear-Women</th>
      <td>50.0</td>
    </tr>
    <tr>
      <th>Watches-Women</th>
      <td>30.0</td>
    </tr>
    <tr>
      <th>Westernwear-Women</th>
      <td>50.0</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ecommerce-fashion-dataset/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which brand is offering the most price reductions on average across all its offerings?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['PriceReduction'] = df.MRP - df.SellPrice
df[['BrandName', 'PriceReduction']].dropna().groupby('BrandName').mean().sort_values('PriceReduction',
                                                                                      ascending=False).rename(
    columns={'PriceReduction': 'average_price_reduction'}).head(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['PriceReduction'] = df.MRP - df.SellPrice
df[['BrandName', 'PriceReduction']].dropna().groupby('BrandName').mean().sort_values('PriceReduction',
                                                                                      ascending=False).rename(
    columns={'PriceReduction': 'average_price_reduction'}).head(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['PriceReduction'] = df.MRP - df.SellPrice
__output__ = df[['BrandName', 'PriceReduction']].dropna().groupby('BrandName'
    ).mean().sort_values('PriceReduction', ascending=False).rename(columns=
    {'PriceReduction': 'average_price_reduction'}).head(1)
</code></pre>
        <p><span onclick="$('#var_output_5aa946e3').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5aa946e3" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>average_price_reduction</th>
    </tr>
    <tr>
      <th>BrandName</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>coach</th>
      <td>7687.461538</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BrandName</th>
      <th>Deatils</th>
      <th>Sizes</th>
      <th>MRP</th>
      <th>SellPrice</th>
      <th>Discount</th>
      <th>Category</th>
      <th>SizeVariations</th>
      <th>color</th>
      <th>PriceReduction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>life</td>
      <td>solid cotton blend collar neck womens a-line dress - indigo</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large, X-Small]</td>
      <td>indigo</td>
      <td>850.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>only</td>
      <td>polyester peter pan collar womens blouson dress - yellow</td>
      <td>Size:34,36,38,40</td>
      <td>3499.0</td>
      <td>2449.0</td>
      <td>0.30</td>
      <td>Westernwear-Women</td>
      <td>[34, 36, 38, 40]</td>
      <td>yellow</td>
      <td>1050.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fratini</td>
      <td>solid polyester blend wide neck womens regular top - off white</td>
      <td>Size:Large,X-Large,XX-Large</td>
      <td>1199.0</td>
      <td>599.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, X-Large, XX-Large]</td>
      <td>off white</td>
      <td>600.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>zink london</td>
      <td>stripes polyester sweetheart neck womens dress - black</td>
      <td>Size:Large,Medium,Small,X-Large</td>
      <td>2299.0</td>
      <td>1379.0</td>
      <td>0.40</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large]</td>
      <td>black</td>
      <td>920.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>life</td>
      <td>regular fit regular length denim womens jeans - stone</td>
      <td>Size:26,28,30,32,34,36</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[26, 28, 30, 32, 34, 36]</td>
      <td>stone</td>
      <td>850.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>kraus</td>
      <td>wide ankle length cotton womens jeans - light blue</td>
      <td>Size:26,28,30,32,34</td>
      <td>1795.0</td>
      <td>1615.0</td>
      <td>0.10</td>
      <td>Westernwear-Women</td>
      <td>[26, 28, 30, 32, 34]</td>
      <td>light blue</td>
      <td>180.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>life</td>
      <td>printed cotton blend collared womens regular dress - white</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1299.0</td>
      <td>649.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large, X-Small]</td>
      <td>white</td>
      <td>650.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19</th>
      <td>swarovski</td>
      <td>constella stylish crystal white pierced earrings</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>8950.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>constella stylish crystal white pierced earrings</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>20</th>
      <td>shaya by caratlane</td>
      <td>the wing woman clover charm necklace</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>1250.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>the wing woman clover charm necklace</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>21</th>
      <td>swarovski</td>
      <td>crystal stylish womens rodhium earrings</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>8950.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>crystal stylish womens rodhium earrings</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Nan</td>
      <td>Nan</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>Nan</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>23</th>
      <td>jewelz</td>
      <td>ethnic gold plated jhumki earrings</td>
      <td>Nan</td>
      <td>1839.0</td>
      <td>643.0</td>
      <td>0.65</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>ethnic gold plated jhumki earrings</td>
      <td>1196.0</td>
    </tr>
    <tr>
      <th>24</th>
      <td>estelle</td>
      <td>womens gold plated double line fancy white and gold pearl necklace</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>2799.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>womens gold plated double line fancy white and gold pearl necklace</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>25</th>
      <td>estelle</td>
      <td>womens gold plated bridge designer mangalsutra necklaces</td>
      <td>Nan</td>
      <td>NaN</td>
      <td>1899.0</td>
      <td>NaN</td>
      <td>Jewellery-Women</td>
      <td>[Nan]</td>
      <td>womens gold plated bridge designer mangalsutra necklaces</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>30758 rows × 10 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>average_price_reduction</th>
    </tr>
    <tr>
      <th>BrandName</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>coach</th>
      <td>7687.461538</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ecommerce-fashion-dataset/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which brand is the most flexible in terms of size choices on average across all its offerings?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_sizes = df[['BrandName', 'SizeVariations']]
df_sizes['NumSizesOffered'] = df.SizeVariations.apply(len)
df_sizes.groupby('BrandName').mean().sort_values('NumSizesOffered').tail(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_sizes = df[['BrandName', 'SizeVariations']]
df_sizes['NumSizesOffered'] = df.SizeVariations.apply(len)
df_sizes.groupby('BrandName').mean().sort_values('NumSizesOffered').tail(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_sizes = df[['BrandName', 'SizeVariations']]
df_sizes['NumSizesOffered'] = df.SizeVariations.apply(len)
__output__ = df_sizes.groupby('BrandName').mean().sort_values('NumSizesOffered'
    ).tail(1)
</code></pre>
        <p><span onclick="$('#var_output_c288ee33').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c288ee33" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>NumSizesOffered</th>
    </tr>
    <tr>
      <th>BrandName</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>parfait</th>
      <td>21.55914</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_sizes, __output__ </p>
    
          <p>df_sizes (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BrandName</th>
      <th>SizeVariations</th>
      <th>NumSizesOffered</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>life</td>
      <td>[Large, Medium, Small, X-Large, X-Small]</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>only</td>
      <td>[34, 36, 38, 40]</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fratini</td>
      <td>[Large, X-Large, XX-Large]</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>zink london</td>
      <td>[Large, Medium, Small, X-Large]</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>life</td>
      <td>[26, 28, 30, 32, 34, 36]</td>
      <td>6</td>
    </tr>
    <tr>
      <th>5</th>
      <td>kraus</td>
      <td>[26, 28, 30, 32, 34]</td>
      <td>5</td>
    </tr>
    <tr>
      <th>6</th>
      <td>life</td>
      <td>[Large, Medium, Small, X-Large, X-Small]</td>
      <td>5</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19</th>
      <td>swarovski</td>
      <td>[Nan]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>20</th>
      <td>shaya by caratlane</td>
      <td>[Nan]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>21</th>
      <td>swarovski</td>
      <td>[Nan]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Nan</td>
      <td>[Nan]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>23</th>
      <td>jewelz</td>
      <td>[Nan]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>24</th>
      <td>estelle</td>
      <td>[Nan]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>25</th>
      <td>estelle</td>
      <td>[Nan]</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>30758 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>NumSizesOffered</th>
    </tr>
    <tr>
      <th>BrandName</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>parfait</th>
      <td>21.55914</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ecommerce-fashion-dataset/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What category has the most variety in the colors offered?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_colors = df[['Category', 'color']]
df_colors.groupby('Category').nunique().sort_values('color').tail(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_colors = df[['Category', 'color']]
df_colors.groupby('Category').nunique().sort_values('color').tail(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_colors = df[['Category', 'color']]
__output__ = df_colors.groupby('Category').nunique().sort_values('color').tail(
    1)
</code></pre>
        <p><span onclick="$('#var_output_c3f1d1f0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c3f1d1f0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>color</th>
    </tr>
    <tr>
      <th>Category</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Watches-Women</th>
      <td>1629</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_colors, __output__ </p>
    
          <p>df_colors (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Category</th>
      <th>color</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Westernwear-Women</td>
      <td>indigo</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Westernwear-Women</td>
      <td>yellow</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Westernwear-Women</td>
      <td>off white</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Westernwear-Women</td>
      <td>black</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Westernwear-Women</td>
      <td>stone</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Westernwear-Women</td>
      <td>light blue</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Westernwear-Women</td>
      <td>white</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Jewellery-Women</td>
      <td>constella stylish crystal white pierced earrings</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Jewellery-Women</td>
      <td>the wing woman clover charm necklace</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Jewellery-Women</td>
      <td>crystal stylish womens rodhium earrings</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Jewellery-Women</td>
      <td>Nan</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Jewellery-Women</td>
      <td>ethnic gold plated jhumki earrings</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Jewellery-Women</td>
      <td>womens gold plated double line fancy white and gold pearl necklace</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Jewellery-Women</td>
      <td>womens gold plated bridge designer mangalsutra necklaces</td>
    </tr>
  </tbody>
</table>
<p>30758 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>color</th>
    </tr>
    <tr>
      <th>Category</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Watches-Women</th>
      <td>1629</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ecommerce-fashion-dataset/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the number of brands in each category.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Category', 'BrandName']].groupby('Category').count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Category', 'BrandName']].groupby('Category').count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Category', 'BrandName']].groupby('Category').count()
</code></pre>
        <p><span onclick="$('#var_output_900305be').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_900305be" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BrandName</th>
    </tr>
    <tr>
      <th>Category</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Footwear-Women</th>
      <td>2574</td>
    </tr>
    <tr>
      <th>Fragrance-Women</th>
      <td>494</td>
    </tr>
    <tr>
      <th>Indianwear-Women</th>
      <td>10374</td>
    </tr>
    <tr>
      <th>Jewellery-Women</th>
      <td>1794</td>
    </tr>
    <tr>
      <th>Lingerie&amp;Nightwear-Women</th>
      <td>3354</td>
    </tr>
    <tr>
      <th>Watches-Women</th>
      <td>1794</td>
    </tr>
    <tr>
      <th>Westernwear-Women</th>
      <td>10374</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BrandName</th>
    </tr>
    <tr>
      <th>Category</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Footwear-Women</th>
      <td>2574</td>
    </tr>
    <tr>
      <th>Fragrance-Women</th>
      <td>494</td>
    </tr>
    <tr>
      <th>Indianwear-Women</th>
      <td>10374</td>
    </tr>
    <tr>
      <th>Jewellery-Women</th>
      <td>1794</td>
    </tr>
    <tr>
      <th>Lingerie&amp;Nightwear-Women</th>
      <td>3354</td>
    </tr>
    <tr>
      <th>Watches-Women</th>
      <td>1794</td>
    </tr>
    <tr>
      <th>Westernwear-Women</th>
      <td>10374</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ecommerce-fashion-dataset/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which brand features in the most categories?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_brands = df[df.BrandName != 'Nan'][['Category', 'BrandName']]
df_brands = df_brands[['Category', 'BrandName']].groupby('BrandName').nunique().sort_values('Category')
df_brands[df_brands.Category == df_brands.Category.iloc[-1]].rename( columns={'Category': 'NumCategories'})</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_brands = df[df.BrandName != 'Nan'][['Category', 'BrandName']]
df_brands = df_brands[['Category', 'BrandName']].groupby('BrandName').nunique().sort_values('Category')
df_brands[df_brands.Category == df_brands.Category.iloc[-1]].rename( columns={'Category': 'NumCategories'})</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_brands = df[df.BrandName != 'Nan'][['Category', 'BrandName']]
df_brands = df_brands[['Category', 'BrandName']].groupby('BrandName').nunique(
    ).sort_values('Category')
__output__ = df_brands[df_brands.Category == df_brands.Category.iloc[-1]
    ].rename(columns={'Category': 'NumCategories'})
</code></pre>
        <p><span onclick="$('#var_output_c460092a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c460092a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>NumCategories</th>
    </tr>
    <tr>
      <th>BrandName</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>puma</th>
      <td>4</td>
    </tr>
    <tr>
      <th>madame</th>
      <td>4</td>
    </tr>
    <tr>
      <th>stop</th>
      <td>4</td>
    </tr>
    <tr>
      <th>haute curry</th>
      <td>4</td>
    </tr>
    <tr>
      <th>janasya</th>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_brands, __output__ </p>
    
          <p>df_brands (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Category</th>
    </tr>
    <tr>
      <th>BrandName</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>new balance</th>
      <td>1</td>
    </tr>
    <tr>
      <th>mia</th>
      <td>1</td>
    </tr>
    <tr>
      <th>mimosa</th>
      <td>1</td>
    </tr>
    <tr>
      <th>missoni</th>
      <td>1</td>
    </tr>
    <tr>
      <th>miu miu</th>
      <td>1</td>
    </tr>
    <tr>
      <th>modare</th>
      <td>1</td>
    </tr>
    <tr>
      <th>monrow</th>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>adidas</th>
      <td>3</td>
    </tr>
    <tr>
      <th>aarke</th>
      <td>3</td>
    </tr>
    <tr>
      <th>puma</th>
      <td>4</td>
    </tr>
    <tr>
      <th>madame</th>
      <td>4</td>
    </tr>
    <tr>
      <th>stop</th>
      <td>4</td>
    </tr>
    <tr>
      <th>haute curry</th>
      <td>4</td>
    </tr>
    <tr>
      <th>janasya</th>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>274 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>NumCategories</th>
    </tr>
    <tr>
      <th>BrandName</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>puma</th>
      <td>4</td>
    </tr>
    <tr>
      <th>madame</th>
      <td>4</td>
    </tr>
    <tr>
      <th>stop</th>
      <td>4</td>
    </tr>
    <tr>
      <th>haute curry</th>
      <td>4</td>
    </tr>
    <tr>
      <th>janasya</th>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> ecommerce-fashion-dataset/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What percentage of items follow a sizing system represented by numbers only?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def is_numbered(x):
    for i in x:
        if not str.isnumeric(i.strip()):
            return False
    return True

df_sizes = df[df.Sizes != 'Nan']
100*df_sizes.SizeVariations.apply(is_numbered).sum()/len(df_sizes)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def is_numbered(x):
    for i in x:
        if not str.isnumeric(i.strip()):
            return False
    return True

df_sizes = df[df.Sizes != 'Nan']
100*df_sizes.SizeVariations.apply(is_numbered).sum()/len(df_sizes)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def is_numbered(x):
    for i in x:
        if not str.isnumeric(i.strip()):
            return False
    return True


df_sizes = df[df.Sizes != 'Nan']
__output__ = 100 * df_sizes.SizeVariations.apply(is_numbered).sum() / len(
    df_sizes)
</code></pre>
        <p><span onclick="$('#var_output_13a8e037').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_13a8e037" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>23.721890183600635</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_sizes, __output__ </p>
    
          <p>df_sizes (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BrandName</th>
      <th>Deatils</th>
      <th>Sizes</th>
      <th>MRP</th>
      <th>SellPrice</th>
      <th>Discount</th>
      <th>Category</th>
      <th>SizeVariations</th>
      <th>color</th>
      <th>PriceReduction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>life</td>
      <td>solid cotton blend collar neck womens a-line dress - indigo</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large, X-Small]</td>
      <td>indigo</td>
      <td>850.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>only</td>
      <td>polyester peter pan collar womens blouson dress - yellow</td>
      <td>Size:34,36,38,40</td>
      <td>3499.0</td>
      <td>2449.0</td>
      <td>0.30</td>
      <td>Westernwear-Women</td>
      <td>[34, 36, 38, 40]</td>
      <td>yellow</td>
      <td>1050.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fratini</td>
      <td>solid polyester blend wide neck womens regular top - off white</td>
      <td>Size:Large,X-Large,XX-Large</td>
      <td>1199.0</td>
      <td>599.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, X-Large, XX-Large]</td>
      <td>off white</td>
      <td>600.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>zink london</td>
      <td>stripes polyester sweetheart neck womens dress - black</td>
      <td>Size:Large,Medium,Small,X-Large</td>
      <td>2299.0</td>
      <td>1379.0</td>
      <td>0.40</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large]</td>
      <td>black</td>
      <td>920.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>life</td>
      <td>regular fit regular length denim womens jeans - stone</td>
      <td>Size:26,28,30,32,34,36</td>
      <td>1699.0</td>
      <td>849.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[26, 28, 30, 32, 34, 36]</td>
      <td>stone</td>
      <td>850.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>kraus</td>
      <td>wide ankle length cotton womens jeans - light blue</td>
      <td>Size:26,28,30,32,34</td>
      <td>1795.0</td>
      <td>1615.0</td>
      <td>0.10</td>
      <td>Westernwear-Women</td>
      <td>[26, 28, 30, 32, 34]</td>
      <td>light blue</td>
      <td>180.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>life</td>
      <td>printed cotton blend collared womens regular dress - white</td>
      <td>Size:Large,Medium,Small,X-Large,X-Small</td>
      <td>1299.0</td>
      <td>649.0</td>
      <td>0.50</td>
      <td>Westernwear-Women</td>
      <td>[Large, Medium, Small, X-Large, X-Small]</td>
      <td>white</td>
      <td>650.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>24</th>
      <td>haute curry</td>
      <td>womens casual wear slip on heels - black</td>
      <td>Size:36,37,38,39,40</td>
      <td>2199.0</td>
      <td>1099.0</td>
      <td>0.50</td>
      <td>Footwear-Women</td>
      <td>[36, 37, 38, 39, 40]</td>
      <td>black</td>
      <td>1100.0</td>
    </tr>
    <tr>
      <th>25</th>
      <td>lemon &amp; pepper</td>
      <td>polyurethane buckle womens casual sandals - black</td>
      <td>Size:36,37,38,39</td>
      <td>NaN</td>
      <td>4499.0</td>
      <td>NaN</td>
      <td>Footwear-Women</td>
      <td>[36, 37, 38, 39]</td>
      <td>black</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>swiss eagle</td>
      <td>womens analogue metallic watch</td>
      <td>Size:Error Size</td>
      <td>13990.0</td>
      <td>4197.0</td>
      <td>0.70</td>
      <td>Watches-Women</td>
      <td>[Error Size]</td>
      <td>womens analogue metallic watch</td>
      <td>9793.0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>lawman watches</td>
      <td>womens rose gold dial stainless steel analogue watch - wi106d</td>
      <td>Size:Error Size</td>
      <td>7499.0</td>
      <td>4999.0</td>
      <td>0.33</td>
      <td>Watches-Women</td>
      <td>[Error Size]</td>
      <td>wi106d</td>
      <td>2500.0</td>
    </tr>
    <tr>
      <th>0</th>
      <td>lawman watches</td>
      <td>womens silver dial stainless steel analogue watch - lwwi105a</td>
      <td>Size:Error Size</td>
      <td>5999.0</td>
      <td>3999.0</td>
      <td>0.33</td>
      <td>Watches-Women</td>
      <td>[Error Size]</td>
      <td>lwwi105a</td>
      <td>2000.0</td>
    </tr>
    <tr>
      <th>12</th>
      <td>miu miu</td>
      <td>eau de parfum - 50 ml</td>
      <td>Size:Error Size</td>
      <td>NaN</td>
      <td>6100.0</td>
      <td>NaN</td>
      <td>Fragrance-Women</td>
      <td>[Error Size]</td>
      <td>50 ml</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>12</th>
      <td>miu miu</td>
      <td>eau de parfum - 30 ml</td>
      <td>Size:Error Size</td>
      <td>NaN</td>
      <td>4400.0</td>
      <td>NaN</td>
      <td>Fragrance-Women</td>
      <td>[Error Size]</td>
      <td>30 ml</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>23257 rows × 10 columns</p>
      
          <p>__output__ (float64):</p>
          <pre><code>23.721890183600635</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rewards/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the median age of premium members?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Membership', 'Age']].groupby('Membership').median().loc['Premium']</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Membership', 'Age']].groupby('Membership').median().loc['Premium']</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Membership', 'Age']].groupby('Membership').median().loc[
    'Premium']
</code></pre>
        <p><span onclick="$('#var_output_77f9b10d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_77f9b10d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Age    39.0
Name: Premium, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Age    39.0
Name: Premium, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rewards/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert all Yes or No columns to their boolean representations.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def convert_to_bool(x):
    if x == 'Yes':
        return True
    if x == 'No':
        return False
    return np.NaN

def is_series_bipolar(x):
    uniq_elems = x.unique().tolist()
    if len(uniq_elems) == 2 and 'Yes' in uniq_elems and 'No' in uniq_elems:
        return True
    return False

df = df.apply(lambda x: x if not is_series_bipolar(x) else x.apply(convert_to_bool))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def convert_to_bool(x):
    if x == 'Yes':
        return True
    if x == 'No':
        return False
    return np.NaN

def is_series_bipolar(x):
    uniq_elems = x.unique().tolist()
    if len(uniq_elems) == 2 and 'Yes' in uniq_elems and 'No' in uniq_elems:
        return True
    return False

df = df.apply(lambda x: x if not is_series_bipolar(x) else x.apply(convert_to_bool))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def convert_to_bool(x):
    if x == 'Yes':
        return True
    if x == 'No':
        return False
    return np.NaN


def is_series_bipolar(x):
    uniq_elems = x.unique().tolist()
    if len(uniq_elems) == 2 and 'Yes' in uniq_elems and 'No' in uniq_elems:
        return True
    return False


__output__ = df = df.apply(lambda x: x if not is_series_bipolar(x) else x.
    apply(convert_to_bool))
</code></pre>
        <p><span onclick="$('#var_output_7029d2e3').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7029d2e3" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Age</th>
      <th>Membership</th>
      <th>Loyalty Points</th>
      <th>Discount</th>
      <th>Gift</th>
      <th>Earlybird</th>
      <th>Reward</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Male</td>
      <td>45</td>
      <td>Premium</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Cashback</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Female</td>
      <td>41</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Female</td>
      <td>25</td>
      <td>Premium</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Male</td>
      <td>38</td>
      <td>Premium</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Cashback</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Male</td>
      <td>32</td>
      <td>Normal</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Male</td>
      <td>28</td>
      <td>Premium</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Cashback</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Female</td>
      <td>41</td>
      <td>Normal</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>143</th>
      <td>Female</td>
      <td>28</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>144</th>
      <td>Male</td>
      <td>46</td>
      <td>Normal</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>145</th>
      <td>Female</td>
      <td>39</td>
      <td>Premium</td>
      <td>Below 500</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>146</th>
      <td>Male</td>
      <td>31</td>
      <td>Normal</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>147</th>
      <td>Male</td>
      <td>24</td>
      <td>Premium</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>148</th>
      <td>Female</td>
      <td>42</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>149</th>
      <td>Male</td>
      <td>43</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 8 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Age</th>
      <th>Membership</th>
      <th>Loyalty Points</th>
      <th>Discount</th>
      <th>Gift</th>
      <th>Earlybird</th>
      <th>Reward</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Male</td>
      <td>45</td>
      <td>Premium</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Cashback</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Female</td>
      <td>41</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Female</td>
      <td>25</td>
      <td>Premium</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Male</td>
      <td>38</td>
      <td>Premium</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Cashback</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Male</td>
      <td>32</td>
      <td>Normal</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Male</td>
      <td>28</td>
      <td>Premium</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Cashback</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Female</td>
      <td>41</td>
      <td>Normal</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>143</th>
      <td>Female</td>
      <td>28</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>144</th>
      <td>Male</td>
      <td>46</td>
      <td>Normal</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>145</th>
      <td>Female</td>
      <td>39</td>
      <td>Premium</td>
      <td>Below 500</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>146</th>
      <td>Male</td>
      <td>31</td>
      <td>Normal</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>147</th>
      <td>Male</td>
      <td>24</td>
      <td>Premium</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>148</th>
      <td>Female</td>
      <td>42</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>149</th>
      <td>Male</td>
      <td>43</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 8 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Age</th>
      <th>Membership</th>
      <th>Loyalty Points</th>
      <th>Discount</th>
      <th>Gift</th>
      <th>Earlybird</th>
      <th>Reward</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Male</td>
      <td>45</td>
      <td>Premium</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Cashback</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Female</td>
      <td>41</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Female</td>
      <td>25</td>
      <td>Premium</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Male</td>
      <td>38</td>
      <td>Premium</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Cashback</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Male</td>
      <td>32</td>
      <td>Normal</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Male</td>
      <td>28</td>
      <td>Premium</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Cashback</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Female</td>
      <td>41</td>
      <td>Normal</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>143</th>
      <td>Female</td>
      <td>28</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>144</th>
      <td>Male</td>
      <td>46</td>
      <td>Normal</td>
      <td>501 to 1000</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>145</th>
      <td>Female</td>
      <td>39</td>
      <td>Premium</td>
      <td>Below 500</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>146</th>
      <td>Male</td>
      <td>31</td>
      <td>Normal</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>147</th>
      <td>Male</td>
      <td>24</td>
      <td>Premium</td>
      <td>Above 1000</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>Coupon or Cashback</td>
    </tr>
    <tr>
      <th>148</th>
      <td>Female</td>
      <td>42</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
    <tr>
      <th>149</th>
      <td>Male</td>
      <td>43</td>
      <td>Normal</td>
      <td>Below 500</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>Coupon</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 8 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rewards/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many premium members in each loyalty group are eligible for gifts?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.Membership == 'Premium'][['Loyalty Points', 'Gift']].groupby('Loyalty Points').sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.Membership == 'Premium'][['Loyalty Points', 'Gift']].groupby('Loyalty Points').sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.Membership == 'Premium'][['Loyalty Points', 'Gift']
    ].groupby('Loyalty Points').sum()
</code></pre>
        <p><span onclick="$('#var_output_f46f4323').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f46f4323" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gift</th>
    </tr>
    <tr>
      <th>Loyalty Points</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>501 to 1000</th>
      <td>22</td>
    </tr>
    <tr>
      <th>Above 1000</th>
      <td>21</td>
    </tr>
    <tr>
      <th>Below 500</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gift</th>
    </tr>
    <tr>
      <th>Loyalty Points</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>501 to 1000</th>
      <td>22</td>
    </tr>
    <tr>
      <th>Above 1000</th>
      <td>21</td>
    </tr>
    <tr>
      <th>Below 500</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rewards/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Among customers with similar reward points, what percentage have subscribed for early offer notifications given their gender? List percentage subscription for each gender in separate columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def get_likelihood(gender_df):
    num_eligible = gender_df.groupby('Gender').sum()['Earlybird']
    counts = gender_df.groupby('Gender').count()['Earlybird']
    return num_eligible/counts

df[['Gender', 'Loyalty Points', 'Earlybird']].groupby('Loyalty Points').apply(get_likelihood)*100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def get_likelihood(gender_df):
    num_eligible = gender_df.groupby('Gender').sum()['Earlybird']
    counts = gender_df.groupby('Gender').count()['Earlybird']
    return num_eligible/counts

df[['Gender', 'Loyalty Points', 'Earlybird']].groupby('Loyalty Points').apply(get_likelihood)*100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def get_likelihood(gender_df):
    num_eligible = gender_df.groupby('Gender').sum()['Earlybird']
    counts = gender_df.groupby('Gender').count()['Earlybird']
    return num_eligible / counts


__output__ = df[['Gender', 'Loyalty Points', 'Earlybird']].groupby(
    'Loyalty Points').apply(get_likelihood) * 100
</code></pre>
        <p><span onclick="$('#var_output_c5b82154').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c5b82154" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Gender</th>
      <th>Female</th>
      <th>Male</th>
    </tr>
    <tr>
      <th>Loyalty Points</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>501 to 1000</th>
      <td>45.454545</td>
      <td>35.000000</td>
    </tr>
    <tr>
      <th>Above 1000</th>
      <td>45.454545</td>
      <td>37.500000</td>
    </tr>
    <tr>
      <th>Below 500</th>
      <td>19.230769</td>
      <td>40.909091</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Gender</th>
      <th>Female</th>
      <th>Male</th>
    </tr>
    <tr>
      <th>Loyalty Points</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>501 to 1000</th>
      <td>45.454545</td>
      <td>35.000000</td>
    </tr>
    <tr>
      <th>Above 1000</th>
      <td>45.454545</td>
      <td>37.500000</td>
    </tr>
    <tr>
      <th>Below 500</th>
      <td>19.230769</td>
      <td>40.909091</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rewards/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What rewards are given to customers of each loayalty group? List the number of each type of reward given.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Loyalty Points', 'Reward']].groupby('Loyalty Points').apply(lambda x: x.Reward.value_counts())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Loyalty Points', 'Reward']].groupby('Loyalty Points').apply(lambda x: x.Reward.value_counts())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Loyalty Points', 'Reward']].groupby('Loyalty Points').apply(
    lambda x: x.Reward.value_counts())
</code></pre>
        <p><span onclick="$('#var_output_45a6e526').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_45a6e526" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Loyalty Points                    
501 to 1000     Coupon                31
                Cashback              22
Above 1000      Coupon or Cashback    49
Below 500       Coupon                48
Name: Reward, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Loyalty Points                    
501 to 1000     Coupon                31
                Cashback              22
Above 1000      Coupon or Cashback    49
Below 500       Coupon                48
Name: Reward, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rewards/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the percent composition of membership type across different point groups. List the values for each loyalty group in seperate columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>get_membership_percentage = lambda x: x.Membership.value_counts()/len(x.Membership)*100

df[['Loyalty Points', 'Membership']].groupby('Loyalty Points').apply(get_membership_percentage).T</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>get_membership_percentage = lambda x: x.Membership.value_counts()/len(x.Membership)*100

df[['Loyalty Points', 'Membership']].groupby('Loyalty Points').apply(get_membership_percentage).T</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>get_membership_percentage = lambda x: x.Membership.value_counts() / len(x.
    Membership) * 100
__output__ = df[['Loyalty Points', 'Membership']].groupby('Loyalty Points'
    ).apply(get_membership_percentage).T
</code></pre>
        <p><span onclick="$('#var_output_1fa87901').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1fa87901" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Loyalty Points</th>
      <th>501 to 1000</th>
      <th>Above 1000</th>
      <th>Below 500</th>
    </tr>
    <tr>
      <th>Membership</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Normal</th>
      <td>58.490566</td>
      <td>57.142857</td>
      <td>70.833333</td>
    </tr>
    <tr>
      <th>Premium</th>
      <td>41.509434</td>
      <td>42.857143</td>
      <td>29.166667</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Loyalty Points</th>
      <th>501 to 1000</th>
      <th>Above 1000</th>
      <th>Below 500</th>
    </tr>
    <tr>
      <th>Membership</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Normal</th>
      <td>58.490566</td>
      <td>57.142857</td>
      <td>70.833333</td>
    </tr>
    <tr>
      <th>Premium</th>
      <td>41.509434</td>
      <td>42.857143</td>
      <td>29.166667</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> rewards/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Does being an early bird affect points earned? Show the number of customers in each loyalty group given their subscription status.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Earlybird', 'Loyalty Points']].groupby('Earlybird').apply(lambda x: x['Loyalty Points'].value_counts())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Earlybird', 'Loyalty Points']].groupby('Earlybird').apply(lambda x: x['Loyalty Points'].value_counts())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Earlybird', 'Loyalty Points']].groupby('Earlybird').apply(
    lambda x: x['Loyalty Points'].value_counts())
</code></pre>
        <p><span onclick="$('#var_output_25f243a9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_25f243a9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Earlybird             
False      Below 500      34
           501 to 1000    31
           Above 1000     28
True       501 to 1000    22
           Above 1000     21
           Below 500      14
Name: Loyalty Points, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Earlybird             
False      Below 500      34
           501 to 1000    31
           Above 1000     28
True       501 to 1000    22
           Above 1000     21
           Below 500      14
Name: Loyalty Points, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the number of ratings to numbers.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.num_rat = df.num_rat.apply(lambda x: x.strip().replace(',', '')).apply(int)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.num_rat = df.num_rat.apply(lambda x: x.strip().replace(',', '')).apply(int)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.num_rat = df.num_rat.apply(lambda x: x.strip().replace(',', '')
    ).apply(int)
</code></pre>
        <p><span onclick="$('#var_output_04b0db96').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_04b0db96" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0       70382
1       48662
2       44943
3       58590
4       44206
        ...  
4397      727
4398      616
4399      565
4400      524
4401      490
Name: num_rat, Length: 4402, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ars_name</th>
      <th>rel_date</th>
      <th>gens</th>
      <th>descs</th>
      <th>avg_rat</th>
      <th>num_rat</th>
      <th>num_revs</th>
      <th>...</th>
      <th>liveness</th>
      <th>loudness</th>
      <th>speechiness</th>
      <th>tempo</th>
      <th>valence</th>
      <th>duration_ms</th>
      <th>time_signature</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Radiohead</td>
      <td>16 June 1997</td>
      <td>Alternative Rock, Art Rock</td>
      <td>melancholic, anxious, futuristic, alienation, existential, male vocals, atmospheric, lonely, cold, introspective</td>
      <td>4.23</td>
      <td>70382</td>
      <td>1531</td>
      <td>...</td>
      <td>0.159375</td>
      <td>-9.102417</td>
      <td>0.056308</td>
      <td>115.450750</td>
      <td>0.291733</td>
      <td>268435.500000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Pink Floyd</td>
      <td>12 September 1975</td>
      <td>Progressive Rock, Art Rock</td>
      <td>melancholic, atmospheric, progressive, male vocals, concept album, introspective, serious, longing, bittersweet, meditative</td>
      <td>4.29</td>
      <td>48662</td>
      <td>983</td>
      <td>...</td>
      <td>0.384940</td>
      <td>-12.689400</td>
      <td>0.039740</td>
      <td>130.018800</td>
      <td>0.259040</td>
      <td>530512.000000</td>
      <td>3.600000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>King Crimson</td>
      <td>10 October 1969</td>
      <td>Progressive Rock, Art Rock</td>
      <td>fantasy, epic, progressive, philosophical, complex, surreal, poetic, male vocals, melancholic, technical</td>
      <td>4.30</td>
      <td>44943</td>
      <td>870</td>
      <td>...</td>
      <td>0.149138</td>
      <td>-14.873125</td>
      <td>0.043463</td>
      <td>118.920625</td>
      <td>0.279400</td>
      <td>507644.125000</td>
      <td>3.875000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Radiohead</td>
      <td>3 October 2000</td>
      <td>Art Rock, Experimental Rock, Electronic</td>
      <td>cold, melancholic, futuristic, atmospheric, anxious, cryptic, sombre, abstract, introspective, male vocals</td>
      <td>4.21</td>
      <td>58590</td>
      <td>734</td>
      <td>...</td>
      <td>0.311412</td>
      <td>-7.811941</td>
      <td>0.268318</td>
      <td>116.045059</td>
      <td>0.398206</td>
      <td>325379.529412</td>
      <td>4.058824</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Kendrick Lamar</td>
      <td>15 March 2015</td>
      <td>Conscious Hip Hop, West Coast Hip Hop, Jazz Rap</td>
      <td>political, conscious, poetic, protest, concept album, introspective, urban, male vocals, eclectic, passionate</td>
      <td>4.27</td>
      <td>44206</td>
      <td>379</td>
      <td>...</td>
      <td>0.318419</td>
      <td>-5.802062</td>
      <td>0.294175</td>
      <td>103.444563</td>
      <td>0.487187</td>
      <td>296225.750000</td>
      <td>3.812500</td>
    </tr>
    <tr>
      <th>5</th>
      <td>My Bloody Valentine</td>
      <td>4 November 1991</td>
      <td>Shoegaze, Noise Pop</td>
      <td>noisy, ethereal, atmospheric, romantic, dense, hypnotic, love, psychedelic, lush, bittersweet</td>
      <td>4.24</td>
      <td>49887</td>
      <td>1223</td>
      <td>...</td>
      <td>0.238555</td>
      <td>-13.224727</td>
      <td>0.049436</td>
      <td>119.816091</td>
      <td>0.286918</td>
      <td>265148.000000</td>
      <td>3.636364</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Pink Floyd</td>
      <td>23 March 1973</td>
      <td>Art Rock, Progressive Rock</td>
      <td>philosophical, atmospheric, introspective, existential, mellow, concept album, male vocals, psychedelic, progressive, epic</td>
      <td>4.20</td>
      <td>57622</td>
      <td>1549</td>
      <td>...</td>
      <td>0.237680</td>
      <td>-15.701900</td>
      <td>0.058660</td>
      <td>120.066200</td>
      <td>0.272830</td>
      <td>257363.600000</td>
      <td>3.700000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4395</th>
      <td>The Koreatown Oddity</td>
      <td>19 June 2020</td>
      <td>West Coast Hip Hop, Conscious Hip Hop, Jazz Rap</td>
      <td>introspective, concept album, male vocals, sampling, playful, humorous, sentimental, bittersweet, surreal, lo-fi</td>
      <td>3.66</td>
      <td>1965</td>
      <td>12</td>
      <td>...</td>
      <td>0.326406</td>
      <td>-6.672187</td>
      <td>0.244925</td>
      <td>95.478562</td>
      <td>0.606000</td>
      <td>214588.687500</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>4396</th>
      <td>Earth, Wind &amp; Fire</td>
      <td>9 June 1979</td>
      <td>Disco, Funk</td>
      <td>happy, summer, party, energetic, uplifting, lush, male vocals, rhythmic, love, technical</td>
      <td>3.68</td>
      <td>1108</td>
      <td>22</td>
      <td>...</td>
      <td>0.177453</td>
      <td>-7.147600</td>
      <td>0.254213</td>
      <td>126.265133</td>
      <td>0.413020</td>
      <td>204345.200000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>4397</th>
      <td>John Hiatt</td>
      <td>May 1987</td>
      <td>Singer/Songwriter, Roots Rock, Americana</td>
      <td>love, lethargic, lonely, existential, melodic, pastoral, sombre, poetic, mellow, calm</td>
      <td>3.68</td>
      <td>727</td>
      <td>37</td>
      <td>...</td>
      <td>0.125710</td>
      <td>-12.683700</td>
      <td>0.030090</td>
      <td>106.136700</td>
      <td>0.568300</td>
      <td>273146.700000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>4398</th>
      <td>Catharsis</td>
      <td>1999</td>
      <td>Crust Punk, Metalcore</td>
      <td>male vocals, anarchism, aggressive, angry, heavy, political, sampling</td>
      <td>3.65</td>
      <td>616</td>
      <td>6</td>
      <td>...</td>
      <td>0.250530</td>
      <td>-6.659900</td>
      <td>0.088560</td>
      <td>127.249950</td>
      <td>0.432750</td>
      <td>202675.450000</td>
      <td>3.950000</td>
    </tr>
    <tr>
      <th>4399</th>
      <td>Gracious</td>
      <td>17 July 1970</td>
      <td>Progressive Rock, Symphonic Prog</td>
      <td>NaN</td>
      <td>3.69</td>
      <td>565</td>
      <td>32</td>
      <td>...</td>
      <td>0.222845</td>
      <td>-4.805273</td>
      <td>0.049027</td>
      <td>149.398818</td>
      <td>0.622545</td>
      <td>193269.454545</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>4400</th>
      <td>And Also the Trees</td>
      <td>12 November 2007</td>
      <td>Art Rock</td>
      <td>atmospheric, poetic, dark, male vocals, ominous, suspenseful, mysterious, cryptic, sombre, pastoral</td>
      <td>3.68</td>
      <td>524</td>
      <td>15</td>
      <td>...</td>
      <td>0.127646</td>
      <td>-13.088692</td>
      <td>0.037354</td>
      <td>118.958923</td>
      <td>0.252892</td>
      <td>229115.846154</td>
      <td>3.923077</td>
    </tr>
    <tr>
      <th>4401</th>
      <td>Minnie Riperton</td>
      <td>22 May 1975</td>
      <td>Smooth Soul, Pop Soul</td>
      <td>lush, female vocals, romantic, uplifting, summer, love, bittersweet, passionate, sensual, warm</td>
      <td>3.69</td>
      <td>490</td>
      <td>14</td>
      <td>...</td>
      <td>0.154910</td>
      <td>-11.508600</td>
      <td>0.048810</td>
      <td>110.463100</td>
      <td>0.576300</td>
      <td>242398.800000</td>
      <td>3.800000</td>
    </tr>
  </tbody>
</table>
<p>4402 rows × 19 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0       70382
1       48662
2       44943
3       58590
4       44206
        ...  
4397      727
4398      616
4399      565
4400      524
4401      490
Name: num_rat, Length: 4402, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What numeric quality does the average rating of a song correlate positively the most?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']

df_num = df.select_dtypes(include=numerics)
df_num.corr()['avg_rat'].iloc[1:].sort_values(ascending=False).head(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']

df_num = df.select_dtypes(include=numerics)
df_num.corr()['avg_rat'].iloc[1:].sort_values(ascending=False).head(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
df_num = df.select_dtypes(include=numerics)
__output__ = df_num.corr()['avg_rat'].iloc[1:].sort_values(ascending=False
    ).head(1)
</code></pre>
        <p><span onclick="$('#var_output_52895c27').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_52895c27" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>num_rat    0.524328
Name: avg_rat, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> numerics, df_num, __output__ </p>
    
          <p>numerics (list):</p>
          <pre><code>['int16', 'int32', 'int64', 'float16', 'float32', 'float64']</code></pre>
      
          <p>df_num (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>avg_rat</th>
      <th>num_rat</th>
      <th>num_revs</th>
      <th>acousticness</th>
      <th>danceability</th>
      <th>energy</th>
      <th>instrumentalness</th>
      <th>liveness</th>
      <th>loudness</th>
      <th>speechiness</th>
      <th>tempo</th>
      <th>valence</th>
      <th>duration_ms</th>
      <th>time_signature</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.23</td>
      <td>70382</td>
      <td>1531</td>
      <td>0.135763</td>
      <td>0.288083</td>
      <td>0.565917</td>
      <td>0.161053</td>
      <td>0.159375</td>
      <td>-9.102417</td>
      <td>0.056308</td>
      <td>115.450750</td>
      <td>0.291733</td>
      <td>268435.500000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.29</td>
      <td>48662</td>
      <td>983</td>
      <td>0.602800</td>
      <td>0.373600</td>
      <td>0.409800</td>
      <td>0.363040</td>
      <td>0.384940</td>
      <td>-12.689400</td>
      <td>0.039740</td>
      <td>130.018800</td>
      <td>0.259040</td>
      <td>530512.000000</td>
      <td>3.600000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.30</td>
      <td>44943</td>
      <td>870</td>
      <td>0.297686</td>
      <td>0.340625</td>
      <td>0.370475</td>
      <td>0.327265</td>
      <td>0.149138</td>
      <td>-14.873125</td>
      <td>0.043463</td>
      <td>118.920625</td>
      <td>0.279400</td>
      <td>507644.125000</td>
      <td>3.875000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.21</td>
      <td>58590</td>
      <td>734</td>
      <td>0.123219</td>
      <td>0.601294</td>
      <td>0.676706</td>
      <td>0.000669</td>
      <td>0.311412</td>
      <td>-7.811941</td>
      <td>0.268318</td>
      <td>116.045059</td>
      <td>0.398206</td>
      <td>325379.529412</td>
      <td>4.058824</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4.27</td>
      <td>44206</td>
      <td>379</td>
      <td>0.322889</td>
      <td>0.590750</td>
      <td>0.707625</td>
      <td>0.000011</td>
      <td>0.318419</td>
      <td>-5.802062</td>
      <td>0.294175</td>
      <td>103.444563</td>
      <td>0.487187</td>
      <td>296225.750000</td>
      <td>3.812500</td>
    </tr>
    <tr>
      <th>5</th>
      <td>4.24</td>
      <td>49887</td>
      <td>1223</td>
      <td>0.185593</td>
      <td>0.227009</td>
      <td>0.615364</td>
      <td>0.787091</td>
      <td>0.238555</td>
      <td>-13.224727</td>
      <td>0.049436</td>
      <td>119.816091</td>
      <td>0.286918</td>
      <td>265148.000000</td>
      <td>3.636364</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4.20</td>
      <td>57622</td>
      <td>1549</td>
      <td>0.390310</td>
      <td>0.383000</td>
      <td>0.400450</td>
      <td>0.595929</td>
      <td>0.237680</td>
      <td>-15.701900</td>
      <td>0.058660</td>
      <td>120.066200</td>
      <td>0.272830</td>
      <td>257363.600000</td>
      <td>3.700000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4395</th>
      <td>3.66</td>
      <td>1965</td>
      <td>12</td>
      <td>0.378261</td>
      <td>0.483063</td>
      <td>0.781562</td>
      <td>0.023943</td>
      <td>0.326406</td>
      <td>-6.672187</td>
      <td>0.244925</td>
      <td>95.478562</td>
      <td>0.606000</td>
      <td>214588.687500</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>4396</th>
      <td>3.68</td>
      <td>1108</td>
      <td>22</td>
      <td>0.046364</td>
      <td>0.871667</td>
      <td>0.569000</td>
      <td>0.000119</td>
      <td>0.177453</td>
      <td>-7.147600</td>
      <td>0.254213</td>
      <td>126.265133</td>
      <td>0.413020</td>
      <td>204345.200000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>4397</th>
      <td>3.68</td>
      <td>727</td>
      <td>37</td>
      <td>0.286402</td>
      <td>0.607100</td>
      <td>0.460700</td>
      <td>0.001658</td>
      <td>0.125710</td>
      <td>-12.683700</td>
      <td>0.030090</td>
      <td>106.136700</td>
      <td>0.568300</td>
      <td>273146.700000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>4398</th>
      <td>3.65</td>
      <td>616</td>
      <td>6</td>
      <td>0.156502</td>
      <td>0.572050</td>
      <td>0.621100</td>
      <td>0.004154</td>
      <td>0.250530</td>
      <td>-6.659900</td>
      <td>0.088560</td>
      <td>127.249950</td>
      <td>0.432750</td>
      <td>202675.450000</td>
      <td>3.950000</td>
    </tr>
    <tr>
      <th>4399</th>
      <td>3.69</td>
      <td>565</td>
      <td>32</td>
      <td>0.075487</td>
      <td>0.528636</td>
      <td>0.731000</td>
      <td>0.000128</td>
      <td>0.222845</td>
      <td>-4.805273</td>
      <td>0.049027</td>
      <td>149.398818</td>
      <td>0.622545</td>
      <td>193269.454545</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>4400</th>
      <td>3.68</td>
      <td>524</td>
      <td>15</td>
      <td>0.417308</td>
      <td>0.397462</td>
      <td>0.458000</td>
      <td>0.543231</td>
      <td>0.127646</td>
      <td>-13.088692</td>
      <td>0.037354</td>
      <td>118.958923</td>
      <td>0.252892</td>
      <td>229115.846154</td>
      <td>3.923077</td>
    </tr>
    <tr>
      <th>4401</th>
      <td>3.69</td>
      <td>490</td>
      <td>14</td>
      <td>0.405390</td>
      <td>0.543100</td>
      <td>0.469300</td>
      <td>0.073309</td>
      <td>0.154910</td>
      <td>-11.508600</td>
      <td>0.048810</td>
      <td>110.463100</td>
      <td>0.576300</td>
      <td>242398.800000</td>
      <td>3.800000</td>
    </tr>
  </tbody>
</table>
<p>4402 rows × 14 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>num_rat    0.524328
Name: avg_rat, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What numeric quality does the average rating of a song correlate to the least?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_num.corr()['avg_rat'].iloc[1:].abs().sort_values().head(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_num.corr()['avg_rat'].iloc[1:].abs().sort_values().head(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_num.corr()['avg_rat'].iloc[1:].abs().sort_values().head(1)
</code></pre>
        <p><span onclick="$('#var_output_2a5ea77f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2a5ea77f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>danceability    0.000421
Name: avg_rat, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>danceability    0.000421
Name: avg_rat, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the release dates to datetime objects and save in separate column named 'rel_datetime'.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def preprocess_datestring(x):
    try:
        x = dateutil.parser.parse(x)
    except ValueError as e:
        return np.NAN
    return x.strftime("%d %B %Y")

convert_to_datetime = lambda datestring: datetime.strptime(datestring, "%d %B %Y")
df['rel_datetime'] = df.rel_date.apply(preprocess_datestring).apply(convert_to_datetime)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def preprocess_datestring(x):
    try:
        x = dateutil.parser.parse(x)
    except ValueError as e:
        return np.NAN
    return x.strftime("%d %B %Y")

convert_to_datetime = lambda datestring: datetime.strptime(datestring, "%d %B %Y")
df['rel_datetime'] = df.rel_date.apply(preprocess_datestring).apply(convert_to_datetime)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def preprocess_datestring(x):
    try:
        x = dateutil.parser.parse(x)
    except ValueError as e:
        return np.NAN
    return x.strftime('%d %B %Y')


convert_to_datetime = lambda datestring: datetime.strptime(datestring,
    '%d %B %Y')
__output__ = df['rel_datetime'] = df.rel_date.apply(preprocess_datestring
    ).apply(convert_to_datetime)
</code></pre>
        <p><span onclick="$('#var_output_9405d46d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9405d46d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      1997-06-16
1      1975-09-12
2      1969-10-10
3      2000-10-03
4      2015-03-15
          ...    
4397   1987-05-10
4398   1999-12-10
4399   1970-07-17
4400   2007-11-12
4401   1975-05-22
Name: rel_date, Length: 4402, dtype: datetime64[ns]</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ars_name</th>
      <th>rel_date</th>
      <th>gens</th>
      <th>descs</th>
      <th>avg_rat</th>
      <th>num_rat</th>
      <th>num_revs</th>
      <th>...</th>
      <th>loudness</th>
      <th>speechiness</th>
      <th>tempo</th>
      <th>valence</th>
      <th>duration_ms</th>
      <th>time_signature</th>
      <th>rel_datetime</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Radiohead</td>
      <td>16 June 1997</td>
      <td>Alternative Rock, Art Rock</td>
      <td>melancholic, anxious, futuristic, alienation, existential, male vocals, atmospheric, lonely, cold, introspective</td>
      <td>4.23</td>
      <td>70382</td>
      <td>1531</td>
      <td>...</td>
      <td>-9.102417</td>
      <td>0.056308</td>
      <td>115.450750</td>
      <td>0.291733</td>
      <td>268435.500000</td>
      <td>4.000000</td>
      <td>1997-06-16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Pink Floyd</td>
      <td>12 September 1975</td>
      <td>Progressive Rock, Art Rock</td>
      <td>melancholic, atmospheric, progressive, male vocals, concept album, introspective, serious, longing, bittersweet, meditative</td>
      <td>4.29</td>
      <td>48662</td>
      <td>983</td>
      <td>...</td>
      <td>-12.689400</td>
      <td>0.039740</td>
      <td>130.018800</td>
      <td>0.259040</td>
      <td>530512.000000</td>
      <td>3.600000</td>
      <td>1975-09-12</td>
    </tr>
    <tr>
      <th>2</th>
      <td>King Crimson</td>
      <td>10 October 1969</td>
      <td>Progressive Rock, Art Rock</td>
      <td>fantasy, epic, progressive, philosophical, complex, surreal, poetic, male vocals, melancholic, technical</td>
      <td>4.30</td>
      <td>44943</td>
      <td>870</td>
      <td>...</td>
      <td>-14.873125</td>
      <td>0.043463</td>
      <td>118.920625</td>
      <td>0.279400</td>
      <td>507644.125000</td>
      <td>3.875000</td>
      <td>1969-10-10</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Radiohead</td>
      <td>3 October 2000</td>
      <td>Art Rock, Experimental Rock, Electronic</td>
      <td>cold, melancholic, futuristic, atmospheric, anxious, cryptic, sombre, abstract, introspective, male vocals</td>
      <td>4.21</td>
      <td>58590</td>
      <td>734</td>
      <td>...</td>
      <td>-7.811941</td>
      <td>0.268318</td>
      <td>116.045059</td>
      <td>0.398206</td>
      <td>325379.529412</td>
      <td>4.058824</td>
      <td>2000-10-03</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Kendrick Lamar</td>
      <td>15 March 2015</td>
      <td>Conscious Hip Hop, West Coast Hip Hop, Jazz Rap</td>
      <td>political, conscious, poetic, protest, concept album, introspective, urban, male vocals, eclectic, passionate</td>
      <td>4.27</td>
      <td>44206</td>
      <td>379</td>
      <td>...</td>
      <td>-5.802062</td>
      <td>0.294175</td>
      <td>103.444563</td>
      <td>0.487187</td>
      <td>296225.750000</td>
      <td>3.812500</td>
      <td>2015-03-15</td>
    </tr>
    <tr>
      <th>5</th>
      <td>My Bloody Valentine</td>
      <td>4 November 1991</td>
      <td>Shoegaze, Noise Pop</td>
      <td>noisy, ethereal, atmospheric, romantic, dense, hypnotic, love, psychedelic, lush, bittersweet</td>
      <td>4.24</td>
      <td>49887</td>
      <td>1223</td>
      <td>...</td>
      <td>-13.224727</td>
      <td>0.049436</td>
      <td>119.816091</td>
      <td>0.286918</td>
      <td>265148.000000</td>
      <td>3.636364</td>
      <td>1991-11-04</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Pink Floyd</td>
      <td>23 March 1973</td>
      <td>Art Rock, Progressive Rock</td>
      <td>philosophical, atmospheric, introspective, existential, mellow, concept album, male vocals, psychedelic, progressive, epic</td>
      <td>4.20</td>
      <td>57622</td>
      <td>1549</td>
      <td>...</td>
      <td>-15.701900</td>
      <td>0.058660</td>
      <td>120.066200</td>
      <td>0.272830</td>
      <td>257363.600000</td>
      <td>3.700000</td>
      <td>1973-03-23</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4395</th>
      <td>The Koreatown Oddity</td>
      <td>19 June 2020</td>
      <td>West Coast Hip Hop, Conscious Hip Hop, Jazz Rap</td>
      <td>introspective, concept album, male vocals, sampling, playful, humorous, sentimental, bittersweet, surreal, lo-fi</td>
      <td>3.66</td>
      <td>1965</td>
      <td>12</td>
      <td>...</td>
      <td>-6.672187</td>
      <td>0.244925</td>
      <td>95.478562</td>
      <td>0.606000</td>
      <td>214588.687500</td>
      <td>4.000000</td>
      <td>2020-06-19</td>
    </tr>
    <tr>
      <th>4396</th>
      <td>Earth, Wind &amp; Fire</td>
      <td>9 June 1979</td>
      <td>Disco, Funk</td>
      <td>happy, summer, party, energetic, uplifting, lush, male vocals, rhythmic, love, technical</td>
      <td>3.68</td>
      <td>1108</td>
      <td>22</td>
      <td>...</td>
      <td>-7.147600</td>
      <td>0.254213</td>
      <td>126.265133</td>
      <td>0.413020</td>
      <td>204345.200000</td>
      <td>4.000000</td>
      <td>1979-06-09</td>
    </tr>
    <tr>
      <th>4397</th>
      <td>John Hiatt</td>
      <td>May 1987</td>
      <td>Singer/Songwriter, Roots Rock, Americana</td>
      <td>love, lethargic, lonely, existential, melodic, pastoral, sombre, poetic, mellow, calm</td>
      <td>3.68</td>
      <td>727</td>
      <td>37</td>
      <td>...</td>
      <td>-12.683700</td>
      <td>0.030090</td>
      <td>106.136700</td>
      <td>0.568300</td>
      <td>273146.700000</td>
      <td>4.000000</td>
      <td>1987-05-10</td>
    </tr>
    <tr>
      <th>4398</th>
      <td>Catharsis</td>
      <td>1999</td>
      <td>Crust Punk, Metalcore</td>
      <td>male vocals, anarchism, aggressive, angry, heavy, political, sampling</td>
      <td>3.65</td>
      <td>616</td>
      <td>6</td>
      <td>...</td>
      <td>-6.659900</td>
      <td>0.088560</td>
      <td>127.249950</td>
      <td>0.432750</td>
      <td>202675.450000</td>
      <td>3.950000</td>
      <td>1999-12-10</td>
    </tr>
    <tr>
      <th>4399</th>
      <td>Gracious</td>
      <td>17 July 1970</td>
      <td>Progressive Rock, Symphonic Prog</td>
      <td>NaN</td>
      <td>3.69</td>
      <td>565</td>
      <td>32</td>
      <td>...</td>
      <td>-4.805273</td>
      <td>0.049027</td>
      <td>149.398818</td>
      <td>0.622545</td>
      <td>193269.454545</td>
      <td>4.000000</td>
      <td>1970-07-17</td>
    </tr>
    <tr>
      <th>4400</th>
      <td>And Also the Trees</td>
      <td>12 November 2007</td>
      <td>Art Rock</td>
      <td>atmospheric, poetic, dark, male vocals, ominous, suspenseful, mysterious, cryptic, sombre, pastoral</td>
      <td>3.68</td>
      <td>524</td>
      <td>15</td>
      <td>...</td>
      <td>-13.088692</td>
      <td>0.037354</td>
      <td>118.958923</td>
      <td>0.252892</td>
      <td>229115.846154</td>
      <td>3.923077</td>
      <td>2007-11-12</td>
    </tr>
    <tr>
      <th>4401</th>
      <td>Minnie Riperton</td>
      <td>22 May 1975</td>
      <td>Smooth Soul, Pop Soul</td>
      <td>lush, female vocals, romantic, uplifting, summer, love, bittersweet, passionate, sensual, warm</td>
      <td>3.69</td>
      <td>490</td>
      <td>14</td>
      <td>...</td>
      <td>-11.508600</td>
      <td>0.048810</td>
      <td>110.463100</td>
      <td>0.576300</td>
      <td>242398.800000</td>
      <td>3.800000</td>
      <td>1975-05-22</td>
    </tr>
  </tbody>
</table>
<p>4402 rows × 20 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      1997-06-16
1      1975-09-12
2      1969-10-10
3      2000-10-03
4      2015-03-15
          ...    
4397   1987-05-10
4398   1999-12-10
4399   1970-07-17
4400   2007-11-12
4401   1975-05-22
Name: rel_date, Length: 4402, dtype: datetime64[ns]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the number of songs in the list from each decade.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def rename_value_counts(x):
    x.index.name = x.name
    x.name = 'Counts'
    return x

df['decade'] = df.rel_datetime.apply(lambda x: f'{(x.year // 10) * 10}s')
x = df.decade.value_counts().sort_index()
rename_value_counts(x)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def rename_value_counts(x):
    x.index.name = x.name
    x.name = 'Counts'
    return x

df['decade'] = df.rel_datetime.apply(lambda x: f'{(x.year // 10) * 10}s')
x = df.decade.value_counts().sort_index()
rename_value_counts(x)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def rename_value_counts(x):
    x.index.name = x.name
    x.name = 'Counts'
    return x


df['decade'] = df.rel_datetime.apply(lambda x: f'{x.year // 10 * 10}s')
x = df.decade.value_counts().sort_index()
__output__ = rename_value_counts(x)
</code></pre>
        <p><span onclick="$('#var_output_e5fa5e02').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e5fa5e02" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>decade
1940s       1
1950s     107
1960s     503
1970s    1097
1980s     608
1990s     947
2000s     767
2010s     325
2020s      47
Name: Counts, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, x, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ars_name</th>
      <th>rel_date</th>
      <th>gens</th>
      <th>descs</th>
      <th>avg_rat</th>
      <th>num_rat</th>
      <th>num_revs</th>
      <th>...</th>
      <th>speechiness</th>
      <th>tempo</th>
      <th>valence</th>
      <th>duration_ms</th>
      <th>time_signature</th>
      <th>rel_datetime</th>
      <th>decade</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Radiohead</td>
      <td>16 June 1997</td>
      <td>Alternative Rock, Art Rock</td>
      <td>melancholic, anxious, futuristic, alienation, existential, male vocals, atmospheric, lonely, cold, introspective</td>
      <td>4.23</td>
      <td>70382</td>
      <td>1531</td>
      <td>...</td>
      <td>0.056308</td>
      <td>115.450750</td>
      <td>0.291733</td>
      <td>268435.500000</td>
      <td>4.000000</td>
      <td>1997-06-16</td>
      <td>1990s</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Pink Floyd</td>
      <td>12 September 1975</td>
      <td>Progressive Rock, Art Rock</td>
      <td>melancholic, atmospheric, progressive, male vocals, concept album, introspective, serious, longing, bittersweet, meditative</td>
      <td>4.29</td>
      <td>48662</td>
      <td>983</td>
      <td>...</td>
      <td>0.039740</td>
      <td>130.018800</td>
      <td>0.259040</td>
      <td>530512.000000</td>
      <td>3.600000</td>
      <td>1975-09-12</td>
      <td>1970s</td>
    </tr>
    <tr>
      <th>2</th>
      <td>King Crimson</td>
      <td>10 October 1969</td>
      <td>Progressive Rock, Art Rock</td>
      <td>fantasy, epic, progressive, philosophical, complex, surreal, poetic, male vocals, melancholic, technical</td>
      <td>4.30</td>
      <td>44943</td>
      <td>870</td>
      <td>...</td>
      <td>0.043463</td>
      <td>118.920625</td>
      <td>0.279400</td>
      <td>507644.125000</td>
      <td>3.875000</td>
      <td>1969-10-10</td>
      <td>1960s</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Radiohead</td>
      <td>3 October 2000</td>
      <td>Art Rock, Experimental Rock, Electronic</td>
      <td>cold, melancholic, futuristic, atmospheric, anxious, cryptic, sombre, abstract, introspective, male vocals</td>
      <td>4.21</td>
      <td>58590</td>
      <td>734</td>
      <td>...</td>
      <td>0.268318</td>
      <td>116.045059</td>
      <td>0.398206</td>
      <td>325379.529412</td>
      <td>4.058824</td>
      <td>2000-10-03</td>
      <td>2000s</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Kendrick Lamar</td>
      <td>15 March 2015</td>
      <td>Conscious Hip Hop, West Coast Hip Hop, Jazz Rap</td>
      <td>political, conscious, poetic, protest, concept album, introspective, urban, male vocals, eclectic, passionate</td>
      <td>4.27</td>
      <td>44206</td>
      <td>379</td>
      <td>...</td>
      <td>0.294175</td>
      <td>103.444563</td>
      <td>0.487187</td>
      <td>296225.750000</td>
      <td>3.812500</td>
      <td>2015-03-15</td>
      <td>2010s</td>
    </tr>
    <tr>
      <th>5</th>
      <td>My Bloody Valentine</td>
      <td>4 November 1991</td>
      <td>Shoegaze, Noise Pop</td>
      <td>noisy, ethereal, atmospheric, romantic, dense, hypnotic, love, psychedelic, lush, bittersweet</td>
      <td>4.24</td>
      <td>49887</td>
      <td>1223</td>
      <td>...</td>
      <td>0.049436</td>
      <td>119.816091</td>
      <td>0.286918</td>
      <td>265148.000000</td>
      <td>3.636364</td>
      <td>1991-11-04</td>
      <td>1990s</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Pink Floyd</td>
      <td>23 March 1973</td>
      <td>Art Rock, Progressive Rock</td>
      <td>philosophical, atmospheric, introspective, existential, mellow, concept album, male vocals, psychedelic, progressive, epic</td>
      <td>4.20</td>
      <td>57622</td>
      <td>1549</td>
      <td>...</td>
      <td>0.058660</td>
      <td>120.066200</td>
      <td>0.272830</td>
      <td>257363.600000</td>
      <td>3.700000</td>
      <td>1973-03-23</td>
      <td>1970s</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4395</th>
      <td>The Koreatown Oddity</td>
      <td>19 June 2020</td>
      <td>West Coast Hip Hop, Conscious Hip Hop, Jazz Rap</td>
      <td>introspective, concept album, male vocals, sampling, playful, humorous, sentimental, bittersweet, surreal, lo-fi</td>
      <td>3.66</td>
      <td>1965</td>
      <td>12</td>
      <td>...</td>
      <td>0.244925</td>
      <td>95.478562</td>
      <td>0.606000</td>
      <td>214588.687500</td>
      <td>4.000000</td>
      <td>2020-06-19</td>
      <td>2020s</td>
    </tr>
    <tr>
      <th>4396</th>
      <td>Earth, Wind &amp; Fire</td>
      <td>9 June 1979</td>
      <td>Disco, Funk</td>
      <td>happy, summer, party, energetic, uplifting, lush, male vocals, rhythmic, love, technical</td>
      <td>3.68</td>
      <td>1108</td>
      <td>22</td>
      <td>...</td>
      <td>0.254213</td>
      <td>126.265133</td>
      <td>0.413020</td>
      <td>204345.200000</td>
      <td>4.000000</td>
      <td>1979-06-09</td>
      <td>1970s</td>
    </tr>
    <tr>
      <th>4397</th>
      <td>John Hiatt</td>
      <td>May 1987</td>
      <td>Singer/Songwriter, Roots Rock, Americana</td>
      <td>love, lethargic, lonely, existential, melodic, pastoral, sombre, poetic, mellow, calm</td>
      <td>3.68</td>
      <td>727</td>
      <td>37</td>
      <td>...</td>
      <td>0.030090</td>
      <td>106.136700</td>
      <td>0.568300</td>
      <td>273146.700000</td>
      <td>4.000000</td>
      <td>1987-05-10</td>
      <td>1980s</td>
    </tr>
    <tr>
      <th>4398</th>
      <td>Catharsis</td>
      <td>1999</td>
      <td>Crust Punk, Metalcore</td>
      <td>male vocals, anarchism, aggressive, angry, heavy, political, sampling</td>
      <td>3.65</td>
      <td>616</td>
      <td>6</td>
      <td>...</td>
      <td>0.088560</td>
      <td>127.249950</td>
      <td>0.432750</td>
      <td>202675.450000</td>
      <td>3.950000</td>
      <td>1999-12-10</td>
      <td>1990s</td>
    </tr>
    <tr>
      <th>4399</th>
      <td>Gracious</td>
      <td>17 July 1970</td>
      <td>Progressive Rock, Symphonic Prog</td>
      <td>NaN</td>
      <td>3.69</td>
      <td>565</td>
      <td>32</td>
      <td>...</td>
      <td>0.049027</td>
      <td>149.398818</td>
      <td>0.622545</td>
      <td>193269.454545</td>
      <td>4.000000</td>
      <td>1970-07-17</td>
      <td>1970s</td>
    </tr>
    <tr>
      <th>4400</th>
      <td>And Also the Trees</td>
      <td>12 November 2007</td>
      <td>Art Rock</td>
      <td>atmospheric, poetic, dark, male vocals, ominous, suspenseful, mysterious, cryptic, sombre, pastoral</td>
      <td>3.68</td>
      <td>524</td>
      <td>15</td>
      <td>...</td>
      <td>0.037354</td>
      <td>118.958923</td>
      <td>0.252892</td>
      <td>229115.846154</td>
      <td>3.923077</td>
      <td>2007-11-12</td>
      <td>2000s</td>
    </tr>
    <tr>
      <th>4401</th>
      <td>Minnie Riperton</td>
      <td>22 May 1975</td>
      <td>Smooth Soul, Pop Soul</td>
      <td>lush, female vocals, romantic, uplifting, summer, love, bittersweet, passionate, sensual, warm</td>
      <td>3.69</td>
      <td>490</td>
      <td>14</td>
      <td>...</td>
      <td>0.048810</td>
      <td>110.463100</td>
      <td>0.576300</td>
      <td>242398.800000</td>
      <td>3.800000</td>
      <td>1975-05-22</td>
      <td>1970s</td>
    </tr>
  </tbody>
</table>
<p>4402 rows × 21 columns</p>
      
          <p>x (Series):</p>
          <pre><code>decade
1940s       1
1950s     107
1960s     503
1970s    1097
1980s     608
1990s     947
2000s     767
2010s     325
2020s      47
Name: Counts, dtype: int64</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>decade
1940s       1
1950s     107
1960s     503
1970s    1097
1980s     608
1990s     947
2000s     767
2010s     325
2020s      47
Name: Counts, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 5 most common genre?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def explode_comma_seperated_series(series):
    return series.apply(lambda x: x.strip().replace(' ', '').split(',')).explode()

def get_most_common_tag_in_column(series, column_name='gens'):
    series = explode_comma_seperated_series(series)
    counts = series.reset_index()[column_name].value_counts().sort_values(ascending=False)
    return rename_value_counts(counts)

get_most_common_tag_in_column(df.gens).head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def explode_comma_seperated_series(series):
    return series.apply(lambda x: x.strip().replace(' ', '').split(',')).explode()

def get_most_common_tag_in_column(series, column_name='gens'):
    series = explode_comma_seperated_series(series)
    counts = series.reset_index()[column_name].value_counts().sort_values(ascending=False)
    return rename_value_counts(counts)

get_most_common_tag_in_column(df.gens).head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def explode_comma_seperated_series(series):
    return series.apply(lambda x: x.strip().replace(' ', '').split(',')
        ).explode()


def get_most_common_tag_in_column(series, column_name='gens'):
    series = explode_comma_seperated_series(series)
    counts = series.reset_index()[column_name].value_counts().sort_values(
        ascending=False)
    return rename_value_counts(counts)


__output__ = get_most_common_tag_in_column(df.gens).head(5)
</code></pre>
        <p><span onclick="$('#var_output_e0a01269').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e0a01269" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>gens
Singer/Songwriter    338
ProgressiveRock      281
HardRock             159
AlternativeRock      153
PopRock              142
Name: Counts, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>gens
Singer/Songwriter    338
ProgressiveRock      281
HardRock             159
AlternativeRock      153
PopRock              142
Name: Counts, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the top 3 most common genre by decade.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['decade', 'gens']].groupby('decade').apply(lambda x: get_most_common_tag_in_column(x.gens).head(3))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['decade', 'gens']].groupby('decade').apply(lambda x: get_most_common_tag_in_column(x.gens).head(3))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['decade', 'gens']].groupby('decade').apply(lambda x:
    get_most_common_tag_in_column(x.gens).head(3))
</code></pre>
        <p><span onclick="$('#var_output_89766c71').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_89766c71" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>decade  gens             
1940s   VocalJazz             1
        TraditionalPop        1
1950s   HardBop              36
        VocalJazz            22
        Standards            17
                             ..
2010s   Singer/Songwriter    23
        Ambient              21
2020s   Singer/Songwriter     5
        ConsciousHipHop       4
        ExperimentalRock      4
Name: Counts, Length: 26, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>decade  gens             
1940s   VocalJazz             1
        TraditionalPop        1
1950s   HardBop              36
        VocalJazz            22
        Standards            17
                             ..
2010s   Singer/Songwriter    23
        Ambient              21
2020s   Singer/Songwriter     5
        ConsciousHipHop       4
        ExperimentalRock      4
Name: Counts, Length: 26, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 5 most common tags associated among the top 10% of songs ranked by rating?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_rat = df[['avg_rat', 'descs']].dropna()

get_most_common_tag_in_column(df_rat[df_rat.avg_rat >= df_rat.avg_rat.quantile(0.9)].descs, 'descs').head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_rat = df[['avg_rat', 'descs']].dropna()

get_most_common_tag_in_column(df_rat[df_rat.avg_rat >= df_rat.avg_rat.quantile(0.9)].descs, 'descs').head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_rat = df[['avg_rat', 'descs']].dropna()
__output__ = get_most_common_tag_in_column(df_rat[df_rat.avg_rat >= df_rat.
    avg_rat.quantile(0.9)].descs, 'descs').head(5)
</code></pre>
        <p><span onclick="$('#var_output_de7e7cb2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_de7e7cb2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>descs
malevocals     284
melodic        162
passionate     138
atmospheric    121
energetic      119
Name: Counts, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_rat, __output__ </p>
    
          <p>df_rat (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>avg_rat</th>
      <th>descs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.23</td>
      <td>melancholic, anxious, futuristic, alienation, existential, male vocals, atmospheric, lonely, cold, introspective</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.29</td>
      <td>melancholic, atmospheric, progressive, male vocals, concept album, introspective, serious, longing, bittersweet, meditative</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.30</td>
      <td>fantasy, epic, progressive, philosophical, complex, surreal, poetic, male vocals, melancholic, technical</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.21</td>
      <td>cold, melancholic, futuristic, atmospheric, anxious, cryptic, sombre, abstract, introspective, male vocals</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4.27</td>
      <td>political, conscious, poetic, protest, concept album, introspective, urban, male vocals, eclectic, passionate</td>
    </tr>
    <tr>
      <th>5</th>
      <td>4.24</td>
      <td>noisy, ethereal, atmospheric, romantic, dense, hypnotic, love, psychedelic, lush, bittersweet</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4.20</td>
      <td>philosophical, atmospheric, introspective, existential, mellow, concept album, male vocals, psychedelic, progressive, epic</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4394</th>
      <td>3.64</td>
      <td>aggressive, heavy, chaotic, angry, misanthropic, rebellious, violence, infernal, passionate, male vocals</td>
    </tr>
    <tr>
      <th>4395</th>
      <td>3.66</td>
      <td>introspective, concept album, male vocals, sampling, playful, humorous, sentimental, bittersweet, surreal, lo-fi</td>
    </tr>
    <tr>
      <th>4396</th>
      <td>3.68</td>
      <td>happy, summer, party, energetic, uplifting, lush, male vocals, rhythmic, love, technical</td>
    </tr>
    <tr>
      <th>4397</th>
      <td>3.68</td>
      <td>love, lethargic, lonely, existential, melodic, pastoral, sombre, poetic, mellow, calm</td>
    </tr>
    <tr>
      <th>4398</th>
      <td>3.65</td>
      <td>male vocals, anarchism, aggressive, angry, heavy, political, sampling</td>
    </tr>
    <tr>
      <th>4400</th>
      <td>3.68</td>
      <td>atmospheric, poetic, dark, male vocals, ominous, suspenseful, mysterious, cryptic, sombre, pastoral</td>
    </tr>
    <tr>
      <th>4401</th>
      <td>3.69</td>
      <td>lush, female vocals, romantic, uplifting, summer, love, bittersweet, passionate, sensual, warm</td>
    </tr>
  </tbody>
</table>
<p>4304 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>descs
malevocals     284
melodic        162
passionate     138
atmospheric    121
energetic      119
Name: Counts, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 5 genres among the top 10% songs that get rated the most number of times?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_num_rat = df[['gens', 'num_rat']].dropna()
df_num_rat = df_num_rat[df_num_rat.num_rat >= df_num_rat.num_rat.quantile(0.9)]
get_most_common_tag_in_column(df_num_rat.gens).head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_num_rat = df[['gens', 'num_rat']].dropna()
df_num_rat = df_num_rat[df_num_rat.num_rat >= df_num_rat.num_rat.quantile(0.9)]
get_most_common_tag_in_column(df_num_rat.gens).head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_num_rat = df[['gens', 'num_rat']].dropna()
df_num_rat = df_num_rat[df_num_rat.num_rat >= df_num_rat.num_rat.quantile(0.9)]
__output__ = get_most_common_tag_in_column(df_num_rat.gens).head(5)
</code></pre>
        <p><span onclick="$('#var_output_26fa7811').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_26fa7811" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>gens
AlternativeRock      37
Singer/Songwriter    35
ArtRock              32
IndieRock            28
Post-Punk            23
Name: Counts, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_num_rat, __output__ </p>
    
          <p>df_num_rat (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gens</th>
      <th>num_rat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Alternative Rock, Art Rock</td>
      <td>70382</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Progressive Rock, Art Rock</td>
      <td>48662</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Progressive Rock, Art Rock</td>
      <td>44943</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Art Rock, Experimental Rock, Electronic</td>
      <td>58590</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Conscious Hip Hop, West Coast Hip Hop, Jazz Rap</td>
      <td>44206</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Shoegaze, Noise Pop</td>
      <td>49887</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Art Rock, Progressive Rock</td>
      <td>57622</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>3894</th>
      <td>West Coast Hip Hop, Conscious Hip Hop</td>
      <td>30228</td>
    </tr>
    <tr>
      <th>3898</th>
      <td>Hard Rock</td>
      <td>16526</td>
    </tr>
    <tr>
      <th>4043</th>
      <td>Electropop, Synthpop</td>
      <td>14569</td>
    </tr>
    <tr>
      <th>4149</th>
      <td>Shoegaze, Dream Pop</td>
      <td>15503</td>
    </tr>
    <tr>
      <th>4229</th>
      <td>Psychedelic Pop, Synthpop, Neo-Psychedelia</td>
      <td>20043</td>
    </tr>
    <tr>
      <th>4360</th>
      <td>Pop Rap, West Coast Hip Hop</td>
      <td>17629</td>
    </tr>
    <tr>
      <th>4361</th>
      <td>Lo-Fi / Slacker Rock, Psychedelic Folk, Indie Folk</td>
      <td>12800</td>
    </tr>
  </tbody>
</table>
<p>441 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>gens
AlternativeRock      37
Singer/Songwriter    35
ArtRock              32
IndieRock            28
Post-Punk            23
Name: Counts, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which artists have featured most on the list after 2000? Show top 5.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_ars = df[(df.rel_datetime > datetime.fromisoformat('2000-01-01'))]
df_ars.ars_name.value_counts().head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_ars = df[(df.rel_datetime > datetime.fromisoformat('2000-01-01'))]
df_ars.ars_name.value_counts().head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_ars = df[df.rel_datetime > datetime.fromisoformat('2000-01-01')]
__output__ = df_ars.ars_name.value_counts().head(5)
</code></pre>
        <p><span onclick="$('#var_output_2bf1bb26').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2bf1bb26" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Kanye West         7
Various Artists    6
Kendrick Lamar     5
Converge           5
Radiohead          5
Name: ars_name, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_ars, __output__ </p>
    
          <p>df_ars (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ars_name</th>
      <th>rel_date</th>
      <th>gens</th>
      <th>descs</th>
      <th>avg_rat</th>
      <th>num_rat</th>
      <th>num_revs</th>
      <th>...</th>
      <th>speechiness</th>
      <th>tempo</th>
      <th>valence</th>
      <th>duration_ms</th>
      <th>time_signature</th>
      <th>rel_datetime</th>
      <th>decade</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>Radiohead</td>
      <td>3 October 2000</td>
      <td>Art Rock, Experimental Rock, Electronic</td>
      <td>cold, melancholic, futuristic, atmospheric, anxious, cryptic, sombre, abstract, introspective, male vocals</td>
      <td>4.21</td>
      <td>58590</td>
      <td>734</td>
      <td>...</td>
      <td>0.268318</td>
      <td>116.045059</td>
      <td>0.398206</td>
      <td>325379.529412</td>
      <td>4.058824</td>
      <td>2000-10-03</td>
      <td>2000s</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Kendrick Lamar</td>
      <td>15 March 2015</td>
      <td>Conscious Hip Hop, West Coast Hip Hop, Jazz Rap</td>
      <td>political, conscious, poetic, protest, concept album, introspective, urban, male vocals, eclectic, passionate</td>
      <td>4.27</td>
      <td>44206</td>
      <td>379</td>
      <td>...</td>
      <td>0.294175</td>
      <td>103.444563</td>
      <td>0.487187</td>
      <td>296225.750000</td>
      <td>3.812500</td>
      <td>2015-03-15</td>
      <td>2010s</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Madvillain</td>
      <td>23 March 2004</td>
      <td>Abstract Hip Hop</td>
      <td>sampling, playful, cryptic, humorous, abstract, mysterious, eclectic, surreal, male vocals, boastful</td>
      <td>4.26</td>
      <td>35573</td>
      <td>376</td>
      <td>...</td>
      <td>0.324564</td>
      <td>111.435318</td>
      <td>0.603091</td>
      <td>126462.500000</td>
      <td>3.863636</td>
      <td>2004-03-23</td>
      <td>2000s</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Radiohead</td>
      <td>10 October 2007</td>
      <td>Art Rock, Alternative Rock</td>
      <td>lush, male vocals, melancholic, introspective, bittersweet, warm, mellow, atmospheric, ethereal, longing</td>
      <td>4.18</td>
      <td>48484</td>
      <td>756</td>
      <td>...</td>
      <td>0.037620</td>
      <td>119.450600</td>
      <td>0.396730</td>
      <td>255862.000000</td>
      <td>3.900000</td>
      <td>2007-10-10</td>
      <td>2000s</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Kendrick Lamar</td>
      <td>22 October 2012</td>
      <td>West Coast Hip Hop, Conscious Hip Hop</td>
      <td>urban, crime, concept album, conscious, introspective, male vocals, passionate, existential, violence, bittersweet</td>
      <td>4.20</td>
      <td>38939</td>
      <td>315</td>
      <td>...</td>
      <td>0.268318</td>
      <td>116.045059</td>
      <td>0.398206</td>
      <td>325379.529412</td>
      <td>4.058824</td>
      <td>2012-10-22</td>
      <td>2010s</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Kanye West</td>
      <td>22 November 2010</td>
      <td>Pop Rap, Hip Hop</td>
      <td>epic, boastful, passionate, sampling, hedonistic, vulgar, melodic, anthemic, introspective, male vocals</td>
      <td>4.07</td>
      <td>48415</td>
      <td>636</td>
      <td>...</td>
      <td>0.131262</td>
      <td>111.951923</td>
      <td>0.364715</td>
      <td>317006.153846</td>
      <td>3.769231</td>
      <td>2010-11-22</td>
      <td>2010s</td>
    </tr>
    <tr>
      <th>51</th>
      <td>Björk</td>
      <td>27 August 2001</td>
      <td>Art Pop, Electronic</td>
      <td>sensual, romantic, winter, sexual, ethereal, atmospheric, lush, introspective, female vocals, soothing</td>
      <td>4.13</td>
      <td>23181</td>
      <td>261</td>
      <td>...</td>
      <td>0.054617</td>
      <td>145.602083</td>
      <td>0.204267</td>
      <td>278255.583333</td>
      <td>3.916667</td>
      <td>2001-08-27</td>
      <td>2000s</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4378</th>
      <td>Thrice</td>
      <td>18 October 2005</td>
      <td>Post-Hardcore, Alternative Rock</td>
      <td>passionate, atmospheric, spiritual, religious, male vocals, sombre, melancholic, melodic, poetic, progressive</td>
      <td>3.65</td>
      <td>2534</td>
      <td>46</td>
      <td>...</td>
      <td>0.104117</td>
      <td>145.247583</td>
      <td>0.169592</td>
      <td>267812.250000</td>
      <td>3.583333</td>
      <td>2005-10-18</td>
      <td>2000s</td>
    </tr>
    <tr>
      <th>4385</th>
      <td>Equilibrium</td>
      <td>27 June 2008</td>
      <td>Folk Metal, Viking Metal</td>
      <td>melodic, epic, energetic, dense, folklore, male vocals, medieval, forest, triumphant, nature</td>
      <td>3.62</td>
      <td>1049</td>
      <td>33</td>
      <td>...</td>
      <td>0.086908</td>
      <td>151.985308</td>
      <td>0.257715</td>
      <td>365713.923077</td>
      <td>3.692308</td>
      <td>2008-06-27</td>
      <td>2000s</td>
    </tr>
    <tr>
      <th>4389</th>
      <td>The Residents</td>
      <td>May 2002</td>
      <td>Art Pop, Experimental Rock</td>
      <td>male vocals, female vocals, introspective, melancholic, ominous, surreal, concept album, dark, death, sombre</td>
      <td>3.67</td>
      <td>651</td>
      <td>15</td>
      <td>...</td>
      <td>0.071535</td>
      <td>114.084000</td>
      <td>0.309280</td>
      <td>178623.300000</td>
      <td>3.700000</td>
      <td>2002-05-10</td>
      <td>2000s</td>
    </tr>
    <tr>
      <th>4391</th>
      <td>Cormega</td>
      <td>25 June 2002</td>
      <td>East Coast Hip Hop, Hardcore Hip Hop</td>
      <td>introspective, rhythmic, sampling, urban, boastful, male vocals, conscious</td>
      <td>3.70</td>
      <td>388</td>
      <td>9</td>
      <td>...</td>
      <td>0.385286</td>
      <td>101.127214</td>
      <td>0.690286</td>
      <td>170679.000000</td>
      <td>3.785714</td>
      <td>2002-06-25</td>
      <td>2000s</td>
    </tr>
    <tr>
      <th>4394</th>
      <td>Nails</td>
      <td>19 March 2013</td>
      <td>Grindcore, Powerviolence</td>
      <td>aggressive, heavy, chaotic, angry, misanthropic, rebellious, violence, infernal, passionate, male vocals</td>
      <td>3.64</td>
      <td>3864</td>
      <td>36</td>
      <td>...</td>
      <td>0.110690</td>
      <td>120.085700</td>
      <td>0.130850</td>
      <td>105885.300000</td>
      <td>4.000000</td>
      <td>2013-03-19</td>
      <td>2010s</td>
    </tr>
    <tr>
      <th>4395</th>
      <td>The Koreatown Oddity</td>
      <td>19 June 2020</td>
      <td>West Coast Hip Hop, Conscious Hip Hop, Jazz Rap</td>
      <td>introspective, concept album, male vocals, sampling, playful, humorous, sentimental, bittersweet, surreal, lo-fi</td>
      <td>3.66</td>
      <td>1965</td>
      <td>12</td>
      <td>...</td>
      <td>0.244925</td>
      <td>95.478562</td>
      <td>0.606000</td>
      <td>214588.687500</td>
      <td>4.000000</td>
      <td>2020-06-19</td>
      <td>2020s</td>
    </tr>
    <tr>
      <th>4400</th>
      <td>And Also the Trees</td>
      <td>12 November 2007</td>
      <td>Art Rock</td>
      <td>atmospheric, poetic, dark, male vocals, ominous, suspenseful, mysterious, cryptic, sombre, pastoral</td>
      <td>3.68</td>
      <td>524</td>
      <td>15</td>
      <td>...</td>
      <td>0.037354</td>
      <td>118.958923</td>
      <td>0.252892</td>
      <td>229115.846154</td>
      <td>3.923077</td>
      <td>2007-11-12</td>
      <td>2000s</td>
    </tr>
  </tbody>
</table>
<p>1139 rows × 21 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Kanye West         7
Various Artists    6
Kendrick Lamar     5
Converge           5
Radiohead          5
Name: ars_name, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How has the features 'speechiness', 'acousticness' and 'danceability' changed over the decades? Show averages for each decade.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>auditory_features = ['speechiness', 'acousticness', 'danceability']

df[auditory_features + ['decade']].groupby('decade').mean().T</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>auditory_features = ['speechiness', 'acousticness', 'danceability']

df[auditory_features + ['decade']].groupby('decade').mean().T</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>auditory_features = ['speechiness', 'acousticness', 'danceability']
__output__ = df[auditory_features + ['decade']].groupby('decade').mean().T
</code></pre>
        <p><span onclick="$('#var_output_06c15d14').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_06c15d14" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>decade</th>
      <th>1940s</th>
      <th>1950s</th>
      <th>1960s</th>
      <th>1970s</th>
      <th>1980s</th>
      <th>1990s</th>
      <th>2000s</th>
      <th>2010s</th>
      <th>2020s</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>speechiness</th>
      <td>0.040225</td>
      <td>0.062837</td>
      <td>0.069184</td>
      <td>0.073230</td>
      <td>0.083101</td>
      <td>0.100129</td>
      <td>0.094369</td>
      <td>0.117705</td>
      <td>0.122188</td>
    </tr>
    <tr>
      <th>acousticness</th>
      <td>0.974250</td>
      <td>0.688571</td>
      <td>0.505866</td>
      <td>0.377647</td>
      <td>0.266925</td>
      <td>0.255499</td>
      <td>0.289134</td>
      <td>0.316662</td>
      <td>0.369516</td>
    </tr>
    <tr>
      <th>danceability</th>
      <td>0.504750</td>
      <td>0.496905</td>
      <td>0.500280</td>
      <td>0.499052</td>
      <td>0.467277</td>
      <td>0.471853</td>
      <td>0.440983</td>
      <td>0.479268</td>
      <td>0.500504</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 9 columns</p>
      
        <p><strong>Hyp output variables:</strong> auditory_features, __output__ </p>
    
          <p>auditory_features (list):</p>
          <pre><code>['speechiness', 'acousticness', 'danceability']</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>decade</th>
      <th>1940s</th>
      <th>1950s</th>
      <th>1960s</th>
      <th>1970s</th>
      <th>1980s</th>
      <th>1990s</th>
      <th>2000s</th>
      <th>2010s</th>
      <th>2020s</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>speechiness</th>
      <td>0.040225</td>
      <td>0.062837</td>
      <td>0.069184</td>
      <td>0.073230</td>
      <td>0.083101</td>
      <td>0.100129</td>
      <td>0.094369</td>
      <td>0.117705</td>
      <td>0.122188</td>
    </tr>
    <tr>
      <th>acousticness</th>
      <td>0.974250</td>
      <td>0.688571</td>
      <td>0.505866</td>
      <td>0.377647</td>
      <td>0.266925</td>
      <td>0.255499</td>
      <td>0.289134</td>
      <td>0.316662</td>
      <td>0.369516</td>
    </tr>
    <tr>
      <th>danceability</th>
      <td>0.504750</td>
      <td>0.496905</td>
      <td>0.500280</td>
      <td>0.499052</td>
      <td>0.467277</td>
      <td>0.471853</td>
      <td>0.440983</td>
      <td>0.479268</td>
      <td>0.500504</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 9 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_11 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the 3 shortest albums among the top 10% of the highest rated? Show the rating and duration of each album.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.avg_rat >= df.avg_rat.quantile(0.9)][['avg_rat', 'album', 'duration_ms']].sort_values('duration_ms').head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.avg_rat >= df.avg_rat.quantile(0.9)][['avg_rat', 'album', 'duration_ms']].sort_values('duration_ms').head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.avg_rat >= df.avg_rat.quantile(0.9)][['avg_rat', 'album',
    'duration_ms']].sort_values('duration_ms').head(3)
</code></pre>
        <p><span onclick="$('#var_output_65b66561').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_65b66561" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>avg_rat</th>
      <th>album</th>
      <th>duration_ms</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>422</th>
      <td>3.92</td>
      <td>UNDERTALE</td>
      <td>56870.200000</td>
    </tr>
    <tr>
      <th>244</th>
      <td>3.98</td>
      <td>Out to Lunch</td>
      <td>94129.428571</td>
    </tr>
    <tr>
      <th>256</th>
      <td>4.01</td>
      <td>The Legend of Zelda [Ocarina of Time]</td>
      <td>94521.357143</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>avg_rat</th>
      <th>album</th>
      <th>duration_ms</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>422</th>
      <td>3.92</td>
      <td>UNDERTALE</td>
      <td>56870.200000</td>
    </tr>
    <tr>
      <th>244</th>
      <td>3.98</td>
      <td>Out to Lunch</td>
      <td>94129.428571</td>
    </tr>
    <tr>
      <th>256</th>
      <td>4.01</td>
      <td>The Legend of Zelda [Ocarina of Time]</td>
      <td>94521.357143</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> top-5000-albums-of-all-time-spotify-features/notebook_1.ipynb|||turn_12 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the top 10 genres most associated with high energy (above 0.8).</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_energy = df[df.energy > 0.8][['descs', 'energy']]
get_most_common_tag_in_column(df.gens, 'gens').head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_energy = df[df.energy > 0.8][['descs', 'energy']]
get_most_common_tag_in_column(df.gens, 'gens').head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_energy = df[df.energy > 0.8][['descs', 'energy']]
__output__ = get_most_common_tag_in_column(df.gens, 'gens').head(5)
</code></pre>
        <p><span onclick="$('#var_output_0d8f318e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0d8f318e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>gens
Singer/Songwriter    338
ProgressiveRock      281
HardRock             159
AlternativeRock      153
PopRock              142
Name: Counts, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_energy, __output__ </p>
    
          <p>df_energy (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>descs</th>
      <th>energy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>30</th>
      <td>sombre, dark, cold, anxious, introspective, lonely, atmospheric, existential, depressive, male vocals</td>
      <td>0.801091</td>
    </tr>
    <tr>
      <th>38</th>
      <td>atmospheric, lush, repetitive, mellow, psychedelic, warm, aquatic, nature, melodic, androgynous vocals</td>
      <td>0.856000</td>
    </tr>
    <tr>
      <th>44</th>
      <td>psychedelic, drugs, poetic, sexual, dark, male vocals, cryptic, hedonistic, mysterious, nocturnal</td>
      <td>0.885545</td>
    </tr>
    <tr>
      <th>60</th>
      <td>aggressive, manic, energetic, angry, noisy, nihilistic, crime, raw, drugs, misanthropic</td>
      <td>0.909846</td>
    </tr>
    <tr>
      <th>67</th>
      <td>energetic, anxious, raw, rebellious, noisy, urban, male vocals, female vocals, dissonant, apathetic</td>
      <td>0.879118</td>
    </tr>
    <tr>
      <th>73</th>
      <td>heavy, energetic, aggressive, male vocals, dark, death, angry, apocalyptic, melodic, cold</td>
      <td>0.922960</td>
    </tr>
    <tr>
      <th>104</th>
      <td>melancholic, melodic, lonely, introspective, male vocals, bittersweet, romantic, poetic, sentimental, existential</td>
      <td>0.822750</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4370</th>
      <td>apocalyptic, ominous, psychedelic, atmospheric, hypnotic, energetic, existential, dense, noisy, chaotic</td>
      <td>0.902222</td>
    </tr>
    <tr>
      <th>4377</th>
      <td>humorous, aggressive, satirical, sarcastic, rhythmic, male vocals, energetic, heavy, violence, vulgar</td>
      <td>0.812094</td>
    </tr>
    <tr>
      <th>4378</th>
      <td>passionate, atmospheric, spiritual, religious, male vocals, sombre, melancholic, melodic, poetic, progressive</td>
      <td>0.840417</td>
    </tr>
    <tr>
      <th>4380</th>
      <td>energetic, rebellious, angry, male vocals, melodic, urban, humorous, manic</td>
      <td>0.895600</td>
    </tr>
    <tr>
      <th>4383</th>
      <td>aggressive, heavy, death, anti-religious, male vocals, hateful, energetic, dark, pessimistic</td>
      <td>0.893833</td>
    </tr>
    <tr>
      <th>4385</th>
      <td>melodic, epic, energetic, dense, folklore, male vocals, medieval, forest, triumphant, nature</td>
      <td>0.901615</td>
    </tr>
    <tr>
      <th>4394</th>
      <td>aggressive, heavy, chaotic, angry, misanthropic, rebellious, violence, infernal, passionate, male vocals</td>
      <td>0.942400</td>
    </tr>
  </tbody>
</table>
<p>777 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>gens
Singer/Songwriter    338
ProgressiveRock      281
HardRock             159
AlternativeRock      153
PopRock              142
Name: Counts, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 3 titles of Blizzard and Valve's best user rated games and when were they released?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>score_type = 'UserScore'
columns = ['CurrentOwner', 'Name', 'UserScore', 'Release']
num_entries = 3
sort_top_score = lambda group, score_type, num_entries, columns: \
    group.sort_values(score_type, ascending=False).head(num_entries)[columns]

pd.concat([sort_top_score(group, score_type, num_entries, columns)
           for owner, group in df.groupby('CurrentOwner')])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>score_type = 'UserScore'
columns = ['CurrentOwner', 'Name', 'UserScore', 'Release']
num_entries = 3
sort_top_score = lambda group, score_type, num_entries, columns: \
    group.sort_values(score_type, ascending=False).head(num_entries)[columns]

pd.concat([sort_top_score(group, score_type, num_entries, columns)
           for owner, group in df.groupby('CurrentOwner')])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>score_type = 'UserScore'
columns = ['CurrentOwner', 'Name', 'UserScore', 'Release']
num_entries = 3
sort_top_score = (lambda group, score_type, num_entries, columns: group.
    sort_values(score_type, ascending=False).head(num_entries)[columns])
__output__ = pd.concat([sort_top_score(group, score_type, num_entries,
    columns) for owner, group in df.groupby('CurrentOwner')])
</code></pre>
        <p><span onclick="$('#var_output_b02e75ea').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b02e75ea" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CurrentOwner</th>
      <th>Name</th>
      <th>UserScore</th>
      <th>Release</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12</th>
      <td>Blizzard</td>
      <td>Warcraft III: Reign of Chaos</td>
      <td>9.2</td>
      <td>July 03, 2002</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Blizzard</td>
      <td>StarCraft</td>
      <td>9.1</td>
      <td>March 31, 1998</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Blizzard</td>
      <td>Warcraft II: Tides of Darkness</td>
      <td>9.0</td>
      <td>December 09, 1995</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Valve</td>
      <td>Counter-Strike</td>
      <td>9.2</td>
      <td>November 09, 2000</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Valve</td>
      <td>Half-Life 2</td>
      <td>9.2</td>
      <td>November 16, 2004</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Valve</td>
      <td>Half-Life 2: Episode Two</td>
      <td>9.2</td>
      <td>October 10, 2007</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 4 columns</p>
      
        <p><strong>Hyp output variables:</strong> score_type, columns, num_entries, __output__ </p>
    
          <p>score_type (str):</p>
          <pre><code>UserScore</code></pre>
      
          <p>columns (list):</p>
          <pre><code>['CurrentOwner', 'Name', 'UserScore', 'Release']</code></pre>
      
          <p>num_entries (int):</p>
          <pre><code>3</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CurrentOwner</th>
      <th>Name</th>
      <th>UserScore</th>
      <th>Release</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12</th>
      <td>Blizzard</td>
      <td>Warcraft III: Reign of Chaos</td>
      <td>9.2</td>
      <td>July 03, 2002</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Blizzard</td>
      <td>StarCraft</td>
      <td>9.1</td>
      <td>March 31, 1998</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Blizzard</td>
      <td>Warcraft II: Tides of Darkness</td>
      <td>9.0</td>
      <td>December 09, 1995</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Valve</td>
      <td>Counter-Strike</td>
      <td>9.2</td>
      <td>November 09, 2000</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Valve</td>
      <td>Half-Life 2</td>
      <td>9.2</td>
      <td>November 16, 2004</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Valve</td>
      <td>Half-Life 2: Episode Two</td>
      <td>9.2</td>
      <td>October 10, 2007</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 4 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the median age of Valve and Blizzard's top 5 user rated titles?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>get_age = lambda datestring: (datetime.now() - datetime.strptime(datestring, "%B %d, %Y")).days / 365 if type(
    datestring) is str else datestring
df['Age'] = df.Release.apply(get_age)
score_type = 'UserScore'
columns = ['CurrentOwner', 'Age']
num_entries = 5

pd.concat([sort_top_score(group, score_type, num_entries, columns)
           for owner, group in df.groupby('CurrentOwner')]).groupby('CurrentOwner').median()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>get_age = lambda datestring: (datetime.now() - datetime.strptime(datestring, "%B %d, %Y")).days / 365 if type(
    datestring) is str else datestring
df['Age'] = df.Release.apply(get_age)
score_type = 'UserScore'
columns = ['CurrentOwner', 'Age']
num_entries = 5

pd.concat([sort_top_score(group, score_type, num_entries, columns)
           for owner, group in df.groupby('CurrentOwner')]).groupby('CurrentOwner').median()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>get_age = lambda datestring: (datetime.now() - datetime.strptime(datestring,
    '%B %d, %Y')).days / 365 if type(datestring) is str else datestring
df['Age'] = df.Release.apply(get_age)
score_type = 'UserScore'
columns = ['CurrentOwner', 'Age']
num_entries = 5
__output__ = pd.concat([sort_top_score(group, score_type, num_entries,
    columns) for owner, group in df.groupby('CurrentOwner')]).groupby(
    'CurrentOwner').median()
</code></pre>
        <p><span onclick="$('#var_output_1156db50').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1156db50" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age</th>
    </tr>
    <tr>
      <th>CurrentOwner</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Blizzard</th>
      <td>24.712329</td>
    </tr>
    <tr>
      <th>Valve</th>
      <td>15.178082</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, columns, num_entries, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Imagelink</th>
      <th>Developers</th>
      <th>Publishers</th>
      <th>Writers</th>
      <th>Composers</th>
      <th>Series</th>
      <th>...</th>
      <th>Designers</th>
      <th>Artists</th>
      <th>Directors</th>
      <th>Producers</th>
      <th>Programmers</th>
      <th>CurrentOwner</th>
      <th>Age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Half-Life</td>
      <td>https://en.wikipedia.org/wiki/File:Half-Life_Cover_Art.jpg</td>
      <td>Valve</td>
      <td>Sierra Studios</td>
      <td>Marc Laidlaw</td>
      <td>Kelly Bailey</td>
      <td>Half-Life</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>24.073973</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Team Fortress Classic</td>
      <td>https://en.wikipedia.org/wiki/File:Team_Fortress_Classic_box.jpg</td>
      <td>Valve</td>
      <td>['Sierra Studios']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>['John Cook', 'Robin Walker']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>23.693151</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Counter-Strike</td>
      <td>https://en.wikipedia.org/wiki/File:Counter-Strike_Box.jpg</td>
      <td>Valve</td>
      <td>['Sierra Studios']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>['Minh Le', 'Jess Cliffe']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>22.098630</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Day of Defeat</td>
      <td>https://en.wikipedia.org/wiki/File:Day_of_Defeat_cover_art.jpg</td>
      <td>Valve</td>
      <td>['Activision']</td>
      <td>NaN</td>
      <td>Michael Gordon Shapiro</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>19.610959</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Counter-Strike: Condition Zero</td>
      <td>https://en.wikipedia.org/wiki/File:CZbox.jpg</td>
      <td>['Ritual Entertainment', 'Turtle Rock Studios', 'Valve']</td>
      <td>['Sierra Entertainment']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.728767</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Counter-Strike: Source</td>
      <td>https://en.wikipedia.org/wiki/File:Counter-Strike_Source_(box_art).jpg</td>
      <td>['Valve', 'Turtle Rock Studios']</td>
      <td>Valve</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.186301</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Half-Life 2</td>
      <td>https://en.wikipedia.org/wiki/File:Half-Life_2_cover.jpg</td>
      <td>Valve</td>
      <td>['Valve']</td>
      <td>Marc Laidlaw</td>
      <td>Kelly Bailey</td>
      <td>Half-Life</td>
      <td>...</td>
      <td>NaN</td>
      <td>Viktor Antonov</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.076712</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Diablo III</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_III_cover.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>Chris Metzen</td>
      <td>Russell Brower</td>
      <td>Diablo</td>
      <td>...</td>
      <td>['Kevin Martens', 'David M. Adams']</td>
      <td>Christian Lichtner</td>
      <td>Jay Wilson</td>
      <td>Alex Mayberry</td>
      <td>Jason Regier</td>
      <td>Blizzard</td>
      <td>10.578082</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Hearthstone: Heroes of Warcraft</td>
      <td>https://en.wikipedia.org/wiki/File:Hearthstone_2016_logo.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>Peter McConnell</td>
      <td>Warcraft</td>
      <td>...</td>
      <td>['Derek Sakamoto', 'Mike Donais']</td>
      <td>NaN</td>
      <td>['Ben Brode', 'Jason Chayes', 'Eric Dodds']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>8.756164</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Heroes of the Storm</td>
      <td>https://en.wikipedia.org/wiki/File:Heroes_of_the_Storm_BlizzHeroes_2017_logo.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>['Glenn Stafford', 'Jason Hayes']</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>['Dustin Browder', 'Alan Dabiri']</td>
      <td>Kaéo Milker</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>7.528767</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Overwatch</td>
      <td>https://en.wikipedia.org/wiki/File:Overwatch_cover_art.jpg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>['Michael Chu', 'Alyssa Wong']</td>
      <td>Derek Duke</td>
      <td>NaN</td>
      <td>...</td>
      <td>['Jeremy Craig', 'Michael Elliott', 'Scott Mercer']</td>
      <td>['William Petras', 'Arnold Tsang']</td>
      <td>['Jeff Kaplan', 'Chris Metzen', 'Aaron Keller']</td>
      <td>NaN</td>
      <td>['Mike Elliott', 'John LeFleur']</td>
      <td>Blizzard</td>
      <td>6.550685</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Diablo Immortal</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_Immortal_App_Logo.png</td>
      <td>['Blizzard Entertainment', 'NetEase']</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Diablo</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Wyatt Cheng</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>0.523288</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Overwatch 2</td>
      <td>https://en.wikipedia.org/wiki/File:Overwatch_2_logo.svg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Diablo IV</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_IV_logo.jpg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Diablo</td>
      <td>...</td>
      <td>Joe Piepiora</td>
      <td>John Mueller</td>
      <td>['Joe Shely', 'Luis Barriga']</td>
      <td>Tiffany Wat</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>49 rows × 22 columns</p>
      
          <p>columns (list):</p>
          <pre><code>['CurrentOwner', 'Age']</code></pre>
      
          <p>num_entries (int):</p>
          <pre><code>5</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age</th>
    </tr>
    <tr>
      <th>CurrentOwner</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Blizzard</th>
      <td>24.712329</td>
    </tr>
    <tr>
      <th>Valve</th>
      <td>15.178082</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What websites were this data sourced from? Show the hostname</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['SourceWebsite'] = df.Source.apply(lambda x: x.split('/')[2])
df[['SourceWebsite']].value_counts()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['SourceWebsite'] = df.Source.apply(lambda x: x.split('/')[2])
df[['SourceWebsite']].value_counts()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['SourceWebsite'] = df.Source.apply(lambda x: x.split('/')[2])
__output__ = df[['SourceWebsite']].value_counts()
</code></pre>
        <p><span onclick="$('#var_output_399eb7a5').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_399eb7a5" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>SourceWebsite   
en.wikipedia.org    49
dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Imagelink</th>
      <th>Developers</th>
      <th>Publishers</th>
      <th>Writers</th>
      <th>Composers</th>
      <th>Series</th>
      <th>...</th>
      <th>Artists</th>
      <th>Directors</th>
      <th>Producers</th>
      <th>Programmers</th>
      <th>CurrentOwner</th>
      <th>Age</th>
      <th>SourceWebsite</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Half-Life</td>
      <td>https://en.wikipedia.org/wiki/File:Half-Life_Cover_Art.jpg</td>
      <td>Valve</td>
      <td>Sierra Studios</td>
      <td>Marc Laidlaw</td>
      <td>Kelly Bailey</td>
      <td>Half-Life</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>24.073973</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Team Fortress Classic</td>
      <td>https://en.wikipedia.org/wiki/File:Team_Fortress_Classic_box.jpg</td>
      <td>Valve</td>
      <td>['Sierra Studios']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>23.693151</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Counter-Strike</td>
      <td>https://en.wikipedia.org/wiki/File:Counter-Strike_Box.jpg</td>
      <td>Valve</td>
      <td>['Sierra Studios']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>22.098630</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Day of Defeat</td>
      <td>https://en.wikipedia.org/wiki/File:Day_of_Defeat_cover_art.jpg</td>
      <td>Valve</td>
      <td>['Activision']</td>
      <td>NaN</td>
      <td>Michael Gordon Shapiro</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>19.610959</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Counter-Strike: Condition Zero</td>
      <td>https://en.wikipedia.org/wiki/File:CZbox.jpg</td>
      <td>['Ritual Entertainment', 'Turtle Rock Studios', 'Valve']</td>
      <td>['Sierra Entertainment']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.728767</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Counter-Strike: Source</td>
      <td>https://en.wikipedia.org/wiki/File:Counter-Strike_Source_(box_art).jpg</td>
      <td>['Valve', 'Turtle Rock Studios']</td>
      <td>Valve</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.186301</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Half-Life 2</td>
      <td>https://en.wikipedia.org/wiki/File:Half-Life_2_cover.jpg</td>
      <td>Valve</td>
      <td>['Valve']</td>
      <td>Marc Laidlaw</td>
      <td>Kelly Bailey</td>
      <td>Half-Life</td>
      <td>...</td>
      <td>Viktor Antonov</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.076712</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Diablo III</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_III_cover.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>Chris Metzen</td>
      <td>Russell Brower</td>
      <td>Diablo</td>
      <td>...</td>
      <td>Christian Lichtner</td>
      <td>Jay Wilson</td>
      <td>Alex Mayberry</td>
      <td>Jason Regier</td>
      <td>Blizzard</td>
      <td>10.578082</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Hearthstone: Heroes of Warcraft</td>
      <td>https://en.wikipedia.org/wiki/File:Hearthstone_2016_logo.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>Peter McConnell</td>
      <td>Warcraft</td>
      <td>...</td>
      <td>NaN</td>
      <td>['Ben Brode', 'Jason Chayes', 'Eric Dodds']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>8.756164</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Heroes of the Storm</td>
      <td>https://en.wikipedia.org/wiki/File:Heroes_of_the_Storm_BlizzHeroes_2017_logo.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>['Glenn Stafford', 'Jason Hayes']</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>['Dustin Browder', 'Alan Dabiri']</td>
      <td>Kaéo Milker</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>7.528767</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Overwatch</td>
      <td>https://en.wikipedia.org/wiki/File:Overwatch_cover_art.jpg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>['Michael Chu', 'Alyssa Wong']</td>
      <td>Derek Duke</td>
      <td>NaN</td>
      <td>...</td>
      <td>['William Petras', 'Arnold Tsang']</td>
      <td>['Jeff Kaplan', 'Chris Metzen', 'Aaron Keller']</td>
      <td>NaN</td>
      <td>['Mike Elliott', 'John LeFleur']</td>
      <td>Blizzard</td>
      <td>6.550685</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Diablo Immortal</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_Immortal_App_Logo.png</td>
      <td>['Blizzard Entertainment', 'NetEase']</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Diablo</td>
      <td>...</td>
      <td>NaN</td>
      <td>Wyatt Cheng</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>0.523288</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Overwatch 2</td>
      <td>https://en.wikipedia.org/wiki/File:Overwatch_2_logo.svg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>NaN</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Diablo IV</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_IV_logo.jpg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Diablo</td>
      <td>...</td>
      <td>John Mueller</td>
      <td>['Joe Shely', 'Luis Barriga']</td>
      <td>Tiffany Wat</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>NaN</td>
      <td>en.wikipedia.org</td>
    </tr>
  </tbody>
</table>
<p>49 rows × 23 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>SourceWebsite   
en.wikipedia.org    49
dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which series did Blizzard both develop and publish by itself?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def is_blizzard(name):
    if type(name) == list:
        for n in name:
            if 'blizzard' in n.lower():
                return True
    elif type(name) == str:
        if 'blizzard' in name.lower():
            return True
    return False

blizzard_df[
    blizzard_df.Publishers.apply(is_blizzard) & blizzard_df.Developers.apply(is_blizzard)].Series.dropna().unique()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def is_blizzard(name):
    if type(name) == list:
        for n in name:
            if 'blizzard' in n.lower():
                return True
    elif type(name) == str:
        if 'blizzard' in name.lower():
            return True
    return False

blizzard_df[
    blizzard_df.Publishers.apply(is_blizzard) & blizzard_df.Developers.apply(is_blizzard)].Series.dropna().unique()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def is_blizzard(name):
    if type(name) == list:
        for n in name:
            if 'blizzard' in n.lower():
                return True
    elif type(name) == str:
        if 'blizzard' in name.lower():
            return True
    return False


__output__ = blizzard_df[blizzard_df.Publishers.apply(is_blizzard) &
    blizzard_df.Developers.apply(is_blizzard)].Series.dropna().unique()
</code></pre>
        <p><span onclick="$('#var_output_c807b101').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c807b101" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>['Diablo' 'StarCraft' 'Warcraft']</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>['Diablo' 'StarCraft' 'Warcraft']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the values in the 'platform' column to list.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def convert_to_list(string):
    string = string.replace('[', '').replace(']', '').replace('\'', '')
    list_string = string.split(',')
    return string.split(',')

df.Platforms = df.Platforms.apply(convert_to_list)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def convert_to_list(string):
    string = string.replace('[', '').replace(']', '').replace('\'', '')
    list_string = string.split(',')
    return string.split(',')

df.Platforms = df.Platforms.apply(convert_to_list)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def convert_to_list(string):
    string = string.replace('[', '').replace(']', '').replace("'", '')
    list_string = string.split(',')
    return string.split(',')


__output__ = df.Platforms = df.Platforms.apply(convert_to_list)
</code></pre>
        <p><span onclick="$('#var_output_c8293042').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c8293042" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0              [Windows,  PlayStation 2,  OS X,  Linux]
1                    [Microsoft Windows,  OS X,  Linux]
2                       [Windows,  Xbox,  OS X,  Linux]
3                    [Microsoft Windows,  OS X,  Linux]
4                              [Windows,  OS X,  Linux]
                            ...                        
17                          [Microsoft Windows,  macOS]
18    [Microsoft Windows,  PlayStation 4,  Xbox One,...
19                            [Android,  iOS,  Windows]
20    [Microsoft Windows,  PlayStation 4,  Xbox One,...
21       [Microsoft Windows,  PlayStation 4,  Xbox One]
Name: Platforms, Length: 49, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Imagelink</th>
      <th>Developers</th>
      <th>Publishers</th>
      <th>Writers</th>
      <th>Composers</th>
      <th>Series</th>
      <th>...</th>
      <th>Artists</th>
      <th>Directors</th>
      <th>Producers</th>
      <th>Programmers</th>
      <th>CurrentOwner</th>
      <th>Age</th>
      <th>SourceWebsite</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Half-Life</td>
      <td>https://en.wikipedia.org/wiki/File:Half-Life_Cover_Art.jpg</td>
      <td>Valve</td>
      <td>Sierra Studios</td>
      <td>Marc Laidlaw</td>
      <td>Kelly Bailey</td>
      <td>Half-Life</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>24.073973</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Team Fortress Classic</td>
      <td>https://en.wikipedia.org/wiki/File:Team_Fortress_Classic_box.jpg</td>
      <td>Valve</td>
      <td>['Sierra Studios']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>23.693151</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Counter-Strike</td>
      <td>https://en.wikipedia.org/wiki/File:Counter-Strike_Box.jpg</td>
      <td>Valve</td>
      <td>['Sierra Studios']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>22.098630</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Day of Defeat</td>
      <td>https://en.wikipedia.org/wiki/File:Day_of_Defeat_cover_art.jpg</td>
      <td>Valve</td>
      <td>['Activision']</td>
      <td>NaN</td>
      <td>Michael Gordon Shapiro</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>19.610959</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Counter-Strike: Condition Zero</td>
      <td>https://en.wikipedia.org/wiki/File:CZbox.jpg</td>
      <td>['Ritual Entertainment', 'Turtle Rock Studios', 'Valve']</td>
      <td>['Sierra Entertainment']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.728767</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Counter-Strike: Source</td>
      <td>https://en.wikipedia.org/wiki/File:Counter-Strike_Source_(box_art).jpg</td>
      <td>['Valve', 'Turtle Rock Studios']</td>
      <td>Valve</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.186301</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Half-Life 2</td>
      <td>https://en.wikipedia.org/wiki/File:Half-Life_2_cover.jpg</td>
      <td>Valve</td>
      <td>['Valve']</td>
      <td>Marc Laidlaw</td>
      <td>Kelly Bailey</td>
      <td>Half-Life</td>
      <td>...</td>
      <td>Viktor Antonov</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.076712</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Diablo III</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_III_cover.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>Chris Metzen</td>
      <td>Russell Brower</td>
      <td>Diablo</td>
      <td>...</td>
      <td>Christian Lichtner</td>
      <td>Jay Wilson</td>
      <td>Alex Mayberry</td>
      <td>Jason Regier</td>
      <td>Blizzard</td>
      <td>10.578082</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Hearthstone: Heroes of Warcraft</td>
      <td>https://en.wikipedia.org/wiki/File:Hearthstone_2016_logo.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>Peter McConnell</td>
      <td>Warcraft</td>
      <td>...</td>
      <td>NaN</td>
      <td>['Ben Brode', 'Jason Chayes', 'Eric Dodds']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>8.756164</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Heroes of the Storm</td>
      <td>https://en.wikipedia.org/wiki/File:Heroes_of_the_Storm_BlizzHeroes_2017_logo.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>['Glenn Stafford', 'Jason Hayes']</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>['Dustin Browder', 'Alan Dabiri']</td>
      <td>Kaéo Milker</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>7.528767</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Overwatch</td>
      <td>https://en.wikipedia.org/wiki/File:Overwatch_cover_art.jpg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>['Michael Chu', 'Alyssa Wong']</td>
      <td>Derek Duke</td>
      <td>NaN</td>
      <td>...</td>
      <td>['William Petras', 'Arnold Tsang']</td>
      <td>['Jeff Kaplan', 'Chris Metzen', 'Aaron Keller']</td>
      <td>NaN</td>
      <td>['Mike Elliott', 'John LeFleur']</td>
      <td>Blizzard</td>
      <td>6.550685</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Diablo Immortal</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_Immortal_App_Logo.png</td>
      <td>['Blizzard Entertainment', 'NetEase']</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Diablo</td>
      <td>...</td>
      <td>NaN</td>
      <td>Wyatt Cheng</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>0.523288</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Overwatch 2</td>
      <td>https://en.wikipedia.org/wiki/File:Overwatch_2_logo.svg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>NaN</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Diablo IV</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_IV_logo.jpg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Diablo</td>
      <td>...</td>
      <td>John Mueller</td>
      <td>['Joe Shely', 'Luis Barriga']</td>
      <td>Tiffany Wat</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>NaN</td>
      <td>en.wikipedia.org</td>
    </tr>
  </tbody>
</table>
<p>49 rows × 23 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0              [Windows,  PlayStation 2,  OS X,  Linux]
1                    [Microsoft Windows,  OS X,  Linux]
2                       [Windows,  Xbox,  OS X,  Linux]
3                    [Microsoft Windows,  OS X,  Linux]
4                              [Windows,  OS X,  Linux]
                            ...                        
17                          [Microsoft Windows,  macOS]
18    [Microsoft Windows,  PlayStation 4,  Xbox One,...
19                            [Android,  iOS,  Windows]
20    [Microsoft Windows,  PlayStation 4,  Xbox One,...
21       [Microsoft Windows,  PlayStation 4,  Xbox One]
Name: Platforms, Length: 49, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Make the platform names upper case and rename any variations of 'MAC OS X', 'MAC OS' and 'WINDOWS' to 'MAC OS X', 'MAC OS' and 'WINDOWS' respectively.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def normalize_platform_names(name):
    name = name.strip().upper()
    if 'OS X' in name:
        return 'MAC OS X'
    elif 'MACOS' in name:
        return 'MAC OS'
    elif 'MICROSOFT' in name:
        return 'WINDOWS'
    return name

df.Platforms = df.Platforms.apply(lambda platforms: [normalize_platform_names(platform) for platform in platforms])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def normalize_platform_names(name):
    name = name.strip().upper()
    if 'OS X' in name:
        return 'MAC OS X'
    elif 'MACOS' in name:
        return 'MAC OS'
    elif 'MICROSOFT' in name:
        return 'WINDOWS'
    return name

df.Platforms = df.Platforms.apply(lambda platforms: [normalize_platform_names(platform) for platform in platforms])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def normalize_platform_names(name):
    name = name.strip().upper()
    if 'OS X' in name:
        return 'MAC OS X'
    elif 'MACOS' in name:
        return 'MAC OS'
    elif 'MICROSOFT' in name:
        return 'WINDOWS'
    return name


__output__ = df.Platforms = df.Platforms.apply(lambda platforms: [
    normalize_platform_names(platform) for platform in platforms])
</code></pre>
        <p><span onclick="$('#var_output_09fc1eb0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_09fc1eb0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0             [WINDOWS, PLAYSTATION 2, MAC OS X, LINUX]
1                            [WINDOWS, MAC OS X, LINUX]
2                      [WINDOWS, XBOX, MAC OS X, LINUX]
3                            [WINDOWS, MAC OS X, LINUX]
4                            [WINDOWS, MAC OS X, LINUX]
                            ...                        
17                                    [WINDOWS, MAC OS]
18    [WINDOWS, PLAYSTATION 4, XBOX ONE, NINTENDO SW...
19                              [ANDROID, IOS, WINDOWS]
20    [WINDOWS, PLAYSTATION 4, XBOX ONE, NINTENDO SW...
21                   [WINDOWS, PLAYSTATION 4, XBOX ONE]
Name: Platforms, Length: 49, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Imagelink</th>
      <th>Developers</th>
      <th>Publishers</th>
      <th>Writers</th>
      <th>Composers</th>
      <th>Series</th>
      <th>...</th>
      <th>Artists</th>
      <th>Directors</th>
      <th>Producers</th>
      <th>Programmers</th>
      <th>CurrentOwner</th>
      <th>Age</th>
      <th>SourceWebsite</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Half-Life</td>
      <td>https://en.wikipedia.org/wiki/File:Half-Life_Cover_Art.jpg</td>
      <td>Valve</td>
      <td>Sierra Studios</td>
      <td>Marc Laidlaw</td>
      <td>Kelly Bailey</td>
      <td>Half-Life</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>24.073973</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Team Fortress Classic</td>
      <td>https://en.wikipedia.org/wiki/File:Team_Fortress_Classic_box.jpg</td>
      <td>Valve</td>
      <td>['Sierra Studios']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>23.693151</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Counter-Strike</td>
      <td>https://en.wikipedia.org/wiki/File:Counter-Strike_Box.jpg</td>
      <td>Valve</td>
      <td>['Sierra Studios']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>22.098630</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Day of Defeat</td>
      <td>https://en.wikipedia.org/wiki/File:Day_of_Defeat_cover_art.jpg</td>
      <td>Valve</td>
      <td>['Activision']</td>
      <td>NaN</td>
      <td>Michael Gordon Shapiro</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>19.610959</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Counter-Strike: Condition Zero</td>
      <td>https://en.wikipedia.org/wiki/File:CZbox.jpg</td>
      <td>['Ritual Entertainment', 'Turtle Rock Studios', 'Valve']</td>
      <td>['Sierra Entertainment']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.728767</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Counter-Strike: Source</td>
      <td>https://en.wikipedia.org/wiki/File:Counter-Strike_Source_(box_art).jpg</td>
      <td>['Valve', 'Turtle Rock Studios']</td>
      <td>Valve</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Counter-Strike</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.186301</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Half-Life 2</td>
      <td>https://en.wikipedia.org/wiki/File:Half-Life_2_cover.jpg</td>
      <td>Valve</td>
      <td>['Valve']</td>
      <td>Marc Laidlaw</td>
      <td>Kelly Bailey</td>
      <td>Half-Life</td>
      <td>...</td>
      <td>Viktor Antonov</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Valve</td>
      <td>18.076712</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Diablo III</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_III_cover.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>Chris Metzen</td>
      <td>Russell Brower</td>
      <td>Diablo</td>
      <td>...</td>
      <td>Christian Lichtner</td>
      <td>Jay Wilson</td>
      <td>Alex Mayberry</td>
      <td>Jason Regier</td>
      <td>Blizzard</td>
      <td>10.578082</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Hearthstone: Heroes of Warcraft</td>
      <td>https://en.wikipedia.org/wiki/File:Hearthstone_2016_logo.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>Peter McConnell</td>
      <td>Warcraft</td>
      <td>...</td>
      <td>NaN</td>
      <td>['Ben Brode', 'Jason Chayes', 'Eric Dodds']</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>8.756164</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Heroes of the Storm</td>
      <td>https://en.wikipedia.org/wiki/File:Heroes_of_the_Storm_BlizzHeroes_2017_logo.png</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>['Glenn Stafford', 'Jason Hayes']</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>['Dustin Browder', 'Alan Dabiri']</td>
      <td>Kaéo Milker</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>7.528767</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Overwatch</td>
      <td>https://en.wikipedia.org/wiki/File:Overwatch_cover_art.jpg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>['Michael Chu', 'Alyssa Wong']</td>
      <td>Derek Duke</td>
      <td>NaN</td>
      <td>...</td>
      <td>['William Petras', 'Arnold Tsang']</td>
      <td>['Jeff Kaplan', 'Chris Metzen', 'Aaron Keller']</td>
      <td>NaN</td>
      <td>['Mike Elliott', 'John LeFleur']</td>
      <td>Blizzard</td>
      <td>6.550685</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Diablo Immortal</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_Immortal_App_Logo.png</td>
      <td>['Blizzard Entertainment', 'NetEase']</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Diablo</td>
      <td>...</td>
      <td>NaN</td>
      <td>Wyatt Cheng</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>0.523288</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Overwatch 2</td>
      <td>https://en.wikipedia.org/wiki/File:Overwatch_2_logo.svg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>NaN</td>
      <td>en.wikipedia.org</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Diablo IV</td>
      <td>https://en.wikipedia.org/wiki/File:Diablo_IV_logo.jpg</td>
      <td>Blizzard Entertainment</td>
      <td>Blizzard Entertainment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Diablo</td>
      <td>...</td>
      <td>John Mueller</td>
      <td>['Joe Shely', 'Luis Barriga']</td>
      <td>Tiffany Wat</td>
      <td>NaN</td>
      <td>Blizzard</td>
      <td>NaN</td>
      <td>en.wikipedia.org</td>
    </tr>
  </tbody>
</table>
<p>49 rows × 23 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0             [WINDOWS, PLAYSTATION 2, MAC OS X, LINUX]
1                            [WINDOWS, MAC OS X, LINUX]
2                      [WINDOWS, XBOX, MAC OS X, LINUX]
3                            [WINDOWS, MAC OS X, LINUX]
4                            [WINDOWS, MAC OS X, LINUX]
                            ...                        
17                                    [WINDOWS, MAC OS]
18    [WINDOWS, PLAYSTATION 4, XBOX ONE, NINTENDO SW...
19                              [ANDROID, IOS, WINDOWS]
20    [WINDOWS, PLAYSTATION 4, XBOX ONE, NINTENDO SW...
21                   [WINDOWS, PLAYSTATION 4, XBOX ONE]
Name: Platforms, Length: 49, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many games are supported by each platform?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_platforms = df[['Name', 'Platforms']]
df_platforms.Platforms.explode().value_counts()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_platforms = df[['Name', 'Platforms']]
df_platforms.Platforms.explode().value_counts()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_platforms = df[['Name', 'Platforms']]
__output__ = df_platforms.Platforms.explode().value_counts()
</code></pre>
        <p><span onclick="$('#var_output_1f0717f8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1f0717f8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>WINDOWS               46
LINUX                 24
MAC OS X              22
XBOX 360              11
PLAYSTATION 3          9
                      ..
MEGA DRIVE/GENESIS     1
SEGA 32X               1
SNES                   1
SEGA GENESIS           1
NINTENDO 64            1
Name: Platforms, Length: 29, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_platforms, __output__ </p>
    
          <p>df_platforms (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Platforms</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Half-Life</td>
      <td>[WINDOWS, PLAYSTATION 2, MAC OS X, LINUX]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Team Fortress Classic</td>
      <td>[WINDOWS, MAC OS X, LINUX]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Counter-Strike</td>
      <td>[WINDOWS, XBOX, MAC OS X, LINUX]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Day of Defeat</td>
      <td>[WINDOWS, MAC OS X, LINUX]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Counter-Strike: Condition Zero</td>
      <td>[WINDOWS, MAC OS X, LINUX]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Counter-Strike: Source</td>
      <td>[WINDOWS, MAC OS X, LINUX]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Half-Life 2</td>
      <td>[WINDOWS, XBOX, XBOX 360, PLAYSTATION 3, MAC OS X, LINUX, ANDROID]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Diablo III</td>
      <td>[WINDOWS, MAC OS X, PLAYSTATION 3, XBOX 360, PLAYSTATION 4, XBOX ONE, NINTENDO SWITCH]</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Hearthstone: Heroes of Warcraft</td>
      <td>[WINDOWS, MAC OS, IOS, ANDROID]</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Heroes of the Storm</td>
      <td>[WINDOWS, MAC OS]</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Overwatch</td>
      <td>[WINDOWS, PLAYSTATION 4, XBOX ONE, NINTENDO SWITCH]</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Diablo Immortal</td>
      <td>[ANDROID, IOS, WINDOWS]</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Overwatch 2</td>
      <td>[WINDOWS, PLAYSTATION 4, XBOX ONE, NINTENDO SWITCH]</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Diablo IV</td>
      <td>[WINDOWS, PLAYSTATION 4, XBOX ONE]</td>
    </tr>
  </tbody>
</table>
<p>49 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>WINDOWS               46
LINUX                 24
MAC OS X              22
XBOX 360              11
PLAYSTATION 3          9
                      ..
MEGA DRIVE/GENESIS     1
SEGA 32X               1
SNES                   1
SEGA GENESIS           1
NINTENDO 64            1
Name: Platforms, Length: 29, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the number of games released by quarter?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_releases = df[['Name', 'Release']].dropna()
df_releases['Quarter'] = df_releases.Release.apply(lambda datestring: datetime.strptime(datestring, "%B %d, %Y")
                                                   .month // 3 + 1)
df_releases.Quarter.value_counts()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_releases = df[['Name', 'Release']].dropna()
df_releases['Quarter'] = df_releases.Release.apply(lambda datestring: datetime.strptime(datestring, "%B %d, %Y")
                                                   .month // 3 + 1)
df_releases.Quarter.value_counts()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_releases = df[['Name', 'Release']].dropna()
df_releases['Quarter'] = df_releases.Release.apply(lambda datestring: 
    datetime.strptime(datestring, '%B %d, %Y').month // 3 + 1)
__output__ = df_releases.Quarter.value_counts()
</code></pre>
        <p><span onclick="$('#var_output_0536f779').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0536f779" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>4    18
2    13
3    10
1     4
5     1
Name: Quarter, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_releases, __output__ </p>
    
          <p>df_releases (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Release</th>
      <th>Quarter</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Half-Life</td>
      <td>November 19, 1998</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Team Fortress Classic</td>
      <td>April 07, 1999</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Counter-Strike</td>
      <td>November 09, 2000</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Day of Defeat</td>
      <td>May 06, 2003</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Counter-Strike: Condition Zero</td>
      <td>March 23, 2004</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Counter-Strike: Source</td>
      <td>October 07, 2004</td>
      <td>4</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Half-Life 2</td>
      <td>November 16, 2004</td>
      <td>4</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>13</th>
      <td>World of Warcraft</td>
      <td>November 23, 2004</td>
      <td>4</td>
    </tr>
    <tr>
      <th>14</th>
      <td>StarCraft II: Wings of Liberty</td>
      <td>July 27, 2010</td>
      <td>3</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Diablo III</td>
      <td>May 15, 2012</td>
      <td>2</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Hearthstone: Heroes of Warcraft</td>
      <td>March 11, 2014</td>
      <td>2</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Heroes of the Storm</td>
      <td>June 02, 2015</td>
      <td>3</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Overwatch</td>
      <td>May 24, 2016</td>
      <td>2</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Diablo Immortal</td>
      <td>June 02, 2022</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>46 rows × 3 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>4    18
2    13
3    10
1     4
5     1
Name: Quarter, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 3 most popular genre based on average user ratings?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_genre = df[['Genres', 'UserScore']].dropna()
df_genre['Genres'] = df_genre.Genres.apply(convert_to_list)
df_genre.explode('Genres').groupby('Genres').mean().sort_values(by='UserScore', ascending=False).head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_genre = df[['Genres', 'UserScore']].dropna()
df_genre['Genres'] = df_genre.Genres.apply(convert_to_list)
df_genre.explode('Genres').groupby('Genres').mean().sort_values(by='UserScore', ascending=False).head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_genre = df[['Genres', 'UserScore']].dropna()
df_genre['Genres'] = df_genre.Genres.apply(convert_to_list)
__output__ = df_genre.explode('Genres').groupby('Genres').mean().sort_values(by
    ='UserScore', ascending=False).head(3)
</code></pre>
        <p><span onclick="$('#var_output_9f12a61b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9f12a61b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>UserScore</th>
    </tr>
    <tr>
      <th>Genres</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Puzzle-platform</th>
      <td>9.15</td>
    </tr>
    <tr>
      <th>Various</th>
      <td>9.10</td>
    </tr>
    <tr>
      <th>Sandbox</th>
      <td>8.90</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_genre, __output__ </p>
    
          <p>df_genre (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Genres</th>
      <th>UserScore</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[First-person shooter]</td>
      <td>9.1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[First-person shooter]</td>
      <td>7.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[First-person shooter]</td>
      <td>9.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[First-person shooter]</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[First-person shooter]</td>
      <td>8.7</td>
    </tr>
    <tr>
      <th>5</th>
      <td>[First-person shooter]</td>
      <td>8.9</td>
    </tr>
    <tr>
      <th>6</th>
      <td>[First-person shooter]</td>
      <td>9.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>12</th>
      <td>[Real-time strategy]</td>
      <td>9.2</td>
    </tr>
    <tr>
      <th>13</th>
      <td>[Massively multiplayer online role-playing]</td>
      <td>7.4</td>
    </tr>
    <tr>
      <th>14</th>
      <td>[Real-time strategy]</td>
      <td>8.3</td>
    </tr>
    <tr>
      <th>15</th>
      <td>[Action role-playing,  hack and slash]</td>
      <td>4.1</td>
    </tr>
    <tr>
      <th>16</th>
      <td>[Digital collectible card game]</td>
      <td>5.7</td>
    </tr>
    <tr>
      <th>17</th>
      <td>[MOBA]</td>
      <td>6.3</td>
    </tr>
    <tr>
      <th>18</th>
      <td>[First-person shooter]</td>
      <td>6.4</td>
    </tr>
  </tbody>
</table>
<p>38 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>UserScore</th>
    </tr>
    <tr>
      <th>Genres</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Puzzle-platform</th>
      <td>9.15</td>
    </tr>
    <tr>
      <th>Various</th>
      <td>9.10</td>
    </tr>
    <tr>
      <th>Sandbox</th>
      <td>8.90</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What series has the most games?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Name', 'Series']].groupby('Series').count().Name.sort_values(ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Name', 'Series']].groupby('Series').count().Name.sort_values(ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Name', 'Series']].groupby('Series').count().Name.sort_values(
    ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_4ac2ef47').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4ac2ef47" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Series
Half-Life         7
Diablo            5
Warcraft          5
Counter-Strike    4
Portal            4
Dota              3
Left 4 Dead       2
StarCraft         2
Name: Name, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Series
Half-Life         7
Diablo            5
Warcraft          5
Counter-Strike    4
Portal            4
Dota              3
Left 4 Dead       2
StarCraft         2
Name: Name, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which designer has been involved in the most games?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_des = df[['Name', 'Designers']].dropna()
df_des['Designers'] = df_des.Designers.apply(convert_to_list)
df_des.explode('Designers').groupby('Designers').count().sort_values('Name', ascending=False).iloc[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_des = df[['Name', 'Designers']].dropna()
df_des['Designers'] = df_des.Designers.apply(convert_to_list)
df_des.explode('Designers').groupby('Designers').count().sort_values('Name', ascending=False).iloc[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_des = df[['Name', 'Designers']].dropna()
df_des['Designers'] = df_des.Designers.apply(convert_to_list)
__output__ = df_des.explode('Designers').groupby('Designers').count(
    ).sort_values('Name', ascending=False).iloc[0]
</code></pre>
        <p><span onclick="$('#var_output_3f06cf9b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_3f06cf9b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Name    3
Name: Ron Millar, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_des, __output__ </p>
    
          <p>df_des (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Designers</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Team Fortress Classic</td>
      <td>[John Cook,  Robin Walker]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Counter-Strike</td>
      <td>[Minh Le,  Jess Cliffe]</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Portal</td>
      <td>[Kim Swift]</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Team Fortress 2</td>
      <td>[John Cook,  Robin Walker]</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Left 4 Dead</td>
      <td>[Mike Booth]</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Left 4 Dead 2</td>
      <td>[Michael Booth]</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Dota 2</td>
      <td>[IceFrog]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Warcraft III: Reign of Chaos</td>
      <td>[Rob Pardo]</td>
    </tr>
    <tr>
      <th>13</th>
      <td>World of Warcraft</td>
      <td>[Rob Pardo,  Jeff Kaplan,  Tom Chilton]</td>
    </tr>
    <tr>
      <th>14</th>
      <td>StarCraft II: Wings of Liberty</td>
      <td>[Dustin Browder]</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Diablo III</td>
      <td>[Kevin Martens,  David M. Adams]</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Hearthstone: Heroes of Warcraft</td>
      <td>[Derek Sakamoto,  Mike Donais]</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Overwatch</td>
      <td>[Jeremy Craig,  Michael Elliott,  Scott Mercer]</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Diablo IV</td>
      <td>[Joe Piepiora]</td>
    </tr>
  </tbody>
</table>
<p>25 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Name    3
Name: Ron Millar, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> valve-blizzard-games-dataset/notebook_1.ipynb|||turn_11 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 3 game engines since 2000?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def filter_date(date_string):
    if type(date_string) is not str:
        return False
    return datetime.strptime(date_string, "%B %d, %Y").year > 2000

df_engines = df[df.Release.apply(filter_date)][['Name', 'Engine']]
df_engines.groupby('Engine').count().Name.sort_values(ascending=False).head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def filter_date(date_string):
    if type(date_string) is not str:
        return False
    return datetime.strptime(date_string, "%B %d, %Y").year > 2000

df_engines = df[df.Release.apply(filter_date)][['Name', 'Engine']]
df_engines.groupby('Engine').count().Name.sort_values(ascending=False).head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def filter_date(date_string):
    if type(date_string) is not str:
        return False
    return datetime.strptime(date_string, '%B %d, %Y').year > 2000


df_engines = df[df.Release.apply(filter_date)][['Name', 'Engine']]
__output__ = df_engines.groupby('Engine').count().Name.sort_values(ascending
    =False).head(3)
</code></pre>
        <p><span onclick="$('#var_output_07d8e3e6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_07d8e3e6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Engine
Source      16
Source 2     5
GoldSrc      2
Name: Name, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_engines, __output__ </p>
    
          <p>df_engines (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Engine</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>Day of Defeat</td>
      <td>GoldSrc</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Counter-Strike: Condition Zero</td>
      <td>GoldSrc</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Counter-Strike: Source</td>
      <td>Source</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Half-Life 2</td>
      <td>Source</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Half-Life 2: Deathmatch</td>
      <td>Source</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Day of Defeat: Source</td>
      <td>Source</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Half-Life 2: Lost Coast</td>
      <td>Source</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>13</th>
      <td>World of Warcraft</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>14</th>
      <td>StarCraft II: Wings of Liberty</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Diablo III</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Hearthstone: Heroes of Warcraft</td>
      <td>Unity</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Heroes of the Storm</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Overwatch</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Diablo Immortal</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>33 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>Engine
Source      16
Source 2     5
GoldSrc      2
Name: Name, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> all-cities-and-towns-extract-from-osm/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Make a new column called 'address_dict' that contains the key value pairs in address as dictionary.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def breakdown_tags(x):
    if type(x) is not str:
        return None
    x = x.split('",')
    x = [i.strip().replace('"', '').split('=>') for i in x]
    for i in x:
        if len(i) != 2:
            x.remove(i)
    x = {i[0]: i[1] for i in x}
    return x

df['address_dict'] = df.address.apply(breakdown_tags).dropna()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def breakdown_tags(x):
    if type(x) is not str:
        return None
    x = x.split('",')
    x = [i.strip().replace('"', '').split('=>') for i in x]
    for i in x:
        if len(i) != 2:
            x.remove(i)
    x = {i[0]: i[1] for i in x}
    return x

df['address_dict'] = df.address.apply(breakdown_tags).dropna()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def breakdown_tags(x):
    if type(x) is not str:
        return None
    x = x.split('",')
    x = [i.strip().replace('"', '').split('=>') for i in x]
    for i in x:
        if len(i) != 2:
            x.remove(i)
    x = {i[0]: i[1] for i in x}
    return x


__output__ = df['address_dict'] = df.address.apply(breakdown_tags).dropna()
</code></pre>
        <p><span onclick="$('#var_output_5444e9cf').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5444e9cf" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0         {'country': 'US', 'continent': 'North America'...
5                                     {'province': 'Leyte'}
8                                   {'province': 'Antique'}
9                                      {'postcode': '4109'}
10                                  {'province': 'Romblon'}
                                ...                        
125674                                {'postcode': '00627'}
125677                                {'postcode': '00771'}
125684                                {'province': 'Aklan'}
125685                                {'province': 'Samar'}
125691                                {'postcode': '00707'}
Name: address, Length: 25671, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_code</th>
      <th>latitude</th>
      <th>longitude</th>
      <th>name</th>
      <th>place_id</th>
      <th>parent_place_id</th>
      <th>linked_place_id</th>
      <th>...</th>
      <th>extratags</th>
      <th>area</th>
      <th>wikipedia</th>
      <th>token_info</th>
      <th>housenumber</th>
      <th>postcode</th>
      <th>address_dict</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>us</td>
      <td>-134.419734</td>
      <td>58.301950</td>
      <td>"name"=&gt;"Juneau", "name:en"=&gt;"Juneau", "name:fa"=&gt;"جونو", "name:lt"=&gt;"Džunas", "name:pl"=&gt;"Juneau", "name:ru"=&gt;"Джуно", "name:ta"=&gt;"ஜூனோ", "name:uk"=&gt;"Джуно", "name:zh"=&gt;"朱诺 / 朱諾", "name:hak"=&gt;"Juneau", "name:nan"=&gt;"Juneau", "name:tli"=&gt;"Dzánti K'ihéeni", "name:zh-Hans"=&gt;"朱诺", "name:zh-Hant"=&gt;"朱諾"</td>
      <td>312456</td>
      <td>NaN</td>
      <td>297182206.0</td>
      <td>...</td>
      <td>"ele"=&gt;"17", "capital"=&gt;"4", "wikidata"=&gt;"Q29445", "wikipedia"=&gt;"en:Juneau, Alaska", "population"=&gt;"31000", "import_uuid"=&gt;"bb7269ee-502a-5391-8056-e3ce0e66489c", "state_capital"=&gt;"yes"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>{'country': 'US', 'continent': 'North America', 'iso_3166_2': 'US-AK'}</td>
    </tr>
    <tr>
      <th>1</th>
      <td>us</td>
      <td>-77.306373</td>
      <td>38.846224</td>
      <td>"name"=&gt;"Fairfax", "name:en"=&gt;"Fairfax"</td>
      <td>430494</td>
      <td>NaN</td>
      <td>298755178.0</td>
      <td>...</td>
      <td>"ele"=&gt;"131", "wikidata"=&gt;"Q501785", "population"=&gt;"24146", "population:date"=&gt;"2006"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>us</td>
      <td>-65.901022</td>
      <td>18.379193</td>
      <td>"name"=&gt;"Canóvanas"</td>
      <td>18375032</td>
      <td>NaN</td>
      <td>298262463.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q2361552", "wikipedia"=&gt;"en:Canóvanas, Puerto Rico"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>us</td>
      <td>144.836572</td>
      <td>13.510013</td>
      <td>"name"=&gt;"Dededo", "name:ch"=&gt;"Dedidu", "name:en"=&gt;"Dededo", "name:ja"=&gt;"デデド"</td>
      <td>5299331</td>
      <td>NaN</td>
      <td>299003598.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q1182147", "wikipedia"=&gt;"en:Dededo, Guam", "population"=&gt;"45000"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>us</td>
      <td>-76.610759</td>
      <td>39.290882</td>
      <td>"name"=&gt;"Baltimore", "name:ar"=&gt;"بالتيمور", "name:az"=&gt;"Baltimor", "name:be"=&gt;"Балтымар", "name:de"=&gt;"Baltimore", "name:en"=&gt;"Baltimore", "name:fr"=&gt;"Baltimore", "name:hi"=&gt;"बाल्टीमोर", "name:ja"=&gt;"ボルチモア", "name:lt"=&gt;"Baltimorė", "name:lv"=&gt;"Baltimora", "name:oc"=&gt;"Baltimore", "name:ru"=&gt;"Балтимор"</td>
      <td>298060487</td>
      <td>NaN</td>
      <td>297180865.0</td>
      <td>...</td>
      <td>"website"=&gt;"https://www.baltimorecity.gov/", "wikidata"=&gt;"Q5092", "wikipedia"=&gt;"en:Baltimore", "population"=&gt;"585708"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ph</td>
      <td>124.964373</td>
      <td>10.605272</td>
      <td>"name"=&gt;"Mahaplag"</td>
      <td>30127710</td>
      <td>NaN</td>
      <td>298692525.0</td>
      <td>...</td>
      <td>"place:PH"=&gt;"municipality", "population"=&gt;"27823", "population:date"=&gt;"2015-08-01", "gns_classification"=&gt;"ADM2"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>{'province': 'Leyte'}</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ph</td>
      <td>124.841531</td>
      <td>11.639055</td>
      <td>"ref"=&gt;"086023000", "name"=&gt;"Zumarraga"</td>
      <td>67432689</td>
      <td>NaN</td>
      <td>296109575.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q229664", "wikipedia"=&gt;"en:Zumarraga, Samar", "population"=&gt;"16295", "designation"=&gt;"municipality", "population:date"=&gt;"2015-08-01"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>125687</th>
      <td>us</td>
      <td>-76.922461</td>
      <td>36.677651</td>
      <td>"name"=&gt;"Franklin"</td>
      <td>429703</td>
      <td>NaN</td>
      <td>297724311.0</td>
      <td>...</td>
      <td>"ele"=&gt;"5", "wikidata"=&gt;"Q350001", "wikipedia"=&gt;"en:Franklin, Virginia", "population"=&gt;"8800", "import_uuid"=&gt;"bb7269ee-502a-5391-8056-e3ce0e66489c", "population:date"=&gt;"2006"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>125688</th>
      <td>us</td>
      <td>-76.345206</td>
      <td>37.030097</td>
      <td>"name"=&gt;"Hampton", "name:en"=&gt;"Hampton"</td>
      <td>444014</td>
      <td>NaN</td>
      <td>297193239.0</td>
      <td>...</td>
      <td>"ele"=&gt;"1", "wikidata"=&gt;"Q342043", "population"=&gt;"137436", "population:date"=&gt;"2010"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>125689</th>
      <td>us</td>
      <td>-105.052080</td>
      <td>39.940399</td>
      <td>"name"=&gt;"Broomfield", "name:en"=&gt;"Broomfield", "name:es"=&gt;"Broomfield", "official_name"=&gt;"City and County of Broomfield", "official_name:es"=&gt;"Ciudad y Condado de Broomfield"</td>
      <td>357888</td>
      <td>NaN</td>
      <td>298150161.0</td>
      <td>...</td>
      <td>"ele"=&gt;"1644", "wikidata"=&gt;"Q492819", "wikipedia"=&gt;"en:Broomfield, Colorado", "population"=&gt;"74112", "import_uuid"=&gt;"bb7269ee-502a-5391-8056-e3ce0e66489c", "population:date"=&gt;"2020"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>125690</th>
      <td>us</td>
      <td>-65.735321</td>
      <td>18.212082</td>
      <td>"name"=&gt;"Naguabo"</td>
      <td>72637889</td>
      <td>NaN</td>
      <td>298261170.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q2659720", "wikipedia"=&gt;"en:Naguabo, Puerto Rico"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>125691</th>
      <td>us</td>
      <td>-65.899548</td>
      <td>18.007344</td>
      <td>"name"=&gt;"Maunabo"</td>
      <td>18324682</td>
      <td>NaN</td>
      <td>298261464.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q967149", "wikipedia"=&gt;"en:Maunabo, Puerto Rico"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>{'postcode': '00707'}</td>
    </tr>
    <tr>
      <th>125692</th>
      <td>us</td>
      <td>-66.539884</td>
      <td>18.452893</td>
      <td>"name"=&gt;"Barceloneta"</td>
      <td>18632745</td>
      <td>NaN</td>
      <td>298261732.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q2025087", "wikipedia"=&gt;"es:Barceloneta (Puerto Rico)"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>125693</th>
      <td>us</td>
      <td>-66.979804</td>
      <td>18.180679</td>
      <td>"name"=&gt;"Maricao"</td>
      <td>18395106</td>
      <td>NaN</td>
      <td>298261565.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q2624359", "wikipedia"=&gt;"en:Maricao, Puerto Rico"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>125694 rows × 24 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0         {'country': 'US', 'continent': 'North America'...
5                                     {'province': 'Leyte'}
8                                   {'province': 'Antique'}
9                                      {'postcode': '4109'}
10                                  {'province': 'Romblon'}
                                ...                        
125674                                {'postcode': '00627'}
125677                                {'postcode': '00771'}
125684                                {'province': 'Aklan'}
125685                                {'province': 'Samar'}
125691                                {'postcode': '00707'}
Name: address, Length: 25671, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> all-cities-and-towns-extract-from-osm/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the unique address tags present in this dataset?. Arrange alphabetically.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.address_dict.dropna().apply(lambda x: list(x.keys())).explode().sort_values().unique()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.address_dict.dropna().apply(lambda x: list(x.keys())).explode().sort_values().unique()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.address_dict.dropna().apply(lambda x: list(x.keys())).explode(
    ).sort_values().unique()
</code></pre>
        <p><span onclick="$('#var_output_02fa1613').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_02fa1613" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>['LGA' 'archipelago' 'arrondissement' 'ba' 'block' 'block:ta' 'canton'
 'chiefdom' 'city' 'city:ar' 'city:en' 'city:ks' 'city:pnb' 'city:ps'
 'city:sd' 'city:simc' 'city:ur' 'clan' 'collectivité' 'comuna'
 'constituency' 'contey' 'continent' 'conurbation' 'country' 'country_1'
 'county' 'de' 'departement' 'department' 'district' 'district:be'
 'district:bn' 'district:ru' 'district:ta' 'district:uk' 'division' 'en'
 'fi' 'governorate' 'grid' 'groupement' 'hamlet' 'health_level6'
 'health_level8' 'historic_county' 'housenumber' 'island' 'island:ja'
 'island:ja_rm' 'iso_3166_2' 'ja' 'municipality' 'municipality:ta'
 'município' 'nation' 'national_park' 'ocean' 'okato' 'parish' 'peninsula'
 'place' 'postbox' 'postcode' 'postcode_1' 'prefecture' 'preserved_county'
 'province' 'province_code' 'província' 'regency' 'region' 'region:be'
 'region:ru' 'region:uk' 'region_code' 'rural_municipality' 'sea'
 'section' 'state' 'state_code' 'street' 'subcounty' 'subdistrict'
 'subdistrict:ta' 'suburb' 'sv' 'taluk' 'territoire' 'territory' 'town'
 'township' 'union_territory' 'union_territorytate' 'urbanization'
 'valley' 'vdc' 'village' 'village:ta' 'ward' 'zh' 'zone']</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>['LGA' 'archipelago' 'arrondissement' 'ba' 'block' 'block:ta' 'canton'
 'chiefdom' 'city' 'city:ar' 'city:en' 'city:ks' 'city:pnb' 'city:ps'
 'city:sd' 'city:simc' 'city:ur' 'clan' 'collectivité' 'comuna'
 'constituency' 'contey' 'continent' 'conurbation' 'country' 'country_1'
 'county' 'de' 'departement' 'department' 'district' 'district:be'
 'district:bn' 'district:ru' 'district:ta' 'district:uk' 'division' 'en'
 'fi' 'governorate' 'grid' 'groupement' 'hamlet' 'health_level6'
 'health_level8' 'historic_county' 'housenumber' 'island' 'island:ja'
 'island:ja_rm' 'iso_3166_2' 'ja' 'municipality' 'municipality:ta'
 'município' 'nation' 'national_park' 'ocean' 'okato' 'parish' 'peninsula'
 'place' 'postbox' 'postcode' 'postcode_1' 'prefecture' 'preserved_county'
 'province' 'province_code' 'província' 'regency' 'region' 'region:be'
 'region:ru' 'region:uk' 'region_code' 'rural_municipality' 'sea'
 'section' 'state' 'state_code' 'street' 'subcounty' 'subdistrict'
 'subdistrict:ta' 'suburb' 'sv' 'taluk' 'territoire' 'territory' 'town'
 'township' 'union_territory' 'union_territorytate' 'urbanization'
 'valley' 'vdc' 'village' 'village:ta' 'ward' 'zh' 'zone']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> all-cities-and-towns-extract-from-osm/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Infer and replace missing postcodes from address.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def fill_postcode(x):
    if type(x.postcode) is str:
        return x.postcode
    if type(x.address_dict) is dict and 'postcode' in x.address_dict.keys():
        return x.address_dict['postcode']
    return None

df.postcode = df.apply(fill_postcode, 1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def fill_postcode(x):
    if type(x.postcode) is str:
        return x.postcode
    if type(x.address_dict) is dict and 'postcode' in x.address_dict.keys():
        return x.address_dict['postcode']
    return None

df.postcode = df.apply(fill_postcode, 1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def fill_postcode(x):
    if type(x.postcode) is str:
        return x.postcode
    if type(x.address_dict) is dict and 'postcode' in x.address_dict.keys():
        return x.address_dict['postcode']
    return None


__output__ = df.postcode = df.apply(fill_postcode, 1)
</code></pre>
        <p><span onclick="$('#var_output_6450e238').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6450e238" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0          None
1          None
2          None
3          None
4          None
          ...  
125689     None
125690     None
125691    00707
125692     None
125693     None
Length: 125694, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_code</th>
      <th>latitude</th>
      <th>longitude</th>
      <th>name</th>
      <th>place_id</th>
      <th>parent_place_id</th>
      <th>linked_place_id</th>
      <th>...</th>
      <th>extratags</th>
      <th>area</th>
      <th>wikipedia</th>
      <th>token_info</th>
      <th>housenumber</th>
      <th>postcode</th>
      <th>address_dict</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>us</td>
      <td>-134.419734</td>
      <td>58.301950</td>
      <td>"name"=&gt;"Juneau", "name:en"=&gt;"Juneau", "name:fa"=&gt;"جونو", "name:lt"=&gt;"Džunas", "name:pl"=&gt;"Juneau", "name:ru"=&gt;"Джуно", "name:ta"=&gt;"ஜூனோ", "name:uk"=&gt;"Джуно", "name:zh"=&gt;"朱诺 / 朱諾", "name:hak"=&gt;"Juneau", "name:nan"=&gt;"Juneau", "name:tli"=&gt;"Dzánti K'ihéeni", "name:zh-Hans"=&gt;"朱诺", "name:zh-Hant"=&gt;"朱諾"</td>
      <td>312456</td>
      <td>NaN</td>
      <td>297182206.0</td>
      <td>...</td>
      <td>"ele"=&gt;"17", "capital"=&gt;"4", "wikidata"=&gt;"Q29445", "wikipedia"=&gt;"en:Juneau, Alaska", "population"=&gt;"31000", "import_uuid"=&gt;"bb7269ee-502a-5391-8056-e3ce0e66489c", "state_capital"=&gt;"yes"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'US', 'continent': 'North America', 'iso_3166_2': 'US-AK'}</td>
    </tr>
    <tr>
      <th>1</th>
      <td>us</td>
      <td>-77.306373</td>
      <td>38.846224</td>
      <td>"name"=&gt;"Fairfax", "name:en"=&gt;"Fairfax"</td>
      <td>430494</td>
      <td>NaN</td>
      <td>298755178.0</td>
      <td>...</td>
      <td>"ele"=&gt;"131", "wikidata"=&gt;"Q501785", "population"=&gt;"24146", "population:date"=&gt;"2006"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>us</td>
      <td>-65.901022</td>
      <td>18.379193</td>
      <td>"name"=&gt;"Canóvanas"</td>
      <td>18375032</td>
      <td>NaN</td>
      <td>298262463.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q2361552", "wikipedia"=&gt;"en:Canóvanas, Puerto Rico"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>us</td>
      <td>144.836572</td>
      <td>13.510013</td>
      <td>"name"=&gt;"Dededo", "name:ch"=&gt;"Dedidu", "name:en"=&gt;"Dededo", "name:ja"=&gt;"デデド"</td>
      <td>5299331</td>
      <td>NaN</td>
      <td>299003598.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q1182147", "wikipedia"=&gt;"en:Dededo, Guam", "population"=&gt;"45000"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>us</td>
      <td>-76.610759</td>
      <td>39.290882</td>
      <td>"name"=&gt;"Baltimore", "name:ar"=&gt;"بالتيمور", "name:az"=&gt;"Baltimor", "name:be"=&gt;"Балтымар", "name:de"=&gt;"Baltimore", "name:en"=&gt;"Baltimore", "name:fr"=&gt;"Baltimore", "name:hi"=&gt;"बाल्टीमोर", "name:ja"=&gt;"ボルチモア", "name:lt"=&gt;"Baltimorė", "name:lv"=&gt;"Baltimora", "name:oc"=&gt;"Baltimore", "name:ru"=&gt;"Балтимор"</td>
      <td>298060487</td>
      <td>NaN</td>
      <td>297180865.0</td>
      <td>...</td>
      <td>"website"=&gt;"https://www.baltimorecity.gov/", "wikidata"=&gt;"Q5092", "wikipedia"=&gt;"en:Baltimore", "population"=&gt;"585708"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ph</td>
      <td>124.964373</td>
      <td>10.605272</td>
      <td>"name"=&gt;"Mahaplag"</td>
      <td>30127710</td>
      <td>NaN</td>
      <td>298692525.0</td>
      <td>...</td>
      <td>"place:PH"=&gt;"municipality", "population"=&gt;"27823", "population:date"=&gt;"2015-08-01", "gns_classification"=&gt;"ADM2"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'province': 'Leyte'}</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ph</td>
      <td>124.841531</td>
      <td>11.639055</td>
      <td>"ref"=&gt;"086023000", "name"=&gt;"Zumarraga"</td>
      <td>67432689</td>
      <td>NaN</td>
      <td>296109575.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q229664", "wikipedia"=&gt;"en:Zumarraga, Samar", "population"=&gt;"16295", "designation"=&gt;"municipality", "population:date"=&gt;"2015-08-01"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>125687</th>
      <td>us</td>
      <td>-76.922461</td>
      <td>36.677651</td>
      <td>"name"=&gt;"Franklin"</td>
      <td>429703</td>
      <td>NaN</td>
      <td>297724311.0</td>
      <td>...</td>
      <td>"ele"=&gt;"5", "wikidata"=&gt;"Q350001", "wikipedia"=&gt;"en:Franklin, Virginia", "population"=&gt;"8800", "import_uuid"=&gt;"bb7269ee-502a-5391-8056-e3ce0e66489c", "population:date"=&gt;"2006"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>125688</th>
      <td>us</td>
      <td>-76.345206</td>
      <td>37.030097</td>
      <td>"name"=&gt;"Hampton", "name:en"=&gt;"Hampton"</td>
      <td>444014</td>
      <td>NaN</td>
      <td>297193239.0</td>
      <td>...</td>
      <td>"ele"=&gt;"1", "wikidata"=&gt;"Q342043", "population"=&gt;"137436", "population:date"=&gt;"2010"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>125689</th>
      <td>us</td>
      <td>-105.052080</td>
      <td>39.940399</td>
      <td>"name"=&gt;"Broomfield", "name:en"=&gt;"Broomfield", "name:es"=&gt;"Broomfield", "official_name"=&gt;"City and County of Broomfield", "official_name:es"=&gt;"Ciudad y Condado de Broomfield"</td>
      <td>357888</td>
      <td>NaN</td>
      <td>298150161.0</td>
      <td>...</td>
      <td>"ele"=&gt;"1644", "wikidata"=&gt;"Q492819", "wikipedia"=&gt;"en:Broomfield, Colorado", "population"=&gt;"74112", "import_uuid"=&gt;"bb7269ee-502a-5391-8056-e3ce0e66489c", "population:date"=&gt;"2020"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>125690</th>
      <td>us</td>
      <td>-65.735321</td>
      <td>18.212082</td>
      <td>"name"=&gt;"Naguabo"</td>
      <td>72637889</td>
      <td>NaN</td>
      <td>298261170.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q2659720", "wikipedia"=&gt;"en:Naguabo, Puerto Rico"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>125691</th>
      <td>us</td>
      <td>-65.899548</td>
      <td>18.007344</td>
      <td>"name"=&gt;"Maunabo"</td>
      <td>18324682</td>
      <td>NaN</td>
      <td>298261464.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q967149", "wikipedia"=&gt;"en:Maunabo, Puerto Rico"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>00707</td>
      <td>{'postcode': '00707'}</td>
    </tr>
    <tr>
      <th>125692</th>
      <td>us</td>
      <td>-66.539884</td>
      <td>18.452893</td>
      <td>"name"=&gt;"Barceloneta"</td>
      <td>18632745</td>
      <td>NaN</td>
      <td>298261732.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q2025087", "wikipedia"=&gt;"es:Barceloneta (Puerto Rico)"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>125693</th>
      <td>us</td>
      <td>-66.979804</td>
      <td>18.180679</td>
      <td>"name"=&gt;"Maricao"</td>
      <td>18395106</td>
      <td>NaN</td>
      <td>298261565.0</td>
      <td>...</td>
      <td>"wikidata"=&gt;"Q2624359", "wikipedia"=&gt;"en:Maricao, Puerto Rico"</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>125694 rows × 24 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0          None
1          None
2          None
3          None
4          None
          ...  
125689     None
125690     None
125691    00707
125692     None
125693     None
Length: 125694, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> all-cities-and-towns-extract-from-osm/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new column "name_en" containing only the English name of the place if it's found.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def get_english_name(x):
    if type(x) is not dict:
        return None
    if 'name:en' in x.keys():
        return x['name:en']
    if 'name' in x.keys() and x['name'].lower().isalpha():
        return x['name']
    return None

df['name_en'] = df.name.apply(breakdown_tags).apply(get_english_name)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def get_english_name(x):
    if type(x) is not dict:
        return None
    if 'name:en' in x.keys():
        return x['name:en']
    if 'name' in x.keys() and x['name'].lower().isalpha():
        return x['name']
    return None

df['name_en'] = df.name.apply(breakdown_tags).apply(get_english_name)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def get_english_name(x):
    if type(x) is not dict:
        return None
    if 'name:en' in x.keys():
        return x['name:en']
    if 'name' in x.keys() and x['name'].lower().isalpha():
        return x['name']
    return None


__output__ = df['name_en'] = df.name.apply(breakdown_tags).apply(
    get_english_name)
</code></pre>
        <p><span onclick="$('#var_output_2ce81c92').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2ce81c92" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0              Juneau
1             Fairfax
2           Canóvanas
3              Dededo
4           Baltimore
             ...     
125689     Broomfield
125690        Naguabo
125691        Maunabo
125692    Barceloneta
125693        Maricao
Name: name, Length: 125694, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_code</th>
      <th>latitude</th>
      <th>longitude</th>
      <th>name</th>
      <th>place_id</th>
      <th>parent_place_id</th>
      <th>linked_place_id</th>
      <th>...</th>
      <th>area</th>
      <th>wikipedia</th>
      <th>token_info</th>
      <th>housenumber</th>
      <th>postcode</th>
      <th>address_dict</th>
      <th>name_en</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>us</td>
      <td>-134.419734</td>
      <td>58.301950</td>
      <td>"name"=&gt;"Juneau", "name:en"=&gt;"Juneau", "name:fa"=&gt;"جونو", "name:lt"=&gt;"Džunas", "name:pl"=&gt;"Juneau", "name:ru"=&gt;"Джуно", "name:ta"=&gt;"ஜூனோ", "name:uk"=&gt;"Джуно", "name:zh"=&gt;"朱诺 / 朱諾", "name:hak"=&gt;"Juneau", "name:nan"=&gt;"Juneau", "name:tli"=&gt;"Dzánti K'ihéeni", "name:zh-Hans"=&gt;"朱诺", "name:zh-Hant"=&gt;"朱諾"</td>
      <td>312456</td>
      <td>NaN</td>
      <td>297182206.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'US', 'continent': 'North America', 'iso_3166_2': 'US-AK'}</td>
      <td>Juneau</td>
    </tr>
    <tr>
      <th>1</th>
      <td>us</td>
      <td>-77.306373</td>
      <td>38.846224</td>
      <td>"name"=&gt;"Fairfax", "name:en"=&gt;"Fairfax"</td>
      <td>430494</td>
      <td>NaN</td>
      <td>298755178.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Fairfax</td>
    </tr>
    <tr>
      <th>2</th>
      <td>us</td>
      <td>-65.901022</td>
      <td>18.379193</td>
      <td>"name"=&gt;"Canóvanas"</td>
      <td>18375032</td>
      <td>NaN</td>
      <td>298262463.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Canóvanas</td>
    </tr>
    <tr>
      <th>3</th>
      <td>us</td>
      <td>144.836572</td>
      <td>13.510013</td>
      <td>"name"=&gt;"Dededo", "name:ch"=&gt;"Dedidu", "name:en"=&gt;"Dededo", "name:ja"=&gt;"デデド"</td>
      <td>5299331</td>
      <td>NaN</td>
      <td>299003598.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Dededo</td>
    </tr>
    <tr>
      <th>4</th>
      <td>us</td>
      <td>-76.610759</td>
      <td>39.290882</td>
      <td>"name"=&gt;"Baltimore", "name:ar"=&gt;"بالتيمور", "name:az"=&gt;"Baltimor", "name:be"=&gt;"Балтымар", "name:de"=&gt;"Baltimore", "name:en"=&gt;"Baltimore", "name:fr"=&gt;"Baltimore", "name:hi"=&gt;"बाल्टीमोर", "name:ja"=&gt;"ボルチモア", "name:lt"=&gt;"Baltimorė", "name:lv"=&gt;"Baltimora", "name:oc"=&gt;"Baltimore", "name:ru"=&gt;"Балтимор"</td>
      <td>298060487</td>
      <td>NaN</td>
      <td>297180865.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Baltimore</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ph</td>
      <td>124.964373</td>
      <td>10.605272</td>
      <td>"name"=&gt;"Mahaplag"</td>
      <td>30127710</td>
      <td>NaN</td>
      <td>298692525.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'province': 'Leyte'}</td>
      <td>Mahaplag</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ph</td>
      <td>124.841531</td>
      <td>11.639055</td>
      <td>"ref"=&gt;"086023000", "name"=&gt;"Zumarraga"</td>
      <td>67432689</td>
      <td>NaN</td>
      <td>296109575.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Zumarraga</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>125687</th>
      <td>us</td>
      <td>-76.922461</td>
      <td>36.677651</td>
      <td>"name"=&gt;"Franklin"</td>
      <td>429703</td>
      <td>NaN</td>
      <td>297724311.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Franklin</td>
    </tr>
    <tr>
      <th>125688</th>
      <td>us</td>
      <td>-76.345206</td>
      <td>37.030097</td>
      <td>"name"=&gt;"Hampton", "name:en"=&gt;"Hampton"</td>
      <td>444014</td>
      <td>NaN</td>
      <td>297193239.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Hampton</td>
    </tr>
    <tr>
      <th>125689</th>
      <td>us</td>
      <td>-105.052080</td>
      <td>39.940399</td>
      <td>"name"=&gt;"Broomfield", "name:en"=&gt;"Broomfield", "name:es"=&gt;"Broomfield", "official_name"=&gt;"City and County of Broomfield", "official_name:es"=&gt;"Ciudad y Condado de Broomfield"</td>
      <td>357888</td>
      <td>NaN</td>
      <td>298150161.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Broomfield</td>
    </tr>
    <tr>
      <th>125690</th>
      <td>us</td>
      <td>-65.735321</td>
      <td>18.212082</td>
      <td>"name"=&gt;"Naguabo"</td>
      <td>72637889</td>
      <td>NaN</td>
      <td>298261170.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Naguabo</td>
    </tr>
    <tr>
      <th>125691</th>
      <td>us</td>
      <td>-65.899548</td>
      <td>18.007344</td>
      <td>"name"=&gt;"Maunabo"</td>
      <td>18324682</td>
      <td>NaN</td>
      <td>298261464.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>00707</td>
      <td>{'postcode': '00707'}</td>
      <td>Maunabo</td>
    </tr>
    <tr>
      <th>125692</th>
      <td>us</td>
      <td>-66.539884</td>
      <td>18.452893</td>
      <td>"name"=&gt;"Barceloneta"</td>
      <td>18632745</td>
      <td>NaN</td>
      <td>298261732.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Barceloneta</td>
    </tr>
    <tr>
      <th>125693</th>
      <td>us</td>
      <td>-66.979804</td>
      <td>18.180679</td>
      <td>"name"=&gt;"Maricao"</td>
      <td>18395106</td>
      <td>NaN</td>
      <td>298261565.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Maricao</td>
    </tr>
  </tbody>
</table>
<p>125694 rows × 25 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0              Juneau
1             Fairfax
2           Canóvanas
3              Dededo
4           Baltimore
             ...     
125689     Broomfield
125690        Naguabo
125691        Maunabo
125692    Barceloneta
125693        Maricao
Name: name, Length: 125694, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> all-cities-and-towns-extract-from-osm/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the 3 largest towns by area in ascending order. Show the name and the area.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby('type').get_group('town').sort_values('area').tail(3)[['name', 'area']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby('type').get_group('town').sort_values('area').tail(3)[['name', 'area']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('type').get_group('town').sort_values('area').tail(3)[[
    'name', 'area']]
</code></pre>
        <p><span onclick="$('#var_output_02ff0c50').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_02ff0c50" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>area</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>122189</th>
      <td>"name"=&gt;"Marine Corps Base Camp Lejeune", "name:en"=&gt;"Marine Corps Base Camp Lejeune", "alt_name"=&gt;"Camp Lejeune"</td>
      <td>0.056495</td>
    </tr>
    <tr>
      <th>96911</th>
      <td>"name"=&gt;"Taloyoak"</td>
      <td>0.059147</td>
    </tr>
    <tr>
      <th>22859</th>
      <td>"name"=&gt;"Zayed City", "name:ar"=&gt;"مدينة زايد", "name:en"=&gt;"Zayed City"</td>
      <td>0.066523</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>area</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>122189</th>
      <td>"name"=&gt;"Marine Corps Base Camp Lejeune", "name:en"=&gt;"Marine Corps Base Camp Lejeune", "alt_name"=&gt;"Camp Lejeune"</td>
      <td>0.056495</td>
    </tr>
    <tr>
      <th>96911</th>
      <td>"name"=&gt;"Taloyoak"</td>
      <td>0.059147</td>
    </tr>
    <tr>
      <th>22859</th>
      <td>"name"=&gt;"Zayed City", "name:ar"=&gt;"مدينة زايد", "name:en"=&gt;"Zayed City"</td>
      <td>0.066523</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> all-cities-and-towns-extract-from-osm/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most important city in the US?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df.groupby('country_code').get_group('us').groupby('type').get_group('city').sort_values('importance',
                                                                                         ascending=False).head(1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df.groupby('country_code').get_group('us').groupby('type').get_group('city').sort_values('importance',
                                                                                         ascending=False).head(1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df.groupby('country_code').get_group('us').groupby('type'
    ).get_group('city').sort_values('importance', ascending=False).head(1)
</code></pre>
        <p><span onclick="$('#var_output_a30a410c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a30a410c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_code</th>
      <th>latitude</th>
      <th>longitude</th>
      <th>name</th>
      <th>place_id</th>
      <th>parent_place_id</th>
      <th>linked_place_id</th>
      <th>...</th>
      <th>area</th>
      <th>wikipedia</th>
      <th>token_info</th>
      <th>housenumber</th>
      <th>postcode</th>
      <th>address_dict</th>
      <th>name_en</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>98539</th>
      <td>us</td>
      <td>-77.094646</td>
      <td>38.984826</td>
      <td>"name"=&gt;"Bethesda", "name:en"=&gt;"Bethesda"</td>
      <td>425966</td>
      <td>295209723.0</td>
      <td>296252957.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>en:Bethesda,_Maryland</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>22814</td>
      <td>NaN</td>
      <td>Bethesda</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 25 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_code</th>
      <th>latitude</th>
      <th>longitude</th>
      <th>name</th>
      <th>place_id</th>
      <th>parent_place_id</th>
      <th>linked_place_id</th>
      <th>...</th>
      <th>area</th>
      <th>wikipedia</th>
      <th>token_info</th>
      <th>housenumber</th>
      <th>postcode</th>
      <th>address_dict</th>
      <th>name_en</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>98539</th>
      <td>us</td>
      <td>-77.094646</td>
      <td>38.984826</td>
      <td>"name"=&gt;"Bethesda", "name:en"=&gt;"Bethesda"</td>
      <td>425966</td>
      <td>295209723.0</td>
      <td>296252957.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>en:Bethesda,_Maryland</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>22814</td>
      <td>NaN</td>
      <td>Bethesda</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 25 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> all-cities-and-towns-extract-from-osm/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many towns are in France?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>len(df.groupby('country_code').get_group('fr').groupby('type').get_group('town'))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>len(df.groupby('country_code').get_group('fr').groupby('type').get_group('town'))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = len(df.groupby('country_code').get_group('fr').groupby('type')
    .get_group('town'))
</code></pre>
        <p><span onclick="$('#var_output_c5c3b5ff').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c5c3b5ff" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>1150</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>1150</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> all-cities-and-towns-extract-from-osm/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which US state is the highest up north?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_states = df.groupby('country_code').get_group('us').groupby('type').get_group('state')
df_states.sort_values('longitude', ascending=False).name_en.iloc[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_states = df.groupby('country_code').get_group('us').groupby('type').get_group('state')
df_states.sort_values('longitude', ascending=False).name_en.iloc[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_states = df.groupby('country_code').get_group('us').groupby('type'
    ).get_group('state')
__output__ = df_states.sort_values('longitude', ascending=False).name_en.iloc[0
    ]
</code></pre>
        <p><span onclick="$('#var_output_0366838a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0366838a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Alaska</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_states, __output__ </p>
    
          <p>df_states (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_code</th>
      <th>latitude</th>
      <th>longitude</th>
      <th>name</th>
      <th>place_id</th>
      <th>parent_place_id</th>
      <th>linked_place_id</th>
      <th>...</th>
      <th>area</th>
      <th>wikipedia</th>
      <th>token_info</th>
      <th>housenumber</th>
      <th>postcode</th>
      <th>address_dict</th>
      <th>name_en</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>103969</th>
      <td>us</td>
      <td>-170.692511</td>
      <td>-14.289304</td>
      <td>"ref"=&gt;"AS", "name"=&gt;"American Samoa", "name:ar"=&gt;"ساموا الأمريكية", "name:be"=&gt;"Амерыканскае Самоа", "name:br"=&gt;"Samoa Amerikan", "name:ca"=&gt;"Samoa Nord-americana", "name:cy"=&gt;"Samoa America", "name:da"=&gt;"Amerikansk Samoa", "name:de"=&gt;"Amerikanisch-Samoa", "name:el"=&gt;"Αμερικανικές Σαμόα", "name:en"=&gt;"American Samoa", "name:eo"=&gt;"Usona Samoo", "name:es"=&gt;"Samoa Americana", "name:et"=&gt;"Ameerika Samoa", "name:fa"=&gt;"ساموآی آمریکا", "name:fi"=&gt;"Amerikan Samoa", "name:fr"=&gt;"Samoa Américaines", "name:gv"=&gt;"Samoa Americaanagh", "name:he"=&gt;"סמואה האמריקנית", "name:hr"=&gt;"Američka Samoa", "name:ia"=&gt;"Samoa American", "name:io"=&gt;"Samoa Usana", "name:is"=&gt;"Bandaríska Samóa", "name:it"=&gt;"Samoa Americane", "name:ja"=&gt;"アメリカ領サモア", "name:kn"=&gt;"ಅಮೆರಿಕನ್ ಸಮೋವಾ", "name:ku"=&gt;"Samoaya Amerîkanî", "name:nl"=&gt;"Amerikaans-Samoa", "name:no"=&gt;"Amerikansk Samoa", "name:pl"=&gt;"Samoa Amerykańskie", "name:ru"=&gt;"Американское Самоа", "name:sk"=&gt;"Americká Samoa", "name:sm"=&gt;"Amerika Sāmoa", "name:sr"=&gt;"Америчка Самоа", "name:sv"=&gt;"Amerikanska Samoa", "name:uk"=&gt;"Американське Самоа", "name:uz"=&gt;"Amerika Samoasi", "name:vi"=&gt;"Samoa thuộc Mỹ", "name:zh"=&gt;"美属萨摩亚", "name:jbo"=&gt;"mer.samoas", "name:lfn"=&gt;"Samoa American"</td>
      <td>4065890</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'AS', 'continent': 'Oceania'}</td>
      <td>American Samoa</td>
    </tr>
    <tr>
      <th>122425</th>
      <td>us</td>
      <td>-111.714358</td>
      <td>39.422519</td>
      <td>"ref"=&gt;"UT", "name"=&gt;"Utah", "name:be"=&gt;"Юта", "name:en"=&gt;"Utah", "name:eo"=&gt;"Utaho", "name:fy"=&gt;"Utah", "name:hu"=&gt;"Utah", "name:ko"=&gt;"유타", "name:mo"=&gt;"Юта", "name:mr"=&gt;"युट्हा", "name:nl"=&gt;"Utah", "name:pl"=&gt;"Utah", "name:ru"=&gt;"Юта", "name:uk"=&gt;"Юта", "name:zh"=&gt;"犹他州", "name:tok"=&gt;"ma Juta", "name:short"=&gt;"UT", "name:abbreviation"=&gt;"Utah"</td>
      <td>1244489</td>
      <td>NaN</td>
      <td>294960736.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Utah</td>
    </tr>
    <tr>
      <th>122428</th>
      <td>us</td>
      <td>-81.463983</td>
      <td>27.756767</td>
      <td>"ref"=&gt;"FL", "name"=&gt;"Florida", "name:af"=&gt;"Florida", "name:an"=&gt;"Florida", "name:ar"=&gt;"فلوريدا", "name:ay"=&gt;"Florida suyu", "name:az"=&gt;"Florida", "name:ba"=&gt;"Флорида", "name:be"=&gt;"Фларыда", "name:bg"=&gt;"Флорида", "name:bh"=&gt;"फ्लोरिडा", "name:bi"=&gt;"Florida", "name:bn"=&gt;"ফ্লোরিডা", "name:bo"=&gt;"ཧྥོ་ལོ་རི་ཌ།", "name:br"=&gt;"Florida", "name:bs"=&gt;"Florida", "name:ca"=&gt;"Florida", "name:ce"=&gt;"Флорида", "name:cs"=&gt;"Florida", "name:cv"=&gt;"Флорида", "name:cy"=&gt;"Florida", "name:da"=&gt;"Florida", "name:de"=&gt;"Florida", "name:el"=&gt;"Φλόριντα", "name:en"=&gt;"Florida", "name:eo"=&gt;"Florido", "name:es"=&gt;"Florida", "name:et"=&gt;"Florida", "name:eu"=&gt;"Florida", "name:fa"=&gt;"فلوریدا", "name:fi"=&gt;"Florida", "name:fo"=&gt;"Florida", "name:fr"=&gt;"Floride", "name:fy"=&gt;"Floarida", "name:ga"=&gt;"Florida", "name:gd"=&gt;"Florida", "name:gl"=&gt;"Florida", "name:gn"=&gt;"Florida", "name:gv"=&gt;"Florida", "name:ha"=&gt;"Florida", "name:he"=&gt;"פלורידה", "name:hi"=&gt;"फ़्लोरिडा", "name:hr"=&gt;"Florida", "name:ht"=&gt;"Florid", "name:hu"=&gt;"Florida", "name:hy"=&gt;"Ֆլորիդա", "name:ia"=&gt;"Florida", "name:id"=&gt;"Florida", "name:ie"=&gt;"Florida", "name:ig"=&gt;"Flórídạ", "name:ik"=&gt;"Florida", "name:io"=&gt;"Florida", "name:is"=&gt;"Flórída", "name:it"=&gt;"Florida", "name:iu"=&gt;"ᑉᓘᕇᑖ", "name:ja"=&gt;"フロリダ州", "name:jv"=&gt;"Florida", "name:ka"=&gt;"ფლორიდა", "name:kk"=&gt;"Флорида", "name:kn"=&gt;"ಫ್ಲಾರಿಡ", "name:ko"=&gt;"플로리다", "name:ku"=&gt;"Florida", "name:kw"=&gt;"Florida", "name:la"=&gt;"Florida", "name:lb"=&gt;"Florida", "name:li"=&gt;"Florida", "name:lt"=&gt;"Florida", "name:lv"=&gt;"Florida", "name:mg"=&gt;"Florida", "name:mi"=&gt;"Florida", "name:mk"=&gt;"Флорида", "name:ml"=&gt;"ഫ്ലോറിഡ", "name:mn"=&gt;"Флорида", "name:mo"=&gt;"Флорида", "name:mr"=&gt;"फ्लोरिडा", "name:ms"=&gt;"Florida", "name:my"=&gt;"ဖလော်ရီဒါပြည်နယ်", "name:na"=&gt;"Florida", "name:ne"=&gt;"फ्लोरिडा", "name:nl"=&gt;"Florida", "name:nn"=&gt;"Florida", "name:no"=&gt;"Florida", "name:nv"=&gt;"Gah Bikeeʼ Taah Yíʼáhí", "name:oc"=&gt;"Florida", "name:os"=&gt;"Флоридæ", "name:pa"=&gt;"ਫ਼ਲੌਰਿਡਾ", "name:pi"=&gt;"फ्लोरिडा", "name:pl"=&gt;"Floryda", "name:pt"=&gt;"Flórida", "name:qu"=&gt;"Florida suyu", "name:rm"=&gt;"Florida", "name:ro"=&gt;"Florida", "name:ru"=&gt;"Флорида", "name:sa"=&gt;"फ्लोरिडा", "name:sc"=&gt;"Flòrida", "name:se"=&gt;"Florida", "name:sh"=&gt;"Florida", "name:sk"=&gt;"Florida", "name:sl"=&gt;"Florida", "name:sn"=&gt;"Florida", "name:so"=&gt;"Florida", "name:sq"=&gt;"Florida", "name:sr"=&gt;"Флорида", "name:sv"=&gt;"Florida", "name:sw"=&gt;"Florida", "name:ta"=&gt;"புளோரிடா", "name:te"=&gt;"ఫ్లోరిడా", "name:tg"=&gt;"Флорида", "name:th"=&gt;"รัฐฟลอริดา", "name:tl"=&gt;"Florida", "name:tr"=&gt;"Florida", "name:tt"=&gt;"Флорида", "name:ug"=&gt;"Florida Shitati", "name:uk"=&gt;"Флорида", "name:ur"=&gt;"فلوریڈا", "name:uz"=&gt;"Florida", "name:vi"=&gt;"Florida", "name:vo"=&gt;"Florida", "name:xh"=&gt;"IFlorida", "name:yi"=&gt;"פלארידע", "name:yo"=&gt;"Florida", "name:zh"=&gt;"佛罗里达州/佛羅里達州", "name:zu"=&gt;"Florida", "name:als"=&gt;"Florida", "name:ang"=&gt;"Florida", "name:arz"=&gt;"فلوريدا", "name:ast"=&gt;"Florida", "name:azb"=&gt;"فلوریدا ایالتی", "name:ban"=&gt;"Florida", "name:bar"=&gt;"Florida", "name:bcl"=&gt;"Florida", "name:bpy"=&gt;"ফ্লোরিডা", "name:bxr"=&gt;"Флорида", "name:cdo"=&gt;"Florida", "name:ceb"=&gt;"Florida", "name:ckb"=&gt;"فلۆریدا", "name:diq"=&gt;"Florida", "name:eml"=&gt;"Flòrida", "name:frp"=&gt;"Florida", "name:frr"=&gt;"Florida", "name:gag"=&gt;"Florida", "name:hak"=&gt;"Florida", "name:haw"=&gt;"Pololika", "name:hif"=&gt;"Florida", "name:hsb"=&gt;"Florida", "name:ilo"=&gt;"Florida", "name:kaa"=&gt;"Florida", "name:kbp"=&gt;"Floriidii", "name:krc"=&gt;"Флорида", "name:lad"=&gt;"Florida", "name:lez"=&gt;"Флорида", "name:lfn"=&gt;"Florida", "name:lij"=&gt;"Florida", "name:lmo"=&gt;"Florida", "name:lrc"=&gt;"فلوریدا", "name:mai"=&gt;"फ्लोरिडा", "name:mhr"=&gt;"Флорида", "name:mrj"=&gt;"Флорида", "name:mzn"=&gt;"فلوریدا", "name:nan"=&gt;"Florida", "name:nds"=&gt;"Florida", "name:new"=&gt;"फ्लोरिदा", "name:pam"=&gt;"Florida", "name:pap"=&gt;"Florida", "name:pms"=&gt;"Florida", "name:pnb"=&gt;"فلوریڈا", "name:rue"=&gt;"Флоріда", "name:sah"=&gt;"Флорида", "name:scn"=&gt;"Florida", "name:sco"=&gt;"Florida", "name:stq"=&gt;"Florida", "name:szl"=&gt;"Florida", "name:tok"=&gt;"ma Lowita", "name:vec"=&gt;"Florida", "name:war"=&gt;"Florida", "name:wuu"=&gt;"佛罗里达州", "name:xal"=&gt;"Флорида", "name:xmf"=&gt;"ფლორიდა", "name:yue"=&gt;"佛羅里達州", "name:zea"=&gt;"Florida", "short_name"=&gt;"Fla.", "name:nds-nl"=&gt;"Florida", "name:bat-smg"=&gt;"Fluorėda", "name:cbk-zam"=&gt;"Florida", "name:zh-Hans"=&gt;"佛罗里达州", "name:zh-Hant"=&gt;"佛羅里達州", "name:be-tarask"=&gt;"Флорыда"</td>
      <td>20789338</td>
      <td>NaN</td>
      <td>294924757.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'US'}</td>
      <td>Florida</td>
    </tr>
    <tr>
      <th>123436</th>
      <td>us</td>
      <td>-82.688140</td>
      <td>40.225357</td>
      <td>"ref"=&gt;"OH", "name"=&gt;"Ohio", "name:be"=&gt;"Агаё", "name:en"=&gt;"Ohio", "name:eo"=&gt;"Ohio", "name:fy"=&gt;"Ohio", "name:hu"=&gt;"Ohio", "name:mo"=&gt;"Охайо", "name:mr"=&gt;"ओहायो", "name:nl"=&gt;"Ohio", "name:pl"=&gt;"Ohio", "name:ru"=&gt;"Огайо", "name:uk"=&gt;"Огайо", "name:zh"=&gt;"俄亥俄州", "name:tok"=&gt;"ma Owajo", "name:short"=&gt;"OH", "name:abbreviation"=&gt;"Ohio"</td>
      <td>1251941</td>
      <td>NaN</td>
      <td>295535828.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Ohio</td>
    </tr>
    <tr>
      <th>123437</th>
      <td>us</td>
      <td>-170.713148</td>
      <td>-14.297124</td>
      <td>"ref"=&gt;"AS", "name"=&gt;"American Samoa", "name:af"=&gt;"Amerikaans-Samoa", "name:am"=&gt;"አሜሪካዊ ሳሞዓ", "name:ar"=&gt;"ساموا الأمريكية", "name:az"=&gt;"Amerika Samoası", "name:ba"=&gt;"Америка Самоаһы", "name:be"=&gt;"Амерыканскае Самоа", "name:bg"=&gt;"Американска Самоа", "name:bn"=&gt;"মার্কিন সামোয়া", "name:br"=&gt;"Samoa Amerikan", "name:bs"=&gt;"Američka Samoa", "name:ca"=&gt;"Samoa Nord-americana", "name:ce"=&gt;"Америкин Самоа", "name:cs"=&gt;"Americká Samoa", "name:cy"=&gt;"Samoa America", "name:da"=&gt;"Amerikansk Samoa", "name:de"=&gt;"Amerikanisch-Samoa", "name:dv"=&gt;"އެމެރިކަން ސަމޯއާ", "name:el"=&gt;"Αμερικανική Σαμόα", "name:en"=&gt;"American Samoa", "name:eo"=&gt;"Samoo Usona", "name:es"=&gt;"Samoa Americana", "name:et"=&gt;"Ameerika Samoa", "name:eu"=&gt;"Samoa Estatubatuarra", "name:fa"=&gt;"ساموآی آمریکا", "name:fi"=&gt;"Amerikan Samoa", "name:fo"=&gt;"Amerikanska Sámoa", "name:fr"=&gt;"Samoa américaines", "name:fy"=&gt;"Amerikaansk-Samoä", "name:ga"=&gt;"Samó Mheiriceá", "name:gd"=&gt;"Samoa Aimearaganach", "name:gl"=&gt;"Samoa Americana", "name:gn"=&gt;"Samóa Amérika pegua", "name:he"=&gt;"סמואה האמריקנית", "name:hi"=&gt;"अमेरिकी समोआ", "name:hr"=&gt;"Američka Samoa", "name:hu"=&gt;"Amerikai Szamoa", "name:hy"=&gt;"Ամերիկյան Սամոա", "name:id"=&gt;"Samoa Amerika", "name:io"=&gt;"Usana Samoa", "name:is"=&gt;"Bandaríska Samóa", "name:it"=&gt;"Samoa Americane", "name:ja"=&gt;"アメリカ領サモア", "name:jv"=&gt;"Samoa Amérika", "name:ka"=&gt;"ამერიკის სამოა", "name:kk"=&gt;"Америка Самоасы", "name:ko"=&gt;"아메리칸사모아", "name:kw"=&gt;"아메리칸사모아", "name:ky"=&gt;"Америка Самоасы", "name:la"=&gt;"Samoa Americana", "name:li"=&gt;"Amerikaans Samoa", "name:lt"=&gt;"Amerikos Samoa", "name:lv"=&gt;"ASV Samoa", "name:mi"=&gt;"Hāmoa Marikena", "name:mk"=&gt;"Американска Самоа", "name:ml"=&gt;"അമേരിക്കൻ സമോവ", "name:mr"=&gt;"अमेरिकन सामोआ", "name:ms"=&gt;"Samoa Amerika", "name:ne"=&gt;"अमेरिकी सामोआ", "name:nl"=&gt;"Amerikaans-Samoa", "name:nn"=&gt;"Amerikansk Samoa", "name:no"=&gt;"Amerikansk Samoa", "name:oc"=&gt;"Samoa Americana", "name:or"=&gt;"ଆମେରିକୀୟ ସମୋଆ", "name:os"=&gt;"Америкæйы Самоæ", "name:pa"=&gt;"ਅਮਰੀਕੀ ਸਮੋਆ", "name:pl"=&gt;"Samoa Amerykańskie", "name:pt"=&gt;"Samoa Americana", "name:qu"=&gt;"Amirika Samwa", "name:ro"=&gt;"Samoa Americană", "name:ru"=&gt;"Американское Самоа", "name:rw"=&gt;"Samowa Nyamerika", "name:sc"=&gt;"Samoa Americanas", "name:se"=&gt;"Amerihká Samoa", "name:sh"=&gt;"Američka Samoa", "name:sk"=&gt;"Americká Samoa", "name:sl"=&gt;"Ameriška Samoa", "name:sm"=&gt;"Amerika Sāmoa", "name:sn"=&gt;"American Samoa", "name:sq"=&gt;"Samoa Amerikane", "name:sr"=&gt;"Америчка Самоа", "name:su"=&gt;"Samoa Amérika", "name:sv"=&gt;"Amerikanska Samoa", "name:sw"=&gt;"Samoa ya Marekani", "name:ta"=&gt;"அமெரிக்க சமோவா", "name:tg"=&gt;"Самоаи Америкоӣ", "name:th"=&gt;"อเมริกันซามัว", "name:tl"=&gt;"American Samoa", "name:to"=&gt;"Haʻamoa-ʻAmelika", "name:tr"=&gt;"Amerikan Samoası", "name:tt"=&gt;"Америка Самоасы", "name:ug"=&gt;"ئامېرىكىغا قاراشلىق ساموئا", "name:uk"=&gt;"Американське Самоа", "name:ur"=&gt;"امریکی سمووا", "name:uz"=&gt;"Amerika Samoasi", "name:vi"=&gt;"Samoa thuộc Mỹ", "name:yi"=&gt;"אמעריקאנישער סאמאא", "name:yo"=&gt;"Sàmóà Amẹ́ríkà", "name:zh"=&gt;"美屬薩摩亞", "name:ace"=&gt;"Samoa Amirika", "name:arz"=&gt;"ساموا الامريكيه", "name:ast"=&gt;"Samoa Americana", "name:bar"=&gt;"Amerikanisch-Samoa", "name:bpy"=&gt;"আমেরিকান সামোয়া", "name:ceb"=&gt;"American Samoa", "name:chr"=&gt;"ᎠᎺᎵᎧ ᏌᎼᎠ", "name:ckb"=&gt;"ساموای ئەمریکا", "name:frp"=&gt;"Samoa amèriquènes", "name:frr"=&gt;"Amerikoonsk Samoa", "name:gag"=&gt;"Amerikan Samoa", "name:hak"=&gt;"Mî-koet liâng Samoa", "name:haw"=&gt;"Sāmoa ʻAmelika", "name:hif"=&gt;"American Samoa", "name:kaa"=&gt;"Amerikalıq Samoa", "name:lfn"=&gt;"Samoa American", "name:lij"=&gt;"Samöa Americann-e", "name:pam"=&gt;"Amerika Samoa", "name:pcd"=&gt;"Samoa anméricaines", "name:rue"=&gt;"Америцька Самоа", "name:scn"=&gt;"Samoa Miricana", "name:shn"=&gt;"သႃႇမူဝ်းဝႃႇ ၶွင်ဢမေႇရိၵၼ်ႇ", "name:war"=&gt;"American Samoa", "name:wuu"=&gt;"美属萨摩亚", "name:xmf"=&gt;"ამერიკაშ სამოა", "ISO3166-2"=&gt;"US-AS"</td>
      <td>98858981</td>
      <td>NaN</td>
      <td>295585742.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'AS', 'continent': 'Oceania'}</td>
      <td>American Samoa</td>
    </tr>
    <tr>
      <th>124000</th>
      <td>us</td>
      <td>-89.433729</td>
      <td>40.079661</td>
      <td>"ref"=&gt;"IL", "name"=&gt;"Illinois", "name:be"=&gt;"Ілінойс", "name:en"=&gt;"Illinois", "name:eo"=&gt;"Ilinojso", "name:fy"=&gt;"Illinois", "name:hu"=&gt;"Illinois", "name:ko"=&gt;"일리노이", "name:mo"=&gt;"Иллинойс", "name:mr"=&gt;"इलीनोय", "name:nl"=&gt;"Illinois", "name:pl"=&gt;"Illinois", "name:ru"=&gt;"Иллинойс", "name:uk"=&gt;"Іллінойс", "name:zh"=&gt;"伊利诺伊州 / 伊利諾州", "name:hak"=&gt;"Illinois", "name:nan"=&gt;"Illinois", "name:tok"=&gt;"ma Ilino", "name:tzl"=&gt;"Idinois", "name:short"=&gt;"IL", "short_name"=&gt;"Ill.", "name:zh-Hans"=&gt;"伊利诺伊州", "name:zh-Hant"=&gt;"伊利諾州", "name:abbreviation"=&gt;"Il."</td>
      <td>4223149</td>
      <td>NaN</td>
      <td>294867509.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'US', 'continent': 'North America'}</td>
      <td>Illinois</td>
    </tr>
    <tr>
      <th>124001</th>
      <td>us</td>
      <td>-86.829534</td>
      <td>33.258882</td>
      <td>"ref"=&gt;"AL", "name"=&gt;"Alabama", "name:be"=&gt;"Алабама", "name:en"=&gt;"Alabama", "name:eo"=&gt;"Alabamo", "name:fy"=&gt;"Alabama", "name:hu"=&gt;"Alabama", "name:ko"=&gt;"앨라배마", "name:mo"=&gt;"Алабама", "name:mr"=&gt;"आलाबामा", "name:nl"=&gt;"Alabama", "name:pl"=&gt;"Alabama", "name:ru"=&gt;"Алабама", "name:uk"=&gt;"Алабама", "name:zh"=&gt;"亚拉巴马州 / 阿拉巴馬州", "name:cdo"=&gt;"Alabama", "name:nan"=&gt;"Alabama", "name:tok"=&gt;"ma Alapama", "name:wuu"=&gt;"阿拉巴馬州", "name:yue"=&gt;"阿拉巴馬州", "name:short"=&gt;"AL", "short_name"=&gt;"Ala.", "name:zh-Hans"=&gt;"亚拉巴马州", "name:zh-Hant"=&gt;"阿拉巴馬州", "name:abbreviation"=&gt;"Ala."</td>
      <td>1242347</td>
      <td>NaN</td>
      <td>294919109.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'US', 'continent': 'North America'}</td>
      <td>Alabama</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>124080</th>
      <td>us</td>
      <td>-105.607716</td>
      <td>38.725178</td>
      <td>"ref"=&gt;"CO", "name"=&gt;"Colorado", "name:be"=&gt;"Каларада", "name:en"=&gt;"Colorado", "name:eo"=&gt;"Koloradio", "name:fy"=&gt;"Kolorado", "name:hu"=&gt;"Colorado", "name:ko"=&gt;"콜로라도", "name:mo"=&gt;"Колорадо", "name:mr"=&gt;"कोलोराडो", "name:nl"=&gt;"Colorado", "name:pl"=&gt;"Kolorado", "name:ru"=&gt;"Колорадо", "name:uk"=&gt;"Колорадо", "name:zh"=&gt;"科罗拉多州 / 科羅拉多州", "name:hak"=&gt;"Colorado", "name:nan"=&gt;"Colorado", "name:tok"=&gt;"ma Kolowato", "name:short"=&gt;"CO", "short_name"=&gt;"Colo.", "name:zh-Hans"=&gt;"科罗拉多州", "name:zh-Hant"=&gt;"科羅拉多州", "name:abbreviation"=&gt;"Colo."</td>
      <td>1249311</td>
      <td>NaN</td>
      <td>297912280.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Colorado</td>
    </tr>
    <tr>
      <th>124084</th>
      <td>us</td>
      <td>-100.540737</td>
      <td>47.620146</td>
      <td>"ref"=&gt;"ND", "name"=&gt;"North Dakota", "name:be"=&gt;"Паўночная Дакота", "name:cs"=&gt;"Severní Dakota", "name:de"=&gt;"Nord-Dakota", "name:en"=&gt;"North Dakota", "name:eo"=&gt;"Norda Dakoto", "name:es"=&gt;"Dakota del Norte", "name:et"=&gt;"Põhja-Dakota", "name:fr"=&gt;"Dakota du Nord", "name:fy"=&gt;"Noard-Dakota", "name:he"=&gt;"דקוטה הצפונית", "name:hu"=&gt;"Észak-Dakota", "name:it"=&gt;"Dakota del Nord", "name:ko"=&gt;"노스다코타", "name:lt"=&gt;"Šiaurės Dakota", "name:mo"=&gt;"Дакота де Норд", "name:mr"=&gt;"उत्तर डकोटा", "name:nl"=&gt;"North Dakota", "name:pl"=&gt;"Dakota Północna", "name:pt"=&gt;"Dakota do Norte", "name:ru"=&gt;"Северная Дакота", "name:sk"=&gt;"Severná Dakota", "name:tt"=&gt;"Төньяк Дакота", "name:uk"=&gt;"Північна Дакота", "name:vi"=&gt;"Bắc Dakota", "name:zh"=&gt;"北达科他州 / 北達科他州", "name:ast"=&gt;"Dakota del Norte", "name:hak"=&gt;"Pet Tha̍t-khô-thâ", "name:lfn"=&gt;"Dakota Norde", "name:nan"=&gt;"North Dakota", "name:tok"=&gt;"ma Notakota", "name:short"=&gt;"ND", "short_name"=&gt;"N.D.", "name:zh-Hans"=&gt;"北达科他州", "name:zh-Hant"=&gt;"北達科他州", "name:abbreviation"=&gt;"N.D."</td>
      <td>1267737</td>
      <td>NaN</td>
      <td>297100313.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'US', 'continent': 'North America'}</td>
      <td>North Dakota</td>
    </tr>
    <tr>
      <th>124088</th>
      <td>us</td>
      <td>144.765168</td>
      <td>13.449994</td>
      <td>"ref"=&gt;"GU", "name"=&gt;"Guam", "name:ar"=&gt;"غوام", "name:be"=&gt;"Гуам", "name:br"=&gt;"Guam", "name:ca"=&gt;"Guam", "name:de"=&gt;"Guam", "name:el"=&gt;"Γκουάμ", "name:en"=&gt;"Guam", "name:eo"=&gt;"Gvamo", "name:es"=&gt;"Guam", "name:fa"=&gt;"گوآم", "name:fi"=&gt;"Guam", "name:fr"=&gt;"Guam", "name:gv"=&gt;"Guam", "name:he"=&gt;"גואם", "name:hu"=&gt;"Guam", "name:ia"=&gt;"Guam", "name:io"=&gt;"Guam", "name:it"=&gt;"Guam", "name:ja"=&gt;"グアム", "name:kn"=&gt;"ಗ್ವಾಮ್", "name:ku"=&gt;"Guam", "name:lt"=&gt;"Guamas", "name:no"=&gt;"Guam", "name:pl"=&gt;"Guam", "name:ru"=&gt;"Гуам", "name:sk"=&gt;"Guam", "name:sl"=&gt;"Guam", "name:sr"=&gt;"Гуам", "name:sv"=&gt;"Guam", "name:uk"=&gt;"Гуам", "name:vi"=&gt;"Guam", "name:zh"=&gt;"关岛 / 關島", "name:lfn"=&gt;"Guam", "name:nan"=&gt;"Guam", "name:nds"=&gt;"Guam", "ISO3166-2"=&gt;"US-GU", "old_name:es"=&gt;"Guaján", "name:zh-Hans"=&gt;"关岛", "name:zh-Hant"=&gt;"關島", "official_name:eo"=&gt;"Teritorio de Gvamo", "official_name:pl"=&gt;"Terytorium Guam"</td>
      <td>5098472</td>
      <td>NaN</td>
      <td>297163263.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'GU', 'continent': 'Oceania'}</td>
      <td>Guam</td>
    </tr>
    <tr>
      <th>124089</th>
      <td>us</td>
      <td>-114.015407</td>
      <td>43.644764</td>
      <td>"ref"=&gt;"ID", "name"=&gt;"Idaho", "name:be"=&gt;"Айдаха", "name:en"=&gt;"Idaho", "name:eo"=&gt;"Idaho", "name:fy"=&gt;"Idaho", "name:hu"=&gt;"Idaho", "name:ko"=&gt;"아이다호", "name:mo"=&gt;"Айдахо", "name:mr"=&gt;"इडाहो", "name:nl"=&gt;"Idaho", "name:pl"=&gt;"Idaho", "name:ru"=&gt;"Айдахо", "name:uk"=&gt;"Айдахо", "name:zh"=&gt;"爱达荷州 / 愛達荷州", "name:hak"=&gt;"Idaho", "name:nan"=&gt;"Idaho", "name:tok"=&gt;"ma Atajo", "name:short"=&gt;"ID", "name:zh-Hans"=&gt;"爱达荷州", "name:zh-Hant"=&gt;"愛達荷州", "name:abbreviation"=&gt;"Idaho"</td>
      <td>1259416</td>
      <td>NaN</td>
      <td>298745703.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Idaho</td>
    </tr>
    <tr>
      <th>124092</th>
      <td>us</td>
      <td>-93.312270</td>
      <td>41.921673</td>
      <td>"ref"=&gt;"IA", "name"=&gt;"Iowa", "name:be"=&gt;"Аёва", "name:en"=&gt;"Iowa", "name:eo"=&gt;"Iovao", "name:fy"=&gt;"Iowa", "name:hu"=&gt;"Iowa", "name:ko"=&gt;"아이오와", "name:mo"=&gt;"Айова", "name:mr"=&gt;"आयोवा", "name:nl"=&gt;"Iowa", "name:pl"=&gt;"Iowa", "name:ru"=&gt;"Айова", "name:uk"=&gt;"Айова", "name:zh"=&gt;"艾奥瓦州 / 愛荷華州", "name:cdo"=&gt;"Iowa", "name:hak"=&gt;"Iowa", "name:nan"=&gt;"Iowa", "name:tok"=&gt;"ma Ajowa", "name:wuu"=&gt;"艾奥瓦州", "name:yue"=&gt;"愛荷華州", "name:short"=&gt;"IA", "name:zh-Hans"=&gt;"艾奥瓦州", "name:zh-Hant"=&gt;"愛荷華州", "name:abbreviation"=&gt;"Iowa"</td>
      <td>1265812</td>
      <td>NaN</td>
      <td>297207729.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Iowa</td>
    </tr>
    <tr>
      <th>124096</th>
      <td>us</td>
      <td>-76.938207</td>
      <td>39.516240</td>
      <td>"ref"=&gt;"MD", "name"=&gt;"Maryland", "name:be"=&gt;"Мэрыленд", "name:en"=&gt;"Maryland", "name:eo"=&gt;"Marilando", "name:fy"=&gt;"Marylân", "name:hu"=&gt;"Maryland", "name:ko"=&gt;"메릴랜드", "name:mo"=&gt;"Мериленд", "name:mr"=&gt;"मेरीलँड", "name:nl"=&gt;"Maryland", "name:pl"=&gt;"Maryland", "name:ru"=&gt;"Мэриленд", "name:uk"=&gt;"Меріленд", "name:zh"=&gt;"马里兰州 / 馬里蘭州", "name:hak"=&gt;"Maryland", "name:nan"=&gt;"Maryland", "name:tok"=&gt;"ma Mewilan", "name:wuu"=&gt;"马里兰州", "name:yue"=&gt;"馬里蘭州", "name:short"=&gt;"MD", "short_name"=&gt;"MD;Md.", "name:zh-Hans"=&gt;"马里兰州", "name:zh-Hant"=&gt;"馬里蘭州", "short_name:en"=&gt;"MD;Md.", "name:abbreviation"=&gt;"Md."</td>
      <td>1266168</td>
      <td>NaN</td>
      <td>297946862.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Maryland</td>
    </tr>
    <tr>
      <th>124196</th>
      <td>us</td>
      <td>-118.755997</td>
      <td>36.701463</td>
      <td>"ref"=&gt;"CA", "name"=&gt;"California", "name:af"=&gt;"Kalifornië", "name:am"=&gt;"ካሊፎርኒያ", "name:an"=&gt;"California", "name:ar"=&gt;"كاليفورنيا", "name:ay"=&gt;"California suyu", "name:az"=&gt;"Kaliforniya", "name:ba"=&gt;"Калифорния", "name:be"=&gt;"Каліфорнія", "name:bg"=&gt;"Калифорния", "name:bh"=&gt;"कैलिफोर्निया", "name:bi"=&gt;"Kalifornia", "name:bn"=&gt;"ক্যালিফোর্নিয়া", "name:bo"=&gt;"ཁྰ་ལེ་ཧྥོར་ནི་ཡ།", "name:br"=&gt;"Kalifornia", "name:bs"=&gt;"Kalifornija", "name:ca"=&gt;"Califòrnia", "name:ce"=&gt;"Калифорни", "name:co"=&gt;"California", "name:cs"=&gt;"Kalifornie", "name:cv"=&gt;"Калифорни", "name:cy"=&gt;"Califfornia", "name:da"=&gt;"Californien", "name:de"=&gt;"Kalifornien", "name:el"=&gt;"Καλιφόρνια", "name:en"=&gt;"California", "name:eo"=&gt;"Kalifornio", "name:es"=&gt;"California", "name:et"=&gt;"California", "name:eu"=&gt;"Kalifornia", "name:fa"=&gt;"کالیفرنیا", "name:fi"=&gt;"Kalifornia", "name:fo"=&gt;"Kalifornia", "name:fr"=&gt;"Californie", "name:fy"=&gt;"Kalifornje", "name:ga"=&gt;"California", "name:gd"=&gt;"Calafòrnia", "name:gl"=&gt;"California", "name:gn"=&gt;"California", "name:gu"=&gt;"કેલિફોર્નિયા", "name:gv"=&gt;"California", "name:ha"=&gt;"California", "name:he"=&gt;"קליפורניה", "name:hi"=&gt;"कैलिफ़ोर्निया", "name:hr"=&gt;"Kalifornija", "name:ht"=&gt;"Kalifòni", "name:hu"=&gt;"Kalifornia", "name:hy"=&gt;"Կալիֆոռնիա", "name:ia"=&gt;"California", "name:id"=&gt;"California", "name:ie"=&gt;"California", "name:ig"=&gt;"California", "name:ik"=&gt;"California", "name:io"=&gt;"Kalifornia", "name:is"=&gt;"Kalifornía", "name:it"=&gt;"California", "name:iu"=&gt;"ᑳᓖᐴᕐᓃᐊ", "name:ja"=&gt;"カリフォルニア州", "name:jv"=&gt;"California", "name:ka"=&gt;"კალიფორნია", "name:kk"=&gt;"Калифорния", "name:km"=&gt;"កាលីហ្វញ៉ា", "name:kn"=&gt;"ಕ್ಯಾಲಿಫೊರ್ನಿಯ", "name:ko"=&gt;"캘리포니아", "name:ku"=&gt;"Kalîforniya", "name:kw"=&gt;"Kaliforni", "name:ky"=&gt;"Калифорния", "name:la"=&gt;"California", "name:lb"=&gt;"Kalifornien", "name:li"=&gt;"Californië", "name:lt"=&gt;"Kalifornija", "name:lv"=&gt;"Kalifornija", "name:mg"=&gt;"Kalifornia", "name:mi"=&gt;"Karapōnia", "name:mk"=&gt;"Калифорнија", "name:ml"=&gt;"കാലിഫോർണിയ", "name:mn"=&gt;"Калифорни", "name:mo"=&gt;"Калифорния", "name:mr"=&gt;"कॅलिफोर्निया", "name:ms"=&gt;"California", "name:my"=&gt;"ကယ်လီဖိုးနီးယားပြည်နယ်", "name:na"=&gt;"California", "name:ne"=&gt;"क्यालिफोर्निया", "name:nl"=&gt;"Californië", "name:nn"=&gt;"California", "name:no"=&gt;"California", "name:nv"=&gt;"Ahééháshį́į́h Hahoodzo", "name:oc"=&gt;"Califòrnia", "name:os"=&gt;"Калифорни", "name:pa"=&gt;"ਕੈਲੀਫ਼ੋਰਨੀਆ", "name:pi"=&gt;"क्यालिफोर्निया", "name:pl"=&gt;"Kalifornia", "name:ps"=&gt;"کالیفرنیا", "name:pt"=&gt;"Califórnia", "name:qu"=&gt;"California suyu", "name:rm"=&gt;"California", "name:ro"=&gt;"California", "name:ru"=&gt;"Калифорния", "name:sa"=&gt;"कालिफ़ोर्निया", "name:sc"=&gt;"Califòrnia", "name:sd"=&gt;"ڪيليفورنيا", "name:se"=&gt;"Kalifornia", "name:sh"=&gt;"Kalifornija", "name:sk"=&gt;"Kalifornia", "name:sl"=&gt;"Kalifornija", "name:sm"=&gt;"Kalefonia", "name:so"=&gt;"Kalifornia", "name:sq"=&gt;"Kalifornia", "name:sr"=&gt;"Калифорнија", "name:su"=&gt;"Kalifornia", "name:sv"=&gt;"Kalifornien", "name:sw"=&gt;"California", "name:ta"=&gt;"கலிபோர்னியா", "name:te"=&gt;"కాలిఫోర్నియా", "name:tg"=&gt;"Калифорния", "name:th"=&gt;"รัฐแคลิฟอร์เนีย", "name:tl"=&gt;"California", "name:tr"=&gt;"Kaliforniya", "name:tt"=&gt;"Калифорния", "name:ug"=&gt;"Kaliforniye Shitati", "name:uk"=&gt;"Каліфорнія", "name:ur"=&gt;"کیلیفورنیا", "name:uz"=&gt;"Kaliforniya", "name:vi"=&gt;"Ca Li", "name:vo"=&gt;"Kalifornän", "name:wa"=&gt;"Californeye", "name:xh"=&gt;"IKhalifoniya", "name:yi"=&gt;"קאליפארניע", "name:yo"=&gt;"Kalifọ́rníà", "name:zh"=&gt;"加利福尼亚州/加利福尼亞州", "name:zu"=&gt;"California", "name:als"=&gt;"Kalifornien", "name:ang"=&gt;"California", "name:arz"=&gt;"كاليفورنيا", "name:ast"=&gt;"California", "name:azb"=&gt;"کالیفورنیا ایالتی", "name:bar"=&gt;"Kalifornien", "name:bcl"=&gt;"California", "name:bpy"=&gt;"ক্যালিফোর্নিয়া", "name:bxr"=&gt;"Калифорни", "name:cdo"=&gt;"California", "name:ceb"=&gt;"California", "name:chy"=&gt;"California", "name:ckb"=&gt;"کالیفۆرنیا", "name:diq"=&gt;"Kaliforniya", "name:dsb"=&gt;"Kaliforniska", "name:eml"=&gt;"Califòrgna", "name:frp"=&gt;"California", "name:frr"=&gt;"California", "name:gag"=&gt;"Kaliforniya", "name:gan"=&gt;"加利福尼亞州", "name:got"=&gt;"𐌺𐌰𐌻𐌹𐍆𐌰𐌿𐍂𐌽𐌾𐌰", "name:hak"=&gt;"California", "name:haw"=&gt;"Kaleponi", "name:hif"=&gt;"California", "name:hsb"=&gt;"Kaliforniska", "name:ilo"=&gt;"California", "name:jbo"=&gt;"la .kaliforniias.", "name:kaa"=&gt;"Kaliforniya shtati", "name:kab"=&gt;"Kalifurnya", "name:kbp"=&gt;"Kalɩfɔrnii", "name:krc"=&gt;"Калифорния", "name:lad"=&gt;"Kalifornia", "name:lfn"=&gt;"California", "name:lij"=&gt;"California", "name:lmo"=&gt;"California", "name:lrc"=&gt;"کاليفورنيا", "name:mai"=&gt;"क्यालिफोर्निया", "name:mhr"=&gt;"Калифорний", "name:mrj"=&gt;"Калифорни", "name:mzn"=&gt;"کالیفرنیا", "name:nah"=&gt;"California", "name:nan"=&gt;"California", "name:nds"=&gt;"Kalifornien", "name:new"=&gt;"क्यालिफोर्निया", "name:pag"=&gt;"California", "name:pam"=&gt;"California", "name:pap"=&gt;"California", "name:pcd"=&gt;"Californie", "name:pdc"=&gt;"Kalifornie", "name:pfl"=&gt;"Kalifornien", "name:pms"=&gt;"Califòrnia", "name:pnb"=&gt;"کیلیفورنیا", "name:sah"=&gt;"Калифорния", "name:scn"=&gt;"California", "name:sco"=&gt;"Californie", "name:stq"=&gt;"Kalifornien", "name:szl"=&gt;"Kaliforńijo", "name:tet"=&gt;"California", "name:tok"=&gt;"ma Kaliponija", "name:tzl"=&gt;"Californica", "name:vec"=&gt;"Całifornia", "name:war"=&gt;"California", "name:wuu"=&gt;"加利福尼亚", "name:xal"=&gt;"Калифорния", "name:xmf"=&gt;"კალიფორნია", "name:yue"=&gt;"加利福尼亞州", "name:zea"=&gt;"California", "short_name"=&gt;"Calif.", "alt_name:vi"=&gt;"California;Ca-li-phoóc-ni-a;Ca-li-pho-ni-a", "name:nds-nl"=&gt;"Kalifornië", "name:bat-smg"=&gt;"Kalėfuornėjė", "name:cbk-zam"=&gt;"California", "name:zh-Hans"=&gt;"加利福尼亚州", "name:zh-Hant"=&gt;"加利福尼亞州", "name:be-tarask"=&gt;"Каліфорнія", "name:abbreviation"=&gt;"Calif."</td>
      <td>298977868</td>
      <td>NaN</td>
      <td>296287291.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>California</td>
    </tr>
  </tbody>
</table>
<p>56 rows × 25 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>Alaska</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> all-cities-and-towns-extract-from-osm/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many countries are south of the equator?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>len(df[df.longitude < 0].country_code.unique())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>len(df[df.longitude < 0].country_code.unique())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = len(df[df.longitude < 0].country_code.unique())
</code></pre>
        <p><span onclick="$('#var_output_15b17918').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_15b17918" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>55</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>55</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> all-cities-and-towns-extract-from-osm/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the population of each state if available.  ---</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_states['population'] = df_states.extratags\
    .apply(breakdown_tags)\
    .apply(lambda x: None if 'population' not in x else x['population'])

df_states[['name_en', 'population']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_states['population'] = df_states.extratags\
    .apply(breakdown_tags)\
    .apply(lambda x: None if 'population' not in x else x['population'])

df_states[['name_en', 'population']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_states['population'] = df_states.extratags.apply(breakdown_tags).apply(
    lambda x: None if 'population' not in x else x['population'])
__output__ = df_states[['name_en', 'population']]
</code></pre>
        <p><span onclick="$('#var_output_4f51dd47').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4f51dd47" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name_en</th>
      <th>population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>103969</th>
      <td>American Samoa</td>
      <td>65600</td>
    </tr>
    <tr>
      <th>122425</th>
      <td>Utah</td>
      <td>2949902</td>
    </tr>
    <tr>
      <th>122428</th>
      <td>Florida</td>
      <td>19893297</td>
    </tr>
    <tr>
      <th>123436</th>
      <td>Ohio</td>
      <td>11594163</td>
    </tr>
    <tr>
      <th>123437</th>
      <td>American Samoa</td>
      <td>None</td>
    </tr>
    <tr>
      <th>124000</th>
      <td>Illinois</td>
      <td>12880580</td>
    </tr>
    <tr>
      <th>124001</th>
      <td>Alabama</td>
      <td>4779736</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>124080</th>
      <td>Colorado</td>
      <td>5355866</td>
    </tr>
    <tr>
      <th>124084</th>
      <td>North Dakota</td>
      <td>641481</td>
    </tr>
    <tr>
      <th>124088</th>
      <td>Guam</td>
      <td>185427</td>
    </tr>
    <tr>
      <th>124089</th>
      <td>Idaho</td>
      <td>1634464</td>
    </tr>
    <tr>
      <th>124092</th>
      <td>Iowa</td>
      <td>3107124</td>
    </tr>
    <tr>
      <th>124096</th>
      <td>Maryland</td>
      <td>5976407</td>
    </tr>
    <tr>
      <th>124196</th>
      <td>California</td>
      <td>37253956</td>
    </tr>
  </tbody>
</table>
<p>56 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_states, __output__ </p>
    
          <p>df_states (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_code</th>
      <th>latitude</th>
      <th>longitude</th>
      <th>name</th>
      <th>place_id</th>
      <th>parent_place_id</th>
      <th>linked_place_id</th>
      <th>...</th>
      <th>wikipedia</th>
      <th>token_info</th>
      <th>housenumber</th>
      <th>postcode</th>
      <th>address_dict</th>
      <th>name_en</th>
      <th>population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>103969</th>
      <td>us</td>
      <td>-170.692511</td>
      <td>-14.289304</td>
      <td>"ref"=&gt;"AS", "name"=&gt;"American Samoa", "name:ar"=&gt;"ساموا الأمريكية", "name:be"=&gt;"Амерыканскае Самоа", "name:br"=&gt;"Samoa Amerikan", "name:ca"=&gt;"Samoa Nord-americana", "name:cy"=&gt;"Samoa America", "name:da"=&gt;"Amerikansk Samoa", "name:de"=&gt;"Amerikanisch-Samoa", "name:el"=&gt;"Αμερικανικές Σαμόα", "name:en"=&gt;"American Samoa", "name:eo"=&gt;"Usona Samoo", "name:es"=&gt;"Samoa Americana", "name:et"=&gt;"Ameerika Samoa", "name:fa"=&gt;"ساموآی آمریکا", "name:fi"=&gt;"Amerikan Samoa", "name:fr"=&gt;"Samoa Américaines", "name:gv"=&gt;"Samoa Americaanagh", "name:he"=&gt;"סמואה האמריקנית", "name:hr"=&gt;"Američka Samoa", "name:ia"=&gt;"Samoa American", "name:io"=&gt;"Samoa Usana", "name:is"=&gt;"Bandaríska Samóa", "name:it"=&gt;"Samoa Americane", "name:ja"=&gt;"アメリカ領サモア", "name:kn"=&gt;"ಅಮೆರಿಕನ್ ಸಮೋವಾ", "name:ku"=&gt;"Samoaya Amerîkanî", "name:nl"=&gt;"Amerikaans-Samoa", "name:no"=&gt;"Amerikansk Samoa", "name:pl"=&gt;"Samoa Amerykańskie", "name:ru"=&gt;"Американское Самоа", "name:sk"=&gt;"Americká Samoa", "name:sm"=&gt;"Amerika Sāmoa", "name:sr"=&gt;"Америчка Самоа", "name:sv"=&gt;"Amerikanska Samoa", "name:uk"=&gt;"Американське Самоа", "name:uz"=&gt;"Amerika Samoasi", "name:vi"=&gt;"Samoa thuộc Mỹ", "name:zh"=&gt;"美属萨摩亚", "name:jbo"=&gt;"mer.samoas", "name:lfn"=&gt;"Samoa American"</td>
      <td>4065890</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'AS', 'continent': 'Oceania'}</td>
      <td>American Samoa</td>
      <td>65600</td>
    </tr>
    <tr>
      <th>122425</th>
      <td>us</td>
      <td>-111.714358</td>
      <td>39.422519</td>
      <td>"ref"=&gt;"UT", "name"=&gt;"Utah", "name:be"=&gt;"Юта", "name:en"=&gt;"Utah", "name:eo"=&gt;"Utaho", "name:fy"=&gt;"Utah", "name:hu"=&gt;"Utah", "name:ko"=&gt;"유타", "name:mo"=&gt;"Юта", "name:mr"=&gt;"युट्हा", "name:nl"=&gt;"Utah", "name:pl"=&gt;"Utah", "name:ru"=&gt;"Юта", "name:uk"=&gt;"Юта", "name:zh"=&gt;"犹他州", "name:tok"=&gt;"ma Juta", "name:short"=&gt;"UT", "name:abbreviation"=&gt;"Utah"</td>
      <td>1244489</td>
      <td>NaN</td>
      <td>294960736.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Utah</td>
      <td>2949902</td>
    </tr>
    <tr>
      <th>122428</th>
      <td>us</td>
      <td>-81.463983</td>
      <td>27.756767</td>
      <td>"ref"=&gt;"FL", "name"=&gt;"Florida", "name:af"=&gt;"Florida", "name:an"=&gt;"Florida", "name:ar"=&gt;"فلوريدا", "name:ay"=&gt;"Florida suyu", "name:az"=&gt;"Florida", "name:ba"=&gt;"Флорида", "name:be"=&gt;"Фларыда", "name:bg"=&gt;"Флорида", "name:bh"=&gt;"फ्लोरिडा", "name:bi"=&gt;"Florida", "name:bn"=&gt;"ফ্লোরিডা", "name:bo"=&gt;"ཧྥོ་ལོ་རི་ཌ།", "name:br"=&gt;"Florida", "name:bs"=&gt;"Florida", "name:ca"=&gt;"Florida", "name:ce"=&gt;"Флорида", "name:cs"=&gt;"Florida", "name:cv"=&gt;"Флорида", "name:cy"=&gt;"Florida", "name:da"=&gt;"Florida", "name:de"=&gt;"Florida", "name:el"=&gt;"Φλόριντα", "name:en"=&gt;"Florida", "name:eo"=&gt;"Florido", "name:es"=&gt;"Florida", "name:et"=&gt;"Florida", "name:eu"=&gt;"Florida", "name:fa"=&gt;"فلوریدا", "name:fi"=&gt;"Florida", "name:fo"=&gt;"Florida", "name:fr"=&gt;"Floride", "name:fy"=&gt;"Floarida", "name:ga"=&gt;"Florida", "name:gd"=&gt;"Florida", "name:gl"=&gt;"Florida", "name:gn"=&gt;"Florida", "name:gv"=&gt;"Florida", "name:ha"=&gt;"Florida", "name:he"=&gt;"פלורידה", "name:hi"=&gt;"फ़्लोरिडा", "name:hr"=&gt;"Florida", "name:ht"=&gt;"Florid", "name:hu"=&gt;"Florida", "name:hy"=&gt;"Ֆլորիդա", "name:ia"=&gt;"Florida", "name:id"=&gt;"Florida", "name:ie"=&gt;"Florida", "name:ig"=&gt;"Flórídạ", "name:ik"=&gt;"Florida", "name:io"=&gt;"Florida", "name:is"=&gt;"Flórída", "name:it"=&gt;"Florida", "name:iu"=&gt;"ᑉᓘᕇᑖ", "name:ja"=&gt;"フロリダ州", "name:jv"=&gt;"Florida", "name:ka"=&gt;"ფლორიდა", "name:kk"=&gt;"Флорида", "name:kn"=&gt;"ಫ್ಲಾರಿಡ", "name:ko"=&gt;"플로리다", "name:ku"=&gt;"Florida", "name:kw"=&gt;"Florida", "name:la"=&gt;"Florida", "name:lb"=&gt;"Florida", "name:li"=&gt;"Florida", "name:lt"=&gt;"Florida", "name:lv"=&gt;"Florida", "name:mg"=&gt;"Florida", "name:mi"=&gt;"Florida", "name:mk"=&gt;"Флорида", "name:ml"=&gt;"ഫ്ലോറിഡ", "name:mn"=&gt;"Флорида", "name:mo"=&gt;"Флорида", "name:mr"=&gt;"फ्लोरिडा", "name:ms"=&gt;"Florida", "name:my"=&gt;"ဖလော်ရီဒါပြည်နယ်", "name:na"=&gt;"Florida", "name:ne"=&gt;"फ्लोरिडा", "name:nl"=&gt;"Florida", "name:nn"=&gt;"Florida", "name:no"=&gt;"Florida", "name:nv"=&gt;"Gah Bikeeʼ Taah Yíʼáhí", "name:oc"=&gt;"Florida", "name:os"=&gt;"Флоридæ", "name:pa"=&gt;"ਫ਼ਲੌਰਿਡਾ", "name:pi"=&gt;"फ्लोरिडा", "name:pl"=&gt;"Floryda", "name:pt"=&gt;"Flórida", "name:qu"=&gt;"Florida suyu", "name:rm"=&gt;"Florida", "name:ro"=&gt;"Florida", "name:ru"=&gt;"Флорида", "name:sa"=&gt;"फ्लोरिडा", "name:sc"=&gt;"Flòrida", "name:se"=&gt;"Florida", "name:sh"=&gt;"Florida", "name:sk"=&gt;"Florida", "name:sl"=&gt;"Florida", "name:sn"=&gt;"Florida", "name:so"=&gt;"Florida", "name:sq"=&gt;"Florida", "name:sr"=&gt;"Флорида", "name:sv"=&gt;"Florida", "name:sw"=&gt;"Florida", "name:ta"=&gt;"புளோரிடா", "name:te"=&gt;"ఫ్లోరిడా", "name:tg"=&gt;"Флорида", "name:th"=&gt;"รัฐฟลอริดา", "name:tl"=&gt;"Florida", "name:tr"=&gt;"Florida", "name:tt"=&gt;"Флорида", "name:ug"=&gt;"Florida Shitati", "name:uk"=&gt;"Флорида", "name:ur"=&gt;"فلوریڈا", "name:uz"=&gt;"Florida", "name:vi"=&gt;"Florida", "name:vo"=&gt;"Florida", "name:xh"=&gt;"IFlorida", "name:yi"=&gt;"פלארידע", "name:yo"=&gt;"Florida", "name:zh"=&gt;"佛罗里达州/佛羅里達州", "name:zu"=&gt;"Florida", "name:als"=&gt;"Florida", "name:ang"=&gt;"Florida", "name:arz"=&gt;"فلوريدا", "name:ast"=&gt;"Florida", "name:azb"=&gt;"فلوریدا ایالتی", "name:ban"=&gt;"Florida", "name:bar"=&gt;"Florida", "name:bcl"=&gt;"Florida", "name:bpy"=&gt;"ফ্লোরিডা", "name:bxr"=&gt;"Флорида", "name:cdo"=&gt;"Florida", "name:ceb"=&gt;"Florida", "name:ckb"=&gt;"فلۆریدا", "name:diq"=&gt;"Florida", "name:eml"=&gt;"Flòrida", "name:frp"=&gt;"Florida", "name:frr"=&gt;"Florida", "name:gag"=&gt;"Florida", "name:hak"=&gt;"Florida", "name:haw"=&gt;"Pololika", "name:hif"=&gt;"Florida", "name:hsb"=&gt;"Florida", "name:ilo"=&gt;"Florida", "name:kaa"=&gt;"Florida", "name:kbp"=&gt;"Floriidii", "name:krc"=&gt;"Флорида", "name:lad"=&gt;"Florida", "name:lez"=&gt;"Флорида", "name:lfn"=&gt;"Florida", "name:lij"=&gt;"Florida", "name:lmo"=&gt;"Florida", "name:lrc"=&gt;"فلوریدا", "name:mai"=&gt;"फ्लोरिडा", "name:mhr"=&gt;"Флорида", "name:mrj"=&gt;"Флорида", "name:mzn"=&gt;"فلوریدا", "name:nan"=&gt;"Florida", "name:nds"=&gt;"Florida", "name:new"=&gt;"फ्लोरिदा", "name:pam"=&gt;"Florida", "name:pap"=&gt;"Florida", "name:pms"=&gt;"Florida", "name:pnb"=&gt;"فلوریڈا", "name:rue"=&gt;"Флоріда", "name:sah"=&gt;"Флорида", "name:scn"=&gt;"Florida", "name:sco"=&gt;"Florida", "name:stq"=&gt;"Florida", "name:szl"=&gt;"Florida", "name:tok"=&gt;"ma Lowita", "name:vec"=&gt;"Florida", "name:war"=&gt;"Florida", "name:wuu"=&gt;"佛罗里达州", "name:xal"=&gt;"Флорида", "name:xmf"=&gt;"ფლორიდა", "name:yue"=&gt;"佛羅里達州", "name:zea"=&gt;"Florida", "short_name"=&gt;"Fla.", "name:nds-nl"=&gt;"Florida", "name:bat-smg"=&gt;"Fluorėda", "name:cbk-zam"=&gt;"Florida", "name:zh-Hans"=&gt;"佛罗里达州", "name:zh-Hant"=&gt;"佛羅里達州", "name:be-tarask"=&gt;"Флорыда"</td>
      <td>20789338</td>
      <td>NaN</td>
      <td>294924757.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'US'}</td>
      <td>Florida</td>
      <td>19893297</td>
    </tr>
    <tr>
      <th>123436</th>
      <td>us</td>
      <td>-82.688140</td>
      <td>40.225357</td>
      <td>"ref"=&gt;"OH", "name"=&gt;"Ohio", "name:be"=&gt;"Агаё", "name:en"=&gt;"Ohio", "name:eo"=&gt;"Ohio", "name:fy"=&gt;"Ohio", "name:hu"=&gt;"Ohio", "name:mo"=&gt;"Охайо", "name:mr"=&gt;"ओहायो", "name:nl"=&gt;"Ohio", "name:pl"=&gt;"Ohio", "name:ru"=&gt;"Огайо", "name:uk"=&gt;"Огайо", "name:zh"=&gt;"俄亥俄州", "name:tok"=&gt;"ma Owajo", "name:short"=&gt;"OH", "name:abbreviation"=&gt;"Ohio"</td>
      <td>1251941</td>
      <td>NaN</td>
      <td>295535828.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Ohio</td>
      <td>11594163</td>
    </tr>
    <tr>
      <th>123437</th>
      <td>us</td>
      <td>-170.713148</td>
      <td>-14.297124</td>
      <td>"ref"=&gt;"AS", "name"=&gt;"American Samoa", "name:af"=&gt;"Amerikaans-Samoa", "name:am"=&gt;"አሜሪካዊ ሳሞዓ", "name:ar"=&gt;"ساموا الأمريكية", "name:az"=&gt;"Amerika Samoası", "name:ba"=&gt;"Америка Самоаһы", "name:be"=&gt;"Амерыканскае Самоа", "name:bg"=&gt;"Американска Самоа", "name:bn"=&gt;"মার্কিন সামোয়া", "name:br"=&gt;"Samoa Amerikan", "name:bs"=&gt;"Američka Samoa", "name:ca"=&gt;"Samoa Nord-americana", "name:ce"=&gt;"Америкин Самоа", "name:cs"=&gt;"Americká Samoa", "name:cy"=&gt;"Samoa America", "name:da"=&gt;"Amerikansk Samoa", "name:de"=&gt;"Amerikanisch-Samoa", "name:dv"=&gt;"އެމެރިކަން ސަމޯއާ", "name:el"=&gt;"Αμερικανική Σαμόα", "name:en"=&gt;"American Samoa", "name:eo"=&gt;"Samoo Usona", "name:es"=&gt;"Samoa Americana", "name:et"=&gt;"Ameerika Samoa", "name:eu"=&gt;"Samoa Estatubatuarra", "name:fa"=&gt;"ساموآی آمریکا", "name:fi"=&gt;"Amerikan Samoa", "name:fo"=&gt;"Amerikanska Sámoa", "name:fr"=&gt;"Samoa américaines", "name:fy"=&gt;"Amerikaansk-Samoä", "name:ga"=&gt;"Samó Mheiriceá", "name:gd"=&gt;"Samoa Aimearaganach", "name:gl"=&gt;"Samoa Americana", "name:gn"=&gt;"Samóa Amérika pegua", "name:he"=&gt;"סמואה האמריקנית", "name:hi"=&gt;"अमेरिकी समोआ", "name:hr"=&gt;"Američka Samoa", "name:hu"=&gt;"Amerikai Szamoa", "name:hy"=&gt;"Ամերիկյան Սամոա", "name:id"=&gt;"Samoa Amerika", "name:io"=&gt;"Usana Samoa", "name:is"=&gt;"Bandaríska Samóa", "name:it"=&gt;"Samoa Americane", "name:ja"=&gt;"アメリカ領サモア", "name:jv"=&gt;"Samoa Amérika", "name:ka"=&gt;"ამერიკის სამოა", "name:kk"=&gt;"Америка Самоасы", "name:ko"=&gt;"아메리칸사모아", "name:kw"=&gt;"아메리칸사모아", "name:ky"=&gt;"Америка Самоасы", "name:la"=&gt;"Samoa Americana", "name:li"=&gt;"Amerikaans Samoa", "name:lt"=&gt;"Amerikos Samoa", "name:lv"=&gt;"ASV Samoa", "name:mi"=&gt;"Hāmoa Marikena", "name:mk"=&gt;"Американска Самоа", "name:ml"=&gt;"അമേരിക്കൻ സമോവ", "name:mr"=&gt;"अमेरिकन सामोआ", "name:ms"=&gt;"Samoa Amerika", "name:ne"=&gt;"अमेरिकी सामोआ", "name:nl"=&gt;"Amerikaans-Samoa", "name:nn"=&gt;"Amerikansk Samoa", "name:no"=&gt;"Amerikansk Samoa", "name:oc"=&gt;"Samoa Americana", "name:or"=&gt;"ଆମେରିକୀୟ ସମୋଆ", "name:os"=&gt;"Америкæйы Самоæ", "name:pa"=&gt;"ਅਮਰੀਕੀ ਸਮੋਆ", "name:pl"=&gt;"Samoa Amerykańskie", "name:pt"=&gt;"Samoa Americana", "name:qu"=&gt;"Amirika Samwa", "name:ro"=&gt;"Samoa Americană", "name:ru"=&gt;"Американское Самоа", "name:rw"=&gt;"Samowa Nyamerika", "name:sc"=&gt;"Samoa Americanas", "name:se"=&gt;"Amerihká Samoa", "name:sh"=&gt;"Američka Samoa", "name:sk"=&gt;"Americká Samoa", "name:sl"=&gt;"Ameriška Samoa", "name:sm"=&gt;"Amerika Sāmoa", "name:sn"=&gt;"American Samoa", "name:sq"=&gt;"Samoa Amerikane", "name:sr"=&gt;"Америчка Самоа", "name:su"=&gt;"Samoa Amérika", "name:sv"=&gt;"Amerikanska Samoa", "name:sw"=&gt;"Samoa ya Marekani", "name:ta"=&gt;"அமெரிக்க சமோவா", "name:tg"=&gt;"Самоаи Америкоӣ", "name:th"=&gt;"อเมริกันซามัว", "name:tl"=&gt;"American Samoa", "name:to"=&gt;"Haʻamoa-ʻAmelika", "name:tr"=&gt;"Amerikan Samoası", "name:tt"=&gt;"Америка Самоасы", "name:ug"=&gt;"ئامېرىكىغا قاراشلىق ساموئا", "name:uk"=&gt;"Американське Самоа", "name:ur"=&gt;"امریکی سمووا", "name:uz"=&gt;"Amerika Samoasi", "name:vi"=&gt;"Samoa thuộc Mỹ", "name:yi"=&gt;"אמעריקאנישער סאמאא", "name:yo"=&gt;"Sàmóà Amẹ́ríkà", "name:zh"=&gt;"美屬薩摩亞", "name:ace"=&gt;"Samoa Amirika", "name:arz"=&gt;"ساموا الامريكيه", "name:ast"=&gt;"Samoa Americana", "name:bar"=&gt;"Amerikanisch-Samoa", "name:bpy"=&gt;"আমেরিকান সামোয়া", "name:ceb"=&gt;"American Samoa", "name:chr"=&gt;"ᎠᎺᎵᎧ ᏌᎼᎠ", "name:ckb"=&gt;"ساموای ئەمریکا", "name:frp"=&gt;"Samoa amèriquènes", "name:frr"=&gt;"Amerikoonsk Samoa", "name:gag"=&gt;"Amerikan Samoa", "name:hak"=&gt;"Mî-koet liâng Samoa", "name:haw"=&gt;"Sāmoa ʻAmelika", "name:hif"=&gt;"American Samoa", "name:kaa"=&gt;"Amerikalıq Samoa", "name:lfn"=&gt;"Samoa American", "name:lij"=&gt;"Samöa Americann-e", "name:pam"=&gt;"Amerika Samoa", "name:pcd"=&gt;"Samoa anméricaines", "name:rue"=&gt;"Америцька Самоа", "name:scn"=&gt;"Samoa Miricana", "name:shn"=&gt;"သႃႇမူဝ်းဝႃႇ ၶွင်ဢမေႇရိၵၼ်ႇ", "name:war"=&gt;"American Samoa", "name:wuu"=&gt;"美属萨摩亚", "name:xmf"=&gt;"ამერიკაშ სამოა", "ISO3166-2"=&gt;"US-AS"</td>
      <td>98858981</td>
      <td>NaN</td>
      <td>295585742.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'AS', 'continent': 'Oceania'}</td>
      <td>American Samoa</td>
      <td>None</td>
    </tr>
    <tr>
      <th>124000</th>
      <td>us</td>
      <td>-89.433729</td>
      <td>40.079661</td>
      <td>"ref"=&gt;"IL", "name"=&gt;"Illinois", "name:be"=&gt;"Ілінойс", "name:en"=&gt;"Illinois", "name:eo"=&gt;"Ilinojso", "name:fy"=&gt;"Illinois", "name:hu"=&gt;"Illinois", "name:ko"=&gt;"일리노이", "name:mo"=&gt;"Иллинойс", "name:mr"=&gt;"इलीनोय", "name:nl"=&gt;"Illinois", "name:pl"=&gt;"Illinois", "name:ru"=&gt;"Иллинойс", "name:uk"=&gt;"Іллінойс", "name:zh"=&gt;"伊利诺伊州 / 伊利諾州", "name:hak"=&gt;"Illinois", "name:nan"=&gt;"Illinois", "name:tok"=&gt;"ma Ilino", "name:tzl"=&gt;"Idinois", "name:short"=&gt;"IL", "short_name"=&gt;"Ill.", "name:zh-Hans"=&gt;"伊利诺伊州", "name:zh-Hant"=&gt;"伊利諾州", "name:abbreviation"=&gt;"Il."</td>
      <td>4223149</td>
      <td>NaN</td>
      <td>294867509.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'US', 'continent': 'North America'}</td>
      <td>Illinois</td>
      <td>12880580</td>
    </tr>
    <tr>
      <th>124001</th>
      <td>us</td>
      <td>-86.829534</td>
      <td>33.258882</td>
      <td>"ref"=&gt;"AL", "name"=&gt;"Alabama", "name:be"=&gt;"Алабама", "name:en"=&gt;"Alabama", "name:eo"=&gt;"Alabamo", "name:fy"=&gt;"Alabama", "name:hu"=&gt;"Alabama", "name:ko"=&gt;"앨라배마", "name:mo"=&gt;"Алабама", "name:mr"=&gt;"आलाबामा", "name:nl"=&gt;"Alabama", "name:pl"=&gt;"Alabama", "name:ru"=&gt;"Алабама", "name:uk"=&gt;"Алабама", "name:zh"=&gt;"亚拉巴马州 / 阿拉巴馬州", "name:cdo"=&gt;"Alabama", "name:nan"=&gt;"Alabama", "name:tok"=&gt;"ma Alapama", "name:wuu"=&gt;"阿拉巴馬州", "name:yue"=&gt;"阿拉巴馬州", "name:short"=&gt;"AL", "short_name"=&gt;"Ala.", "name:zh-Hans"=&gt;"亚拉巴马州", "name:zh-Hant"=&gt;"阿拉巴馬州", "name:abbreviation"=&gt;"Ala."</td>
      <td>1242347</td>
      <td>NaN</td>
      <td>294919109.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'US', 'continent': 'North America'}</td>
      <td>Alabama</td>
      <td>4779736</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>124080</th>
      <td>us</td>
      <td>-105.607716</td>
      <td>38.725178</td>
      <td>"ref"=&gt;"CO", "name"=&gt;"Colorado", "name:be"=&gt;"Каларада", "name:en"=&gt;"Colorado", "name:eo"=&gt;"Koloradio", "name:fy"=&gt;"Kolorado", "name:hu"=&gt;"Colorado", "name:ko"=&gt;"콜로라도", "name:mo"=&gt;"Колорадо", "name:mr"=&gt;"कोलोराडो", "name:nl"=&gt;"Colorado", "name:pl"=&gt;"Kolorado", "name:ru"=&gt;"Колорадо", "name:uk"=&gt;"Колорадо", "name:zh"=&gt;"科罗拉多州 / 科羅拉多州", "name:hak"=&gt;"Colorado", "name:nan"=&gt;"Colorado", "name:tok"=&gt;"ma Kolowato", "name:short"=&gt;"CO", "short_name"=&gt;"Colo.", "name:zh-Hans"=&gt;"科罗拉多州", "name:zh-Hant"=&gt;"科羅拉多州", "name:abbreviation"=&gt;"Colo."</td>
      <td>1249311</td>
      <td>NaN</td>
      <td>297912280.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Colorado</td>
      <td>5355866</td>
    </tr>
    <tr>
      <th>124084</th>
      <td>us</td>
      <td>-100.540737</td>
      <td>47.620146</td>
      <td>"ref"=&gt;"ND", "name"=&gt;"North Dakota", "name:be"=&gt;"Паўночная Дакота", "name:cs"=&gt;"Severní Dakota", "name:de"=&gt;"Nord-Dakota", "name:en"=&gt;"North Dakota", "name:eo"=&gt;"Norda Dakoto", "name:es"=&gt;"Dakota del Norte", "name:et"=&gt;"Põhja-Dakota", "name:fr"=&gt;"Dakota du Nord", "name:fy"=&gt;"Noard-Dakota", "name:he"=&gt;"דקוטה הצפונית", "name:hu"=&gt;"Észak-Dakota", "name:it"=&gt;"Dakota del Nord", "name:ko"=&gt;"노스다코타", "name:lt"=&gt;"Šiaurės Dakota", "name:mo"=&gt;"Дакота де Норд", "name:mr"=&gt;"उत्तर डकोटा", "name:nl"=&gt;"North Dakota", "name:pl"=&gt;"Dakota Północna", "name:pt"=&gt;"Dakota do Norte", "name:ru"=&gt;"Северная Дакота", "name:sk"=&gt;"Severná Dakota", "name:tt"=&gt;"Төньяк Дакота", "name:uk"=&gt;"Північна Дакота", "name:vi"=&gt;"Bắc Dakota", "name:zh"=&gt;"北达科他州 / 北達科他州", "name:ast"=&gt;"Dakota del Norte", "name:hak"=&gt;"Pet Tha̍t-khô-thâ", "name:lfn"=&gt;"Dakota Norde", "name:nan"=&gt;"North Dakota", "name:tok"=&gt;"ma Notakota", "name:short"=&gt;"ND", "short_name"=&gt;"N.D.", "name:zh-Hans"=&gt;"北达科他州", "name:zh-Hant"=&gt;"北達科他州", "name:abbreviation"=&gt;"N.D."</td>
      <td>1267737</td>
      <td>NaN</td>
      <td>297100313.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'US', 'continent': 'North America'}</td>
      <td>North Dakota</td>
      <td>641481</td>
    </tr>
    <tr>
      <th>124088</th>
      <td>us</td>
      <td>144.765168</td>
      <td>13.449994</td>
      <td>"ref"=&gt;"GU", "name"=&gt;"Guam", "name:ar"=&gt;"غوام", "name:be"=&gt;"Гуам", "name:br"=&gt;"Guam", "name:ca"=&gt;"Guam", "name:de"=&gt;"Guam", "name:el"=&gt;"Γκουάμ", "name:en"=&gt;"Guam", "name:eo"=&gt;"Gvamo", "name:es"=&gt;"Guam", "name:fa"=&gt;"گوآم", "name:fi"=&gt;"Guam", "name:fr"=&gt;"Guam", "name:gv"=&gt;"Guam", "name:he"=&gt;"גואם", "name:hu"=&gt;"Guam", "name:ia"=&gt;"Guam", "name:io"=&gt;"Guam", "name:it"=&gt;"Guam", "name:ja"=&gt;"グアム", "name:kn"=&gt;"ಗ್ವಾಮ್", "name:ku"=&gt;"Guam", "name:lt"=&gt;"Guamas", "name:no"=&gt;"Guam", "name:pl"=&gt;"Guam", "name:ru"=&gt;"Гуам", "name:sk"=&gt;"Guam", "name:sl"=&gt;"Guam", "name:sr"=&gt;"Гуам", "name:sv"=&gt;"Guam", "name:uk"=&gt;"Гуам", "name:vi"=&gt;"Guam", "name:zh"=&gt;"关岛 / 關島", "name:lfn"=&gt;"Guam", "name:nan"=&gt;"Guam", "name:nds"=&gt;"Guam", "ISO3166-2"=&gt;"US-GU", "old_name:es"=&gt;"Guaján", "name:zh-Hans"=&gt;"关岛", "name:zh-Hant"=&gt;"關島", "official_name:eo"=&gt;"Teritorio de Gvamo", "official_name:pl"=&gt;"Terytorium Guam"</td>
      <td>5098472</td>
      <td>NaN</td>
      <td>297163263.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>{'country': 'GU', 'continent': 'Oceania'}</td>
      <td>Guam</td>
      <td>185427</td>
    </tr>
    <tr>
      <th>124089</th>
      <td>us</td>
      <td>-114.015407</td>
      <td>43.644764</td>
      <td>"ref"=&gt;"ID", "name"=&gt;"Idaho", "name:be"=&gt;"Айдаха", "name:en"=&gt;"Idaho", "name:eo"=&gt;"Idaho", "name:fy"=&gt;"Idaho", "name:hu"=&gt;"Idaho", "name:ko"=&gt;"아이다호", "name:mo"=&gt;"Айдахо", "name:mr"=&gt;"इडाहो", "name:nl"=&gt;"Idaho", "name:pl"=&gt;"Idaho", "name:ru"=&gt;"Айдахо", "name:uk"=&gt;"Айдахо", "name:zh"=&gt;"爱达荷州 / 愛達荷州", "name:hak"=&gt;"Idaho", "name:nan"=&gt;"Idaho", "name:tok"=&gt;"ma Atajo", "name:short"=&gt;"ID", "name:zh-Hans"=&gt;"爱达荷州", "name:zh-Hant"=&gt;"愛達荷州", "name:abbreviation"=&gt;"Idaho"</td>
      <td>1259416</td>
      <td>NaN</td>
      <td>298745703.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Idaho</td>
      <td>1634464</td>
    </tr>
    <tr>
      <th>124092</th>
      <td>us</td>
      <td>-93.312270</td>
      <td>41.921673</td>
      <td>"ref"=&gt;"IA", "name"=&gt;"Iowa", "name:be"=&gt;"Аёва", "name:en"=&gt;"Iowa", "name:eo"=&gt;"Iovao", "name:fy"=&gt;"Iowa", "name:hu"=&gt;"Iowa", "name:ko"=&gt;"아이오와", "name:mo"=&gt;"Айова", "name:mr"=&gt;"आयोवा", "name:nl"=&gt;"Iowa", "name:pl"=&gt;"Iowa", "name:ru"=&gt;"Айова", "name:uk"=&gt;"Айова", "name:zh"=&gt;"艾奥瓦州 / 愛荷華州", "name:cdo"=&gt;"Iowa", "name:hak"=&gt;"Iowa", "name:nan"=&gt;"Iowa", "name:tok"=&gt;"ma Ajowa", "name:wuu"=&gt;"艾奥瓦州", "name:yue"=&gt;"愛荷華州", "name:short"=&gt;"IA", "name:zh-Hans"=&gt;"艾奥瓦州", "name:zh-Hant"=&gt;"愛荷華州", "name:abbreviation"=&gt;"Iowa"</td>
      <td>1265812</td>
      <td>NaN</td>
      <td>297207729.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Iowa</td>
      <td>3107124</td>
    </tr>
    <tr>
      <th>124096</th>
      <td>us</td>
      <td>-76.938207</td>
      <td>39.516240</td>
      <td>"ref"=&gt;"MD", "name"=&gt;"Maryland", "name:be"=&gt;"Мэрыленд", "name:en"=&gt;"Maryland", "name:eo"=&gt;"Marilando", "name:fy"=&gt;"Marylân", "name:hu"=&gt;"Maryland", "name:ko"=&gt;"메릴랜드", "name:mo"=&gt;"Мериленд", "name:mr"=&gt;"मेरीलँड", "name:nl"=&gt;"Maryland", "name:pl"=&gt;"Maryland", "name:ru"=&gt;"Мэриленд", "name:uk"=&gt;"Меріленд", "name:zh"=&gt;"马里兰州 / 馬里蘭州", "name:hak"=&gt;"Maryland", "name:nan"=&gt;"Maryland", "name:tok"=&gt;"ma Mewilan", "name:wuu"=&gt;"马里兰州", "name:yue"=&gt;"馬里蘭州", "name:short"=&gt;"MD", "short_name"=&gt;"MD;Md.", "name:zh-Hans"=&gt;"马里兰州", "name:zh-Hant"=&gt;"馬里蘭州", "short_name:en"=&gt;"MD;Md.", "name:abbreviation"=&gt;"Md."</td>
      <td>1266168</td>
      <td>NaN</td>
      <td>297946862.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>Maryland</td>
      <td>5976407</td>
    </tr>
    <tr>
      <th>124196</th>
      <td>us</td>
      <td>-118.755997</td>
      <td>36.701463</td>
      <td>"ref"=&gt;"CA", "name"=&gt;"California", "name:af"=&gt;"Kalifornië", "name:am"=&gt;"ካሊፎርኒያ", "name:an"=&gt;"California", "name:ar"=&gt;"كاليفورنيا", "name:ay"=&gt;"California suyu", "name:az"=&gt;"Kaliforniya", "name:ba"=&gt;"Калифорния", "name:be"=&gt;"Каліфорнія", "name:bg"=&gt;"Калифорния", "name:bh"=&gt;"कैलिफोर्निया", "name:bi"=&gt;"Kalifornia", "name:bn"=&gt;"ক্যালিফোর্নিয়া", "name:bo"=&gt;"ཁྰ་ལེ་ཧྥོར་ནི་ཡ།", "name:br"=&gt;"Kalifornia", "name:bs"=&gt;"Kalifornija", "name:ca"=&gt;"Califòrnia", "name:ce"=&gt;"Калифорни", "name:co"=&gt;"California", "name:cs"=&gt;"Kalifornie", "name:cv"=&gt;"Калифорни", "name:cy"=&gt;"Califfornia", "name:da"=&gt;"Californien", "name:de"=&gt;"Kalifornien", "name:el"=&gt;"Καλιφόρνια", "name:en"=&gt;"California", "name:eo"=&gt;"Kalifornio", "name:es"=&gt;"California", "name:et"=&gt;"California", "name:eu"=&gt;"Kalifornia", "name:fa"=&gt;"کالیفرنیا", "name:fi"=&gt;"Kalifornia", "name:fo"=&gt;"Kalifornia", "name:fr"=&gt;"Californie", "name:fy"=&gt;"Kalifornje", "name:ga"=&gt;"California", "name:gd"=&gt;"Calafòrnia", "name:gl"=&gt;"California", "name:gn"=&gt;"California", "name:gu"=&gt;"કેલિફોર્નિયા", "name:gv"=&gt;"California", "name:ha"=&gt;"California", "name:he"=&gt;"קליפורניה", "name:hi"=&gt;"कैलिफ़ोर्निया", "name:hr"=&gt;"Kalifornija", "name:ht"=&gt;"Kalifòni", "name:hu"=&gt;"Kalifornia", "name:hy"=&gt;"Կալիֆոռնիա", "name:ia"=&gt;"California", "name:id"=&gt;"California", "name:ie"=&gt;"California", "name:ig"=&gt;"California", "name:ik"=&gt;"California", "name:io"=&gt;"Kalifornia", "name:is"=&gt;"Kalifornía", "name:it"=&gt;"California", "name:iu"=&gt;"ᑳᓖᐴᕐᓃᐊ", "name:ja"=&gt;"カリフォルニア州", "name:jv"=&gt;"California", "name:ka"=&gt;"კალიფორნია", "name:kk"=&gt;"Калифорния", "name:km"=&gt;"កាលីហ្វញ៉ា", "name:kn"=&gt;"ಕ್ಯಾಲಿಫೊರ್ನಿಯ", "name:ko"=&gt;"캘리포니아", "name:ku"=&gt;"Kalîforniya", "name:kw"=&gt;"Kaliforni", "name:ky"=&gt;"Калифорния", "name:la"=&gt;"California", "name:lb"=&gt;"Kalifornien", "name:li"=&gt;"Californië", "name:lt"=&gt;"Kalifornija", "name:lv"=&gt;"Kalifornija", "name:mg"=&gt;"Kalifornia", "name:mi"=&gt;"Karapōnia", "name:mk"=&gt;"Калифорнија", "name:ml"=&gt;"കാലിഫോർണിയ", "name:mn"=&gt;"Калифорни", "name:mo"=&gt;"Калифорния", "name:mr"=&gt;"कॅलिफोर्निया", "name:ms"=&gt;"California", "name:my"=&gt;"ကယ်လီဖိုးနီးယားပြည်နယ်", "name:na"=&gt;"California", "name:ne"=&gt;"क्यालिफोर्निया", "name:nl"=&gt;"Californië", "name:nn"=&gt;"California", "name:no"=&gt;"California", "name:nv"=&gt;"Ahééháshį́į́h Hahoodzo", "name:oc"=&gt;"Califòrnia", "name:os"=&gt;"Калифорни", "name:pa"=&gt;"ਕੈਲੀਫ਼ੋਰਨੀਆ", "name:pi"=&gt;"क्यालिफोर्निया", "name:pl"=&gt;"Kalifornia", "name:ps"=&gt;"کالیفرنیا", "name:pt"=&gt;"Califórnia", "name:qu"=&gt;"California suyu", "name:rm"=&gt;"California", "name:ro"=&gt;"California", "name:ru"=&gt;"Калифорния", "name:sa"=&gt;"कालिफ़ोर्निया", "name:sc"=&gt;"Califòrnia", "name:sd"=&gt;"ڪيليفورنيا", "name:se"=&gt;"Kalifornia", "name:sh"=&gt;"Kalifornija", "name:sk"=&gt;"Kalifornia", "name:sl"=&gt;"Kalifornija", "name:sm"=&gt;"Kalefonia", "name:so"=&gt;"Kalifornia", "name:sq"=&gt;"Kalifornia", "name:sr"=&gt;"Калифорнија", "name:su"=&gt;"Kalifornia", "name:sv"=&gt;"Kalifornien", "name:sw"=&gt;"California", "name:ta"=&gt;"கலிபோர்னியா", "name:te"=&gt;"కాలిఫోర్నియా", "name:tg"=&gt;"Калифорния", "name:th"=&gt;"รัฐแคลิฟอร์เนีย", "name:tl"=&gt;"California", "name:tr"=&gt;"Kaliforniya", "name:tt"=&gt;"Калифорния", "name:ug"=&gt;"Kaliforniye Shitati", "name:uk"=&gt;"Каліфорнія", "name:ur"=&gt;"کیلیفورنیا", "name:uz"=&gt;"Kaliforniya", "name:vi"=&gt;"Ca Li", "name:vo"=&gt;"Kalifornän", "name:wa"=&gt;"Californeye", "name:xh"=&gt;"IKhalifoniya", "name:yi"=&gt;"קאליפארניע", "name:yo"=&gt;"Kalifọ́rníà", "name:zh"=&gt;"加利福尼亚州/加利福尼亞州", "name:zu"=&gt;"California", "name:als"=&gt;"Kalifornien", "name:ang"=&gt;"California", "name:arz"=&gt;"كاليفورنيا", "name:ast"=&gt;"California", "name:azb"=&gt;"کالیفورنیا ایالتی", "name:bar"=&gt;"Kalifornien", "name:bcl"=&gt;"California", "name:bpy"=&gt;"ক্যালিফোর্নিয়া", "name:bxr"=&gt;"Калифорни", "name:cdo"=&gt;"California", "name:ceb"=&gt;"California", "name:chy"=&gt;"California", "name:ckb"=&gt;"کالیفۆرنیا", "name:diq"=&gt;"Kaliforniya", "name:dsb"=&gt;"Kaliforniska", "name:eml"=&gt;"Califòrgna", "name:frp"=&gt;"California", "name:frr"=&gt;"California", "name:gag"=&gt;"Kaliforniya", "name:gan"=&gt;"加利福尼亞州", "name:got"=&gt;"𐌺𐌰𐌻𐌹𐍆𐌰𐌿𐍂𐌽𐌾𐌰", "name:hak"=&gt;"California", "name:haw"=&gt;"Kaleponi", "name:hif"=&gt;"California", "name:hsb"=&gt;"Kaliforniska", "name:ilo"=&gt;"California", "name:jbo"=&gt;"la .kaliforniias.", "name:kaa"=&gt;"Kaliforniya shtati", "name:kab"=&gt;"Kalifurnya", "name:kbp"=&gt;"Kalɩfɔrnii", "name:krc"=&gt;"Калифорния", "name:lad"=&gt;"Kalifornia", "name:lfn"=&gt;"California", "name:lij"=&gt;"California", "name:lmo"=&gt;"California", "name:lrc"=&gt;"کاليفورنيا", "name:mai"=&gt;"क्यालिफोर्निया", "name:mhr"=&gt;"Калифорний", "name:mrj"=&gt;"Калифорни", "name:mzn"=&gt;"کالیفرنیا", "name:nah"=&gt;"California", "name:nan"=&gt;"California", "name:nds"=&gt;"Kalifornien", "name:new"=&gt;"क्यालिफोर्निया", "name:pag"=&gt;"California", "name:pam"=&gt;"California", "name:pap"=&gt;"California", "name:pcd"=&gt;"Californie", "name:pdc"=&gt;"Kalifornie", "name:pfl"=&gt;"Kalifornien", "name:pms"=&gt;"Califòrnia", "name:pnb"=&gt;"کیلیفورنیا", "name:sah"=&gt;"Калифорния", "name:scn"=&gt;"California", "name:sco"=&gt;"Californie", "name:stq"=&gt;"Kalifornien", "name:szl"=&gt;"Kaliforńijo", "name:tet"=&gt;"California", "name:tok"=&gt;"ma Kaliponija", "name:tzl"=&gt;"Californica", "name:vec"=&gt;"Całifornia", "name:war"=&gt;"California", "name:wuu"=&gt;"加利福尼亚", "name:xal"=&gt;"Калифорния", "name:xmf"=&gt;"კალიფორნია", "name:yue"=&gt;"加利福尼亞州", "name:zea"=&gt;"California", "short_name"=&gt;"Calif.", "alt_name:vi"=&gt;"California;Ca-li-phoóc-ni-a;Ca-li-pho-ni-a", "name:nds-nl"=&gt;"Kalifornië", "name:bat-smg"=&gt;"Kalėfuornėjė", "name:cbk-zam"=&gt;"California", "name:zh-Hans"=&gt;"加利福尼亚州", "name:zh-Hant"=&gt;"加利福尼亞州", "name:be-tarask"=&gt;"Каліфорнія", "name:abbreviation"=&gt;"Calif."</td>
      <td>298977868</td>
      <td>NaN</td>
      <td>296287291.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>California</td>
      <td>37253956</td>
    </tr>
  </tbody>
</table>
<p>56 rows × 26 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name_en</th>
      <th>population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>103969</th>
      <td>American Samoa</td>
      <td>65600</td>
    </tr>
    <tr>
      <th>122425</th>
      <td>Utah</td>
      <td>2949902</td>
    </tr>
    <tr>
      <th>122428</th>
      <td>Florida</td>
      <td>19893297</td>
    </tr>
    <tr>
      <th>123436</th>
      <td>Ohio</td>
      <td>11594163</td>
    </tr>
    <tr>
      <th>123437</th>
      <td>American Samoa</td>
      <td>None</td>
    </tr>
    <tr>
      <th>124000</th>
      <td>Illinois</td>
      <td>12880580</td>
    </tr>
    <tr>
      <th>124001</th>
      <td>Alabama</td>
      <td>4779736</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>124080</th>
      <td>Colorado</td>
      <td>5355866</td>
    </tr>
    <tr>
      <th>124084</th>
      <td>North Dakota</td>
      <td>641481</td>
    </tr>
    <tr>
      <th>124088</th>
      <td>Guam</td>
      <td>185427</td>
    </tr>
    <tr>
      <th>124089</th>
      <td>Idaho</td>
      <td>1634464</td>
    </tr>
    <tr>
      <th>124092</th>
      <td>Iowa</td>
      <td>3107124</td>
    </tr>
    <tr>
      <th>124096</th>
      <td>Maryland</td>
      <td>5976407</td>
    </tr>
    <tr>
      <th>124196</th>
      <td>California</td>
      <td>37253956</td>
    </tr>
  </tbody>
</table>
<p>56 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> greenhouse-gases-and-air-pollutant-emissions/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new dataset by adding the 2019 data from EU27 with all the data in EU28.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>index = ['airpol', 'cpa08', 'induse', 'origin', 'unit']
df_eu27_28 = df_eu28.set_index(index).join(df_eu27[index + ['2019']].set_index(index)).reset_index()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>index = ['airpol', 'cpa08', 'induse', 'origin', 'unit']
df_eu27_28 = df_eu28.set_index(index).join(df_eu27[index + ['2019']].set_index(index)).reset_index()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>index = ['airpol', 'cpa08', 'induse', 'origin', 'unit']
__output__ = df_eu27_28 = df_eu28.set_index(index).join(df_eu27[index + [
    '2019']].set_index(index)).reset_index()
</code></pre>
        <p><span onclick="$('#var_output_4f295c41').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4f295c41" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airpol</th>
      <th>cpa08</th>
      <th>induse</th>
      <th>origin</th>
      <th>unit</th>
      <th>geo\time</th>
      <th>2018</th>
      <th>...</th>
      <th>2013</th>
      <th>2012</th>
      <th>2011</th>
      <th>2010</th>
      <th>2009</th>
      <th>2008</th>
      <th>2019</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>DOM</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>3.952</td>
      <td>...</td>
      <td>4.182</td>
      <td>4.260</td>
      <td>3.965</td>
      <td>3.955</td>
      <td>4.025</td>
      <td>4.082</td>
      <td>3.960</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>DOM</td>
      <td>T</td>
      <td>EU28</td>
      <td>2027709.000</td>
      <td>...</td>
      <td>2116310.000</td>
      <td>2149511.000</td>
      <td>1996301.000</td>
      <td>1992765.000</td>
      <td>2023324.000</td>
      <td>2046045.000</td>
      <td>1769659.000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>DOM</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>2027.709</td>
      <td>...</td>
      <td>2116.310</td>
      <td>2149.511</td>
      <td>1996.301</td>
      <td>1992.765</td>
      <td>2023.324</td>
      <td>2046.045</td>
      <td>1769.659</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>ROW</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>0.932</td>
      <td>...</td>
      <td>0.706</td>
      <td>0.762</td>
      <td>0.857</td>
      <td>0.853</td>
      <td>0.774</td>
      <td>0.991</td>
      <td>0.745</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>ROW</td>
      <td>T</td>
      <td>EU28</td>
      <td>477994.000</td>
      <td>...</td>
      <td>357358.000</td>
      <td>384481.000</td>
      <td>431637.000</td>
      <td>429703.000</td>
      <td>389072.000</td>
      <td>496690.000</td>
      <td>332721.000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>ROW</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>477.994</td>
      <td>...</td>
      <td>357.358</td>
      <td>384.481</td>
      <td>431.637</td>
      <td>429.703</td>
      <td>389.072</td>
      <td>496.690</td>
      <td>332.721</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>WORLD</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>4.884</td>
      <td>...</td>
      <td>4.888</td>
      <td>5.022</td>
      <td>4.822</td>
      <td>4.808</td>
      <td>4.799</td>
      <td>5.073</td>
      <td>4.705</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>173657</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>DOM</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>3091.019</td>
      <td>...</td>
      <td>4200.575</td>
      <td>4808.396</td>
      <td>5267.915</td>
      <td>5398.041</td>
      <td>5833.225</td>
      <td>7052.391</td>
      <td>2841.218</td>
    </tr>
    <tr>
      <th>173658</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>ROW</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>1.585</td>
      <td>...</td>
      <td>1.973</td>
      <td>2.292</td>
      <td>2.574</td>
      <td>2.529</td>
      <td>2.387</td>
      <td>3.804</td>
      <td>1.530</td>
    </tr>
    <tr>
      <th>173659</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>ROW</td>
      <td>T</td>
      <td>EU28</td>
      <td>813364.000</td>
      <td>...</td>
      <td>998410.000</td>
      <td>1156497.000</td>
      <td>1295839.000</td>
      <td>1273968.000</td>
      <td>1200031.000</td>
      <td>1906401.000</td>
      <td>683708.000</td>
    </tr>
    <tr>
      <th>173660</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>ROW</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>813.364</td>
      <td>...</td>
      <td>998.410</td>
      <td>1156.497</td>
      <td>1295.839</td>
      <td>1273.968</td>
      <td>1200.031</td>
      <td>1906.401</td>
      <td>683.708</td>
    </tr>
    <tr>
      <th>173661</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>WORLD</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>7.610</td>
      <td>...</td>
      <td>10.273</td>
      <td>11.821</td>
      <td>13.036</td>
      <td>13.243</td>
      <td>13.991</td>
      <td>17.875</td>
      <td>7.888</td>
    </tr>
    <tr>
      <th>173662</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>WORLD</td>
      <td>T</td>
      <td>EU28</td>
      <td>3904382.000</td>
      <td>...</td>
      <td>5198985.000</td>
      <td>5964893.000</td>
      <td>6563754.000</td>
      <td>6672009.000</td>
      <td>7033257.000</td>
      <td>8958792.000</td>
      <td>3524926.000</td>
    </tr>
    <tr>
      <th>173663</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>WORLD</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>3904.382</td>
      <td>...</td>
      <td>5198.985</td>
      <td>5964.893</td>
      <td>6563.754</td>
      <td>6672.009</td>
      <td>7033.257</td>
      <td>8958.792</td>
      <td>3524.926</td>
    </tr>
  </tbody>
</table>
<p>173664 rows × 18 columns</p>
      
        <p><strong>Hyp output variables:</strong> index, __output__, df_eu27_28 </p>
    
          <p>index (list):</p>
          <pre><code>['airpol', 'cpa08', 'induse', 'origin', 'unit']</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airpol</th>
      <th>cpa08</th>
      <th>induse</th>
      <th>origin</th>
      <th>unit</th>
      <th>geo\time</th>
      <th>2018</th>
      <th>...</th>
      <th>2013</th>
      <th>2012</th>
      <th>2011</th>
      <th>2010</th>
      <th>2009</th>
      <th>2008</th>
      <th>2019</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>DOM</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>3.952</td>
      <td>...</td>
      <td>4.182</td>
      <td>4.260</td>
      <td>3.965</td>
      <td>3.955</td>
      <td>4.025</td>
      <td>4.082</td>
      <td>3.960</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>DOM</td>
      <td>T</td>
      <td>EU28</td>
      <td>2027709.000</td>
      <td>...</td>
      <td>2116310.000</td>
      <td>2149511.000</td>
      <td>1996301.000</td>
      <td>1992765.000</td>
      <td>2023324.000</td>
      <td>2046045.000</td>
      <td>1769659.000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>DOM</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>2027.709</td>
      <td>...</td>
      <td>2116.310</td>
      <td>2149.511</td>
      <td>1996.301</td>
      <td>1992.765</td>
      <td>2023.324</td>
      <td>2046.045</td>
      <td>1769.659</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>ROW</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>0.932</td>
      <td>...</td>
      <td>0.706</td>
      <td>0.762</td>
      <td>0.857</td>
      <td>0.853</td>
      <td>0.774</td>
      <td>0.991</td>
      <td>0.745</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>ROW</td>
      <td>T</td>
      <td>EU28</td>
      <td>477994.000</td>
      <td>...</td>
      <td>357358.000</td>
      <td>384481.000</td>
      <td>431637.000</td>
      <td>429703.000</td>
      <td>389072.000</td>
      <td>496690.000</td>
      <td>332721.000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>ROW</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>477.994</td>
      <td>...</td>
      <td>357.358</td>
      <td>384.481</td>
      <td>431.637</td>
      <td>429.703</td>
      <td>389.072</td>
      <td>496.690</td>
      <td>332.721</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>WORLD</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>4.884</td>
      <td>...</td>
      <td>4.888</td>
      <td>5.022</td>
      <td>4.822</td>
      <td>4.808</td>
      <td>4.799</td>
      <td>5.073</td>
      <td>4.705</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>173657</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>DOM</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>3091.019</td>
      <td>...</td>
      <td>4200.575</td>
      <td>4808.396</td>
      <td>5267.915</td>
      <td>5398.041</td>
      <td>5833.225</td>
      <td>7052.391</td>
      <td>2841.218</td>
    </tr>
    <tr>
      <th>173658</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>ROW</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>1.585</td>
      <td>...</td>
      <td>1.973</td>
      <td>2.292</td>
      <td>2.574</td>
      <td>2.529</td>
      <td>2.387</td>
      <td>3.804</td>
      <td>1.530</td>
    </tr>
    <tr>
      <th>173659</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>ROW</td>
      <td>T</td>
      <td>EU28</td>
      <td>813364.000</td>
      <td>...</td>
      <td>998410.000</td>
      <td>1156497.000</td>
      <td>1295839.000</td>
      <td>1273968.000</td>
      <td>1200031.000</td>
      <td>1906401.000</td>
      <td>683708.000</td>
    </tr>
    <tr>
      <th>173660</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>ROW</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>813.364</td>
      <td>...</td>
      <td>998.410</td>
      <td>1156.497</td>
      <td>1295.839</td>
      <td>1273.968</td>
      <td>1200.031</td>
      <td>1906.401</td>
      <td>683.708</td>
    </tr>
    <tr>
      <th>173661</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>WORLD</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>7.610</td>
      <td>...</td>
      <td>10.273</td>
      <td>11.821</td>
      <td>13.036</td>
      <td>13.243</td>
      <td>13.991</td>
      <td>17.875</td>
      <td>7.888</td>
    </tr>
    <tr>
      <th>173662</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>WORLD</td>
      <td>T</td>
      <td>EU28</td>
      <td>3904382.000</td>
      <td>...</td>
      <td>5198985.000</td>
      <td>5964893.000</td>
      <td>6563754.000</td>
      <td>6672009.000</td>
      <td>7033257.000</td>
      <td>8958792.000</td>
      <td>3524926.000</td>
    </tr>
    <tr>
      <th>173663</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>WORLD</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>3904.382</td>
      <td>...</td>
      <td>5198.985</td>
      <td>5964.893</td>
      <td>6563.754</td>
      <td>6672.009</td>
      <td>7033.257</td>
      <td>8958.792</td>
      <td>3524.926</td>
    </tr>
  </tbody>
</table>
<p>173664 rows × 18 columns</p>
      
          <p>df_eu27_28 (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airpol</th>
      <th>cpa08</th>
      <th>induse</th>
      <th>origin</th>
      <th>unit</th>
      <th>geo\time</th>
      <th>2018</th>
      <th>...</th>
      <th>2013</th>
      <th>2012</th>
      <th>2011</th>
      <th>2010</th>
      <th>2009</th>
      <th>2008</th>
      <th>2019</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>DOM</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>3.952</td>
      <td>...</td>
      <td>4.182</td>
      <td>4.260</td>
      <td>3.965</td>
      <td>3.955</td>
      <td>4.025</td>
      <td>4.082</td>
      <td>3.960</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>DOM</td>
      <td>T</td>
      <td>EU28</td>
      <td>2027709.000</td>
      <td>...</td>
      <td>2116310.000</td>
      <td>2149511.000</td>
      <td>1996301.000</td>
      <td>1992765.000</td>
      <td>2023324.000</td>
      <td>2046045.000</td>
      <td>1769659.000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>DOM</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>2027.709</td>
      <td>...</td>
      <td>2116.310</td>
      <td>2149.511</td>
      <td>1996.301</td>
      <td>1992.765</td>
      <td>2023.324</td>
      <td>2046.045</td>
      <td>1769.659</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>ROW</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>0.932</td>
      <td>...</td>
      <td>0.706</td>
      <td>0.762</td>
      <td>0.857</td>
      <td>0.853</td>
      <td>0.774</td>
      <td>0.991</td>
      <td>0.745</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>ROW</td>
      <td>T</td>
      <td>EU28</td>
      <td>477994.000</td>
      <td>...</td>
      <td>357358.000</td>
      <td>384481.000</td>
      <td>431637.000</td>
      <td>429703.000</td>
      <td>389072.000</td>
      <td>496690.000</td>
      <td>332721.000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>ROW</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>477.994</td>
      <td>...</td>
      <td>357.358</td>
      <td>384.481</td>
      <td>431.637</td>
      <td>429.703</td>
      <td>389.072</td>
      <td>496.690</td>
      <td>332.721</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ACG</td>
      <td>CPA_A01</td>
      <td>P3</td>
      <td>WORLD</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>4.884</td>
      <td>...</td>
      <td>4.888</td>
      <td>5.022</td>
      <td>4.822</td>
      <td>4.808</td>
      <td>4.799</td>
      <td>5.073</td>
      <td>4.705</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>173657</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>DOM</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>3091.019</td>
      <td>...</td>
      <td>4200.575</td>
      <td>4808.396</td>
      <td>5267.915</td>
      <td>5398.041</td>
      <td>5833.225</td>
      <td>7052.391</td>
      <td>2841.218</td>
    </tr>
    <tr>
      <th>173658</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>ROW</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>1.585</td>
      <td>...</td>
      <td>1.973</td>
      <td>2.292</td>
      <td>2.574</td>
      <td>2.529</td>
      <td>2.387</td>
      <td>3.804</td>
      <td>1.530</td>
    </tr>
    <tr>
      <th>173659</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>ROW</td>
      <td>T</td>
      <td>EU28</td>
      <td>813364.000</td>
      <td>...</td>
      <td>998410.000</td>
      <td>1156497.000</td>
      <td>1295839.000</td>
      <td>1273968.000</td>
      <td>1200031.000</td>
      <td>1906401.000</td>
      <td>683708.000</td>
    </tr>
    <tr>
      <th>173660</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>ROW</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>813.364</td>
      <td>...</td>
      <td>998.410</td>
      <td>1156.497</td>
      <td>1295.839</td>
      <td>1273.968</td>
      <td>1200.031</td>
      <td>1906.401</td>
      <td>683.708</td>
    </tr>
    <tr>
      <th>173661</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>WORLD</td>
      <td>KG_HAB</td>
      <td>EU28</td>
      <td>7.610</td>
      <td>...</td>
      <td>10.273</td>
      <td>11.821</td>
      <td>13.036</td>
      <td>13.243</td>
      <td>13.991</td>
      <td>17.875</td>
      <td>7.888</td>
    </tr>
    <tr>
      <th>173662</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>WORLD</td>
      <td>T</td>
      <td>EU28</td>
      <td>3904382.000</td>
      <td>...</td>
      <td>5198985.000</td>
      <td>5964893.000</td>
      <td>6563754.000</td>
      <td>6672009.000</td>
      <td>7033257.000</td>
      <td>8958792.000</td>
      <td>3524926.000</td>
    </tr>
    <tr>
      <th>173663</th>
      <td>SOX_SO2E</td>
      <td>TOT_HH</td>
      <td>TFU</td>
      <td>WORLD</td>
      <td>THS_T</td>
      <td>EU28</td>
      <td>3904.382</td>
      <td>...</td>
      <td>5198.985</td>
      <td>5964.893</td>
      <td>6563.754</td>
      <td>6672.009</td>
      <td>7033.257</td>
      <td>8958.792</td>
      <td>3524.926</td>
    </tr>
  </tbody>
</table>
<p>173664 rows × 18 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> greenhouse-gases-and-air-pollutant-emissions/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total final consumption expenditure (P3) of global warming potential(GHG) across the world from 2014 to 2018. Show in kilograms per capita.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>years = [str(i) for i in range(2014, 2019)]
df_eu27_28[(df_eu27_28.airpol == 'GHG') & (df_eu27_28.origin == 'WORLD') & (df_eu27_28.induse == 'P3') & (
            df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.unit == 'KG_HAB')][years]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>years = [str(i) for i in range(2014, 2019)]
df_eu27_28[(df_eu27_28.airpol == 'GHG') & (df_eu27_28.origin == 'WORLD') & (df_eu27_28.induse == 'P3') & (
            df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.unit == 'KG_HAB')][years]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>years = [str(i) for i in range(2014, 2019)]
__output__ = df_eu27_28[(df_eu27_28.airpol == 'GHG') & (df_eu27_28.origin ==
    'WORLD') & (df_eu27_28.induse == 'P3') & (df_eu27_28.cpa08 == 'TOTAL') &
    (df_eu27_28.unit == 'KG_HAB')][years]
</code></pre>
        <p><span onclick="$('#var_output_e6d302ca').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e6d302ca" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>64914</th>
      <td>5782.676</td>
      <td>5734.535</td>
      <td>5781.153</td>
      <td>5655.929</td>
      <td>5520.323</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 5 columns</p>
      
        <p><strong>Hyp output variables:</strong> years, __output__ </p>
    
          <p>years (list):</p>
          <pre><code>['2014', '2015', '2016', '2017', '2018']</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>64914</th>
      <td>5782.676</td>
      <td>5734.535</td>
      <td>5781.153</td>
      <td>5655.929</td>
      <td>5520.323</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 5 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> greenhouse-gases-and-air-pollutant-emissions/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total gross capital formation (P5) of Tropospheric ozone precursors (O3PR) for each year in the EU. Show in tonnes.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>years = [str(i) for i in range(2008, 2020)]
df_eu27_28[(df_eu27_28.airpol == 'O3PR') & (df_eu27_28.origin == 'DOM') & (df_eu27_28.induse == 'P5') & (
            df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.unit == 'T')][years]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>years = [str(i) for i in range(2008, 2020)]
df_eu27_28[(df_eu27_28.airpol == 'O3PR') & (df_eu27_28.origin == 'DOM') & (df_eu27_28.induse == 'P5') & (
            df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.unit == 'T')][years]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>years = [str(i) for i in range(2008, 2020)]
__output__ = df_eu27_28[(df_eu27_28.airpol == 'O3PR') & (df_eu27_28.origin ==
    'DOM') & (df_eu27_28.induse == 'P5') & (df_eu27_28.cpa08 == 'TOTAL') &
    (df_eu27_28.unit == 'T')][years]
</code></pre>
        <p><span onclick="$('#var_output_46181be8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_46181be8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2008</th>
      <th>2009</th>
      <th>2010</th>
      <th>2011</th>
      <th>2012</th>
      <th>2013</th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>144550</th>
      <td>3843769.0</td>
      <td>3213550.0</td>
      <td>3156426.0</td>
      <td>3114880.0</td>
      <td>2670746.0</td>
      <td>2507777.0</td>
      <td>2547215.0</td>
      <td>2505422.0</td>
      <td>2561405.0</td>
      <td>2326853.0</td>
      <td>2292952.0</td>
      <td>2039337.0</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 12 columns</p>
      
        <p><strong>Hyp output variables:</strong> years, __output__ </p>
    
          <p>years (list):</p>
          <pre><code>['2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2008</th>
      <th>2009</th>
      <th>2010</th>
      <th>2011</th>
      <th>2012</th>
      <th>2013</th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>144550</th>
      <td>3843769.0</td>
      <td>3213550.0</td>
      <td>3156426.0</td>
      <td>3114880.0</td>
      <td>2670746.0</td>
      <td>2507777.0</td>
      <td>2547215.0</td>
      <td>2505422.0</td>
      <td>2561405.0</td>
      <td>2326853.0</td>
      <td>2292952.0</td>
      <td>2039337.0</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 12 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> greenhouse-gases-and-air-pollutant-emissions/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total footprint (P3_P5) of Acidification (ACG) for each year outside the EU. Show in thousands of tonnes.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_eu27_28[(df_eu27_28.airpol == 'ACG') & (df_eu27_28.origin == 'ROW') & (df_eu27_28.induse == 'P3_P5') & (
            df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.unit == 'THS_T')][years]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_eu27_28[(df_eu27_28.airpol == 'ACG') & (df_eu27_28.origin == 'ROW') & (df_eu27_28.induse == 'P3_P5') & (
            df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.unit == 'THS_T')][years]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_eu27_28[(df_eu27_28.airpol == 'ACG') & (df_eu27_28.origin ==
    'ROW') & (df_eu27_28.induse == 'P3_P5') & (df_eu27_28.cpa08 == 'TOTAL') &
    (df_eu27_28.unit == 'THS_T')][years]
</code></pre>
        <p><span onclick="$('#var_output_25284ec9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_25284ec9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2008</th>
      <th>2009</th>
      <th>2010</th>
      <th>2011</th>
      <th>2012</th>
      <th>2013</th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7034</th>
      <td>4570.394</td>
      <td>3336.72</td>
      <td>3592.538</td>
      <td>3717.976</td>
      <td>3550.043</td>
      <td>3254.371</td>
      <td>3183.534</td>
      <td>3156.907</td>
      <td>3077.51</td>
      <td>3166.373</td>
      <td>3150.001</td>
      <td>2509.479</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 12 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2008</th>
      <th>2009</th>
      <th>2010</th>
      <th>2011</th>
      <th>2012</th>
      <th>2013</th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7034</th>
      <td>4570.394</td>
      <td>3336.72</td>
      <td>3592.538</td>
      <td>3717.976</td>
      <td>3550.043</td>
      <td>3254.371</td>
      <td>3183.534</td>
      <td>3156.907</td>
      <td>3077.51</td>
      <td>3166.373</td>
      <td>3150.001</td>
      <td>2509.479</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 12 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> greenhouse-gases-and-air-pollutant-emissions/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the accumulated footprint (P3_P5) of CO2 in millions of tonnes from 2008 to 2019 for each CPA classification in the world?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def sum_over_years(x):
    x['acc_p3p5'] = x[years].T.sum()/1e6
    return x

df_eu27_28[(df_eu27_28.airpol == 'CO2')
           & (df_eu27_28.unit == 'T') & (df_eu27_28.induse == 'P3_P5') & (df_eu27_28.origin == 'WORLD')].apply(
    sum_over_years, axis=1)[['cpa08', 'acc_p3p5']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def sum_over_years(x):
    x['acc_p3p5'] = x[years].T.sum()/1e6
    return x

df_eu27_28[(df_eu27_28.airpol == 'CO2')
           & (df_eu27_28.unit == 'T') & (df_eu27_28.induse == 'P3_P5') & (df_eu27_28.origin == 'WORLD')].apply(
    sum_over_years, axis=1)[['cpa08', 'acc_p3p5']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def sum_over_years(x):
    x['acc_p3p5'] = x[years].T.sum() / 1000000.0
    return x


__output__ = df_eu27_28[(df_eu27_28.airpol == 'CO2') & (df_eu27_28.unit ==
    'T') & (df_eu27_28.induse == 'P3_P5') & (df_eu27_28.origin == 'WORLD')
    ].apply(sum_over_years, axis=1)[['cpa08', 'acc_p3p5']]
</code></pre>
        <p><span onclick="$('#var_output_536acdb4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_536acdb4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cpa08</th>
      <th>acc_p3p5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>36196</th>
      <td>CPA_A01</td>
      <td>698.787304</td>
    </tr>
    <tr>
      <th>36304</th>
      <td>CPA_A02</td>
      <td>30.824115</td>
    </tr>
    <tr>
      <th>36412</th>
      <td>CPA_A03</td>
      <td>70.469124</td>
    </tr>
    <tr>
      <th>36520</th>
      <td>CPA_B</td>
      <td>166.131380</td>
    </tr>
    <tr>
      <th>36628</th>
      <td>CPA_C10-12</td>
      <td>2433.581339</td>
    </tr>
    <tr>
      <th>36736</th>
      <td>CPA_C13-15</td>
      <td>544.589647</td>
    </tr>
    <tr>
      <th>36844</th>
      <td>CPA_C16</td>
      <td>59.285876</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>42676</th>
      <td>CPA_S95</td>
      <td>32.803532</td>
    </tr>
    <tr>
      <th>42784</th>
      <td>CPA_S96</td>
      <td>245.848049</td>
    </tr>
    <tr>
      <th>42892</th>
      <td>CPA_T</td>
      <td>3.665649</td>
    </tr>
    <tr>
      <th>43000</th>
      <td>CPA_U</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>43108</th>
      <td>HH</td>
      <td>10439.518559</td>
    </tr>
    <tr>
      <th>43216</th>
      <td>TOTAL</td>
      <td>35414.384616</td>
    </tr>
    <tr>
      <th>43324</th>
      <td>TOT_HH</td>
      <td>45853.903172</td>
    </tr>
  </tbody>
</table>
<p>67 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cpa08</th>
      <th>acc_p3p5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>36196</th>
      <td>CPA_A01</td>
      <td>698.787304</td>
    </tr>
    <tr>
      <th>36304</th>
      <td>CPA_A02</td>
      <td>30.824115</td>
    </tr>
    <tr>
      <th>36412</th>
      <td>CPA_A03</td>
      <td>70.469124</td>
    </tr>
    <tr>
      <th>36520</th>
      <td>CPA_B</td>
      <td>166.131380</td>
    </tr>
    <tr>
      <th>36628</th>
      <td>CPA_C10-12</td>
      <td>2433.581339</td>
    </tr>
    <tr>
      <th>36736</th>
      <td>CPA_C13-15</td>
      <td>544.589647</td>
    </tr>
    <tr>
      <th>36844</th>
      <td>CPA_C16</td>
      <td>59.285876</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>42676</th>
      <td>CPA_S95</td>
      <td>32.803532</td>
    </tr>
    <tr>
      <th>42784</th>
      <td>CPA_S96</td>
      <td>245.848049</td>
    </tr>
    <tr>
      <th>42892</th>
      <td>CPA_T</td>
      <td>3.665649</td>
    </tr>
    <tr>
      <th>43000</th>
      <td>CPA_U</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>43108</th>
      <td>HH</td>
      <td>10439.518559</td>
    </tr>
    <tr>
      <th>43216</th>
      <td>TOTAL</td>
      <td>35414.384616</td>
    </tr>
    <tr>
      <th>43324</th>
      <td>TOT_HH</td>
      <td>45853.903172</td>
    </tr>
  </tbody>
</table>
<p>67 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> greenhouse-gases-and-air-pollutant-emissions/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total accumulated footprint (P3_P5) of each CO2 equivalent pollutants in megatonnes from 2008 to 2019 in the EU across all cpa classes?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def is_equiv(x, equiv='CO2E'):
    if equiv in x:
        return True
    return False

df_eu27_28[(df_eu27_28.airpol.apply(is_equiv))
           & (df_eu27_28.unit == 'T') & (df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.induse == 'P3_P5') & (
                       df_eu27_28.origin == 'DOM')].apply(sum_over_years, axis=1)[['airpol', 'acc_p3p5']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def is_equiv(x, equiv='CO2E'):
    if equiv in x:
        return True
    return False

df_eu27_28[(df_eu27_28.airpol.apply(is_equiv))
           & (df_eu27_28.unit == 'T') & (df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.induse == 'P3_P5') & (
                       df_eu27_28.origin == 'DOM')].apply(sum_over_years, axis=1)[['airpol', 'acc_p3p5']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def is_equiv(x, equiv='CO2E'):
    if equiv in x:
        return True
    return False


__output__ = df_eu27_28[df_eu27_28.airpol.apply(is_equiv) & (df_eu27_28.
    unit == 'T') & (df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.induse ==
    'P3_P5') & (df_eu27_28.origin == 'DOM')].apply(sum_over_years, axis=1)[[
    'airpol', 'acc_p3p5']]
</code></pre>
        <p><span onclick="$('#var_output_abaac22f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_abaac22f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airpol</th>
      <th>acc_p3p5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>21502</th>
      <td>CH4_CO2E</td>
      <td>4362.824621</td>
    </tr>
    <tr>
      <th>50446</th>
      <td>CO2_N2O_CH4_CO2E</td>
      <td>34881.707789</td>
    </tr>
    <tr>
      <th>72154</th>
      <td>HFC_CO2E</td>
      <td>807.594480</td>
    </tr>
    <tr>
      <th>86626</th>
      <td>N2O_CO2E</td>
      <td>2294.210513</td>
    </tr>
    <tr>
      <th>93862</th>
      <td>NF3_SF6_CO2E</td>
      <td>56.882634</td>
    </tr>
    <tr>
      <th>151750</th>
      <td>PFC_CO2E</td>
      <td>26.270431</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airpol</th>
      <th>acc_p3p5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>21502</th>
      <td>CH4_CO2E</td>
      <td>4362.824621</td>
    </tr>
    <tr>
      <th>50446</th>
      <td>CO2_N2O_CH4_CO2E</td>
      <td>34881.707789</td>
    </tr>
    <tr>
      <th>72154</th>
      <td>HFC_CO2E</td>
      <td>807.594480</td>
    </tr>
    <tr>
      <th>86626</th>
      <td>N2O_CO2E</td>
      <td>2294.210513</td>
    </tr>
    <tr>
      <th>93862</th>
      <td>NF3_SF6_CO2E</td>
      <td>56.882634</td>
    </tr>
    <tr>
      <th>151750</th>
      <td>PFC_CO2E</td>
      <td>26.270431</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> greenhouse-gases-and-air-pollutant-emissions/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the unique pollutants? Discard environmental pressures 'ACG', 'GHG' and 'O3PR'?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def get_base_pollutant(x):
    x = x.split('_')
    if len(x) <= 2:
        return x[0]
    return '_'.join(x[:-1])

def is_environmental_pressure(x):
    if x in ['ACG', 'GHG', 'O3PR']:
        return True
    return False

df_eu27_28[~df_eu27_28.airpol.apply(is_environmental_pressure)].airpol.apply(get_base_pollutant).unique()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def get_base_pollutant(x):
    x = x.split('_')
    if len(x) <= 2:
        return x[0]
    return '_'.join(x[:-1])

def is_environmental_pressure(x):
    if x in ['ACG', 'GHG', 'O3PR']:
        return True
    return False

df_eu27_28[~df_eu27_28.airpol.apply(is_environmental_pressure)].airpol.apply(get_base_pollutant).unique()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def get_base_pollutant(x):
    x = x.split('_')
    if len(x) <= 2:
        return x[0]
    return '_'.join(x[:-1])


def is_environmental_pressure(x):
    if x in ['ACG', 'GHG', 'O3PR']:
        return True
    return False


__output__ = df_eu27_28[~df_eu27_28.airpol.apply(is_environmental_pressure)
    ].airpol.apply(get_base_pollutant).unique()
</code></pre>
        <p><span onclick="$('#var_output_d874a5f3').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d874a5f3" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>['CH4' 'CO' 'CO2' 'CO2_N2O_CH4' 'HFC' 'N2O' 'NF3_SF6' 'NH3' 'NMVOC' 'NOX'
 'PFC' 'PM10' 'PM2' 'SOX']</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>['CH4' 'CO' 'CO2' 'CO2_N2O_CH4' 'HFC' 'N2O' 'NF3_SF6' 'NH3' 'NMVOC' 'NOX'
 'PFC' 'PM10' 'PM2' 'SOX']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> greenhouse-gases-and-air-pollutant-emissions/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the total accumulated Gross capital formation (P5) of each S02 equivalent pollutants in tonnes from 2008 to 2019 in the EU across all cpa classes?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>is_SO2_equiv = lambda x: is_equiv(x, 'SO2E')
df_eu27_28[(df_eu27_28.airpol.apply(is_SO2_equiv))
           & (df_eu27_28.unit == 'T') & (df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.induse == 'P3_P5') & (
                       df_eu27_28.origin == 'DOM')].apply(sum_over_years, axis=1)[['airpol', 'acc_p3p5']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>is_SO2_equiv = lambda x: is_equiv(x, 'SO2E')
df_eu27_28[(df_eu27_28.airpol.apply(is_SO2_equiv))
           & (df_eu27_28.unit == 'T') & (df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.induse == 'P3_P5') & (
                       df_eu27_28.origin == 'DOM')].apply(sum_over_years, axis=1)[['airpol', 'acc_p3p5']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>is_SO2_equiv = lambda x: is_equiv(x, 'SO2E')
__output__ = df_eu27_28[df_eu27_28.airpol.apply(is_SO2_equiv) & (df_eu27_28
    .unit == 'T') & (df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.induse ==
    'P3_P5') & (df_eu27_28.origin == 'DOM')].apply(sum_over_years, axis=1)[[
    'airpol', 'acc_p3p5']]
</code></pre>
        <p><span onclick="$('#var_output_4169b7a0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4169b7a0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airpol</th>
      <th>acc_p3p5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>108334</th>
      <td>NH3_SO2E</td>
      <td>71.296661</td>
    </tr>
    <tr>
      <th>137278</th>
      <td>NOX_SO2E</td>
      <td>56.750994</td>
    </tr>
    <tr>
      <th>173458</th>
      <td>SOX_SO2E</td>
      <td>33.433146</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>airpol</th>
      <th>acc_p3p5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>108334</th>
      <td>NH3_SO2E</td>
      <td>71.296661</td>
    </tr>
    <tr>
      <th>137278</th>
      <td>NOX_SO2E</td>
      <td>56.750994</td>
    </tr>
    <tr>
      <th>173458</th>
      <td>SOX_SO2E</td>
      <td>33.433146</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> greenhouse-gases-and-air-pollutant-emissions/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the total footprint in kilotons of CO2 and its equivalent pollutants across the world in 2019?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_eu27_28[(df_eu27_28.airpol.apply(is_equiv) | df_eu27_28.airpol.apply(lambda x: 'CO2' in x))
           & (df_eu27_28.unit == 'THS_T') & (df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.induse == 'P3_P5') & (
                       df_eu27_28.origin == 'WORLD')]['2019'].sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_eu27_28[(df_eu27_28.airpol.apply(is_equiv) | df_eu27_28.airpol.apply(lambda x: 'CO2' in x))
           & (df_eu27_28.unit == 'THS_T') & (df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.induse == 'P3_P5') & (
                       df_eu27_28.origin == 'WORLD')]['2019'].sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_eu27_28[(df_eu27_28.airpol.apply(is_equiv) | df_eu27_28.
    airpol.apply(lambda x: 'CO2' in x)) & (df_eu27_28.unit == 'THS_T') & (
    df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.induse == 'P3_P5') & (
    df_eu27_28.origin == 'WORLD')]['2019'].sum()
</code></pre>
        <p><span onclick="$('#var_output_99524ede').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_99524ede" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>5909939.136</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>5909939.136</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> greenhouse-gases-and-air-pollutant-emissions/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent decrease of total global footprint of particulate matter (PM10 and PM2) from 2008 to 2018</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_eu27_28[((df_eu27_28.airpol == 'PM10') | (df_eu27_28.airpol == 'PM2_5'))
           & (df_eu27_28.unit == 'THS_T') & (df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.induse == 'P3_P5') & (
                       df_eu27_28.origin == 'WORLD')].apply(lambda x: 100*(x['2008']-x['2018'])/x['2008'], 1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_eu27_28[((df_eu27_28.airpol == 'PM10') | (df_eu27_28.airpol == 'PM2_5'))
           & (df_eu27_28.unit == 'THS_T') & (df_eu27_28.cpa08 == 'TOTAL') & (df_eu27_28.induse == 'P3_P5') & (
                       df_eu27_28.origin == 'WORLD')].apply(lambda x: 100*(x['2008']-x['2018'])/x['2008'], 1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_eu27_28[((df_eu27_28.airpol == 'PM10') | (df_eu27_28.airpol ==
    'PM2_5')) & (df_eu27_28.unit == 'THS_T') & (df_eu27_28.cpa08 == 'TOTAL'
    ) & (df_eu27_28.induse == 'P3_P5') & (df_eu27_28.origin == 'WORLD')].apply(
    lambda x: 100 * (x['2008'] - x['2018']) / x['2008'], 1)
</code></pre>
        <p><span onclick="$('#var_output_603fcfe4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_603fcfe4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>158993    30.181356
166229    33.914607
dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>158993    30.181356
166229    33.914607
dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> monkeypox-dataset-daily-updated/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert all polar columns (Y/N/NA) to boolean.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>bool_conversion_dict = {'Y': True, 'N': False}

def convert2bool(x):
    if 'Y/N/NA' not in x.name:
        return x
    return x.apply(lambda i: np.NaN if i not in bool_conversion_dict else bool_conversion_dict[i])

df_case_det = df_case_det.apply(convert2bool)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>bool_conversion_dict = {'Y': True, 'N': False}

def convert2bool(x):
    if 'Y/N/NA' not in x.name:
        return x
    return x.apply(lambda i: np.NaN if i not in bool_conversion_dict else bool_conversion_dict[i])

df_case_det = df_case_det.apply(convert2bool)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>bool_conversion_dict = {'Y': True, 'N': False}


def convert2bool(x):
    if 'Y/N/NA' not in x.name:
        return x
    return x.apply(lambda i: np.NaN if i not in bool_conversion_dict else
        bool_conversion_dict[i])


__output__ = df_case_det = df_case_det.apply(convert2bool)
</code></pre>
        <p><span onclick="$('#var_output_a505aab3').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a505aab3" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date_confirmation</th>
      <th>Country</th>
      <th>City</th>
      <th>Age</th>
      <th>Gender</th>
      <th>Symptoms</th>
      <th>Hospitalised (Y/N/NA)</th>
      <th>Isolated (Y/N/NA)</th>
      <th>Travel_history (Y/N/NA)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2022-02-28</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>37804</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37805</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37806</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37807</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37808</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37809</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37810</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>37811 rows × 9 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_case_det, __output__ </p>
    
          <p>df_case_det (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date_confirmation</th>
      <th>Country</th>
      <th>City</th>
      <th>Age</th>
      <th>Gender</th>
      <th>Symptoms</th>
      <th>Hospitalised (Y/N/NA)</th>
      <th>Isolated (Y/N/NA)</th>
      <th>Travel_history (Y/N/NA)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2022-02-28</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>37804</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37805</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37806</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37807</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37808</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37809</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37810</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>37811 rows × 9 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date_confirmation</th>
      <th>Country</th>
      <th>City</th>
      <th>Age</th>
      <th>Gender</th>
      <th>Symptoms</th>
      <th>Hospitalised (Y/N/NA)</th>
      <th>Isolated (Y/N/NA)</th>
      <th>Travel_history (Y/N/NA)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2022-02-28</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>37804</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37805</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37806</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37807</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37808</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37809</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37810</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>37811 rows × 9 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> monkeypox-dataset-daily-updated/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert Gender to either 'Male', 'Female' or None.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def convert_gender(x):
    if type(x) is not str:
        return None
    x = x.strip()
    if x.lower() == 'male':
        return 'Male'
    return 'Female'

df_case_det.Gender = df_case_det.Gender.apply(convert_gender)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def convert_gender(x):
    if type(x) is not str:
        return None
    x = x.strip()
    if x.lower() == 'male':
        return 'Male'
    return 'Female'

df_case_det.Gender = df_case_det.Gender.apply(convert_gender)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def convert_gender(x):
    if type(x) is not str:
        return None
    x = x.strip()
    if x.lower() == 'male':
        return 'Male'
    return 'Female'


__output__ = df_case_det.Gender = df_case_det.Gender.apply(convert_gender)
</code></pre>
        <p><span onclick="$('#var_output_8d96dc9d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8d96dc9d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0        None
1        None
2        None
3        None
4        None
         ... 
37806    None
37807    None
37808    None
37809    None
37810    None
Name: Gender, Length: 37811, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_case_det, __output__ </p>
    
          <p>df_case_det (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date_confirmation</th>
      <th>Country</th>
      <th>City</th>
      <th>Age</th>
      <th>Gender</th>
      <th>Symptoms</th>
      <th>Hospitalised (Y/N/NA)</th>
      <th>Isolated (Y/N/NA)</th>
      <th>Travel_history (Y/N/NA)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2022-02-28</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>37804</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37805</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37806</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37807</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37808</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37809</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37810</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>37811 rows × 9 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0        None
1        None
2        None
3        None
4        None
         ... 
37806    None
37807    None
37808    None
37809    None
37810    None
Name: Gender, Length: 37811, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> monkeypox-dataset-daily-updated/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the comma seperated symptoms list to python list.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def convert2list(x):
    if type(x) is not str:
        return np.NaN
    x = x.replace(';', ',').replace('and', ',')
    return [i.strip() for i in x.split(',')]

df_case_det.Symptoms = df_case_det.Symptoms.apply(convert2list)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def convert2list(x):
    if type(x) is not str:
        return np.NaN
    x = x.replace(';', ',').replace('and', ',')
    return [i.strip() for i in x.split(',')]

df_case_det.Symptoms = df_case_det.Symptoms.apply(convert2list)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def convert2list(x):
    if type(x) is not str:
        return np.NaN
    x = x.replace(';', ',').replace('and', ',')
    return [i.strip() for i in x.split(',')]


__output__ = df_case_det.Symptoms = df_case_det.Symptoms.apply(convert2list)
</code></pre>
        <p><span onclick="$('#var_output_ad2576cd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ad2576cd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0        NaN
1        NaN
2        NaN
3        NaN
4        NaN
        ... 
37806    NaN
37807    NaN
37808    NaN
37809    NaN
37810    NaN
Name: Symptoms, Length: 37811, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_case_det, __output__ </p>
    
          <p>df_case_det (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date_confirmation</th>
      <th>Country</th>
      <th>City</th>
      <th>Age</th>
      <th>Gender</th>
      <th>Symptoms</th>
      <th>Hospitalised (Y/N/NA)</th>
      <th>Isolated (Y/N/NA)</th>
      <th>Travel_history (Y/N/NA)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2022-02-28</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>37804</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37805</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37806</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37807</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37808</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37809</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>37810</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>37811 rows × 9 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0        NaN
1        NaN
2        NaN
3        NaN
4        NaN
        ... 
37806    NaN
37807    NaN
37808    NaN
37809    NaN
37810    NaN
Name: Symptoms, Length: 37811, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> monkeypox-dataset-daily-updated/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert date of confirmation to datetime and classify each entry according to the quartile interval the date falls in. List in seperate column.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_case_det.Date_confirmation = df_case_det.Date_confirmation.apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))
df_case_det['date_quartile_interval'] = pd.qcut(df_case_det.Date_confirmation, 4)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_case_det.Date_confirmation = df_case_det.Date_confirmation.apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))
df_case_det['date_quartile_interval'] = pd.qcut(df_case_det.Date_confirmation, 4)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_case_det.Date_confirmation = df_case_det.Date_confirmation.apply(lambda
    x: datetime.strptime(x, '%Y-%m-%d'))
__output__ = df_case_det['date_quartile_interval'] = pd.qcut(df_case_det.
    Date_confirmation, 4)
</code></pre>
        <p><span onclick="$('#var_output_235d9cd8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_235d9cd8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0        (2022-01-30 23:59:59.999999999, 2022-07-08]
1        (2022-01-30 23:59:59.999999999, 2022-07-08]
2        (2022-01-30 23:59:59.999999999, 2022-07-08]
3        (2022-01-30 23:59:59.999999999, 2022-07-08]
4        (2022-01-30 23:59:59.999999999, 2022-07-08]
                            ...                     
37806                       (2022-08-05, 2022-08-16]
37807                       (2022-08-05, 2022-08-16]
37808                       (2022-08-05, 2022-08-16]
37809                       (2022-08-05, 2022-08-16]
37810                       (2022-08-05, 2022-08-16]
Name: Date_confirmation, Length: 37811, dtype: category
Categories (4, interval[datetime64[ns], right]): [ <
                                                  (2022-01-30 23:59:59.999999999, 2022-07-08] < (2022-07-08, 2022-07-26] <
                                                  (2022-07-26, 2022-08-05] < (2022-08-05, 2022-08-16]]</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_case_det, __output__ </p>
    
          <p>df_case_det (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date_confirmation</th>
      <th>Country</th>
      <th>City</th>
      <th>Age</th>
      <th>Gender</th>
      <th>Symptoms</th>
      <th>Hospitalised (Y/N/NA)</th>
      <th>Isolated (Y/N/NA)</th>
      <th>Travel_history (Y/N/NA)</th>
      <th>date_quartile_interval</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2022-02-28</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>37804</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
    </tr>
    <tr>
      <th>37805</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
    </tr>
    <tr>
      <th>37806</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
    </tr>
    <tr>
      <th>37807</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
    </tr>
    <tr>
      <th>37808</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
    </tr>
    <tr>
      <th>37809</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
    </tr>
    <tr>
      <th>37810</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
    </tr>
  </tbody>
</table>
<p>37811 rows × 10 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0        (2022-01-30 23:59:59.999999999, 2022-07-08]
1        (2022-01-30 23:59:59.999999999, 2022-07-08]
2        (2022-01-30 23:59:59.999999999, 2022-07-08]
3        (2022-01-30 23:59:59.999999999, 2022-07-08]
4        (2022-01-30 23:59:59.999999999, 2022-07-08]
                            ...                     
37806                       (2022-08-05, 2022-08-16]
37807                       (2022-08-05, 2022-08-16]
37808                       (2022-08-05, 2022-08-16]
37809                       (2022-08-05, 2022-08-16]
37810                       (2022-08-05, 2022-08-16]
Name: Date_confirmation, Length: 37811, dtype: category
Categories (4, interval[datetime64[ns], right]): [ <
                                                  (2022-01-30 23:59:59.999999999, 2022-07-08] < (2022-07-08, 2022-07-26] <
                                                  (2022-07-26, 2022-08-05] < (2022-08-05, 2022-08-16]]</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> monkeypox-dataset-daily-updated/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 3 most common symptoms by number among the cases that lead to hospitalization? List each symptom with number of cases.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_case_det[df_case_det['Hospitalised (Y/N/NA)'] == True].Symptoms.explode().value_counts().sort_values(
    ascending=False).head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_case_det[df_case_det['Hospitalised (Y/N/NA)'] == True].Symptoms.explode().value_counts().sort_values(
    ascending=False).head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_case_det[df_case_det['Hospitalised (Y/N/NA)'] == True
    ].Symptoms.explode().value_counts().sort_values(ascending=False).head(3)
</code></pre>
        <p><span onclick="$('#var_output_407f5333').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_407f5333" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>fever       15
headache     6
rash         5
Name: Symptoms, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>fever       15
headache     6
rash         5
Name: Symptoms, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> monkeypox-dataset-daily-updated/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the top 3 most common symptom for each interval? List the number of entries associated with the symptoms in each quartile.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_case_det[['date_quartile_interval', 'Symptoms']].groupby('date_quartile_interval').apply(
    lambda x: x.explode('Symptoms')['Symptoms'].value_counts().sort_values(ascending=False).head(3))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_case_det[['date_quartile_interval', 'Symptoms']].groupby('date_quartile_interval').apply(
    lambda x: x.explode('Symptoms')['Symptoms'].value_counts().sort_values(ascending=False).head(3))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_case_det[['date_quartile_interval', 'Symptoms']].groupby(
    'date_quartile_interval').apply(lambda x: x.explode('Symptoms')[
    'Symptoms'].value_counts().sort_values(ascending=False).head(3))
</code></pre>
        <p><span onclick="$('#var_output_8ec3177c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8ec3177c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>date_quartile_interval                                            
(2022-01-30 23:59:59.999999999, 2022-07-08]  fever                    33
                                             genital ulcer lesions    30
                                             genital ulcers           22
(2022-07-08, 2022-07-26]                     Rash                     18
                                             fever                    14
                                             rash                      4
(2022-07-26, 2022-08-05]                     fatigue                   5
                                             fever                     5
                                             skin manifestations       3
(2022-08-05, 2022-08-16]                     fever                     3
                                             rash                      2
                                             Swollen lymph nodes       1
Name: Symptoms, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>date_quartile_interval                                            
(2022-01-30 23:59:59.999999999, 2022-07-08]  fever                    33
                                             genital ulcer lesions    30
                                             genital ulcers           22
(2022-07-08, 2022-07-26]                     Rash                     18
                                             fever                    14
                                             rash                      4
(2022-07-26, 2022-08-05]                     fatigue                   5
                                             fever                     5
                                             skin manifestations       3
(2022-08-05, 2022-08-16]                     fever                     3
                                             rash                      2
                                             Swollen lymph nodes       1
Name: Symptoms, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> monkeypox-dataset-daily-updated/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the top 3 most common symptoms among males and females? List the number of entries associated with the symptoms for each gender.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_case_det[['Symptoms', 'Gender']].groupby('Gender').apply(
    lambda x: x.explode('Symptoms')['Symptoms'].value_counts().sort_values(ascending=False).head(3))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_case_det[['Symptoms', 'Gender']].groupby('Gender').apply(
    lambda x: x.explode('Symptoms')['Symptoms'].value_counts().sort_values(ascending=False).head(3))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_case_det[['Symptoms', 'Gender']].groupby('Gender').apply(lambda
    x: x.explode('Symptoms')['Symptoms'].value_counts().sort_values(
    ascending=False).head(3))
</code></pre>
        <p><span onclick="$('#var_output_30917997').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_30917997" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Gender                       
Female  fever                     3
        Fatigue                   1
        headache                  1
Male    fever                    45
        genital ulcer lesions    30
        genital ulcers           22
Name: Symptoms, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Gender                       
Female  fever                     3
        Fatigue                   1
        headache                  1
Male    fever                    45
        genital ulcer lesions    30
        genital ulcers           22
Name: Symptoms, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> monkeypox-dataset-daily-updated/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a boolean column showing if a patient has ulcer.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def has_condition(x, condition='ulcer'):
    if type(x) is not list:
        return False
    for i in x:
        if condition in i.lower():
            return True
    return False

has_ulcer = lambda x: has_condition(x, 'ulcer')
df_case_det['HasUlcer'] = df_case_det.Symptoms.apply(has_ulcer)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def has_condition(x, condition='ulcer'):
    if type(x) is not list:
        return False
    for i in x:
        if condition in i.lower():
            return True
    return False

has_ulcer = lambda x: has_condition(x, 'ulcer')
df_case_det['HasUlcer'] = df_case_det.Symptoms.apply(has_ulcer)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def has_condition(x, condition='ulcer'):
    if type(x) is not list:
        return False
    for i in x:
        if condition in i.lower():
            return True
    return False


has_ulcer = lambda x: has_condition(x, 'ulcer')
__output__ = df_case_det['HasUlcer'] = df_case_det.Symptoms.apply(has_ulcer)
</code></pre>
        <p><span onclick="$('#var_output_35e56c27').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_35e56c27" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0        False
1        False
2        False
3        False
4        False
         ...  
37806    False
37807    False
37808    False
37809    False
37810    False
Name: Symptoms, Length: 37811, dtype: bool</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_case_det, __output__ </p>
    
          <p>df_case_det (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date_confirmation</th>
      <th>Country</th>
      <th>City</th>
      <th>Age</th>
      <th>Gender</th>
      <th>Symptoms</th>
      <th>Hospitalised (Y/N/NA)</th>
      <th>Isolated (Y/N/NA)</th>
      <th>Travel_history (Y/N/NA)</th>
      <th>date_quartile_interval</th>
      <th>HasUlcer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2022-01-31</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2022-02-17</td>
      <td>Cameroon</td>
      <td>NaN</td>
      <td>0-39</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2022-02-28</td>
      <td>Nigeria</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-01-30 23:59:59.999999999, 2022-07-08]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>37804</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>37805</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>37806</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>37807</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>37808</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>37809</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>37810</th>
      <td>2022-08-16</td>
      <td>Spain</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>(2022-08-05, 2022-08-16]</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>37811 rows × 11 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0        False
1        False
2        False
3        False
4        False
         ...  
37806    False
37807    False
37808    False
37809    False
37810    False
Name: Symptoms, Length: 37811, dtype: bool</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> monkeypox-dataset-daily-updated/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which countries have cases where ulcers were reported? Show the number of such cases for each.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_ulcer = df_case_det[['Country', 'HasUlcer']].groupby('Country').sum()
df_ulcer[df_ulcer > 0].dropna()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_ulcer = df_case_det[['Country', 'HasUlcer']].groupby('Country').sum()
df_ulcer[df_ulcer > 0].dropna()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_ulcer = df_case_det[['Country', 'HasUlcer']].groupby('Country').sum()
__output__ = df_ulcer[df_ulcer > 0].dropna()
</code></pre>
        <p><span onclick="$('#var_output_a72c6a1c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a72c6a1c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>HasUlcer</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Argentina</th>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Canada</th>
      <td>52.0</td>
    </tr>
    <tr>
      <th>Portugal</th>
      <td>20.0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_ulcer, __output__ </p>
    
          <p>df_ulcer (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>HasUlcer</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Andorra</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Argentina</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Australia</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Austria</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Barbados</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Belgium</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Benin</th>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Thailand</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Turkey</th>
      <td>0</td>
    </tr>
    <tr>
      <th>United Arab Emirates</th>
      <td>0</td>
    </tr>
    <tr>
      <th>United States</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Uruguay</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Venezuela</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Wales</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>97 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>HasUlcer</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Argentina</th>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Canada</th>
      <td>52.0</td>
    </tr>
    <tr>
      <th>Portugal</th>
      <td>20.0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> monkeypox-dataset-daily-updated/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # When was the first case with lesion confirmed?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_l = df_case_det[['Date_confirmation', 'Symptoms']].dropna()
df_l['HasLesion'] = df_l.Symptoms.apply(lambda x: has_condition(x, 'lesion'))
df_l.Date_confirmation[df_l.HasLesion].sort_values().iloc[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_l = df_case_det[['Date_confirmation', 'Symptoms']].dropna()
df_l['HasLesion'] = df_l.Symptoms.apply(lambda x: has_condition(x, 'lesion'))
df_l.Date_confirmation[df_l.HasLesion].sort_values().iloc[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_l = df_case_det[['Date_confirmation', 'Symptoms']].dropna()
df_l['HasLesion'] = df_l.Symptoms.apply(lambda x: has_condition(x, 'lesion'))
__output__ = df_l.Date_confirmation[df_l.HasLesion].sort_values().iloc[0]
</code></pre>
        <p><span onclick="$('#var_output_65df0262').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_65df0262" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Timestamp):</p>
          <pre><code>2022-05-17 00:00:00</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_l, __output__ </p>
    
          <p>df_l (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date_confirmation</th>
      <th>Symptoms</th>
      <th>HasLesion</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26</th>
      <td>2022-05-06</td>
      <td>[rash]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>37</th>
      <td>2022-05-12</td>
      <td>[rash]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>38</th>
      <td>2022-05-13</td>
      <td>[vesicular rash]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>39</th>
      <td>2022-05-15</td>
      <td>[vesicular rash]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>40</th>
      <td>2022-05-15</td>
      <td>[vesicular rash]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>41</th>
      <td>2022-05-15</td>
      <td>[vesicular rash]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>42</th>
      <td>2022-05-15</td>
      <td>[vesicular rash]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>28477</th>
      <td>2022-08-05</td>
      <td>[fever, blisters on limbs, genitals]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>29181</th>
      <td>2022-08-06</td>
      <td>[Swollen lymph nodes, rash, back pain]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>29957</th>
      <td>2022-08-08</td>
      <td>[general weakness, fever, skin rashes]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>29963</th>
      <td>2022-08-08</td>
      <td>[fatigue, malaise, fever, diarrhea, skin lesions, pustules]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>33012</th>
      <td>2022-08-10</td>
      <td>[headache, fever, joint pain, vesicular lesions on face]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>33112</th>
      <td>2022-08-10</td>
      <td>[rash]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>36247</th>
      <td>2022-08-14</td>
      <td>[blisters]</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>173 rows × 3 columns</p>
      
          <p>__output__ (Timestamp):</p>
          <pre><code>2022-05-17 00:00:00</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-mental-health/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert all columns answering polar questions (Yes/No) to boolean.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>conversion_dict = {'Yes': True, 'No': False}

def convert2bool(x):
    if set(x.unique()) == set(['Yes', 'No']):
        return x.apply(lambda y: conversion_dict[y])
    return x

df = df.apply(convert2bool)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>conversion_dict = {'Yes': True, 'No': False}

def convert2bool(x):
    if set(x.unique()) == set(['Yes', 'No']):
        return x.apply(lambda y: conversion_dict[y])
    return x

df = df.apply(convert2bool)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>conversion_dict = {'Yes': True, 'No': False}


def convert2bool(x):
    if set(x.unique()) == set(['Yes', 'No']):
        return x.apply(lambda y: conversion_dict[y])
    return x


__output__ = df = df.apply(convert2bool)
</code></pre>
        <p><span onclick="$('#var_output_4bbfc56c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4bbfc56c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Timestamp</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Course</th>
      <th>StudyYear</th>
      <th>CGPA</th>
      <th>IsMarried</th>
      <th>Depression</th>
      <th>Anxiety</th>
      <th>PanicAttack</th>
      <th>Treatment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8/7/2020 12:02</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8/7/2020 12:04</td>
      <td>Male</td>
      <td>21.0</td>
      <td>Islamic education</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8/7/2020 12:05</td>
      <td>Male</td>
      <td>19.0</td>
      <td>BIT</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8/7/2020 12:06</td>
      <td>Female</td>
      <td>22.0</td>
      <td>Laws</td>
      <td>3</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8/7/2020 12:13</td>
      <td>Male</td>
      <td>23.0</td>
      <td>Mathemathics</td>
      <td>4</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>8/7/2020 12:31</td>
      <td>Male</td>
      <td>19.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8/7/2020 12:32</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan islam</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>94</th>
      <td>13/07/2020 17:30:44</td>
      <td>Female</td>
      <td>24.0</td>
      <td>Fiqh</td>
      <td>3</td>
      <td>0 - 1.99</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>95</th>
      <td>13/07/2020 19:08:32</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Islamic Education</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>96</th>
      <td>13/07/2020 19:56:49</td>
      <td>Female</td>
      <td>21.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>97</th>
      <td>13/07/2020 21:21:42</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>98</th>
      <td>13/07/2020 21:22:56</td>
      <td>Female</td>
      <td>19.0</td>
      <td>Nursing</td>
      <td>3</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>99</th>
      <td>13/07/2020 21:23:57</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan Islam</td>
      <td>4</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>100</th>
      <td>18/07/2020 20:16:21</td>
      <td>Male</td>
      <td>20.0</td>
      <td>Biomedical science</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>101 rows × 11 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Timestamp</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Course</th>
      <th>StudyYear</th>
      <th>CGPA</th>
      <th>IsMarried</th>
      <th>Depression</th>
      <th>Anxiety</th>
      <th>PanicAttack</th>
      <th>Treatment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8/7/2020 12:02</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8/7/2020 12:04</td>
      <td>Male</td>
      <td>21.0</td>
      <td>Islamic education</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8/7/2020 12:05</td>
      <td>Male</td>
      <td>19.0</td>
      <td>BIT</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8/7/2020 12:06</td>
      <td>Female</td>
      <td>22.0</td>
      <td>Laws</td>
      <td>3</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8/7/2020 12:13</td>
      <td>Male</td>
      <td>23.0</td>
      <td>Mathemathics</td>
      <td>4</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>8/7/2020 12:31</td>
      <td>Male</td>
      <td>19.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8/7/2020 12:32</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan islam</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>94</th>
      <td>13/07/2020 17:30:44</td>
      <td>Female</td>
      <td>24.0</td>
      <td>Fiqh</td>
      <td>3</td>
      <td>0 - 1.99</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>95</th>
      <td>13/07/2020 19:08:32</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Islamic Education</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>96</th>
      <td>13/07/2020 19:56:49</td>
      <td>Female</td>
      <td>21.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>97</th>
      <td>13/07/2020 21:21:42</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>98</th>
      <td>13/07/2020 21:22:56</td>
      <td>Female</td>
      <td>19.0</td>
      <td>Nursing</td>
      <td>3</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>99</th>
      <td>13/07/2020 21:23:57</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan Islam</td>
      <td>4</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>100</th>
      <td>18/07/2020 20:16:21</td>
      <td>Male</td>
      <td>20.0</td>
      <td>Biomedical science</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>101 rows × 11 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Timestamp</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Course</th>
      <th>StudyYear</th>
      <th>CGPA</th>
      <th>IsMarried</th>
      <th>Depression</th>
      <th>Anxiety</th>
      <th>PanicAttack</th>
      <th>Treatment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8/7/2020 12:02</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8/7/2020 12:04</td>
      <td>Male</td>
      <td>21.0</td>
      <td>Islamic education</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8/7/2020 12:05</td>
      <td>Male</td>
      <td>19.0</td>
      <td>BIT</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8/7/2020 12:06</td>
      <td>Female</td>
      <td>22.0</td>
      <td>Laws</td>
      <td>3</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8/7/2020 12:13</td>
      <td>Male</td>
      <td>23.0</td>
      <td>Mathemathics</td>
      <td>4</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>8/7/2020 12:31</td>
      <td>Male</td>
      <td>19.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8/7/2020 12:32</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan islam</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>94</th>
      <td>13/07/2020 17:30:44</td>
      <td>Female</td>
      <td>24.0</td>
      <td>Fiqh</td>
      <td>3</td>
      <td>0 - 1.99</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>95</th>
      <td>13/07/2020 19:08:32</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Islamic Education</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>96</th>
      <td>13/07/2020 19:56:49</td>
      <td>Female</td>
      <td>21.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>97</th>
      <td>13/07/2020 21:21:42</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>98</th>
      <td>13/07/2020 21:22:56</td>
      <td>Female</td>
      <td>19.0</td>
      <td>Nursing</td>
      <td>3</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>99</th>
      <td>13/07/2020 21:23:57</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan Islam</td>
      <td>4</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>100</th>
      <td>18/07/2020 20:16:21</td>
      <td>Male</td>
      <td>20.0</td>
      <td>Biomedical science</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>101 rows × 11 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-mental-health/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the percent likelihood that a student suffers from depression given their year of study?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>dfsy = df[['StudyYear', 'Depression']]
dfsy_grp = dfsy.groupby('StudyYear')
100 * dfsy_grp.sum() / dfsy_grp.count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>dfsy = df[['StudyYear', 'Depression']]
dfsy_grp = dfsy.groupby('StudyYear')
100 * dfsy_grp.sum() / dfsy_grp.count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>dfsy = df[['StudyYear', 'Depression']]
dfsy_grp = dfsy.groupby('StudyYear')
__output__ = 100 * dfsy_grp.sum() / dfsy_grp.count()
</code></pre>
        <p><span onclick="$('#var_output_65dcdede').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_65dcdede" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Depression</th>
    </tr>
    <tr>
      <th>StudyYear</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>32.558140</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38.461538</td>
    </tr>
    <tr>
      <th>3</th>
      <td>41.666667</td>
    </tr>
    <tr>
      <th>4</th>
      <td>12.500000</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> dfsy, __output__ </p>
    
          <p>dfsy (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>StudyYear</th>
      <th>Depression</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2</td>
      <td>True</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>94</th>
      <td>3</td>
      <td>False</td>
    </tr>
    <tr>
      <th>95</th>
      <td>1</td>
      <td>False</td>
    </tr>
    <tr>
      <th>96</th>
      <td>1</td>
      <td>False</td>
    </tr>
    <tr>
      <th>97</th>
      <td>2</td>
      <td>True</td>
    </tr>
    <tr>
      <th>98</th>
      <td>3</td>
      <td>True</td>
    </tr>
    <tr>
      <th>99</th>
      <td>4</td>
      <td>False</td>
    </tr>
    <tr>
      <th>100</th>
      <td>2</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>101 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Depression</th>
    </tr>
    <tr>
      <th>StudyYear</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>32.558140</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38.461538</td>
    </tr>
    <tr>
      <th>3</th>
      <td>41.666667</td>
    </tr>
    <tr>
      <th>4</th>
      <td>12.500000</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-mental-health/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What percentage of students who suffer from depression also suffer from anxiety?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>anxiety = df[df.Depression == True].Anxiety
100 * anxiety.sum() / anxiety.count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>anxiety = df[df.Depression == True].Anxiety
100 * anxiety.sum() / anxiety.count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>anxiety = df[df.Depression == True].Anxiety
__output__ = 100 * anxiety.sum() / anxiety.count()
</code></pre>
        <p><span onclick="$('#var_output_7bc6b583').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7bc6b583" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>51.42857142857143</code></pre>
      
        <p><strong>Hyp output variables:</strong> anxiety, __output__ </p>
    
          <p>anxiety (Series):</p>
          <pre><code>0     False
2      True
3     False
6     False
11    False
      ...  
87     True
92    False
93    False
97     True
98    False
Name: Anxiety, Length: 35, dtype: bool</code></pre>
      
          <p>__output__ (float64):</p>
          <pre><code>51.42857142857143</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-mental-health/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How likely are men suffering from depression to seek treatment compared to women? Show the likelihoods in percentage.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>dfg = df[df.Depression][['Gender', 'Treatment']].groupby('Gender')
dfg.sum() / dfg.count() * 100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>dfg = df[df.Depression][['Gender', 'Treatment']].groupby('Gender')
dfg.sum() / dfg.count() * 100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>dfg = df[df.Depression][['Gender', 'Treatment']].groupby('Gender')
__output__ = dfg.sum() / dfg.count() * 100
</code></pre>
        <p><span onclick="$('#var_output_061c9611').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_061c9611" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Treatment</th>
    </tr>
    <tr>
      <th>Gender</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Female</th>
      <td>17.241379</td>
    </tr>
    <tr>
      <th>Male</th>
      <td>16.666667</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Treatment</th>
    </tr>
    <tr>
      <th>Gender</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Female</th>
      <td>17.241379</td>
    </tr>
    <tr>
      <th>Male</th>
      <td>16.666667</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-mental-health/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How likely are married students suffering from depression to avoid treatment compared to single students? Show the likelihoods in percentage.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>dfg = df[df.Depression][['IsMarried', 'Treatment']].groupby('IsMarried')
(1 - dfg.sum() / dfg.count()) * 100</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>dfg = df[df.Depression][['IsMarried', 'Treatment']].groupby('IsMarried')
(1 - dfg.sum() / dfg.count()) * 100</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>dfg = df[df.Depression][['IsMarried', 'Treatment']].groupby('IsMarried')
__output__ = (1 - dfg.sum() / dfg.count()) * 100
</code></pre>
        <p><span onclick="$('#var_output_fda14e23').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_fda14e23" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Treatment</th>
    </tr>
    <tr>
      <th>IsMarried</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>False</th>
      <td>89.473684</td>
    </tr>
    <tr>
      <th>True</th>
      <td>75.000000</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Treatment</th>
    </tr>
    <tr>
      <th>IsMarried</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>False</th>
      <td>89.473684</td>
    </tr>
    <tr>
      <th>True</th>
      <td>75.000000</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-mental-health/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which grade group is most likely to suffer from mental health issues?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>grade_df = (100 * df[df.Anxiety | df.Depression | df.PanicAttack][['CGPA']].apply(lambda x: x.value_counts()) / df[
    ['CGPA']].apply(lambda x: x.value_counts()))
grade_df.sort_values('CGPA').iloc[-1].name</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>grade_df = (100 * df[df.Anxiety | df.Depression | df.PanicAttack][['CGPA']].apply(lambda x: x.value_counts()) / df[
    ['CGPA']].apply(lambda x: x.value_counts()))
grade_df.sort_values('CGPA').iloc[-1].name</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>grade_df = 100 * df[df.Anxiety | df.Depression | df.PanicAttack][['CGPA']
    ].apply(lambda x: x.value_counts()) / df[['CGPA']].apply(lambda x: x.
    value_counts())
__output__ = grade_df.sort_values('CGPA').iloc[-1].name
</code></pre>
        <p><span onclick="$('#var_output_4214e977').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4214e977" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>3.50 - 4.00 </code></pre>
      
        <p><strong>Hyp output variables:</strong> grade_df, __output__ </p>
    
          <p>grade_df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CGPA</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0 - 1.99</th>
      <td>25.000000</td>
    </tr>
    <tr>
      <th>2.00 - 2.49</th>
      <td>50.000000</td>
    </tr>
    <tr>
      <th>2.50 - 2.99</th>
      <td>75.000000</td>
    </tr>
    <tr>
      <th>3.00 - 3.49</th>
      <td>65.116279</td>
    </tr>
    <tr>
      <th>3.50 - 4.00</th>
      <td>63.829787</td>
    </tr>
    <tr>
      <th>3.50 - 4.00</th>
      <td>100.000000</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>3.50 - 4.00 </code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-mental-health/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Categorize the students into groups by quartiles of their ages in a new column and show the percent likelihood of suffering from depression given age group.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['AgeGroup'] = pd.qcut(df.Age, 4, duplicates='drop')
df_age_groups = df[['AgeGroup', 'Depression']].groupby('AgeGroup')
100 * df_age_groups.sum() / df_age_groups.count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['AgeGroup'] = pd.qcut(df.Age, 4, duplicates='drop')
df_age_groups = df[['AgeGroup', 'Depression']].groupby('AgeGroup')
100 * df_age_groups.sum() / df_age_groups.count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['AgeGroup'] = pd.qcut(df.Age, 4, duplicates='drop')
df_age_groups = df[['AgeGroup', 'Depression']].groupby('AgeGroup')
__output__ = 100 * df_age_groups.sum() / df_age_groups.count()
</code></pre>
        <p><span onclick="$('#var_output_e618fb09').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e618fb09" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Depression</th>
    </tr>
    <tr>
      <th>AgeGroup</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(17.999, 19.0]</th>
      <td>37.735849</td>
    </tr>
    <tr>
      <th>(19.0, 23.0]</th>
      <td>37.500000</td>
    </tr>
    <tr>
      <th>(23.0, 24.0]</th>
      <td>26.086957</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Timestamp</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Course</th>
      <th>StudyYear</th>
      <th>CGPA</th>
      <th>IsMarried</th>
      <th>Depression</th>
      <th>Anxiety</th>
      <th>PanicAttack</th>
      <th>Treatment</th>
      <th>AgeGroup</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8/7/2020 12:02</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8/7/2020 12:04</td>
      <td>Male</td>
      <td>21.0</td>
      <td>Islamic education</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8/7/2020 12:05</td>
      <td>Male</td>
      <td>19.0</td>
      <td>BIT</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8/7/2020 12:06</td>
      <td>Female</td>
      <td>22.0</td>
      <td>Laws</td>
      <td>3</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8/7/2020 12:13</td>
      <td>Male</td>
      <td>23.0</td>
      <td>Mathemathics</td>
      <td>4</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>8/7/2020 12:31</td>
      <td>Male</td>
      <td>19.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8/7/2020 12:32</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan islam</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>94</th>
      <td>13/07/2020 17:30:44</td>
      <td>Female</td>
      <td>24.0</td>
      <td>Fiqh</td>
      <td>3</td>
      <td>0 - 1.99</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(23.0, 24.0]</td>
    </tr>
    <tr>
      <th>95</th>
      <td>13/07/2020 19:08:32</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Islamic Education</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
    </tr>
    <tr>
      <th>96</th>
      <td>13/07/2020 19:56:49</td>
      <td>Female</td>
      <td>21.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
    </tr>
    <tr>
      <th>97</th>
      <td>13/07/2020 21:21:42</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
    </tr>
    <tr>
      <th>98</th>
      <td>13/07/2020 21:22:56</td>
      <td>Female</td>
      <td>19.0</td>
      <td>Nursing</td>
      <td>3</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
    </tr>
    <tr>
      <th>99</th>
      <td>13/07/2020 21:23:57</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan Islam</td>
      <td>4</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
    </tr>
    <tr>
      <th>100</th>
      <td>18/07/2020 20:16:21</td>
      <td>Male</td>
      <td>20.0</td>
      <td>Biomedical science</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
    </tr>
  </tbody>
</table>
<p>101 rows × 12 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Depression</th>
    </tr>
    <tr>
      <th>AgeGroup</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(17.999, 19.0]</th>
      <td>37.735849</td>
    </tr>
    <tr>
      <th>(19.0, 23.0]</th>
      <td>37.500000</td>
    </tr>
    <tr>
      <th>(23.0, 24.0]</th>
      <td>26.086957</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.2, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-mental-health/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the chances of students having more than one mental health issue? Show in percentage.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>issues = ['Depression', 'Anxiety', 'PanicAttack']
suffers_from_at_least_n_issues = lambda x, n: x[issues].T.sum() >= n
df['AtLeast2Issues'] = df.apply(lambda x: suffers_from_at_least_n_issues(x, 2), 1)
100 * df.AtLeast2Issues.sum() / len(df)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>issues = ['Depression', 'Anxiety', 'PanicAttack']
suffers_from_at_least_n_issues = lambda x, n: x[issues].T.sum() >= n
df['AtLeast2Issues'] = df.apply(lambda x: suffers_from_at_least_n_issues(x, 2), 1)
100 * df.AtLeast2Issues.sum() / len(df)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>issues = ['Depression', 'Anxiety', 'PanicAttack']
suffers_from_at_least_n_issues = lambda x, n: x[issues].T.sum() >= n
df['AtLeast2Issues'] = df.apply(lambda x: suffers_from_at_least_n_issues(x,
    2), 1)
__output__ = 100 * df.AtLeast2Issues.sum() / len(df)
</code></pre>
        <p><span onclick="$('#var_output_ac8052a4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ac8052a4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>27.722772277227723</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, issues, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Timestamp</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Course</th>
      <th>StudyYear</th>
      <th>CGPA</th>
      <th>IsMarried</th>
      <th>Depression</th>
      <th>Anxiety</th>
      <th>PanicAttack</th>
      <th>Treatment</th>
      <th>AgeGroup</th>
      <th>AtLeast2Issues</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8/7/2020 12:02</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8/7/2020 12:04</td>
      <td>Male</td>
      <td>21.0</td>
      <td>Islamic education</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8/7/2020 12:05</td>
      <td>Male</td>
      <td>19.0</td>
      <td>BIT</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8/7/2020 12:06</td>
      <td>Female</td>
      <td>22.0</td>
      <td>Laws</td>
      <td>3</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8/7/2020 12:13</td>
      <td>Male</td>
      <td>23.0</td>
      <td>Mathemathics</td>
      <td>4</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>8/7/2020 12:31</td>
      <td>Male</td>
      <td>19.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8/7/2020 12:32</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan islam</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>94</th>
      <td>13/07/2020 17:30:44</td>
      <td>Female</td>
      <td>24.0</td>
      <td>Fiqh</td>
      <td>3</td>
      <td>0 - 1.99</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(23.0, 24.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>95</th>
      <td>13/07/2020 19:08:32</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Islamic Education</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>96</th>
      <td>13/07/2020 19:56:49</td>
      <td>Female</td>
      <td>21.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>97</th>
      <td>13/07/2020 21:21:42</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>98</th>
      <td>13/07/2020 21:22:56</td>
      <td>Female</td>
      <td>19.0</td>
      <td>Nursing</td>
      <td>3</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>99</th>
      <td>13/07/2020 21:23:57</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan Islam</td>
      <td>4</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>100</th>
      <td>18/07/2020 20:16:21</td>
      <td>Male</td>
      <td>20.0</td>
      <td>Biomedical science</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>101 rows × 13 columns</p>
      
          <p>issues (list):</p>
          <pre><code>['Depression', 'Anxiety', 'PanicAttack']</code></pre>
      
          <p>__output__ (float64):</p>
          <pre><code>27.722772277227723</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.16666666666666666, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-mental-health/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How likely is it for students undergoing treatment to suffer from less than two issues?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>len(df[~df.AtLeast2Issues & df.Treatment]) / df.Treatment.sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>len(df[~df.AtLeast2Issues & df.Treatment]) / df.Treatment.sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = len(df[~df.AtLeast2Issues & df.Treatment]) / df.Treatment.sum()
</code></pre>
        <p><span onclick="$('#var_output_839bc92c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_839bc92c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>0.0</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (float64):</p>
          <pre><code>0.0</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-mental-health/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Extract the data for students who suffer from at least one mental health problem.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_patients = df[df.apply(lambda x: suffers_from_at_least_n_issues(x, 1), 1)]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>['df_patients']</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_patients = df[df.apply(lambda x: suffers_from_at_least_n_issues(x, 1), 1)]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_patients = df[df.apply(lambda x:
    suffers_from_at_least_n_issues(x, 1), 1)]
</code></pre>
        <p><span onclick="$('#var_output_dc72af0c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_dc72af0c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> df_patients </p>
    
          <p>df_patients (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Timestamp</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Course</th>
      <th>StudyYear</th>
      <th>CGPA</th>
      <th>IsMarried</th>
      <th>Depression</th>
      <th>Anxiety</th>
      <th>PanicAttack</th>
      <th>Treatment</th>
      <th>AgeGroup</th>
      <th>AtLeast2Issues</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8/7/2020 12:02</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8/7/2020 12:04</td>
      <td>Male</td>
      <td>21.0</td>
      <td>Islamic education</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8/7/2020 12:05</td>
      <td>Male</td>
      <td>19.0</td>
      <td>BIT</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8/7/2020 12:06</td>
      <td>Female</td>
      <td>22.0</td>
      <td>Laws</td>
      <td>3</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>8/7/2020 12:31</td>
      <td>Male</td>
      <td>19.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8/7/2020 12:32</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan islam</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8/7/2020 12:33</td>
      <td>Female</td>
      <td>18.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>91</th>
      <td>13/07/2020 14:38:12</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Koe</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>92</th>
      <td>13/07/2020 14:48:05</td>
      <td>Female</td>
      <td>19.0</td>
      <td>KOE</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>93</th>
      <td>13/07/2020 16:15:13</td>
      <td>Female</td>
      <td>18.0</td>
      <td>BENL</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>94</th>
      <td>13/07/2020 17:30:44</td>
      <td>Female</td>
      <td>24.0</td>
      <td>Fiqh</td>
      <td>3</td>
      <td>0 - 1.99</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(23.0, 24.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>96</th>
      <td>13/07/2020 19:56:49</td>
      <td>Female</td>
      <td>21.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>97</th>
      <td>13/07/2020 21:21:42</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>98</th>
      <td>13/07/2020 21:22:56</td>
      <td>Female</td>
      <td>19.0</td>
      <td>Nursing</td>
      <td>3</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>64 rows × 13 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__, df_patients </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Timestamp</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Course</th>
      <th>StudyYear</th>
      <th>CGPA</th>
      <th>IsMarried</th>
      <th>Depression</th>
      <th>Anxiety</th>
      <th>PanicAttack</th>
      <th>Treatment</th>
      <th>AgeGroup</th>
      <th>AtLeast2Issues</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8/7/2020 12:02</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8/7/2020 12:04</td>
      <td>Male</td>
      <td>21.0</td>
      <td>Islamic education</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8/7/2020 12:05</td>
      <td>Male</td>
      <td>19.0</td>
      <td>BIT</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8/7/2020 12:06</td>
      <td>Female</td>
      <td>22.0</td>
      <td>Laws</td>
      <td>3</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>8/7/2020 12:31</td>
      <td>Male</td>
      <td>19.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8/7/2020 12:32</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan islam</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8/7/2020 12:33</td>
      <td>Female</td>
      <td>18.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>91</th>
      <td>13/07/2020 14:38:12</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Koe</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>92</th>
      <td>13/07/2020 14:48:05</td>
      <td>Female</td>
      <td>19.0</td>
      <td>KOE</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>93</th>
      <td>13/07/2020 16:15:13</td>
      <td>Female</td>
      <td>18.0</td>
      <td>BENL</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>94</th>
      <td>13/07/2020 17:30:44</td>
      <td>Female</td>
      <td>24.0</td>
      <td>Fiqh</td>
      <td>3</td>
      <td>0 - 1.99</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(23.0, 24.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>96</th>
      <td>13/07/2020 19:56:49</td>
      <td>Female</td>
      <td>21.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>97</th>
      <td>13/07/2020 21:21:42</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>98</th>
      <td>13/07/2020 21:22:56</td>
      <td>Female</td>
      <td>19.0</td>
      <td>Nursing</td>
      <td>3</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>64 rows × 13 columns</p>
      
          <p>df_patients (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Timestamp</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Course</th>
      <th>StudyYear</th>
      <th>CGPA</th>
      <th>IsMarried</th>
      <th>Depression</th>
      <th>Anxiety</th>
      <th>PanicAttack</th>
      <th>Treatment</th>
      <th>AgeGroup</th>
      <th>AtLeast2Issues</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8/7/2020 12:02</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8/7/2020 12:04</td>
      <td>Male</td>
      <td>21.0</td>
      <td>Islamic education</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8/7/2020 12:05</td>
      <td>Male</td>
      <td>19.0</td>
      <td>BIT</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8/7/2020 12:06</td>
      <td>Female</td>
      <td>22.0</td>
      <td>Laws</td>
      <td>3</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>8/7/2020 12:31</td>
      <td>Male</td>
      <td>19.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8/7/2020 12:32</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan islam</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8/7/2020 12:33</td>
      <td>Female</td>
      <td>18.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>91</th>
      <td>13/07/2020 14:38:12</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Koe</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>92</th>
      <td>13/07/2020 14:48:05</td>
      <td>Female</td>
      <td>19.0</td>
      <td>KOE</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>93</th>
      <td>13/07/2020 16:15:13</td>
      <td>Female</td>
      <td>18.0</td>
      <td>BENL</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>94</th>
      <td>13/07/2020 17:30:44</td>
      <td>Female</td>
      <td>24.0</td>
      <td>Fiqh</td>
      <td>3</td>
      <td>0 - 1.99</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(23.0, 24.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>96</th>
      <td>13/07/2020 19:56:49</td>
      <td>Female</td>
      <td>21.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(19.0, 23.0]</td>
      <td>False</td>
    </tr>
    <tr>
      <th>97</th>
      <td>13/07/2020 21:21:42</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
    <tr>
      <th>98</th>
      <td>13/07/2020 21:22:56</td>
      <td>Female</td>
      <td>19.0</td>
      <td>Nursing</td>
      <td>3</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>(17.999, 19.0]</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>64 rows × 13 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', 'df_patients', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.2, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> student-mental-health/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the number of students suffering from each combination of anxiety, depression and panic attacks.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>issue_combinations = issues + list(combinations(issues, 2)) + list(combinations(issues, 3))

def count_combinations(x):
    for issue_combination in issue_combinations:
        if type(issue_combination) is str:
            name = 'Only_' + issue_combination
        else:
            name = '_AND_'.join(list(issue_combination))
        x[name] = True
        for issue in issues:
            if issue in issue_combination and not x[issue]:
                x[name] = False
                break
            if issue not in issue_combination and x[issue]:
                x[name] = False
                break
    return x

df_patients = df_patients.apply(count_combinations, 1)
df_patients[[i for i in df_patients.columns if '_' in i]].sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>issue_combinations = issues + list(combinations(issues, 2)) + list(combinations(issues, 3))

def count_combinations(x):
    for issue_combination in issue_combinations:
        if type(issue_combination) is str:
            name = 'Only_' + issue_combination
        else:
            name = '_AND_'.join(list(issue_combination))
        x[name] = True
        for issue in issues:
            if issue in issue_combination and not x[issue]:
                x[name] = False
                break
            if issue not in issue_combination and x[issue]:
                x[name] = False
                break
    return x

df_patients = df_patients.apply(count_combinations, 1)
df_patients[[i for i in df_patients.columns if '_' in i]].sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>issue_combinations = issues + list(combinations(issues, 2)) + list(combinations
    (issues, 3))


def count_combinations(x):
    for issue_combination in issue_combinations:
        if type(issue_combination) is str:
            name = 'Only_' + issue_combination
        else:
            name = '_AND_'.join(list(issue_combination))
        x[name] = True
        for issue in issues:
            if issue in issue_combination and not x[issue]:
                x[name] = False
                break
            if issue not in issue_combination and x[issue]:
                x[name] = False
                break
    return x


df_patients = df_patients.apply(count_combinations, 1)
__output__ = df_patients[[i for i in df_patients.columns if '_' in i]].sum()
</code></pre>
        <p><span onclick="$('#var_output_e4c84393').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e4c84393" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Only_Depression                           10
Only_Anxiety                              13
Only_PanicAttack                          13
Depression_AND_Anxiety                     8
Depression_AND_PanicAttack                 7
Anxiety_AND_PanicAttack                    3
Depression_AND_Anxiety_AND_PanicAttack    10
dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_patients, issue_combinations, __output__ </p>
    
          <p>df_patients (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Timestamp</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Course</th>
      <th>StudyYear</th>
      <th>CGPA</th>
      <th>IsMarried</th>
      <th>...</th>
      <th>Only_Depression</th>
      <th>Only_Anxiety</th>
      <th>Only_PanicAttack</th>
      <th>Depression_AND_Anxiety</th>
      <th>Depression_AND_PanicAttack</th>
      <th>Anxiety_AND_PanicAttack</th>
      <th>Depression_AND_Anxiety_AND_PanicAttack</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8/7/2020 12:02</td>
      <td>Female</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8/7/2020 12:04</td>
      <td>Male</td>
      <td>21.0</td>
      <td>Islamic education</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8/7/2020 12:05</td>
      <td>Male</td>
      <td>19.0</td>
      <td>BIT</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8/7/2020 12:06</td>
      <td>Female</td>
      <td>22.0</td>
      <td>Laws</td>
      <td>3</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>...</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>8/7/2020 12:31</td>
      <td>Male</td>
      <td>19.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8/7/2020 12:32</td>
      <td>Female</td>
      <td>23.0</td>
      <td>Pendidikan islam</td>
      <td>2</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8/7/2020 12:33</td>
      <td>Female</td>
      <td>18.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>91</th>
      <td>13/07/2020 14:38:12</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Koe</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>92</th>
      <td>13/07/2020 14:48:05</td>
      <td>Female</td>
      <td>19.0</td>
      <td>KOE</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>True</td>
      <td>...</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>93</th>
      <td>13/07/2020 16:15:13</td>
      <td>Female</td>
      <td>18.0</td>
      <td>BENL</td>
      <td>1</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>...</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>94</th>
      <td>13/07/2020 17:30:44</td>
      <td>Female</td>
      <td>24.0</td>
      <td>Fiqh</td>
      <td>3</td>
      <td>0 - 1.99</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>96</th>
      <td>13/07/2020 19:56:49</td>
      <td>Female</td>
      <td>21.0</td>
      <td>BCS</td>
      <td>1</td>
      <td>3.50 - 4.00</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>97</th>
      <td>13/07/2020 21:21:42</td>
      <td>Male</td>
      <td>18.0</td>
      <td>Engineering</td>
      <td>2</td>
      <td>3.00 - 3.49</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>98</th>
      <td>13/07/2020 21:22:56</td>
      <td>Female</td>
      <td>19.0</td>
      <td>Nursing</td>
      <td>3</td>
      <td>3.50 - 4.00</td>
      <td>True</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>64 rows × 20 columns</p>
      
          <p>issue_combinations (list):</p>
          <pre><code>['Depression', 'Anxiety', 'PanicAttack', ('Depression', 'Anxiety'), ('Depression', 'PanicAttack'), ('Anxiety', 'PanicAttack'), ('Depression', 'Anxiety', 'PanicAttack')]</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>Only_Depression                           10
Only_Anxiety                              13
Only_PanicAttack                          13
Depression_AND_Anxiety                     8
Depression_AND_PanicAttack                 7
Anxiety_AND_PanicAttack                    3
Depression_AND_Anxiety_AND_PanicAttack    10
dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.16666666666666666, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> football-manager-2022-player-data/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create two columns that have the country and the league where each player plays at.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def find_country_and_league(x):
    country = x.League_where_the_player_plays.split(' ')[0]
    league = re.findall('\(([^)]+)\)', x.League_where_the_player_plays)[0]
    x['Country_where_the_player_plays'] = country
    x['League_where_the_player_plays'] = league
    return x

df = df.apply(find_country_and_league, 1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def find_country_and_league(x):
    country = x.League_where_the_player_plays.split(' ')[0]
    league = re.findall('\(([^)]+)\)', x.League_where_the_player_plays)[0]
    x['Country_where_the_player_plays'] = country
    x['League_where_the_player_plays'] = league
    return x

df = df.apply(find_country_and_league, 1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def find_country_and_league(x):
    country = x.League_where_the_player_plays.split(' ')[0]
    league = re.findall('\\(([^)]+)\\)', x.League_where_the_player_plays)[0]
    x['Country_where_the_player_plays'] = country
    x['League_where_the_player_plays'] = league
    return x


__output__ = df = df.apply(find_country_and_league, 1)
</code></pre>
        <p><span onclick="$('#var_output_9698ddc1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9698ddc1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name_of_the_player</th>
      <th>Number_of_appearances</th>
      <th>Minutes_played</th>
      <th>Minutes_played_per_game</th>
      <th>Height_of_the_player_in_cm</th>
      <th>Weight_of_the_player_in_kg</th>
      <th>Age_of_the_player</th>
      <th>...</th>
      <th>Total_saves</th>
      <th>Saves_divided_by_expected_saves</th>
      <th>Gaols_divided_by_expected_goals</th>
      <th>Distance_run_by_minutes</th>
      <th>Transfer_value_range</th>
      <th>Average_transfer_value</th>
      <th>Country_where_the_player_plays</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Josip Mijatović</td>
      <td>12.0</td>
      <td>809.0</td>
      <td>67.416667</td>
      <td>173.0</td>
      <td>68.0</td>
      <td>20</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>5.555556</td>
      <td>0.126823</td>
      <td>€3K - €9K</td>
      <td>6000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Duje Ninčević</td>
      <td>15.0</td>
      <td>1161.0</td>
      <td>77.400000</td>
      <td>172.0</td>
      <td>69.0</td>
      <td>25</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.129457</td>
      <td>€0 - €2.5K</td>
      <td>1250.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Marin Karabatić</td>
      <td>15.0</td>
      <td>1350.0</td>
      <td>90.000000</td>
      <td>170.0</td>
      <td>62.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.128000</td>
      <td>€0 - €12K</td>
      <td>6000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vicko Ševelj</td>
      <td>20.0</td>
      <td>1738.0</td>
      <td>86.900000</td>
      <td>192.0</td>
      <td>86.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>2.380952</td>
      <td>0.058631</td>
      <td>€100K - €1M</td>
      <td>550000.0</td>
      <td>Bosnia</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fran Vujnović</td>
      <td>15.0</td>
      <td>1384.0</td>
      <td>92.266667</td>
      <td>190.0</td>
      <td>77.0</td>
      <td>19</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.016040</td>
      <td>€14K - €150K</td>
      <td>82000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Šimun Mikolčić</td>
      <td>15.0</td>
      <td>1380.0</td>
      <td>92.000000</td>
      <td>180.0</td>
      <td>70.0</td>
      <td>18</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>25.000000</td>
      <td>0.013623</td>
      <td>€35K - €350K</td>
      <td>192500.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Romano Lisjak</td>
      <td>16.0</td>
      <td>1440.0</td>
      <td>90.000000</td>
      <td>188.0</td>
      <td>80.0</td>
      <td>21</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.847458</td>
      <td>0.101319</td>
      <td>€0 - €50K</td>
      <td>25000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1115</th>
      <td>Gianluigi Donnarumma</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>196.0</td>
      <td>90.0</td>
      <td>23</td>
      <td>...</td>
      <td>48.0</td>
      <td>-1.132610</td>
      <td>0.000000</td>
      <td>0.070351</td>
      <td>€254M - €276M</td>
      <td>265000000.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>Éder Militão</td>
      <td>17.0</td>
      <td>1457.0</td>
      <td>85.705882</td>
      <td>186.0</td>
      <td>79.0</td>
      <td>24</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.113315</td>
      <td>€94M - €149M</td>
      <td>121500000.0</td>
      <td>Spain</td>
    </tr>
    <tr>
      <th>1117</th>
      <td>Sergio Ramos</td>
      <td>11.0</td>
      <td>924.0</td>
      <td>84.000000</td>
      <td>184.0</td>
      <td>82.0</td>
      <td>36</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.123268</td>
      <td>€12M - €18M</td>
      <td>15000000.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>1118</th>
      <td>Marquinhos</td>
      <td>13.0</td>
      <td>1129.0</td>
      <td>86.846154</td>
      <td>183.0</td>
      <td>75.0</td>
      <td>28</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>3.448276</td>
      <td>0.126749</td>
      <td>€99M - €128M</td>
      <td>113500000.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>1119</th>
      <td>Thibaut Courtois</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>199.0</td>
      <td>96.0</td>
      <td>30</td>
      <td>...</td>
      <td>48.0</td>
      <td>-0.848956</td>
      <td>0.000000</td>
      <td>0.072982</td>
      <td>€172M - €225M</td>
      <td>198500000.0</td>
      <td>Spain</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>Raphaël Varane</td>
      <td>17.0</td>
      <td>1463.0</td>
      <td>86.058824</td>
      <td>191.0</td>
      <td>81.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.107792</td>
      <td>€101M - €127M</td>
      <td>114000000.0</td>
      <td>England</td>
    </tr>
    <tr>
      <th>1121</th>
      <td>Jan Oblak</td>
      <td>19.0</td>
      <td>1687.0</td>
      <td>88.789474</td>
      <td>189.0</td>
      <td>84.0</td>
      <td>29</td>
      <td>...</td>
      <td>45.0</td>
      <td>-3.118503</td>
      <td>0.000000</td>
      <td>0.067635</td>
      <td>€112M - €178M</td>
      <td>145000000.0</td>
      <td>Spain</td>
    </tr>
  </tbody>
</table>
<p>1122 rows × 45 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name_of_the_player</th>
      <th>Number_of_appearances</th>
      <th>Minutes_played</th>
      <th>Minutes_played_per_game</th>
      <th>Height_of_the_player_in_cm</th>
      <th>Weight_of_the_player_in_kg</th>
      <th>Age_of_the_player</th>
      <th>...</th>
      <th>Total_saves</th>
      <th>Saves_divided_by_expected_saves</th>
      <th>Gaols_divided_by_expected_goals</th>
      <th>Distance_run_by_minutes</th>
      <th>Transfer_value_range</th>
      <th>Average_transfer_value</th>
      <th>Country_where_the_player_plays</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Josip Mijatović</td>
      <td>12.0</td>
      <td>809.0</td>
      <td>67.416667</td>
      <td>173.0</td>
      <td>68.0</td>
      <td>20</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>5.555556</td>
      <td>0.126823</td>
      <td>€3K - €9K</td>
      <td>6000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Duje Ninčević</td>
      <td>15.0</td>
      <td>1161.0</td>
      <td>77.400000</td>
      <td>172.0</td>
      <td>69.0</td>
      <td>25</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.129457</td>
      <td>€0 - €2.5K</td>
      <td>1250.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Marin Karabatić</td>
      <td>15.0</td>
      <td>1350.0</td>
      <td>90.000000</td>
      <td>170.0</td>
      <td>62.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.128000</td>
      <td>€0 - €12K</td>
      <td>6000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vicko Ševelj</td>
      <td>20.0</td>
      <td>1738.0</td>
      <td>86.900000</td>
      <td>192.0</td>
      <td>86.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>2.380952</td>
      <td>0.058631</td>
      <td>€100K - €1M</td>
      <td>550000.0</td>
      <td>Bosnia</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fran Vujnović</td>
      <td>15.0</td>
      <td>1384.0</td>
      <td>92.266667</td>
      <td>190.0</td>
      <td>77.0</td>
      <td>19</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.016040</td>
      <td>€14K - €150K</td>
      <td>82000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Šimun Mikolčić</td>
      <td>15.0</td>
      <td>1380.0</td>
      <td>92.000000</td>
      <td>180.0</td>
      <td>70.0</td>
      <td>18</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>25.000000</td>
      <td>0.013623</td>
      <td>€35K - €350K</td>
      <td>192500.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Romano Lisjak</td>
      <td>16.0</td>
      <td>1440.0</td>
      <td>90.000000</td>
      <td>188.0</td>
      <td>80.0</td>
      <td>21</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.847458</td>
      <td>0.101319</td>
      <td>€0 - €50K</td>
      <td>25000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1115</th>
      <td>Gianluigi Donnarumma</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>196.0</td>
      <td>90.0</td>
      <td>23</td>
      <td>...</td>
      <td>48.0</td>
      <td>-1.132610</td>
      <td>0.000000</td>
      <td>0.070351</td>
      <td>€254M - €276M</td>
      <td>265000000.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>Éder Militão</td>
      <td>17.0</td>
      <td>1457.0</td>
      <td>85.705882</td>
      <td>186.0</td>
      <td>79.0</td>
      <td>24</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.113315</td>
      <td>€94M - €149M</td>
      <td>121500000.0</td>
      <td>Spain</td>
    </tr>
    <tr>
      <th>1117</th>
      <td>Sergio Ramos</td>
      <td>11.0</td>
      <td>924.0</td>
      <td>84.000000</td>
      <td>184.0</td>
      <td>82.0</td>
      <td>36</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.123268</td>
      <td>€12M - €18M</td>
      <td>15000000.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>1118</th>
      <td>Marquinhos</td>
      <td>13.0</td>
      <td>1129.0</td>
      <td>86.846154</td>
      <td>183.0</td>
      <td>75.0</td>
      <td>28</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>3.448276</td>
      <td>0.126749</td>
      <td>€99M - €128M</td>
      <td>113500000.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>1119</th>
      <td>Thibaut Courtois</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>199.0</td>
      <td>96.0</td>
      <td>30</td>
      <td>...</td>
      <td>48.0</td>
      <td>-0.848956</td>
      <td>0.000000</td>
      <td>0.072982</td>
      <td>€172M - €225M</td>
      <td>198500000.0</td>
      <td>Spain</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>Raphaël Varane</td>
      <td>17.0</td>
      <td>1463.0</td>
      <td>86.058824</td>
      <td>191.0</td>
      <td>81.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.107792</td>
      <td>€101M - €127M</td>
      <td>114000000.0</td>
      <td>England</td>
    </tr>
    <tr>
      <th>1121</th>
      <td>Jan Oblak</td>
      <td>19.0</td>
      <td>1687.0</td>
      <td>88.789474</td>
      <td>189.0</td>
      <td>84.0</td>
      <td>29</td>
      <td>...</td>
      <td>45.0</td>
      <td>-3.118503</td>
      <td>0.000000</td>
      <td>0.067635</td>
      <td>€112M - €178M</td>
      <td>145000000.0</td>
      <td>Spain</td>
    </tr>
  </tbody>
</table>
<p>1122 rows × 45 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name_of_the_player</th>
      <th>Number_of_appearances</th>
      <th>Minutes_played</th>
      <th>Minutes_played_per_game</th>
      <th>Height_of_the_player_in_cm</th>
      <th>Weight_of_the_player_in_kg</th>
      <th>Age_of_the_player</th>
      <th>...</th>
      <th>Total_saves</th>
      <th>Saves_divided_by_expected_saves</th>
      <th>Gaols_divided_by_expected_goals</th>
      <th>Distance_run_by_minutes</th>
      <th>Transfer_value_range</th>
      <th>Average_transfer_value</th>
      <th>Country_where_the_player_plays</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Josip Mijatović</td>
      <td>12.0</td>
      <td>809.0</td>
      <td>67.416667</td>
      <td>173.0</td>
      <td>68.0</td>
      <td>20</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>5.555556</td>
      <td>0.126823</td>
      <td>€3K - €9K</td>
      <td>6000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Duje Ninčević</td>
      <td>15.0</td>
      <td>1161.0</td>
      <td>77.400000</td>
      <td>172.0</td>
      <td>69.0</td>
      <td>25</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.129457</td>
      <td>€0 - €2.5K</td>
      <td>1250.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Marin Karabatić</td>
      <td>15.0</td>
      <td>1350.0</td>
      <td>90.000000</td>
      <td>170.0</td>
      <td>62.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.128000</td>
      <td>€0 - €12K</td>
      <td>6000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vicko Ševelj</td>
      <td>20.0</td>
      <td>1738.0</td>
      <td>86.900000</td>
      <td>192.0</td>
      <td>86.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>2.380952</td>
      <td>0.058631</td>
      <td>€100K - €1M</td>
      <td>550000.0</td>
      <td>Bosnia</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fran Vujnović</td>
      <td>15.0</td>
      <td>1384.0</td>
      <td>92.266667</td>
      <td>190.0</td>
      <td>77.0</td>
      <td>19</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.016040</td>
      <td>€14K - €150K</td>
      <td>82000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Šimun Mikolčić</td>
      <td>15.0</td>
      <td>1380.0</td>
      <td>92.000000</td>
      <td>180.0</td>
      <td>70.0</td>
      <td>18</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>25.000000</td>
      <td>0.013623</td>
      <td>€35K - €350K</td>
      <td>192500.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Romano Lisjak</td>
      <td>16.0</td>
      <td>1440.0</td>
      <td>90.000000</td>
      <td>188.0</td>
      <td>80.0</td>
      <td>21</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.847458</td>
      <td>0.101319</td>
      <td>€0 - €50K</td>
      <td>25000.0</td>
      <td>Croatia</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1115</th>
      <td>Gianluigi Donnarumma</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>196.0</td>
      <td>90.0</td>
      <td>23</td>
      <td>...</td>
      <td>48.0</td>
      <td>-1.132610</td>
      <td>0.000000</td>
      <td>0.070351</td>
      <td>€254M - €276M</td>
      <td>265000000.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>Éder Militão</td>
      <td>17.0</td>
      <td>1457.0</td>
      <td>85.705882</td>
      <td>186.0</td>
      <td>79.0</td>
      <td>24</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.113315</td>
      <td>€94M - €149M</td>
      <td>121500000.0</td>
      <td>Spain</td>
    </tr>
    <tr>
      <th>1117</th>
      <td>Sergio Ramos</td>
      <td>11.0</td>
      <td>924.0</td>
      <td>84.000000</td>
      <td>184.0</td>
      <td>82.0</td>
      <td>36</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.123268</td>
      <td>€12M - €18M</td>
      <td>15000000.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>1118</th>
      <td>Marquinhos</td>
      <td>13.0</td>
      <td>1129.0</td>
      <td>86.846154</td>
      <td>183.0</td>
      <td>75.0</td>
      <td>28</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>3.448276</td>
      <td>0.126749</td>
      <td>€99M - €128M</td>
      <td>113500000.0</td>
      <td>France</td>
    </tr>
    <tr>
      <th>1119</th>
      <td>Thibaut Courtois</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>199.0</td>
      <td>96.0</td>
      <td>30</td>
      <td>...</td>
      <td>48.0</td>
      <td>-0.848956</td>
      <td>0.000000</td>
      <td>0.072982</td>
      <td>€172M - €225M</td>
      <td>198500000.0</td>
      <td>Spain</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>Raphaël Varane</td>
      <td>17.0</td>
      <td>1463.0</td>
      <td>86.058824</td>
      <td>191.0</td>
      <td>81.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.107792</td>
      <td>€101M - €127M</td>
      <td>114000000.0</td>
      <td>England</td>
    </tr>
    <tr>
      <th>1121</th>
      <td>Jan Oblak</td>
      <td>19.0</td>
      <td>1687.0</td>
      <td>88.789474</td>
      <td>189.0</td>
      <td>84.0</td>
      <td>29</td>
      <td>...</td>
      <td>45.0</td>
      <td>-3.118503</td>
      <td>0.000000</td>
      <td>0.067635</td>
      <td>€112M - €178M</td>
      <td>145000000.0</td>
      <td>Spain</td>
    </tr>
  </tbody>
</table>
<p>1122 rows × 45 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> football-manager-2022-player-data/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Add two numeric columns for maximum and minimum transfer values.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def str2val(x):
    if not x:
        return x
    x = x.strip()
    if x[-1] == 'K':
        return float(x[1:-1]) * 1e3
    elif x[-1] == 'M':
        return float(x[1:-1]) * 1e6
    return None

def add_min_max_value(x):
    rng = x.Transfer_value_range.split('-')
    if len(rng) != 2:
        rng = (None, None)
    rng_min, rng_max = rng
    x['transfer_value_min'] = str2val(rng_min)
    x['transfer_value_max'] = str2val(rng_max)
    return x

df = df.apply(add_min_max_value, 1)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def str2val(x):
    if not x:
        return x
    x = x.strip()
    if x[-1] == 'K':
        return float(x[1:-1]) * 1e3
    elif x[-1] == 'M':
        return float(x[1:-1]) * 1e6
    return None

def add_min_max_value(x):
    rng = x.Transfer_value_range.split('-')
    if len(rng) != 2:
        rng = (None, None)
    rng_min, rng_max = rng
    x['transfer_value_min'] = str2val(rng_min)
    x['transfer_value_max'] = str2val(rng_max)
    return x

df = df.apply(add_min_max_value, 1)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def str2val(x):
    if not x:
        return x
    x = x.strip()
    if x[-1] == 'K':
        return float(x[1:-1]) * 1000.0
    elif x[-1] == 'M':
        return float(x[1:-1]) * 1000000.0
    return None


def add_min_max_value(x):
    rng = x.Transfer_value_range.split('-')
    if len(rng) != 2:
        rng = None, None
    rng_min, rng_max = rng
    x['transfer_value_min'] = str2val(rng_min)
    x['transfer_value_max'] = str2val(rng_max)
    return x


__output__ = df = df.apply(add_min_max_value, 1)
</code></pre>
        <p><span onclick="$('#var_output_77cae561').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_77cae561" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name_of_the_player</th>
      <th>Number_of_appearances</th>
      <th>Minutes_played</th>
      <th>Minutes_played_per_game</th>
      <th>Height_of_the_player_in_cm</th>
      <th>Weight_of_the_player_in_kg</th>
      <th>Age_of_the_player</th>
      <th>...</th>
      <th>Gaols_divided_by_expected_goals</th>
      <th>Distance_run_by_minutes</th>
      <th>Transfer_value_range</th>
      <th>Average_transfer_value</th>
      <th>Country_where_the_player_plays</th>
      <th>transfer_value_min</th>
      <th>transfer_value_max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Josip Mijatović</td>
      <td>12.0</td>
      <td>809.0</td>
      <td>67.416667</td>
      <td>173.0</td>
      <td>68.0</td>
      <td>20</td>
      <td>...</td>
      <td>5.555556</td>
      <td>0.126823</td>
      <td>€3K - €9K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>3000.0</td>
      <td>9000.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Duje Ninčević</td>
      <td>15.0</td>
      <td>1161.0</td>
      <td>77.400000</td>
      <td>172.0</td>
      <td>69.0</td>
      <td>25</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.129457</td>
      <td>€0 - €2.5K</td>
      <td>1250.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>2500.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Marin Karabatić</td>
      <td>15.0</td>
      <td>1350.0</td>
      <td>90.000000</td>
      <td>170.0</td>
      <td>62.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.128000</td>
      <td>€0 - €12K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>12000.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vicko Ševelj</td>
      <td>20.0</td>
      <td>1738.0</td>
      <td>86.900000</td>
      <td>192.0</td>
      <td>86.0</td>
      <td>22</td>
      <td>...</td>
      <td>2.380952</td>
      <td>0.058631</td>
      <td>€100K - €1M</td>
      <td>550000.0</td>
      <td>Bosnia</td>
      <td>100000.0</td>
      <td>1000000.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fran Vujnović</td>
      <td>15.0</td>
      <td>1384.0</td>
      <td>92.266667</td>
      <td>190.0</td>
      <td>77.0</td>
      <td>19</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.016040</td>
      <td>€14K - €150K</td>
      <td>82000.0</td>
      <td>Croatia</td>
      <td>14000.0</td>
      <td>150000.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Šimun Mikolčić</td>
      <td>15.0</td>
      <td>1380.0</td>
      <td>92.000000</td>
      <td>180.0</td>
      <td>70.0</td>
      <td>18</td>
      <td>...</td>
      <td>25.000000</td>
      <td>0.013623</td>
      <td>€35K - €350K</td>
      <td>192500.0</td>
      <td>Croatia</td>
      <td>35000.0</td>
      <td>350000.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Romano Lisjak</td>
      <td>16.0</td>
      <td>1440.0</td>
      <td>90.000000</td>
      <td>188.0</td>
      <td>80.0</td>
      <td>21</td>
      <td>...</td>
      <td>0.847458</td>
      <td>0.101319</td>
      <td>€0 - €50K</td>
      <td>25000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>50000.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1115</th>
      <td>Gianluigi Donnarumma</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>196.0</td>
      <td>90.0</td>
      <td>23</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.070351</td>
      <td>€254M - €276M</td>
      <td>265000000.0</td>
      <td>France</td>
      <td>254000000.0</td>
      <td>276000000.0</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>Éder Militão</td>
      <td>17.0</td>
      <td>1457.0</td>
      <td>85.705882</td>
      <td>186.0</td>
      <td>79.0</td>
      <td>24</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.113315</td>
      <td>€94M - €149M</td>
      <td>121500000.0</td>
      <td>Spain</td>
      <td>94000000.0</td>
      <td>149000000.0</td>
    </tr>
    <tr>
      <th>1117</th>
      <td>Sergio Ramos</td>
      <td>11.0</td>
      <td>924.0</td>
      <td>84.000000</td>
      <td>184.0</td>
      <td>82.0</td>
      <td>36</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.123268</td>
      <td>€12M - €18M</td>
      <td>15000000.0</td>
      <td>France</td>
      <td>12000000.0</td>
      <td>18000000.0</td>
    </tr>
    <tr>
      <th>1118</th>
      <td>Marquinhos</td>
      <td>13.0</td>
      <td>1129.0</td>
      <td>86.846154</td>
      <td>183.0</td>
      <td>75.0</td>
      <td>28</td>
      <td>...</td>
      <td>3.448276</td>
      <td>0.126749</td>
      <td>€99M - €128M</td>
      <td>113500000.0</td>
      <td>France</td>
      <td>99000000.0</td>
      <td>128000000.0</td>
    </tr>
    <tr>
      <th>1119</th>
      <td>Thibaut Courtois</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>199.0</td>
      <td>96.0</td>
      <td>30</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.072982</td>
      <td>€172M - €225M</td>
      <td>198500000.0</td>
      <td>Spain</td>
      <td>172000000.0</td>
      <td>225000000.0</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>Raphaël Varane</td>
      <td>17.0</td>
      <td>1463.0</td>
      <td>86.058824</td>
      <td>191.0</td>
      <td>81.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.107792</td>
      <td>€101M - €127M</td>
      <td>114000000.0</td>
      <td>England</td>
      <td>101000000.0</td>
      <td>127000000.0</td>
    </tr>
    <tr>
      <th>1121</th>
      <td>Jan Oblak</td>
      <td>19.0</td>
      <td>1687.0</td>
      <td>88.789474</td>
      <td>189.0</td>
      <td>84.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.067635</td>
      <td>€112M - €178M</td>
      <td>145000000.0</td>
      <td>Spain</td>
      <td>112000000.0</td>
      <td>178000000.0</td>
    </tr>
  </tbody>
</table>
<p>1122 rows × 47 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name_of_the_player</th>
      <th>Number_of_appearances</th>
      <th>Minutes_played</th>
      <th>Minutes_played_per_game</th>
      <th>Height_of_the_player_in_cm</th>
      <th>Weight_of_the_player_in_kg</th>
      <th>Age_of_the_player</th>
      <th>...</th>
      <th>Gaols_divided_by_expected_goals</th>
      <th>Distance_run_by_minutes</th>
      <th>Transfer_value_range</th>
      <th>Average_transfer_value</th>
      <th>Country_where_the_player_plays</th>
      <th>transfer_value_min</th>
      <th>transfer_value_max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Josip Mijatović</td>
      <td>12.0</td>
      <td>809.0</td>
      <td>67.416667</td>
      <td>173.0</td>
      <td>68.0</td>
      <td>20</td>
      <td>...</td>
      <td>5.555556</td>
      <td>0.126823</td>
      <td>€3K - €9K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>3000.0</td>
      <td>9000.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Duje Ninčević</td>
      <td>15.0</td>
      <td>1161.0</td>
      <td>77.400000</td>
      <td>172.0</td>
      <td>69.0</td>
      <td>25</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.129457</td>
      <td>€0 - €2.5K</td>
      <td>1250.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>2500.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Marin Karabatić</td>
      <td>15.0</td>
      <td>1350.0</td>
      <td>90.000000</td>
      <td>170.0</td>
      <td>62.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.128000</td>
      <td>€0 - €12K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>12000.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vicko Ševelj</td>
      <td>20.0</td>
      <td>1738.0</td>
      <td>86.900000</td>
      <td>192.0</td>
      <td>86.0</td>
      <td>22</td>
      <td>...</td>
      <td>2.380952</td>
      <td>0.058631</td>
      <td>€100K - €1M</td>
      <td>550000.0</td>
      <td>Bosnia</td>
      <td>100000.0</td>
      <td>1000000.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fran Vujnović</td>
      <td>15.0</td>
      <td>1384.0</td>
      <td>92.266667</td>
      <td>190.0</td>
      <td>77.0</td>
      <td>19</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.016040</td>
      <td>€14K - €150K</td>
      <td>82000.0</td>
      <td>Croatia</td>
      <td>14000.0</td>
      <td>150000.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Šimun Mikolčić</td>
      <td>15.0</td>
      <td>1380.0</td>
      <td>92.000000</td>
      <td>180.0</td>
      <td>70.0</td>
      <td>18</td>
      <td>...</td>
      <td>25.000000</td>
      <td>0.013623</td>
      <td>€35K - €350K</td>
      <td>192500.0</td>
      <td>Croatia</td>
      <td>35000.0</td>
      <td>350000.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Romano Lisjak</td>
      <td>16.0</td>
      <td>1440.0</td>
      <td>90.000000</td>
      <td>188.0</td>
      <td>80.0</td>
      <td>21</td>
      <td>...</td>
      <td>0.847458</td>
      <td>0.101319</td>
      <td>€0 - €50K</td>
      <td>25000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>50000.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1115</th>
      <td>Gianluigi Donnarumma</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>196.0</td>
      <td>90.0</td>
      <td>23</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.070351</td>
      <td>€254M - €276M</td>
      <td>265000000.0</td>
      <td>France</td>
      <td>254000000.0</td>
      <td>276000000.0</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>Éder Militão</td>
      <td>17.0</td>
      <td>1457.0</td>
      <td>85.705882</td>
      <td>186.0</td>
      <td>79.0</td>
      <td>24</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.113315</td>
      <td>€94M - €149M</td>
      <td>121500000.0</td>
      <td>Spain</td>
      <td>94000000.0</td>
      <td>149000000.0</td>
    </tr>
    <tr>
      <th>1117</th>
      <td>Sergio Ramos</td>
      <td>11.0</td>
      <td>924.0</td>
      <td>84.000000</td>
      <td>184.0</td>
      <td>82.0</td>
      <td>36</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.123268</td>
      <td>€12M - €18M</td>
      <td>15000000.0</td>
      <td>France</td>
      <td>12000000.0</td>
      <td>18000000.0</td>
    </tr>
    <tr>
      <th>1118</th>
      <td>Marquinhos</td>
      <td>13.0</td>
      <td>1129.0</td>
      <td>86.846154</td>
      <td>183.0</td>
      <td>75.0</td>
      <td>28</td>
      <td>...</td>
      <td>3.448276</td>
      <td>0.126749</td>
      <td>€99M - €128M</td>
      <td>113500000.0</td>
      <td>France</td>
      <td>99000000.0</td>
      <td>128000000.0</td>
    </tr>
    <tr>
      <th>1119</th>
      <td>Thibaut Courtois</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>199.0</td>
      <td>96.0</td>
      <td>30</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.072982</td>
      <td>€172M - €225M</td>
      <td>198500000.0</td>
      <td>Spain</td>
      <td>172000000.0</td>
      <td>225000000.0</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>Raphaël Varane</td>
      <td>17.0</td>
      <td>1463.0</td>
      <td>86.058824</td>
      <td>191.0</td>
      <td>81.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.107792</td>
      <td>€101M - €127M</td>
      <td>114000000.0</td>
      <td>England</td>
      <td>101000000.0</td>
      <td>127000000.0</td>
    </tr>
    <tr>
      <th>1121</th>
      <td>Jan Oblak</td>
      <td>19.0</td>
      <td>1687.0</td>
      <td>88.789474</td>
      <td>189.0</td>
      <td>84.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.067635</td>
      <td>€112M - €178M</td>
      <td>145000000.0</td>
      <td>Spain</td>
      <td>112000000.0</td>
      <td>178000000.0</td>
    </tr>
  </tbody>
</table>
<p>1122 rows × 47 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name_of_the_player</th>
      <th>Number_of_appearances</th>
      <th>Minutes_played</th>
      <th>Minutes_played_per_game</th>
      <th>Height_of_the_player_in_cm</th>
      <th>Weight_of_the_player_in_kg</th>
      <th>Age_of_the_player</th>
      <th>...</th>
      <th>Gaols_divided_by_expected_goals</th>
      <th>Distance_run_by_minutes</th>
      <th>Transfer_value_range</th>
      <th>Average_transfer_value</th>
      <th>Country_where_the_player_plays</th>
      <th>transfer_value_min</th>
      <th>transfer_value_max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Josip Mijatović</td>
      <td>12.0</td>
      <td>809.0</td>
      <td>67.416667</td>
      <td>173.0</td>
      <td>68.0</td>
      <td>20</td>
      <td>...</td>
      <td>5.555556</td>
      <td>0.126823</td>
      <td>€3K - €9K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>3000.0</td>
      <td>9000.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Duje Ninčević</td>
      <td>15.0</td>
      <td>1161.0</td>
      <td>77.400000</td>
      <td>172.0</td>
      <td>69.0</td>
      <td>25</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.129457</td>
      <td>€0 - €2.5K</td>
      <td>1250.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>2500.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Marin Karabatić</td>
      <td>15.0</td>
      <td>1350.0</td>
      <td>90.000000</td>
      <td>170.0</td>
      <td>62.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.128000</td>
      <td>€0 - €12K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>12000.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vicko Ševelj</td>
      <td>20.0</td>
      <td>1738.0</td>
      <td>86.900000</td>
      <td>192.0</td>
      <td>86.0</td>
      <td>22</td>
      <td>...</td>
      <td>2.380952</td>
      <td>0.058631</td>
      <td>€100K - €1M</td>
      <td>550000.0</td>
      <td>Bosnia</td>
      <td>100000.0</td>
      <td>1000000.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fran Vujnović</td>
      <td>15.0</td>
      <td>1384.0</td>
      <td>92.266667</td>
      <td>190.0</td>
      <td>77.0</td>
      <td>19</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.016040</td>
      <td>€14K - €150K</td>
      <td>82000.0</td>
      <td>Croatia</td>
      <td>14000.0</td>
      <td>150000.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Šimun Mikolčić</td>
      <td>15.0</td>
      <td>1380.0</td>
      <td>92.000000</td>
      <td>180.0</td>
      <td>70.0</td>
      <td>18</td>
      <td>...</td>
      <td>25.000000</td>
      <td>0.013623</td>
      <td>€35K - €350K</td>
      <td>192500.0</td>
      <td>Croatia</td>
      <td>35000.0</td>
      <td>350000.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Romano Lisjak</td>
      <td>16.0</td>
      <td>1440.0</td>
      <td>90.000000</td>
      <td>188.0</td>
      <td>80.0</td>
      <td>21</td>
      <td>...</td>
      <td>0.847458</td>
      <td>0.101319</td>
      <td>€0 - €50K</td>
      <td>25000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>50000.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1115</th>
      <td>Gianluigi Donnarumma</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>196.0</td>
      <td>90.0</td>
      <td>23</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.070351</td>
      <td>€254M - €276M</td>
      <td>265000000.0</td>
      <td>France</td>
      <td>254000000.0</td>
      <td>276000000.0</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>Éder Militão</td>
      <td>17.0</td>
      <td>1457.0</td>
      <td>85.705882</td>
      <td>186.0</td>
      <td>79.0</td>
      <td>24</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.113315</td>
      <td>€94M - €149M</td>
      <td>121500000.0</td>
      <td>Spain</td>
      <td>94000000.0</td>
      <td>149000000.0</td>
    </tr>
    <tr>
      <th>1117</th>
      <td>Sergio Ramos</td>
      <td>11.0</td>
      <td>924.0</td>
      <td>84.000000</td>
      <td>184.0</td>
      <td>82.0</td>
      <td>36</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.123268</td>
      <td>€12M - €18M</td>
      <td>15000000.0</td>
      <td>France</td>
      <td>12000000.0</td>
      <td>18000000.0</td>
    </tr>
    <tr>
      <th>1118</th>
      <td>Marquinhos</td>
      <td>13.0</td>
      <td>1129.0</td>
      <td>86.846154</td>
      <td>183.0</td>
      <td>75.0</td>
      <td>28</td>
      <td>...</td>
      <td>3.448276</td>
      <td>0.126749</td>
      <td>€99M - €128M</td>
      <td>113500000.0</td>
      <td>France</td>
      <td>99000000.0</td>
      <td>128000000.0</td>
    </tr>
    <tr>
      <th>1119</th>
      <td>Thibaut Courtois</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>199.0</td>
      <td>96.0</td>
      <td>30</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.072982</td>
      <td>€172M - €225M</td>
      <td>198500000.0</td>
      <td>Spain</td>
      <td>172000000.0</td>
      <td>225000000.0</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>Raphaël Varane</td>
      <td>17.0</td>
      <td>1463.0</td>
      <td>86.058824</td>
      <td>191.0</td>
      <td>81.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.107792</td>
      <td>€101M - €127M</td>
      <td>114000000.0</td>
      <td>England</td>
      <td>101000000.0</td>
      <td>127000000.0</td>
    </tr>
    <tr>
      <th>1121</th>
      <td>Jan Oblak</td>
      <td>19.0</td>
      <td>1687.0</td>
      <td>88.789474</td>
      <td>189.0</td>
      <td>84.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.067635</td>
      <td>€112M - €178M</td>
      <td>145000000.0</td>
      <td>Spain</td>
      <td>112000000.0</td>
      <td>178000000.0</td>
    </tr>
  </tbody>
</table>
<p>1122 rows × 47 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> football-manager-2022-player-data/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Determine how many goalkeepers each league has.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def is_goalkeeper(x):
    return (x.Shots_caught > 0) | (x.Shots_blocked > 0) | (x.Shots_repelled > 0)

df[df.apply(is_goalkeeper, 1)]['League_where_the_player_plays'].value_counts()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def is_goalkeeper(x):
    return (x.Shots_caught > 0) | (x.Shots_blocked > 0) | (x.Shots_repelled > 0)

df[df.apply(is_goalkeeper, 1)]['League_where_the_player_plays'].value_counts()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def is_goalkeeper(x):
    return (x.Shots_caught > 0) | (x.Shots_blocked > 0) | (x.Shots_repelled > 0
        )


__output__ = df[df.apply(is_goalkeeper, 1)]['League_where_the_player_plays'
    ].value_counts()
</code></pre>
        <p><span onclick="$('#var_output_497596a4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_497596a4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Ligue 1             14
Serie A             12
Ligue 2             11
Liga Portugal 2     11
Eredivisie          10
                    ..
A' Katigorías        1
Süper Lig            1
EFL Championship     1
Favbet Liha          1
Bundesliga           1
Name: League_where_the_player_plays, Length: 54, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Ligue 1             14
Serie A             12
Ligue 2             11
Liga Portugal 2     11
Eredivisie          10
                    ..
A' Katigorías        1
Süper Lig            1
EFL Championship     1
Favbet Liha          1
Bundesliga           1
Name: League_where_the_player_plays, Length: 54, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> football-manager-2022-player-data/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Add a column showing BMI (weight in kg by height in meters squared) and find the average BMI of players by country. Sort in ascending order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['BMI'] = df.Weight_of_the_player_in_kg / (df.Height_of_the_player_in_cm / 100) ** 2
df[['BMI', 'Country_where_the_player_plays']].groupby('Country_where_the_player_plays').mean().sort_values('BMI')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['BMI'] = df.Weight_of_the_player_in_kg / (df.Height_of_the_player_in_cm / 100) ** 2
df[['BMI', 'Country_where_the_player_plays']].groupby('Country_where_the_player_plays').mean().sort_values('BMI')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['BMI'] = df.Weight_of_the_player_in_kg / (df.Height_of_the_player_in_cm /
    100) ** 2
__output__ = df[['BMI', 'Country_where_the_player_plays']].groupby(
    'Country_where_the_player_plays').mean().sort_values('BMI')
</code></pre>
        <p><span onclick="$('#var_output_283116f7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_283116f7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BMI</th>
    </tr>
    <tr>
      <th>Country_where_the_player_plays</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Moldova</th>
      <td>21.521947</td>
    </tr>
    <tr>
      <th>DR</th>
      <td>21.678807</td>
    </tr>
    <tr>
      <th>Sweden</th>
      <td>22.239844</td>
    </tr>
    <tr>
      <th>Serbia</th>
      <td>22.274030</td>
    </tr>
    <tr>
      <th>Romania</th>
      <td>22.276676</td>
    </tr>
    <tr>
      <th>Turkey</th>
      <td>22.347583</td>
    </tr>
    <tr>
      <th>Chile</th>
      <td>22.426761</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Argentina</th>
      <td>23.330813</td>
    </tr>
    <tr>
      <th>Russia</th>
      <td>23.351773</td>
    </tr>
    <tr>
      <th>Denmark</th>
      <td>23.459395</td>
    </tr>
    <tr>
      <th>Paraguay</th>
      <td>23.564920</td>
    </tr>
    <tr>
      <th>Norway</th>
      <td>23.707434</td>
    </tr>
    <tr>
      <th>Germany</th>
      <td>23.960151</td>
    </tr>
    <tr>
      <th>Ecuador</th>
      <td>28.024822</td>
    </tr>
  </tbody>
</table>
<p>37 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name_of_the_player</th>
      <th>Number_of_appearances</th>
      <th>Minutes_played</th>
      <th>Minutes_played_per_game</th>
      <th>Height_of_the_player_in_cm</th>
      <th>Weight_of_the_player_in_kg</th>
      <th>Age_of_the_player</th>
      <th>...</th>
      <th>Distance_run_by_minutes</th>
      <th>Transfer_value_range</th>
      <th>Average_transfer_value</th>
      <th>Country_where_the_player_plays</th>
      <th>transfer_value_min</th>
      <th>transfer_value_max</th>
      <th>BMI</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Josip Mijatović</td>
      <td>12.0</td>
      <td>809.0</td>
      <td>67.416667</td>
      <td>173.0</td>
      <td>68.0</td>
      <td>20</td>
      <td>...</td>
      <td>0.126823</td>
      <td>€3K - €9K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>3000.0</td>
      <td>9000.0</td>
      <td>22.720438</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Duje Ninčević</td>
      <td>15.0</td>
      <td>1161.0</td>
      <td>77.400000</td>
      <td>172.0</td>
      <td>69.0</td>
      <td>25</td>
      <td>...</td>
      <td>0.129457</td>
      <td>€0 - €2.5K</td>
      <td>1250.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>2500.0</td>
      <td>23.323418</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Marin Karabatić</td>
      <td>15.0</td>
      <td>1350.0</td>
      <td>90.000000</td>
      <td>170.0</td>
      <td>62.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.128000</td>
      <td>€0 - €12K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>12000.0</td>
      <td>21.453287</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vicko Ševelj</td>
      <td>20.0</td>
      <td>1738.0</td>
      <td>86.900000</td>
      <td>192.0</td>
      <td>86.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.058631</td>
      <td>€100K - €1M</td>
      <td>550000.0</td>
      <td>Bosnia</td>
      <td>100000.0</td>
      <td>1000000.0</td>
      <td>23.328993</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fran Vujnović</td>
      <td>15.0</td>
      <td>1384.0</td>
      <td>92.266667</td>
      <td>190.0</td>
      <td>77.0</td>
      <td>19</td>
      <td>...</td>
      <td>0.016040</td>
      <td>€14K - €150K</td>
      <td>82000.0</td>
      <td>Croatia</td>
      <td>14000.0</td>
      <td>150000.0</td>
      <td>21.329640</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Šimun Mikolčić</td>
      <td>15.0</td>
      <td>1380.0</td>
      <td>92.000000</td>
      <td>180.0</td>
      <td>70.0</td>
      <td>18</td>
      <td>...</td>
      <td>0.013623</td>
      <td>€35K - €350K</td>
      <td>192500.0</td>
      <td>Croatia</td>
      <td>35000.0</td>
      <td>350000.0</td>
      <td>21.604938</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Romano Lisjak</td>
      <td>16.0</td>
      <td>1440.0</td>
      <td>90.000000</td>
      <td>188.0</td>
      <td>80.0</td>
      <td>21</td>
      <td>...</td>
      <td>0.101319</td>
      <td>€0 - €50K</td>
      <td>25000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>50000.0</td>
      <td>22.634676</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1115</th>
      <td>Gianluigi Donnarumma</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>196.0</td>
      <td>90.0</td>
      <td>23</td>
      <td>...</td>
      <td>0.070351</td>
      <td>€254M - €276M</td>
      <td>265000000.0</td>
      <td>France</td>
      <td>254000000.0</td>
      <td>276000000.0</td>
      <td>23.427738</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>Éder Militão</td>
      <td>17.0</td>
      <td>1457.0</td>
      <td>85.705882</td>
      <td>186.0</td>
      <td>79.0</td>
      <td>24</td>
      <td>...</td>
      <td>0.113315</td>
      <td>€94M - €149M</td>
      <td>121500000.0</td>
      <td>Spain</td>
      <td>94000000.0</td>
      <td>149000000.0</td>
      <td>22.835010</td>
    </tr>
    <tr>
      <th>1117</th>
      <td>Sergio Ramos</td>
      <td>11.0</td>
      <td>924.0</td>
      <td>84.000000</td>
      <td>184.0</td>
      <td>82.0</td>
      <td>36</td>
      <td>...</td>
      <td>0.123268</td>
      <td>€12M - €18M</td>
      <td>15000000.0</td>
      <td>France</td>
      <td>12000000.0</td>
      <td>18000000.0</td>
      <td>24.220227</td>
    </tr>
    <tr>
      <th>1118</th>
      <td>Marquinhos</td>
      <td>13.0</td>
      <td>1129.0</td>
      <td>86.846154</td>
      <td>183.0</td>
      <td>75.0</td>
      <td>28</td>
      <td>...</td>
      <td>0.126749</td>
      <td>€99M - €128M</td>
      <td>113500000.0</td>
      <td>France</td>
      <td>99000000.0</td>
      <td>128000000.0</td>
      <td>22.395413</td>
    </tr>
    <tr>
      <th>1119</th>
      <td>Thibaut Courtois</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>199.0</td>
      <td>96.0</td>
      <td>30</td>
      <td>...</td>
      <td>0.072982</td>
      <td>€172M - €225M</td>
      <td>198500000.0</td>
      <td>Spain</td>
      <td>172000000.0</td>
      <td>225000000.0</td>
      <td>24.241812</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>Raphaël Varane</td>
      <td>17.0</td>
      <td>1463.0</td>
      <td>86.058824</td>
      <td>191.0</td>
      <td>81.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.107792</td>
      <td>€101M - €127M</td>
      <td>114000000.0</td>
      <td>England</td>
      <td>101000000.0</td>
      <td>127000000.0</td>
      <td>22.203339</td>
    </tr>
    <tr>
      <th>1121</th>
      <td>Jan Oblak</td>
      <td>19.0</td>
      <td>1687.0</td>
      <td>88.789474</td>
      <td>189.0</td>
      <td>84.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.067635</td>
      <td>€112M - €178M</td>
      <td>145000000.0</td>
      <td>Spain</td>
      <td>112000000.0</td>
      <td>178000000.0</td>
      <td>23.515579</td>
    </tr>
  </tbody>
</table>
<p>1122 rows × 48 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BMI</th>
    </tr>
    <tr>
      <th>Country_where_the_player_plays</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Moldova</th>
      <td>21.521947</td>
    </tr>
    <tr>
      <th>DR</th>
      <td>21.678807</td>
    </tr>
    <tr>
      <th>Sweden</th>
      <td>22.239844</td>
    </tr>
    <tr>
      <th>Serbia</th>
      <td>22.274030</td>
    </tr>
    <tr>
      <th>Romania</th>
      <td>22.276676</td>
    </tr>
    <tr>
      <th>Turkey</th>
      <td>22.347583</td>
    </tr>
    <tr>
      <th>Chile</th>
      <td>22.426761</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Argentina</th>
      <td>23.330813</td>
    </tr>
    <tr>
      <th>Russia</th>
      <td>23.351773</td>
    </tr>
    <tr>
      <th>Denmark</th>
      <td>23.459395</td>
    </tr>
    <tr>
      <th>Paraguay</th>
      <td>23.564920</td>
    </tr>
    <tr>
      <th>Norway</th>
      <td>23.707434</td>
    </tr>
    <tr>
      <th>Germany</th>
      <td>23.960151</td>
    </tr>
    <tr>
      <th>Ecuador</th>
      <td>28.024822</td>
    </tr>
  </tbody>
</table>
<p>37 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> football-manager-2022-player-data/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average total goals scored for strikers of different age groups? Group age by quartiles.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_strikers = df[(df.Total_goals_scored > 0) | (df.Asists_per_game > 0) | (df.Penalty_score_ratio > 0)]
df['Age_group'] = pd.qcut(df_strikers.Age_of_the_player, 4)
df.dropna()[['Age_group', 'Total_goals_scored']].groupby('Age_group').mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_strikers = df[(df.Total_goals_scored > 0) | (df.Asists_per_game > 0) | (df.Penalty_score_ratio > 0)]
df['Age_group'] = pd.qcut(df_strikers.Age_of_the_player, 4)
df.dropna()[['Age_group', 'Total_goals_scored']].groupby('Age_group').mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_strikers = df[(df.Total_goals_scored > 0) | (df.Asists_per_game > 0) | (
    df.Penalty_score_ratio > 0)]
df['Age_group'] = pd.qcut(df_strikers.Age_of_the_player, 4)
__output__ = df.dropna()[['Age_group', 'Total_goals_scored']].groupby(
    'Age_group').mean()
</code></pre>
        <p><span onclick="$('#var_output_0896811e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0896811e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Total_goals_scored</th>
    </tr>
    <tr>
      <th>Age_group</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(17.999, 24.0]</th>
      <td>1.095238</td>
    </tr>
    <tr>
      <th>(24.0, 26.0]</th>
      <td>1.236486</td>
    </tr>
    <tr>
      <th>(26.0, 28.0]</th>
      <td>1.216783</td>
    </tr>
    <tr>
      <th>(28.0, 39.0]</th>
      <td>0.993548</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, df_strikers, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name_of_the_player</th>
      <th>Number_of_appearances</th>
      <th>Minutes_played</th>
      <th>Minutes_played_per_game</th>
      <th>Height_of_the_player_in_cm</th>
      <th>Weight_of_the_player_in_kg</th>
      <th>Age_of_the_player</th>
      <th>...</th>
      <th>Transfer_value_range</th>
      <th>Average_transfer_value</th>
      <th>Country_where_the_player_plays</th>
      <th>transfer_value_min</th>
      <th>transfer_value_max</th>
      <th>BMI</th>
      <th>Age_group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Josip Mijatović</td>
      <td>12.0</td>
      <td>809.0</td>
      <td>67.416667</td>
      <td>173.0</td>
      <td>68.0</td>
      <td>20</td>
      <td>...</td>
      <td>€3K - €9K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>3000.0</td>
      <td>9000.0</td>
      <td>22.720438</td>
      <td>(17.999, 24.0]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Duje Ninčević</td>
      <td>15.0</td>
      <td>1161.0</td>
      <td>77.400000</td>
      <td>172.0</td>
      <td>69.0</td>
      <td>25</td>
      <td>...</td>
      <td>€0 - €2.5K</td>
      <td>1250.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>2500.0</td>
      <td>23.323418</td>
      <td>(24.0, 26.0]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Marin Karabatić</td>
      <td>15.0</td>
      <td>1350.0</td>
      <td>90.000000</td>
      <td>170.0</td>
      <td>62.0</td>
      <td>22</td>
      <td>...</td>
      <td>€0 - €12K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>12000.0</td>
      <td>21.453287</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vicko Ševelj</td>
      <td>20.0</td>
      <td>1738.0</td>
      <td>86.900000</td>
      <td>192.0</td>
      <td>86.0</td>
      <td>22</td>
      <td>...</td>
      <td>€100K - €1M</td>
      <td>550000.0</td>
      <td>Bosnia</td>
      <td>100000.0</td>
      <td>1000000.0</td>
      <td>23.328993</td>
      <td>(17.999, 24.0]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fran Vujnović</td>
      <td>15.0</td>
      <td>1384.0</td>
      <td>92.266667</td>
      <td>190.0</td>
      <td>77.0</td>
      <td>19</td>
      <td>...</td>
      <td>€14K - €150K</td>
      <td>82000.0</td>
      <td>Croatia</td>
      <td>14000.0</td>
      <td>150000.0</td>
      <td>21.329640</td>
      <td>(17.999, 24.0]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Šimun Mikolčić</td>
      <td>15.0</td>
      <td>1380.0</td>
      <td>92.000000</td>
      <td>180.0</td>
      <td>70.0</td>
      <td>18</td>
      <td>...</td>
      <td>€35K - €350K</td>
      <td>192500.0</td>
      <td>Croatia</td>
      <td>35000.0</td>
      <td>350000.0</td>
      <td>21.604938</td>
      <td>(17.999, 24.0]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Romano Lisjak</td>
      <td>16.0</td>
      <td>1440.0</td>
      <td>90.000000</td>
      <td>188.0</td>
      <td>80.0</td>
      <td>21</td>
      <td>...</td>
      <td>€0 - €50K</td>
      <td>25000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>50000.0</td>
      <td>22.634676</td>
      <td>(17.999, 24.0]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1115</th>
      <td>Gianluigi Donnarumma</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>196.0</td>
      <td>90.0</td>
      <td>23</td>
      <td>...</td>
      <td>€254M - €276M</td>
      <td>265000000.0</td>
      <td>France</td>
      <td>254000000.0</td>
      <td>276000000.0</td>
      <td>23.427738</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>Éder Militão</td>
      <td>17.0</td>
      <td>1457.0</td>
      <td>85.705882</td>
      <td>186.0</td>
      <td>79.0</td>
      <td>24</td>
      <td>...</td>
      <td>€94M - €149M</td>
      <td>121500000.0</td>
      <td>Spain</td>
      <td>94000000.0</td>
      <td>149000000.0</td>
      <td>22.835010</td>
      <td>(17.999, 24.0]</td>
    </tr>
    <tr>
      <th>1117</th>
      <td>Sergio Ramos</td>
      <td>11.0</td>
      <td>924.0</td>
      <td>84.000000</td>
      <td>184.0</td>
      <td>82.0</td>
      <td>36</td>
      <td>...</td>
      <td>€12M - €18M</td>
      <td>15000000.0</td>
      <td>France</td>
      <td>12000000.0</td>
      <td>18000000.0</td>
      <td>24.220227</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1118</th>
      <td>Marquinhos</td>
      <td>13.0</td>
      <td>1129.0</td>
      <td>86.846154</td>
      <td>183.0</td>
      <td>75.0</td>
      <td>28</td>
      <td>...</td>
      <td>€99M - €128M</td>
      <td>113500000.0</td>
      <td>France</td>
      <td>99000000.0</td>
      <td>128000000.0</td>
      <td>22.395413</td>
      <td>(26.0, 28.0]</td>
    </tr>
    <tr>
      <th>1119</th>
      <td>Thibaut Courtois</td>
      <td>19.0</td>
      <td>1710.0</td>
      <td>90.000000</td>
      <td>199.0</td>
      <td>96.0</td>
      <td>30</td>
      <td>...</td>
      <td>€172M - €225M</td>
      <td>198500000.0</td>
      <td>Spain</td>
      <td>172000000.0</td>
      <td>225000000.0</td>
      <td>24.241812</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>Raphaël Varane</td>
      <td>17.0</td>
      <td>1463.0</td>
      <td>86.058824</td>
      <td>191.0</td>
      <td>81.0</td>
      <td>29</td>
      <td>...</td>
      <td>€101M - €127M</td>
      <td>114000000.0</td>
      <td>England</td>
      <td>101000000.0</td>
      <td>127000000.0</td>
      <td>22.203339</td>
      <td>(28.0, 39.0]</td>
    </tr>
    <tr>
      <th>1121</th>
      <td>Jan Oblak</td>
      <td>19.0</td>
      <td>1687.0</td>
      <td>88.789474</td>
      <td>189.0</td>
      <td>84.0</td>
      <td>29</td>
      <td>...</td>
      <td>€112M - €178M</td>
      <td>145000000.0</td>
      <td>Spain</td>
      <td>112000000.0</td>
      <td>178000000.0</td>
      <td>23.515579</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>1122 rows × 49 columns</p>
      
          <p>df_strikers (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name_of_the_player</th>
      <th>Number_of_appearances</th>
      <th>Minutes_played</th>
      <th>Minutes_played_per_game</th>
      <th>Height_of_the_player_in_cm</th>
      <th>Weight_of_the_player_in_kg</th>
      <th>Age_of_the_player</th>
      <th>...</th>
      <th>Distance_run_by_minutes</th>
      <th>Transfer_value_range</th>
      <th>Average_transfer_value</th>
      <th>Country_where_the_player_plays</th>
      <th>transfer_value_min</th>
      <th>transfer_value_max</th>
      <th>BMI</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Josip Mijatović</td>
      <td>12.0</td>
      <td>809.0</td>
      <td>67.416667</td>
      <td>173.0</td>
      <td>68.0</td>
      <td>20</td>
      <td>...</td>
      <td>0.126823</td>
      <td>€3K - €9K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>3000.0</td>
      <td>9000.0</td>
      <td>22.720438</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Duje Ninčević</td>
      <td>15.0</td>
      <td>1161.0</td>
      <td>77.400000</td>
      <td>172.0</td>
      <td>69.0</td>
      <td>25</td>
      <td>...</td>
      <td>0.129457</td>
      <td>€0 - €2.5K</td>
      <td>1250.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>2500.0</td>
      <td>23.323418</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vicko Ševelj</td>
      <td>20.0</td>
      <td>1738.0</td>
      <td>86.900000</td>
      <td>192.0</td>
      <td>86.0</td>
      <td>22</td>
      <td>...</td>
      <td>0.058631</td>
      <td>€100K - €1M</td>
      <td>550000.0</td>
      <td>Bosnia</td>
      <td>100000.0</td>
      <td>1000000.0</td>
      <td>23.328993</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fran Vujnović</td>
      <td>15.0</td>
      <td>1384.0</td>
      <td>92.266667</td>
      <td>190.0</td>
      <td>77.0</td>
      <td>19</td>
      <td>...</td>
      <td>0.016040</td>
      <td>€14K - €150K</td>
      <td>82000.0</td>
      <td>Croatia</td>
      <td>14000.0</td>
      <td>150000.0</td>
      <td>21.329640</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Šimun Mikolčić</td>
      <td>15.0</td>
      <td>1380.0</td>
      <td>92.000000</td>
      <td>180.0</td>
      <td>70.0</td>
      <td>18</td>
      <td>...</td>
      <td>0.013623</td>
      <td>€35K - €350K</td>
      <td>192500.0</td>
      <td>Croatia</td>
      <td>35000.0</td>
      <td>350000.0</td>
      <td>21.604938</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Romano Lisjak</td>
      <td>16.0</td>
      <td>1440.0</td>
      <td>90.000000</td>
      <td>188.0</td>
      <td>80.0</td>
      <td>21</td>
      <td>...</td>
      <td>0.101319</td>
      <td>€0 - €50K</td>
      <td>25000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>50000.0</td>
      <td>22.634676</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Dominik Ivkič</td>
      <td>15.0</td>
      <td>1350.0</td>
      <td>90.000000</td>
      <td>190.0</td>
      <td>78.0</td>
      <td>25</td>
      <td>...</td>
      <td>0.095481</td>
      <td>€0 - €14K</td>
      <td>7000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>14000.0</td>
      <td>21.606648</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1110</th>
      <td>Fabinho</td>
      <td>14.0</td>
      <td>1209.0</td>
      <td>86.357143</td>
      <td>188.0</td>
      <td>78.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.143259</td>
      <td>€112M - €178M</td>
      <td>145000000.0</td>
      <td>England</td>
      <td>112000000.0</td>
      <td>178000000.0</td>
      <td>22.068809</td>
    </tr>
    <tr>
      <th>1111</th>
      <td>Casemiro</td>
      <td>18.0</td>
      <td>1557.0</td>
      <td>86.500000</td>
      <td>185.0</td>
      <td>84.0</td>
      <td>30</td>
      <td>...</td>
      <td>0.135389</td>
      <td>€89M - €142M</td>
      <td>115500000.0</td>
      <td>Spain</td>
      <td>89000000.0</td>
      <td>142000000.0</td>
      <td>24.543462</td>
    </tr>
    <tr>
      <th>1113</th>
      <td>Matthijs de Ligt</td>
      <td>16.0</td>
      <td>1390.0</td>
      <td>86.875000</td>
      <td>189.0</td>
      <td>89.0</td>
      <td>23</td>
      <td>...</td>
      <td>0.116619</td>
      <td>€92M - €119M</td>
      <td>105500000.0</td>
      <td>Italy</td>
      <td>92000000.0</td>
      <td>119000000.0</td>
      <td>24.915316</td>
    </tr>
    <tr>
      <th>1114</th>
      <td>Saúl</td>
      <td>13.0</td>
      <td>1119.0</td>
      <td>86.076923</td>
      <td>184.0</td>
      <td>76.0</td>
      <td>27</td>
      <td>...</td>
      <td>0.142002</td>
      <td>€62M - €99M</td>
      <td>80500000.0</td>
      <td>Spain</td>
      <td>62000000.0</td>
      <td>99000000.0</td>
      <td>22.448015</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>Éder Militão</td>
      <td>17.0</td>
      <td>1457.0</td>
      <td>85.705882</td>
      <td>186.0</td>
      <td>79.0</td>
      <td>24</td>
      <td>...</td>
      <td>0.113315</td>
      <td>€94M - €149M</td>
      <td>121500000.0</td>
      <td>Spain</td>
      <td>94000000.0</td>
      <td>149000000.0</td>
      <td>22.835010</td>
    </tr>
    <tr>
      <th>1118</th>
      <td>Marquinhos</td>
      <td>13.0</td>
      <td>1129.0</td>
      <td>86.846154</td>
      <td>183.0</td>
      <td>75.0</td>
      <td>28</td>
      <td>...</td>
      <td>0.126749</td>
      <td>€99M - €128M</td>
      <td>113500000.0</td>
      <td>France</td>
      <td>99000000.0</td>
      <td>128000000.0</td>
      <td>22.395413</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>Raphaël Varane</td>
      <td>17.0</td>
      <td>1463.0</td>
      <td>86.058824</td>
      <td>191.0</td>
      <td>81.0</td>
      <td>29</td>
      <td>...</td>
      <td>0.107792</td>
      <td>€101M - €127M</td>
      <td>114000000.0</td>
      <td>England</td>
      <td>101000000.0</td>
      <td>127000000.0</td>
      <td>22.203339</td>
    </tr>
  </tbody>
</table>
<p>731 rows × 48 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Total_goals_scored</th>
    </tr>
    <tr>
      <th>Age_group</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(17.999, 24.0]</th>
      <td>1.095238</td>
    </tr>
    <tr>
      <th>(24.0, 26.0]</th>
      <td>1.236486</td>
    </tr>
    <tr>
      <th>(26.0, 28.0]</th>
      <td>1.216783</td>
    </tr>
    <tr>
      <th>(28.0, 39.0]</th>
      <td>0.993548</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> football-manager-2022-player-data/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the top 5 countries with the highest average players' ability. Show the country name and their current ability in descending order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Country_where_the_player_plays', 'Current_Ability']]\
    .groupby('Country_where_the_player_plays').mean()\
    .sort_values('Current_Ability', ascending=False).head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Country_where_the_player_plays', 'Current_Ability']]\
    .groupby('Country_where_the_player_plays').mean()\
    .sort_values('Current_Ability', ascending=False).head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Country_where_the_player_plays', 'Current_Ability']].groupby(
    'Country_where_the_player_plays').mean().sort_values('Current_Ability',
    ascending=False).head(5)
</code></pre>
        <p><span onclick="$('#var_output_a9866dc8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a9866dc8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Current_Ability</th>
    </tr>
    <tr>
      <th>Country_where_the_player_plays</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>England</th>
      <td>150.278689</td>
    </tr>
    <tr>
      <th>Spain</th>
      <td>148.826087</td>
    </tr>
    <tr>
      <th>Germany</th>
      <td>143.571429</td>
    </tr>
    <tr>
      <th>Ukraine</th>
      <td>134.600000</td>
    </tr>
    <tr>
      <th>Turkey</th>
      <td>132.000000</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Current_Ability</th>
    </tr>
    <tr>
      <th>Country_where_the_player_plays</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>England</th>
      <td>150.278689</td>
    </tr>
    <tr>
      <th>Spain</th>
      <td>148.826087</td>
    </tr>
    <tr>
      <th>Germany</th>
      <td>143.571429</td>
    </tr>
    <tr>
      <th>Ukraine</th>
      <td>134.600000</td>
    </tr>
    <tr>
      <th>Turkey</th>
      <td>132.000000</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> football-manager-2022-player-data/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # List the top 5 countries with the most number of leagues. Show the number of leagues in descending order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Country_where_the_player_plays', 'League_where_the_player_plays']].groupby('Country_where_the_player_plays')\
    .nunique().sort_values('League_where_the_player_plays', ascending=False).head(5)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Country_where_the_player_plays', 'League_where_the_player_plays']].groupby('Country_where_the_player_plays')\
    .nunique().sort_values('League_where_the_player_plays', ascending=False).head(5)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Country_where_the_player_plays',
    'League_where_the_player_plays']].groupby('Country_where_the_player_plays'
    ).nunique().sort_values('League_where_the_player_plays', ascending=False
    ).head(5)
</code></pre>
        <p><span onclick="$('#var_output_05b90133').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_05b90133" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>League_where_the_player_plays</th>
    </tr>
    <tr>
      <th>Country_where_the_player_plays</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>France</th>
      <td>12</td>
    </tr>
    <tr>
      <th>Italy</th>
      <td>10</td>
    </tr>
    <tr>
      <th>Portugal</th>
      <td>10</td>
    </tr>
    <tr>
      <th>Croatia</th>
      <td>6</td>
    </tr>
    <tr>
      <th>Belgium</th>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>League_where_the_player_plays</th>
    </tr>
    <tr>
      <th>Country_where_the_player_plays</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>France</th>
      <td>12</td>
    </tr>
    <tr>
      <th>Italy</th>
      <td>10</td>
    </tr>
    <tr>
      <th>Portugal</th>
      <td>10</td>
    </tr>
    <tr>
      <th>Croatia</th>
      <td>6</td>
    </tr>
    <tr>
      <th>Belgium</th>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> football-manager-2022-player-data/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Group BMI into quartile bins and find the average distance run by strikers in each group.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_strikers['BMI_group'] = pd.qcut(df_strikers.BMI, 4)
df_strikers[['BMI_group', 'Distance_run_in_total']].groupby('BMI_group').mean()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_strikers['BMI_group'] = pd.qcut(df_strikers.BMI, 4)
df_strikers[['BMI_group', 'Distance_run_in_total']].groupby('BMI_group').mean()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_strikers['BMI_group'] = pd.qcut(df_strikers.BMI, 4)
__output__ = df_strikers[['BMI_group', 'Distance_run_in_total']].groupby(
    'BMI_group').mean()
</code></pre>
        <p><span onclick="$('#var_output_bc96bfa8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bc96bfa8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Distance_run_in_total</th>
    </tr>
    <tr>
      <th>BMI_group</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(18.113999999999997, 21.952]</th>
      <td>148.048649</td>
    </tr>
    <tr>
      <th>(21.952, 22.72]</th>
      <td>147.650000</td>
    </tr>
    <tr>
      <th>(22.72, 23.546]</th>
      <td>149.612778</td>
    </tr>
    <tr>
      <th>(23.546, 28.704]</th>
      <td>147.635165</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_strikers, __output__ </p>
    
          <p>df_strikers (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name_of_the_player</th>
      <th>Number_of_appearances</th>
      <th>Minutes_played</th>
      <th>Minutes_played_per_game</th>
      <th>Height_of_the_player_in_cm</th>
      <th>Weight_of_the_player_in_kg</th>
      <th>Age_of_the_player</th>
      <th>...</th>
      <th>Transfer_value_range</th>
      <th>Average_transfer_value</th>
      <th>Country_where_the_player_plays</th>
      <th>transfer_value_min</th>
      <th>transfer_value_max</th>
      <th>BMI</th>
      <th>BMI_group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Josip Mijatović</td>
      <td>12.0</td>
      <td>809.0</td>
      <td>67.416667</td>
      <td>173.0</td>
      <td>68.0</td>
      <td>20</td>
      <td>...</td>
      <td>€3K - €9K</td>
      <td>6000.0</td>
      <td>Croatia</td>
      <td>3000.0</td>
      <td>9000.0</td>
      <td>22.720438</td>
      <td>(21.952, 22.72]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Duje Ninčević</td>
      <td>15.0</td>
      <td>1161.0</td>
      <td>77.400000</td>
      <td>172.0</td>
      <td>69.0</td>
      <td>25</td>
      <td>...</td>
      <td>€0 - €2.5K</td>
      <td>1250.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>2500.0</td>
      <td>23.323418</td>
      <td>(22.72, 23.546]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Vicko Ševelj</td>
      <td>20.0</td>
      <td>1738.0</td>
      <td>86.900000</td>
      <td>192.0</td>
      <td>86.0</td>
      <td>22</td>
      <td>...</td>
      <td>€100K - €1M</td>
      <td>550000.0</td>
      <td>Bosnia</td>
      <td>100000.0</td>
      <td>1000000.0</td>
      <td>23.328993</td>
      <td>(22.72, 23.546]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fran Vujnović</td>
      <td>15.0</td>
      <td>1384.0</td>
      <td>92.266667</td>
      <td>190.0</td>
      <td>77.0</td>
      <td>19</td>
      <td>...</td>
      <td>€14K - €150K</td>
      <td>82000.0</td>
      <td>Croatia</td>
      <td>14000.0</td>
      <td>150000.0</td>
      <td>21.329640</td>
      <td>(18.113999999999997, 21.952]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Šimun Mikolčić</td>
      <td>15.0</td>
      <td>1380.0</td>
      <td>92.000000</td>
      <td>180.0</td>
      <td>70.0</td>
      <td>18</td>
      <td>...</td>
      <td>€35K - €350K</td>
      <td>192500.0</td>
      <td>Croatia</td>
      <td>35000.0</td>
      <td>350000.0</td>
      <td>21.604938</td>
      <td>(18.113999999999997, 21.952]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Romano Lisjak</td>
      <td>16.0</td>
      <td>1440.0</td>
      <td>90.000000</td>
      <td>188.0</td>
      <td>80.0</td>
      <td>21</td>
      <td>...</td>
      <td>€0 - €50K</td>
      <td>25000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>50000.0</td>
      <td>22.634676</td>
      <td>(21.952, 22.72]</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Dominik Ivkič</td>
      <td>15.0</td>
      <td>1350.0</td>
      <td>90.000000</td>
      <td>190.0</td>
      <td>78.0</td>
      <td>25</td>
      <td>...</td>
      <td>€0 - €14K</td>
      <td>7000.0</td>
      <td>Croatia</td>
      <td>NaN</td>
      <td>14000.0</td>
      <td>21.606648</td>
      <td>(18.113999999999997, 21.952]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1110</th>
      <td>Fabinho</td>
      <td>14.0</td>
      <td>1209.0</td>
      <td>86.357143</td>
      <td>188.0</td>
      <td>78.0</td>
      <td>29</td>
      <td>...</td>
      <td>€112M - €178M</td>
      <td>145000000.0</td>
      <td>England</td>
      <td>112000000.0</td>
      <td>178000000.0</td>
      <td>22.068809</td>
      <td>(21.952, 22.72]</td>
    </tr>
    <tr>
      <th>1111</th>
      <td>Casemiro</td>
      <td>18.0</td>
      <td>1557.0</td>
      <td>86.500000</td>
      <td>185.0</td>
      <td>84.0</td>
      <td>30</td>
      <td>...</td>
      <td>€89M - €142M</td>
      <td>115500000.0</td>
      <td>Spain</td>
      <td>89000000.0</td>
      <td>142000000.0</td>
      <td>24.543462</td>
      <td>(23.546, 28.704]</td>
    </tr>
    <tr>
      <th>1113</th>
      <td>Matthijs de Ligt</td>
      <td>16.0</td>
      <td>1390.0</td>
      <td>86.875000</td>
      <td>189.0</td>
      <td>89.0</td>
      <td>23</td>
      <td>...</td>
      <td>€92M - €119M</td>
      <td>105500000.0</td>
      <td>Italy</td>
      <td>92000000.0</td>
      <td>119000000.0</td>
      <td>24.915316</td>
      <td>(23.546, 28.704]</td>
    </tr>
    <tr>
      <th>1114</th>
      <td>Saúl</td>
      <td>13.0</td>
      <td>1119.0</td>
      <td>86.076923</td>
      <td>184.0</td>
      <td>76.0</td>
      <td>27</td>
      <td>...</td>
      <td>€62M - €99M</td>
      <td>80500000.0</td>
      <td>Spain</td>
      <td>62000000.0</td>
      <td>99000000.0</td>
      <td>22.448015</td>
      <td>(21.952, 22.72]</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>Éder Militão</td>
      <td>17.0</td>
      <td>1457.0</td>
      <td>85.705882</td>
      <td>186.0</td>
      <td>79.0</td>
      <td>24</td>
      <td>...</td>
      <td>€94M - €149M</td>
      <td>121500000.0</td>
      <td>Spain</td>
      <td>94000000.0</td>
      <td>149000000.0</td>
      <td>22.835010</td>
      <td>(22.72, 23.546]</td>
    </tr>
    <tr>
      <th>1118</th>
      <td>Marquinhos</td>
      <td>13.0</td>
      <td>1129.0</td>
      <td>86.846154</td>
      <td>183.0</td>
      <td>75.0</td>
      <td>28</td>
      <td>...</td>
      <td>€99M - €128M</td>
      <td>113500000.0</td>
      <td>France</td>
      <td>99000000.0</td>
      <td>128000000.0</td>
      <td>22.395413</td>
      <td>(21.952, 22.72]</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>Raphaël Varane</td>
      <td>17.0</td>
      <td>1463.0</td>
      <td>86.058824</td>
      <td>191.0</td>
      <td>81.0</td>
      <td>29</td>
      <td>...</td>
      <td>€101M - €127M</td>
      <td>114000000.0</td>
      <td>England</td>
      <td>101000000.0</td>
      <td>127000000.0</td>
      <td>22.203339</td>
      <td>(21.952, 22.72]</td>
    </tr>
  </tbody>
</table>
<p>731 rows × 49 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Distance_run_in_total</th>
    </tr>
    <tr>
      <th>BMI_group</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(18.113999999999997, 21.952]</th>
      <td>148.048649</td>
    </tr>
    <tr>
      <th>(21.952, 22.72]</th>
      <td>147.650000</td>
    </tr>
    <tr>
      <th>(22.72, 23.546]</th>
      <td>149.612778</td>
    </tr>
    <tr>
      <th>(23.546, 28.704]</th>
      <td>147.635165</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> football-manager-2022-player-data/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Among the top 25% of strikers who made interceptions, who had the least fouls?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_strikers[df_strikers.Interceptions_made_per_game > df_strikers.Interceptions_made_per_game.quantile(0.75)]\
    .sort_values('Fouls_made_in_total', ascending=False).head(1).Name_of_the_player.values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_strikers[df_strikers.Interceptions_made_per_game > df_strikers.Interceptions_made_per_game.quantile(0.75)]\
    .sort_values('Fouls_made_in_total', ascending=False).head(1).Name_of_the_player.values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_strikers[df_strikers.Interceptions_made_per_game >
    df_strikers.Interceptions_made_per_game.quantile(0.75)].sort_values(
    'Fouls_made_in_total', ascending=False).head(1).Name_of_the_player.values[0
    ]
</code></pre>
        <p><span onclick="$('#var_output_f42e0c82').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f42e0c82" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Kelvin Leerdam</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Kelvin Leerdam</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> football-manager-2022-player-data/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Find the correlation between current ability and average transfer value, as well as log and log squared of average transfer value.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_corr = df.loc[:, ['Current_Ability', 'Average_transfer_value']]
df_corr['Log_atv'] = np.log(df_corr.Average_transfer_value)
df_corr['Log_atv_square'] = df_corr['Log_atv']**2
df_corr.corr()[['Current_Ability']].iloc[1:]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_corr = df.loc[:, ['Current_Ability', 'Average_transfer_value']]
df_corr['Log_atv'] = np.log(df_corr.Average_transfer_value)
df_corr['Log_atv_square'] = df_corr['Log_atv']**2
df_corr.corr()[['Current_Ability']].iloc[1:]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_corr = df.loc[:, ['Current_Ability', 'Average_transfer_value']]
df_corr['Log_atv'] = np.log(df_corr.Average_transfer_value)
df_corr['Log_atv_square'] = df_corr['Log_atv'] ** 2
__output__ = df_corr.corr()[['Current_Ability']].iloc[1:]
</code></pre>
        <p><span onclick="$('#var_output_1536750d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1536750d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Current_Ability</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Average_transfer_value</th>
      <td>0.620883</td>
    </tr>
    <tr>
      <th>Log_atv</th>
      <td>0.888490</td>
    </tr>
    <tr>
      <th>Log_atv_square</th>
      <td>0.902069</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_corr, __output__ </p>
    
          <p>df_corr (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Current_Ability</th>
      <th>Average_transfer_value</th>
      <th>Log_atv</th>
      <th>Log_atv_square</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>84</td>
      <td>6000.0</td>
      <td>8.699515</td>
      <td>75.681557</td>
    </tr>
    <tr>
      <th>1</th>
      <td>79</td>
      <td>1250.0</td>
      <td>7.130899</td>
      <td>50.849718</td>
    </tr>
    <tr>
      <th>2</th>
      <td>87</td>
      <td>6000.0</td>
      <td>8.699515</td>
      <td>75.681557</td>
    </tr>
    <tr>
      <th>3</th>
      <td>95</td>
      <td>550000.0</td>
      <td>13.217674</td>
      <td>174.706894</td>
    </tr>
    <tr>
      <th>4</th>
      <td>83</td>
      <td>82000.0</td>
      <td>11.314475</td>
      <td>128.017334</td>
    </tr>
    <tr>
      <th>5</th>
      <td>81</td>
      <td>192500.0</td>
      <td>12.167851</td>
      <td>148.056608</td>
    </tr>
    <tr>
      <th>6</th>
      <td>78</td>
      <td>25000.0</td>
      <td>10.126631</td>
      <td>102.548658</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1115</th>
      <td>162</td>
      <td>265000000.0</td>
      <td>19.395240</td>
      <td>376.175350</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>168</td>
      <td>121500000.0</td>
      <td>18.615425</td>
      <td>346.534041</td>
    </tr>
    <tr>
      <th>1117</th>
      <td>156</td>
      <td>15000000.0</td>
      <td>16.523561</td>
      <td>273.028060</td>
    </tr>
    <tr>
      <th>1118</th>
      <td>163</td>
      <td>113500000.0</td>
      <td>18.547313</td>
      <td>344.002834</td>
    </tr>
    <tr>
      <th>1119</th>
      <td>180</td>
      <td>198500000.0</td>
      <td>19.106300</td>
      <td>365.050687</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>164</td>
      <td>114000000.0</td>
      <td>18.551709</td>
      <td>344.165907</td>
    </tr>
    <tr>
      <th>1121</th>
      <td>178</td>
      <td>145000000.0</td>
      <td>18.792244</td>
      <td>353.148446</td>
    </tr>
  </tbody>
</table>
<p>1122 rows × 4 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Current_Ability</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Average_transfer_value</th>
      <td>0.620883</td>
    </tr>
    <tr>
      <th>Log_atv</th>
      <td>0.888490</td>
    </tr>
    <tr>
      <th>Log_atv_square</th>
      <td>0.902069</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> laptop-ranked-dataset/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new column showing the name of the processor brand and list the unique brands.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['Processor_Brand_Name'] = df.Processor_name.str.split(' ').apply(lambda x: x[0])
df.Processor_Brand_Name.unique()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['Processor_Brand_Name'] = df.Processor_name.str.split(' ').apply(lambda x: x[0])
df.Processor_Brand_Name.unique()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['Processor_Brand_Name'] = df.Processor_name.str.split(' ').apply(lambda
    x: x[0])
__output__ = df.Processor_Brand_Name.unique()
</code></pre>
        <p><span onclick="$('#var_output_6fe9f281').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6fe9f281" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>['intel' 'amd' 'qualcomm' 'apple' 'mediatek']</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>link</th>
      <th>name</th>
      <th>user_rating</th>
      <th>Price_in_Indian_Rupees</th>
      <th>Type</th>
      <th>Dedicated_Graphic_Memory_Capacity</th>
      <th>Processor_Brand</th>
      <th>...</th>
      <th>battery_backup</th>
      <th>gpu_name</th>
      <th>gpu_benchmark</th>
      <th>ram_type_tokenized</th>
      <th>gpu_processor_tokenized</th>
      <th>Company_Name</th>
      <th>Processor_Brand_Name</th>
    </tr>
    <tr>
      <th>index</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>https://www.flipkart.com/asus-rog-strix-scar-17-core-i9-12th-gen-32-gb-1-tb-ssd-windows-11-home-8-gb-graphics-nvidia-geforce-rtx-3070-ti-g733zw-ll139ws-gaming-laptop/p/itm0e721469cc7cc?pid=COMGCZUJCBRGXYFX&amp;lid=LSTCOMGCZUJCBRGXYFXT7VNUU&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_73&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGCZUJCBRGXYFX.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>asus rog strix scar 17 core i9 12th gen - (32 gb/1 tb ssd/windows 11 home/8 gb graphics/nvidia geforce rtx 3070 ti) g733zw-ll139ws gaming laptop  (17.3 inch, off black, 2.90 kg, with ms office)</td>
      <td>5.0</td>
      <td>234990</td>
      <td>gaming laptop</td>
      <td>8.0</td>
      <td>1</td>
      <td>...</td>
      <td>4.0</td>
      <td>nvidia geforce rtx 3070 ti</td>
      <td>168.00</td>
      <td>7</td>
      <td>1</td>
      <td>asus</td>
      <td>intel</td>
    </tr>
    <tr>
      <th>1</th>
      <td>https://www.flipkart.com/asus-rog-strix-scar-15-core-i9-12th-gen-32-gb-1-tb-ssd-windows-11-home-8-gb-graphics-nvidia-geforce-rtx-3070-ti-g533zw-ln136ws-gaming-laptop/p/itmd6e8ba35232e4?pid=COMGCZUJVKGPCCYE&amp;lid=LSTCOMGCZUJVKGPCCYEPSSUDZ&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_74&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGCZUJVKGPCCYE.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>asus rog strix scar 15 core i9 12th gen - (32 gb/1 tb ssd/windows 11 home/8 gb graphics/nvidia geforce rtx 3070 ti) g533zw-ln136ws gaming laptop  (15.6 inch, off black, 2.30 kg, with ms office)</td>
      <td>NaN</td>
      <td>229990</td>
      <td>gaming laptop</td>
      <td>8.0</td>
      <td>1</td>
      <td>...</td>
      <td>4.0</td>
      <td>nvidia geforce rtx 3070 ti</td>
      <td>168.00</td>
      <td>7</td>
      <td>1</td>
      <td>asus</td>
      <td>intel</td>
    </tr>
    <tr>
      <th>2</th>
      <td>https://www.flipkart.com/hp-victus-ryzen-7-octa-core-5800h-16-gb-512-gb-ssd-windows-11-home-4-graphics-nvidia-geforce-rtx-3050-16-e0351ax-gaming-laptop/p/itm3a869e89d6498?pid=COMG8N9HRE7QYYBE&amp;lid=LSTCOMG8N9HRE7QYYBEALDT8F&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_75&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMG8N9HRE7QYYBE.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>hp victus ryzen 7 octa core 5800h - (16 gb/512 gb ssd/windows 11 home/4 gb graphics/nvidia geforce rtx 3050) 16-e0351ax gaming laptop  (16.1 inch, mica silver, 2.48 kg, with ms office)</td>
      <td>NaN</td>
      <td>104091</td>
      <td>gaming laptop</td>
      <td>4.0</td>
      <td>2</td>
      <td>...</td>
      <td>4.0</td>
      <td>nvidia geforce rtx 3050</td>
      <td>72.60</td>
      <td>4</td>
      <td>2</td>
      <td>hp</td>
      <td>amd</td>
    </tr>
    <tr>
      <th>3</th>
      <td>https://www.flipkart.com/lenovo-ideapad-gaming-3i-ryzen-7-octa-core-r7-5800h-5th-gen-16-gb-512-gb-ssd-windows-11-home-4-graphics-nvidia-geforce-rtx-3050-15ach6-laptop/p/itmbc01bfc64700e?pid=COMGD8Z2J9JH7AAX&amp;lid=LSTCOMGD8Z2J9JH7AAXOJWV00&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_76&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGD8Z2J9JH7AAX.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>lenovo ideapad gaming 3i ryzen 7 octa core r7-5800h 5th gen - (16 gb/512 gb ssd/windows 11 home/4 gb graphics/nvidia geforce rtx 3050) 15ach6 gaming laptop  (15.6 inch, shadow black, 2.25 kg, with ms office)</td>
      <td>NaN</td>
      <td>87717</td>
      <td>gaming laptop</td>
      <td>4.0</td>
      <td>2</td>
      <td>...</td>
      <td>4.0</td>
      <td>nvidia geforce rtx 3050</td>
      <td>72.60</td>
      <td>4</td>
      <td>2</td>
      <td>lenovo</td>
      <td>amd</td>
    </tr>
    <tr>
      <th>4</th>
      <td>https://www.flipkart.com/lenovo-yoga-slim-7-core-i5-11th-gen-16-gb-512-gb-ssd-windows-11-home-82a300mbin-thin-light-laptop/p/itm8d670bbb74a5b?pid=COMGD8RMGDEUBVSZ&amp;lid=LSTCOMGD8RMGDEUBVSZY8IBIK&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_77&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGD8RMGDEUBVSZ.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>lenovo yoga slim 7 core i5 11th gen - (16 gb/512 gb ssd/windows 11 home) 82a300mbin thin and light laptop  (14 inch, slate grey, with ms office)</td>
      <td>NaN</td>
      <td>75990</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>4.5</td>
      <td>intel hd</td>
      <td>4.23</td>
      <td>4</td>
      <td>3</td>
      <td>lenovo</td>
      <td>intel</td>
    </tr>
    <tr>
      <th>5</th>
      <td>https://www.flipkart.com/lenovo-yoga-slim-7-core-i7-11th-gen-16-gb-512-gb-ssd-windows-11-home-14itl05-thin-light-laptop/p/itm4a202e05ce632?pid=COMGD8NWUVM8F5YG&amp;lid=LSTCOMGD8NWUVM8F5YGEYMIMD&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_78&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGD8NWUVM8F5YG.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>lenovo yoga slim 7 core i7 11th gen - (16 gb/512 gb ssd/windows 11 home) 14itl05 thin and light laptop  (14 inch, slate grey, 1.36 kg, with ms office)</td>
      <td>NaN</td>
      <td>78395</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>4.5</td>
      <td>iris xe</td>
      <td>17.50</td>
      <td>4</td>
      <td>4</td>
      <td>lenovo</td>
      <td>intel</td>
    </tr>
    <tr>
      <th>6</th>
      <td>https://www.flipkart.com/lenovo-v15-celeron-dual-core-4-gb-256-gb-ssd-windows-10-82c30053ih-thin-light-laptop/p/itmbb8fd7d46586e?pid=COMGDF2CDX97JDPC&amp;lid=LSTCOMGDF2CDX97JDPCNUVMWS&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_79&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGDF2CDX97JDPC.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>lenovo lenovo v15 celeron dual core - (4 gb/256 gb ssd/windows 10) 82c30053ih thin and light laptop  (15.6 inch, iron grey)</td>
      <td>3.0</td>
      <td>29290</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>4.5</td>
      <td>intel hd</td>
      <td>4.23</td>
      <td>4</td>
      <td>3</td>
      <td>lenovo</td>
      <td>intel</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>977</th>
      <td>https://www.flipkart.com/lenovo-yoga-core-i7-10th-gen-16-gb-1-tb-ssd-windows-10-home-s940-14iil-thin-light-laptop/p/itm1bfe27dc8132c?pid=COMFVW9TKWBN3ZB8&amp;lid=LSTCOMFVW9TKWBN3ZB8BJY4JS&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_978&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVW9TKWBN3ZB8.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>lenovo yoga core i7 10th gen - (16 gb/1 tb ssd/windows 10 home) yoga s940-14iil thin and light laptop  (14 inch, grey, black, 1.25 kg)</td>
      <td>2.5</td>
      <td>142990</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>4.5</td>
      <td>intel iris plus</td>
      <td>10.60</td>
      <td>6</td>
      <td>22</td>
      <td>lenovo</td>
      <td>intel</td>
    </tr>
    <tr>
      <th>978</th>
      <td>https://www.flipkart.com/lenovo-core-i7-10th-gen-16-gb-512-gb-ssd-windows-10-pro-thinkpad-x1-carbon-thin-light-laptop/p/itm3ec77a5aa6dca?pid=COMFVW9TT73PM9QH&amp;lid=LSTCOMFVW9TT73PM9QHOKKKH5&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_979&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVW9TT73PM9QH.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>lenovo core i7 10th gen - (16 gb/512 gb ssd/windows 10 pro) thinkpad x1 carbon thin and light laptop  (14 inch, black, 1.09 kg)</td>
      <td>NaN</td>
      <td>214760</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>4.5</td>
      <td>intel uhd</td>
      <td>5.05</td>
      <td>2</td>
      <td>7</td>
      <td>lenovo</td>
      <td>intel</td>
    </tr>
    <tr>
      <th>979</th>
      <td>https://www.flipkart.com/nokia-purebook-x14-core-i5-10th-gen-8-gb-512-gb-ssd-windows-10-home-nki510ul85s-thin-light-laptop/p/itmdc10c8866a3a4?pid=COMFUJ4NXDKZ4VFN&amp;lid=LSTCOMFUJ4NXDKZ4VFNROFWVT&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_980&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFUJ4NXDKZ4VFN.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>nokia purebook x14 core i5 10th gen - (8 gb/512 gb ssd/windows 10 home) nki510ul85s thin and light laptop  (14 inch, black, 1.1 kg)</td>
      <td>4.4</td>
      <td>53990</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>4.5</td>
      <td>intel uhd</td>
      <td>5.05</td>
      <td>4</td>
      <td>7</td>
      <td>nokia</td>
      <td>intel</td>
    </tr>
    <tr>
      <th>980</th>
      <td>https://www.flipkart.com/hp-spectre-folio-core-i7-10th-gen-16-gb-512-gb-ssd-windows-10-home-13-ak1004tu-2-1-laptop/p/itm2d34c3ce7c08b?pid=COMFVNK6TZQ9GRB6&amp;lid=LSTCOMFVNK6TZQ9GRB6YPJWRI&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_981&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVNK6TZQ9GRB6.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>hp spectre folio core i7 10th gen - (16 gb/512 gb ssd/windows 10 home) 13-ak1004tu 2 in 1 laptop  (13.3 inch, cognac brown, 1.49 kg, with ms office)</td>
      <td>NaN</td>
      <td>239759</td>
      <td>2 in 1 laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>5.0</td>
      <td>nvidia geforce gtx</td>
      <td>70.90</td>
      <td>2</td>
      <td>23</td>
      <td>hp</td>
      <td>intel</td>
    </tr>
    <tr>
      <th>981</th>
      <td>https://www.flipkart.com/hp-envy-x360-ryzen-5-hexa-core-4500u-8-gb-512-gb-ssd-windows-10-pro-13-ay0078au-2-1-laptop/p/itm0a53f83e64513?pid=COMFVNK6BBG5FMMH&amp;lid=LSTCOMFVNK6BBG5FMMHNZTNJZ&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_982&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVNK6BBG5FMMH.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>hp envy x360 ryzen 5 hexa core 4500u - (8 gb/512 gb ssd/windows 10 pro) 13-ay0078au 2 in 1 laptop  (13.3 inch, nightfall black, 1.32 kg, with ms office)</td>
      <td>NaN</td>
      <td>85555</td>
      <td>2 in 1 laptop</td>
      <td>0.0</td>
      <td>2</td>
      <td>...</td>
      <td>5.0</td>
      <td>amd radeon</td>
      <td>102.00</td>
      <td>4</td>
      <td>5</td>
      <td>hp</td>
      <td>amd</td>
    </tr>
    <tr>
      <th>982</th>
      <td>https://www.flipkart.com/hp-14a-celeron-dual-core-4-gb-64-gb-emmc-storage-chrome-os-14a-na0002tu-chromebook/p/itm04b4752804ffa?pid=COMFVNK6BRCJSH6R&amp;lid=LSTCOMFVNK6BRCJSH6RYCDEOQ&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_983&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVNK6BRCJSH6R.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>hp 14a celeron dual core - (4 gb/64 gb emmc storage/chrome os) 14a- na0002tu chromebook  (14 inch, ceramic white, 1.46 kg)</td>
      <td>3.6</td>
      <td>26990</td>
      <td>notebook</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>4.5</td>
      <td>intel uhd 605</td>
      <td>2.13</td>
      <td>4</td>
      <td>24</td>
      <td>hp</td>
      <td>intel</td>
    </tr>
    <tr>
      <th>983</th>
      <td>https://www.flipkart.com/lenovo-core-i3-10th-gen-4-gb-1-tb-hdd-windows-10-pro-v14-laptop/p/itmfe9416142ecb8?pid=COMFVSYVPYVEGZBH&amp;lid=LSTCOMFVSYVPYVEGZBHZP5VIF&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_984&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVSYVPYVEGZBH.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>lenovo core i3 10th gen - (4 gb/1 tb hdd/windows 10 pro) v14 laptop  (14 inch, black, 1.6 kg)</td>
      <td>3.1</td>
      <td>44590</td>
      <td>notebook</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>4.5</td>
      <td>amd radeon r4</td>
      <td>3.50</td>
      <td>4</td>
      <td>40</td>
      <td>lenovo</td>
      <td>intel</td>
    </tr>
  </tbody>
</table>
<p>984 rows × 28 columns</p>
      
          <p>__output__ (ndarray):</p>
          <pre><code>['intel' 'amd' 'qualcomm' 'apple' 'mediatek']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> laptop-ranked-dataset/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many gaming laptops with expandable memory does each brand offer?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Company_Name', 'Expandable_Memory']][(df['Expandable_Memory'] == 1) & (df.Type == 'gaming laptop')].groupby(
    'Company_Name').count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Company_Name', 'Expandable_Memory']][(df['Expandable_Memory'] == 1) & (df.Type == 'gaming laptop')].groupby(
    'Company_Name').count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Company_Name', 'Expandable_Memory']][(df[
    'Expandable_Memory'] == 1) & (df.Type == 'gaming laptop')].groupby(
    'Company_Name').count()
</code></pre>
        <p><span onclick="$('#var_output_ba6f371d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ba6f371d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Expandable_Memory</th>
    </tr>
    <tr>
      <th>Company_Name</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>acer</th>
      <td>18</td>
    </tr>
    <tr>
      <th>asus</th>
      <td>55</td>
    </tr>
    <tr>
      <th>dell</th>
      <td>19</td>
    </tr>
    <tr>
      <th>hp</th>
      <td>14</td>
    </tr>
    <tr>
      <th>lenovo</th>
      <td>17</td>
    </tr>
    <tr>
      <th>msi</th>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Expandable_Memory</th>
    </tr>
    <tr>
      <th>Company_Name</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>acer</th>
      <td>18</td>
    </tr>
    <tr>
      <th>asus</th>
      <td>55</td>
    </tr>
    <tr>
      <th>dell</th>
      <td>19</td>
    </tr>
    <tr>
      <th>hp</th>
      <td>14</td>
    </tr>
    <tr>
      <th>lenovo</th>
      <td>17</td>
    </tr>
    <tr>
      <th>msi</th>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> laptop-ranked-dataset/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which laptop with at least 16 GB of DDR5 RAM is the cheapest?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df.RAM_in_GB >= 16) & df.RAM_Type.str.contains('ddr5')].sort_values('Price_in_Indian_Rupees').name[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df.RAM_in_GB >= 16) & df.RAM_Type.str.contains('ddr5')].sort_values('Price_in_Indian_Rupees').name[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df.RAM_in_GB >= 16) & df.RAM_Type.str.contains('ddr5')
    ].sort_values('Price_in_Indian_Rupees').name[0]
</code></pre>
        <p><span onclick="$('#var_output_c9f129f7').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c9f129f7" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>asus rog strix scar 17 core i9 12th gen - (32 gb/1 tb ssd/windows 11 home/8 gb graphics/nvidia geforce rtx 3070 ti) g733zw-ll139ws gaming laptop  (17.3 inch, off black, 2.90 kg, with ms office)</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>asus rog strix scar 17 core i9 12th gen - (32 gb/1 tb ssd/windows 11 home/8 gb graphics/nvidia geforce rtx 3070 ti) g733zw-ll139ws gaming laptop  (17.3 inch, off black, 2.90 kg, with ms office)</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> laptop-ranked-dataset/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Display the median GPU benchmark score for each rtx 3000 series graphics card.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['gpu_name', 'gpu_benchmark']][df.gpu_name.str.contains('rtx 30')].groupby('gpu_name').median()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['gpu_name', 'gpu_benchmark']][df.gpu_name.str.contains('rtx 30')].groupby('gpu_name').median()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['gpu_name', 'gpu_benchmark']][df.gpu_name.str.contains(
    'rtx 30')].groupby('gpu_name').median()
</code></pre>
        <p><span onclick="$('#var_output_90a53869').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_90a53869" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gpu_benchmark</th>
    </tr>
    <tr>
      <th>gpu_name</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>nvidia geforce rtx 3050</th>
      <td>72.6</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3050 ti</th>
      <td>59.0</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3050ti</th>
      <td>59.0</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3060</th>
      <td>132.0</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3070</th>
      <td>154.0</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3070 ti</th>
      <td>168.0</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3080 ti</th>
      <td>233.0</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gpu_benchmark</th>
    </tr>
    <tr>
      <th>gpu_name</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>nvidia geforce rtx 3050</th>
      <td>72.6</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3050 ti</th>
      <td>59.0</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3050ti</th>
      <td>59.0</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3060</th>
      <td>132.0</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3070</th>
      <td>154.0</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3070 ti</th>
      <td>168.0</td>
    </tr>
    <tr>
      <th>nvidia geforce rtx 3080 ti</th>
      <td>233.0</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> laptop-ranked-dataset/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new column showing the number of processor cores if inferrable from the name.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def infer_core_count(x):
    if 'dual' in x:
        return 2
    if 'quad' in x:
        return 4
    if 'hexa' in x:
        return 6
    if 'octa' in x:
        return 8
    return None

df['processor_cores'] = df.name.apply(infer_core_count)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def infer_core_count(x):
    if 'dual' in x:
        return 2
    if 'quad' in x:
        return 4
    if 'hexa' in x:
        return 6
    if 'octa' in x:
        return 8
    return None

df['processor_cores'] = df.name.apply(infer_core_count)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def infer_core_count(x):
    if 'dual' in x:
        return 2
    if 'quad' in x:
        return 4
    if 'hexa' in x:
        return 6
    if 'octa' in x:
        return 8
    return None


__output__ = df['processor_cores'] = df.name.apply(infer_core_count)
</code></pre>
        <p><span onclick="$('#var_output_0f7011c2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0f7011c2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>index
0      NaN
1      NaN
2      8.0
3      8.0
4      NaN
      ... 
979    NaN
980    NaN
981    6.0
982    2.0
983    NaN
Name: name, Length: 984, dtype: float64</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>link</th>
      <th>name</th>
      <th>user_rating</th>
      <th>Price_in_Indian_Rupees</th>
      <th>Type</th>
      <th>Dedicated_Graphic_Memory_Capacity</th>
      <th>Processor_Brand</th>
      <th>...</th>
      <th>gpu_name</th>
      <th>gpu_benchmark</th>
      <th>ram_type_tokenized</th>
      <th>gpu_processor_tokenized</th>
      <th>Company_Name</th>
      <th>Processor_Brand_Name</th>
      <th>processor_cores</th>
    </tr>
    <tr>
      <th>index</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>https://www.flipkart.com/asus-rog-strix-scar-17-core-i9-12th-gen-32-gb-1-tb-ssd-windows-11-home-8-gb-graphics-nvidia-geforce-rtx-3070-ti-g733zw-ll139ws-gaming-laptop/p/itm0e721469cc7cc?pid=COMGCZUJCBRGXYFX&amp;lid=LSTCOMGCZUJCBRGXYFXT7VNUU&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_73&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGCZUJCBRGXYFX.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>asus rog strix scar 17 core i9 12th gen - (32 gb/1 tb ssd/windows 11 home/8 gb graphics/nvidia geforce rtx 3070 ti) g733zw-ll139ws gaming laptop  (17.3 inch, off black, 2.90 kg, with ms office)</td>
      <td>5.0</td>
      <td>234990</td>
      <td>gaming laptop</td>
      <td>8.0</td>
      <td>1</td>
      <td>...</td>
      <td>nvidia geforce rtx 3070 ti</td>
      <td>168.00</td>
      <td>7</td>
      <td>1</td>
      <td>asus</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>https://www.flipkart.com/asus-rog-strix-scar-15-core-i9-12th-gen-32-gb-1-tb-ssd-windows-11-home-8-gb-graphics-nvidia-geforce-rtx-3070-ti-g533zw-ln136ws-gaming-laptop/p/itmd6e8ba35232e4?pid=COMGCZUJVKGPCCYE&amp;lid=LSTCOMGCZUJVKGPCCYEPSSUDZ&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_74&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGCZUJVKGPCCYE.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>asus rog strix scar 15 core i9 12th gen - (32 gb/1 tb ssd/windows 11 home/8 gb graphics/nvidia geforce rtx 3070 ti) g533zw-ln136ws gaming laptop  (15.6 inch, off black, 2.30 kg, with ms office)</td>
      <td>NaN</td>
      <td>229990</td>
      <td>gaming laptop</td>
      <td>8.0</td>
      <td>1</td>
      <td>...</td>
      <td>nvidia geforce rtx 3070 ti</td>
      <td>168.00</td>
      <td>7</td>
      <td>1</td>
      <td>asus</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>https://www.flipkart.com/hp-victus-ryzen-7-octa-core-5800h-16-gb-512-gb-ssd-windows-11-home-4-graphics-nvidia-geforce-rtx-3050-16-e0351ax-gaming-laptop/p/itm3a869e89d6498?pid=COMG8N9HRE7QYYBE&amp;lid=LSTCOMG8N9HRE7QYYBEALDT8F&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_75&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMG8N9HRE7QYYBE.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>hp victus ryzen 7 octa core 5800h - (16 gb/512 gb ssd/windows 11 home/4 gb graphics/nvidia geforce rtx 3050) 16-e0351ax gaming laptop  (16.1 inch, mica silver, 2.48 kg, with ms office)</td>
      <td>NaN</td>
      <td>104091</td>
      <td>gaming laptop</td>
      <td>4.0</td>
      <td>2</td>
      <td>...</td>
      <td>nvidia geforce rtx 3050</td>
      <td>72.60</td>
      <td>4</td>
      <td>2</td>
      <td>hp</td>
      <td>amd</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>https://www.flipkart.com/lenovo-ideapad-gaming-3i-ryzen-7-octa-core-r7-5800h-5th-gen-16-gb-512-gb-ssd-windows-11-home-4-graphics-nvidia-geforce-rtx-3050-15ach6-laptop/p/itmbc01bfc64700e?pid=COMGD8Z2J9JH7AAX&amp;lid=LSTCOMGD8Z2J9JH7AAXOJWV00&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_76&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGD8Z2J9JH7AAX.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>lenovo ideapad gaming 3i ryzen 7 octa core r7-5800h 5th gen - (16 gb/512 gb ssd/windows 11 home/4 gb graphics/nvidia geforce rtx 3050) 15ach6 gaming laptop  (15.6 inch, shadow black, 2.25 kg, with ms office)</td>
      <td>NaN</td>
      <td>87717</td>
      <td>gaming laptop</td>
      <td>4.0</td>
      <td>2</td>
      <td>...</td>
      <td>nvidia geforce rtx 3050</td>
      <td>72.60</td>
      <td>4</td>
      <td>2</td>
      <td>lenovo</td>
      <td>amd</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>https://www.flipkart.com/lenovo-yoga-slim-7-core-i5-11th-gen-16-gb-512-gb-ssd-windows-11-home-82a300mbin-thin-light-laptop/p/itm8d670bbb74a5b?pid=COMGD8RMGDEUBVSZ&amp;lid=LSTCOMGD8RMGDEUBVSZY8IBIK&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_77&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGD8RMGDEUBVSZ.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>lenovo yoga slim 7 core i5 11th gen - (16 gb/512 gb ssd/windows 11 home) 82a300mbin thin and light laptop  (14 inch, slate grey, with ms office)</td>
      <td>NaN</td>
      <td>75990</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>intel hd</td>
      <td>4.23</td>
      <td>4</td>
      <td>3</td>
      <td>lenovo</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>https://www.flipkart.com/lenovo-yoga-slim-7-core-i7-11th-gen-16-gb-512-gb-ssd-windows-11-home-14itl05-thin-light-laptop/p/itm4a202e05ce632?pid=COMGD8NWUVM8F5YG&amp;lid=LSTCOMGD8NWUVM8F5YGEYMIMD&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_78&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGD8NWUVM8F5YG.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>lenovo yoga slim 7 core i7 11th gen - (16 gb/512 gb ssd/windows 11 home) 14itl05 thin and light laptop  (14 inch, slate grey, 1.36 kg, with ms office)</td>
      <td>NaN</td>
      <td>78395</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>iris xe</td>
      <td>17.50</td>
      <td>4</td>
      <td>4</td>
      <td>lenovo</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>https://www.flipkart.com/lenovo-v15-celeron-dual-core-4-gb-256-gb-ssd-windows-10-82c30053ih-thin-light-laptop/p/itmbb8fd7d46586e?pid=COMGDF2CDX97JDPC&amp;lid=LSTCOMGDF2CDX97JDPCNUVMWS&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_4_79&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=ea708dc0-b248-4808-91aa-11961fc788e8.COMGDF2CDX97JDPC.SEARCH&amp;ssid=3s0bamxoztl6qzgg1653219740289</td>
      <td>lenovo lenovo v15 celeron dual core - (4 gb/256 gb ssd/windows 10) 82c30053ih thin and light laptop  (15.6 inch, iron grey)</td>
      <td>3.0</td>
      <td>29290</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>intel hd</td>
      <td>4.23</td>
      <td>4</td>
      <td>3</td>
      <td>lenovo</td>
      <td>intel</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>977</th>
      <td>https://www.flipkart.com/lenovo-yoga-core-i7-10th-gen-16-gb-1-tb-ssd-windows-10-home-s940-14iil-thin-light-laptop/p/itm1bfe27dc8132c?pid=COMFVW9TKWBN3ZB8&amp;lid=LSTCOMFVW9TKWBN3ZB8BJY4JS&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_978&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVW9TKWBN3ZB8.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>lenovo yoga core i7 10th gen - (16 gb/1 tb ssd/windows 10 home) yoga s940-14iil thin and light laptop  (14 inch, grey, black, 1.25 kg)</td>
      <td>2.5</td>
      <td>142990</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>intel iris plus</td>
      <td>10.60</td>
      <td>6</td>
      <td>22</td>
      <td>lenovo</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>978</th>
      <td>https://www.flipkart.com/lenovo-core-i7-10th-gen-16-gb-512-gb-ssd-windows-10-pro-thinkpad-x1-carbon-thin-light-laptop/p/itm3ec77a5aa6dca?pid=COMFVW9TT73PM9QH&amp;lid=LSTCOMFVW9TT73PM9QHOKKKH5&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_979&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVW9TT73PM9QH.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>lenovo core i7 10th gen - (16 gb/512 gb ssd/windows 10 pro) thinkpad x1 carbon thin and light laptop  (14 inch, black, 1.09 kg)</td>
      <td>NaN</td>
      <td>214760</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>intel uhd</td>
      <td>5.05</td>
      <td>2</td>
      <td>7</td>
      <td>lenovo</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>979</th>
      <td>https://www.flipkart.com/nokia-purebook-x14-core-i5-10th-gen-8-gb-512-gb-ssd-windows-10-home-nki510ul85s-thin-light-laptop/p/itmdc10c8866a3a4?pid=COMFUJ4NXDKZ4VFN&amp;lid=LSTCOMFUJ4NXDKZ4VFNROFWVT&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_980&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFUJ4NXDKZ4VFN.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>nokia purebook x14 core i5 10th gen - (8 gb/512 gb ssd/windows 10 home) nki510ul85s thin and light laptop  (14 inch, black, 1.1 kg)</td>
      <td>4.4</td>
      <td>53990</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>intel uhd</td>
      <td>5.05</td>
      <td>4</td>
      <td>7</td>
      <td>nokia</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>980</th>
      <td>https://www.flipkart.com/hp-spectre-folio-core-i7-10th-gen-16-gb-512-gb-ssd-windows-10-home-13-ak1004tu-2-1-laptop/p/itm2d34c3ce7c08b?pid=COMFVNK6TZQ9GRB6&amp;lid=LSTCOMFVNK6TZQ9GRB6YPJWRI&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_981&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVNK6TZQ9GRB6.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>hp spectre folio core i7 10th gen - (16 gb/512 gb ssd/windows 10 home) 13-ak1004tu 2 in 1 laptop  (13.3 inch, cognac brown, 1.49 kg, with ms office)</td>
      <td>NaN</td>
      <td>239759</td>
      <td>2 in 1 laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>nvidia geforce gtx</td>
      <td>70.90</td>
      <td>2</td>
      <td>23</td>
      <td>hp</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>981</th>
      <td>https://www.flipkart.com/hp-envy-x360-ryzen-5-hexa-core-4500u-8-gb-512-gb-ssd-windows-10-pro-13-ay0078au-2-1-laptop/p/itm0a53f83e64513?pid=COMFVNK6BBG5FMMH&amp;lid=LSTCOMFVNK6BBG5FMMHNZTNJZ&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_982&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVNK6BBG5FMMH.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>hp envy x360 ryzen 5 hexa core 4500u - (8 gb/512 gb ssd/windows 10 pro) 13-ay0078au 2 in 1 laptop  (13.3 inch, nightfall black, 1.32 kg, with ms office)</td>
      <td>NaN</td>
      <td>85555</td>
      <td>2 in 1 laptop</td>
      <td>0.0</td>
      <td>2</td>
      <td>...</td>
      <td>amd radeon</td>
      <td>102.00</td>
      <td>4</td>
      <td>5</td>
      <td>hp</td>
      <td>amd</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>982</th>
      <td>https://www.flipkart.com/hp-14a-celeron-dual-core-4-gb-64-gb-emmc-storage-chrome-os-14a-na0002tu-chromebook/p/itm04b4752804ffa?pid=COMFVNK6BRCJSH6R&amp;lid=LSTCOMFVNK6BRCJSH6RYCDEOQ&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_983&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVNK6BRCJSH6R.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>hp 14a celeron dual core - (4 gb/64 gb emmc storage/chrome os) 14a- na0002tu chromebook  (14 inch, ceramic white, 1.46 kg)</td>
      <td>3.6</td>
      <td>26990</td>
      <td>notebook</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>intel uhd 605</td>
      <td>2.13</td>
      <td>4</td>
      <td>24</td>
      <td>hp</td>
      <td>intel</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>983</th>
      <td>https://www.flipkart.com/lenovo-core-i3-10th-gen-4-gb-1-tb-hdd-windows-10-pro-v14-laptop/p/itmfe9416142ecb8?pid=COMFVSYVPYVEGZBH&amp;lid=LSTCOMFVSYVPYVEGZBHZP5VIF&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_984&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVSYVPYVEGZBH.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>lenovo core i3 10th gen - (4 gb/1 tb hdd/windows 10 pro) v14 laptop  (14 inch, black, 1.6 kg)</td>
      <td>3.1</td>
      <td>44590</td>
      <td>notebook</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>amd radeon r4</td>
      <td>3.50</td>
      <td>4</td>
      <td>40</td>
      <td>lenovo</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>984 rows × 29 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>index
0      NaN
1      NaN
2      8.0
3      8.0
4      NaN
      ... 
979    NaN
980    NaN
981    6.0
982    2.0
983    NaN
Name: name, Length: 984, dtype: float64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> laptop-ranked-dataset/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the mean prices and standard deviations of laptops equipped with an RTX3060 GPU and 16 GB ram?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>prices = df[df.gpu_name.str.contains('rtx 3060') & (df.RAM_in_GB == 16)].Price_in_Indian_Rupees
mean = prices.mean()
std = prices.std()
mean, std</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>['mean', 'std']</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>prices = df[df.gpu_name.str.contains('rtx 3060') & (df.RAM_in_GB == 16)].Price_in_Indian_Rupees
mean = prices.mean()
std = prices.std()
mean, std</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>prices = df[df.gpu_name.str.contains('rtx 3060') & (df.RAM_in_GB == 16)
    ].Price_in_Indian_Rupees
mean = prices.mean()
std = prices.std()
__output__ = mean, std
</code></pre>
        <p><span onclick="$('#var_output_65219f70').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_65219f70" style="display: none;">
          
        <p><strong>Ref output variables:</strong> mean, std </p>
    
          <p>mean (float64):</p>
          <pre><code>123818.57142857143</code></pre>
      
          <p>std (float):</p>
          <pre><code>25739.916031543777</code></pre>
      
        <p><strong>Hyp output variables:</strong> prices, mean, std, __output__ </p>
    
          <p>prices (Series):</p>
          <pre><code>index
34     106990
40     138990
42     127990
143    155490
153    133990
        ...  
831     88990
841     94990
857     87490
878     99990
885     94990
Name: Price_in_Indian_Rupees, Length: 35, dtype: int64</code></pre>
      
          <p>mean (float64):</p>
          <pre><code>123818.57142857143</code></pre>
      
          <p>std (float):</p>
          <pre><code>25739.916031543777</code></pre>
      
          <p>__output__ (tuple):</p>
          <pre><code>(123818.57142857143, 25739.916031543777)</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('mean', 'mean', None), ('std', 'std', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> laptop-ranked-dataset/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show a list of Acer's model names that are available.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def infer_product_model(x):
    processor_company = x.Processor_Brand_Name
    processor = x.Processor_name.replace(processor_company, '')
    if processor:
        x['model_name'] = x['name'].replace(x.Company_Name, '').split(processor)[0]
        processor_phrases = x.Processor_name.split(' ')[:2]
        for p in processor_phrases:
            x.model_name = x.model_name.split(p)[0]
        if x.model_name:
            return x
    x['model_name'] = None
    return x

df_comp = df.groupby('Company_Name')
df_acer = df_comp.get_group('acer')
df_acer.apply(infer_product_model, axis=1).model_name.dropna().unique()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def infer_product_model(x):
    processor_company = x.Processor_Brand_Name
    processor = x.Processor_name.replace(processor_company, '')
    if processor:
        x['model_name'] = x['name'].replace(x.Company_Name, '').split(processor)[0]
        processor_phrases = x.Processor_name.split(' ')[:2]
        for p in processor_phrases:
            x.model_name = x.model_name.split(p)[0]
        if x.model_name:
            return x
    x['model_name'] = None
    return x

df_comp = df.groupby('Company_Name')
df_acer = df_comp.get_group('acer')
df_acer.apply(infer_product_model, axis=1).model_name.dropna().unique()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def infer_product_model(x):
    processor_company = x.Processor_Brand_Name
    processor = x.Processor_name.replace(processor_company, '')
    if processor:
        x['model_name'] = x['name'].replace(x.Company_Name, '').split(processor
            )[0]
        processor_phrases = x.Processor_name.split(' ')[:2]
        for p in processor_phrases:
            x.model_name = x.model_name.split(p)[0]
        if x.model_name:
            return x
    x['model_name'] = None
    return x


df_comp = df.groupby('Company_Name')
df_acer = df_comp.get_group('acer')
__output__ = df_acer.apply(infer_product_model, axis=1).model_name.dropna(
    ).unique()
</code></pre>
        <p><span onclick="$('#var_output_a4fa1ac5').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a4fa1ac5" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>[' aspire 5' ' nitro 5' ' aspire 3' ' predator helios 300' ' extensa 15'
 ' swift x' ' ' ' aspire vero(green pc )' ' aspire' ' travelmate'
 ' swift 3' ' nitro' ' aspire 7' ' predator triton 300' ' swift 5']</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_acer, __output__ </p>
    
          <p>df_acer (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>link</th>
      <th>name</th>
      <th>user_rating</th>
      <th>Price_in_Indian_Rupees</th>
      <th>Type</th>
      <th>Dedicated_Graphic_Memory_Capacity</th>
      <th>Processor_Brand</th>
      <th>...</th>
      <th>gpu_name</th>
      <th>gpu_benchmark</th>
      <th>ram_type_tokenized</th>
      <th>gpu_processor_tokenized</th>
      <th>Company_Name</th>
      <th>Processor_Brand_Name</th>
      <th>processor_cores</th>
    </tr>
    <tr>
      <th>index</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>48</th>
      <td>https://www.flipkart.com/acer-aspire-5-core-i5-11th-gen-8-gb-512-gb-ssd-windows-11-home-a515-56-thin-light-laptop/p/itm12dd44dc68337?pid=COMGCRQZPZ28VKGZ&amp;lid=LSTCOMGCRQZPZ28VKGZLPMFCK&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_3_49&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=3bb02c6c-b455-418b-a470-8350fc177df4.COMGCRQZPZ28VKGZ.SEARCH&amp;ssid=4zuv1hdz4pvb55341653220010478</td>
      <td>acer aspire 5 core i5 11th gen - (8 gb/512 gb ssd/windows 11 home) a515-56 thin and light laptop  (15.6 inch, pure silver, 1.65 kg, with ms office)</td>
      <td>4.3</td>
      <td>49990</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>intel iris xe</td>
      <td>17.50</td>
      <td>4</td>
      <td>8</td>
      <td>acer</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>56</th>
      <td>https://www.flipkart.com/acer-celeron-dual-core-4-gb-256-gb-ssd-windows-11-home-tmb311-31-notebook/p/itmbefaffe20d994?pid=COMGDQHGUHNRQFVV&amp;lid=LSTCOMGDQHGUHNRQFVVGTUGNR&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_3_57&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=3bb02c6c-b455-418b-a470-8350fc177df4.COMGDQHGUHNRQFVV.SEARCH&amp;ssid=4zuv1hdz4pvb55341653220010478</td>
      <td>acer celeron dual core - (4 gb/256 gb ssd/windows 11 home) tmb311-31 notebook  (11.6 inch, black, 1.4 kg)</td>
      <td>NaN</td>
      <td>24990</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>intel uhd 600</td>
      <td>1.53</td>
      <td>4</td>
      <td>14</td>
      <td>acer</td>
      <td>intel</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>57</th>
      <td>https://www.flipkart.com/acer-celeron-dual-core-4-gb-128-gb-ssd-windows-11-home-tmb311-31-notebook/p/itm6aa758693b829?pid=COMGDQHGXZTMFCXH&amp;lid=LSTCOMGDQHGXZTMFCXHO6DZWK&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_3_58&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=3bb02c6c-b455-418b-a470-8350fc177df4.COMGDQHGXZTMFCXH.SEARCH&amp;ssid=4zuv1hdz4pvb55341653220010478</td>
      <td>acer celeron dual core - (4 gb/128 gb ssd/windows 11 home) tmb311-31 notebook  (11.6 inch, black, 1.4 kg)</td>
      <td>NaN</td>
      <td>23990</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>intel uhd 600</td>
      <td>1.53</td>
      <td>4</td>
      <td>14</td>
      <td>acer</td>
      <td>intel</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>58</th>
      <td>https://www.flipkart.com/acer-nitro-5-core-i5-11th-gen-8-gb-512-gb-ssd-windows-11-home-4-graphics-nvidia-geforce-gtx-1650-an515-57-gaming-laptop/p/itmad93d3d647683?pid=COMGD37VAQKJRQTQ&amp;lid=LSTCOMGD37VAQKJRQTQGEWALO&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_3_59&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=3bb02c6c-b455-418b-a470-8350fc177df4.COMGD37VAQKJRQTQ.SEARCH&amp;ssid=4zuv1hdz4pvb55341653220010478</td>
      <td>acer nitro 5 core i5 11th gen - (8 gb/512 gb ssd/windows 11 home/4 gb graphics/nvidia geforce gtx 1650) an515-57 gaming laptop  (15.6 inch, shale black, 2.2 kg)</td>
      <td>NaN</td>
      <td>64990</td>
      <td>gaming laptop</td>
      <td>4.0</td>
      <td>1</td>
      <td>...</td>
      <td>nvidia geforce gtx 1650</td>
      <td>59.90</td>
      <td>4</td>
      <td>6</td>
      <td>acer</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>60</th>
      <td>https://www.flipkart.com/acer-aspire-3-core-i5-11th-gen-8-gb-512-gb-ssd-windows-11-home-a315-58-thin-light-laptop/p/itm8d95bd7a30486?pid=COMGCRQZ9EXVDBHY&amp;lid=LSTCOMGCRQZ9EXVDBHYO5T0LN&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_3_61&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=3bb02c6c-b455-418b-a470-8350fc177df4.COMGCRQZ9EXVDBHY.SEARCH&amp;ssid=4zuv1hdz4pvb55341653220010478</td>
      <td>acer aspire 3 core i5 11th gen - (8 gb/512 gb ssd/windows 11 home) a315-58 thin and light laptop  (15.6 inch, pure silver, 1.7 kg, with ms office)</td>
      <td>NaN</td>
      <td>49890</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>intel iris xe</td>
      <td>17.50</td>
      <td>4</td>
      <td>8</td>
      <td>acer</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>61</th>
      <td>https://www.flipkart.com/acer-nitro-5-core-i7-12th-gen-16-gb-1-tb-hdd-512-gb-ssd-windows-11-home-4-graphics-nvidia-geforce-rtx-3050-ti-an515-58-gaming-laptop/p/itmbf08089d88cc1?pid=COMGD37VGBNYYGGK&amp;lid=LSTCOMGD37VGBNYYGGKPT5E0I&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_3_62&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=3bb02c6c-b455-418b-a470-8350fc177df4.COMGD37VGBNYYGGK.SEARCH&amp;ssid=4zuv1hdz4pvb55341653220010478</td>
      <td>acer nitro 5 core i7 12th gen - (16 gb/1 tb hdd/512 gb ssd/windows 11 home/4 gb graphics/nvidia geforce rtx 3050 ti) an515-58 gaming laptop  (15.6 inch, shale black, 2.6 kg)</td>
      <td>NaN</td>
      <td>109990</td>
      <td>gaming laptop</td>
      <td>4.0</td>
      <td>1</td>
      <td>...</td>
      <td>nvidia geforce rtx 3050 ti</td>
      <td>59.00</td>
      <td>4</td>
      <td>10</td>
      <td>acer</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>162</th>
      <td>https://www.flipkart.com/acer-predator-helios-300-core-i9-11th-gen-16-gb-1-tb-ssd-windows-11-home-6-gb-graphics-nvidia-geforce-rtx-3060-360-hz-ph315-54-gaming-laptop/p/itmd71aac320ff3e?pid=COMGBWPJRJSF43UR&amp;lid=LSTCOMGBWPJRJSF43URMEP1FG&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_7_163&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=21fe1715-1274-454f-b672-703b04ce5a95.COMGBWPJRJSF43UR.SEARCH&amp;ssid=k3w59zhoio2x9s741653220445133</td>
      <td>acer predator helios 300 core i9 11th gen - (16 gb/1 tb ssd/windows 11 home/6 gb graphics/nvidia geforce rtx 3060/360 hz) ph315-54 gaming laptop  (15.6 inch, abyssal black, 2.3 kg)</td>
      <td>NaN</td>
      <td>144990</td>
      <td>gaming laptop</td>
      <td>6.0</td>
      <td>1</td>
      <td>...</td>
      <td>nvidia geforce rtx 3060</td>
      <td>132.00</td>
      <td>4</td>
      <td>12</td>
      <td>acer</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>907</th>
      <td>https://www.flipkart.com/acer-aspire-7-ryzen-5-hexa-core-5500u-8-gb-512-gb-ssd-windows-10-home-4-graphics-nvidia-geforce-gtx-1650-a715-42g-gaming-laptop/p/itm4385fddc2c72c?pid=COMGYCG8ZBXWPYUU&amp;lid=LSTCOMGYCG8ZBXWPYUUSTSMVQ&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_38_908&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=2d88e63c-8087-48eb-91a6-4124e36a52f2.COMGYCG8ZBXWPYUU.SEARCH&amp;ssid=uk6v12vl7ri8b8jk1653223815210</td>
      <td>acer aspire 7 ryzen 5 hexa core 5500u - (8 gb/512 gb ssd/windows 10 home/4 gb graphics/nvidia geforce gtx 1650) a715-42g gaming laptop  (15.6 inch, black, 2.15 kg)</td>
      <td>4.5</td>
      <td>54990</td>
      <td>gaming laptop</td>
      <td>4.0</td>
      <td>2</td>
      <td>...</td>
      <td>nvidia geforce gtx 1650</td>
      <td>59.90</td>
      <td>4</td>
      <td>6</td>
      <td>acer</td>
      <td>amd</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>941</th>
      <td>https://www.flipkart.com/acer-predator-triton-300-core-i7-10th-gen-16-gb-2-tb-ssd-windows-10-home-8-gb-graphics-nvidia-geforce-rtx-2070-max-q-design-pt315-52-gaming-laptop/p/itm868679c081b00?pid=COMFXV7SZ6DK2M8Q&amp;lid=LSTCOMFXV7SZ6DK2M8QV44RJI&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_40_942&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=e330306f-bd3b-4423-b8b1-96d40037c046.COMFXV7SZ6DK2M8Q.SEARCH&amp;ssid=svp9tvsb8i8iohds1653224074789</td>
      <td>acer predator triton 300 core i7 10th gen - (16 gb/2 tb ssd/windows 10 home/8 gb graphics/nvidia geforce rtx 2070 with max-q design) pt315-52 gaming laptop  (15.6 inch, black, 2.1 kg)</td>
      <td>3.8</td>
      <td>159990</td>
      <td>gaming laptop</td>
      <td>8.0</td>
      <td>1</td>
      <td>...</td>
      <td>nvidia geforce rtx 2070 max-q</td>
      <td>78.40</td>
      <td>4</td>
      <td>56</td>
      <td>acer</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>944</th>
      <td>https://www.flipkart.com/acer-aspire-3-core-i5-10th-gen-8-gb-1-tb-hdd-windows-10-home-2-gb-graphics-a315-57g-laptop/p/itmb6a7ac69d473a?pid=COMFYFXF7SNDRHGH&amp;lid=LSTCOMFYFXF7SNDRHGH5OSTE4&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_40_945&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=e330306f-bd3b-4423-b8b1-96d40037c046.COMFYFXF7SNDRHGH.SEARCH&amp;ssid=svp9tvsb8i8iohds1653224074789</td>
      <td>acer aspire 3 core i5 10th gen - (8 gb/1 tb hdd/windows 10 home/2 gb graphics) a315-57g laptop  (15.6 inch, charcoal black, 1.9 kg)</td>
      <td>3.2</td>
      <td>45990</td>
      <td>notebook</td>
      <td>2.0</td>
      <td>1</td>
      <td>...</td>
      <td>nvidia geforce gtx mx 330</td>
      <td>16.50</td>
      <td>4</td>
      <td>57</td>
      <td>acer</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>959</th>
      <td>https://www.flipkart.com/acer-aspire-7-ryzen-5-quad-core-3550h-8-gb-512-gb-ssd-windows-10-home-4-graphics-nvidia-geforce-gtx-1650-ti-a715-41g-r7yz-gaming-laptop/p/itmd0a81b14dbe3f?pid=COMFVW9TGFYZZGFQ&amp;lid=LSTCOMFVW9TGFYZZGFQWAXP94&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_40_960&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=e330306f-bd3b-4423-b8b1-96d40037c046.COMFVW9TGFYZZGFQ.SEARCH&amp;ssid=svp9tvsb8i8iohds1653224074789</td>
      <td>acer aspire 7 ryzen 5 quad core 3550h - (8 gb/512 gb ssd/windows 10 home/4 gb graphics/nvidia geforce gtx 1650 ti) a715-41g-r7yz gaming laptop  (15.6 inch, charcoal black, 2.15 kg)</td>
      <td>4.5</td>
      <td>51990</td>
      <td>gaming laptop</td>
      <td>4.0</td>
      <td>2</td>
      <td>...</td>
      <td>nvidia geforce gtx 1650 ti</td>
      <td>41.80</td>
      <td>4</td>
      <td>31</td>
      <td>acer</td>
      <td>amd</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>960</th>
      <td>https://www.flipkart.com/acer-aspire-7-ryzen-5-quad-core-3550h-8-gb-512-gb-ssd-windows-10-home-4-graphics-nvidia-geforce-gtx-1650-ti-a715-41g-r7yz-gaming-laptop/p/itmd0a81b14dbe3f?pid=COMFVW9TGFYZZGFQ&amp;lid=LSTCOMFVW9TGFYZZGFQWAXP94&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_961&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFVW9TGFYZZGFQ.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>acer aspire 7 ryzen 5 quad core 3550h - (8 gb/512 gb ssd/windows 10 home/4 gb graphics/nvidia geforce gtx 1650 ti) a715-41g-r7yz gaming laptop  (15.6 inch, charcoal black, 2.15 kg)</td>
      <td>4.5</td>
      <td>51990</td>
      <td>gaming laptop</td>
      <td>4.0</td>
      <td>2</td>
      <td>...</td>
      <td>nvidia geforce gtx 1650 ti</td>
      <td>41.80</td>
      <td>4</td>
      <td>31</td>
      <td>acer</td>
      <td>amd</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>961</th>
      <td>https://www.flipkart.com/acer-swift-5-core-i7-11th-gen-intel-evo-16-gb-1-tb-ssd-windows-10-home-sf514-55ta-72vg-thin-light-laptop/p/itma3571f30f2d68?pid=COMFWXXFBYZV73VS&amp;lid=LSTCOMFWXXFBYZV73VS7EP09A&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_962&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFWXXFBYZV73VS.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>acer swift 5 core i7 11th gen intel evo - (16 gb/1 tb ssd/windows 10 home) sf514-55ta-72vg thin and light laptop  (14 inch, mist green, 1.05 kg)</td>
      <td>4.3</td>
      <td>93190</td>
      <td>thin and light laptop</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>intel iris xe</td>
      <td>17.50</td>
      <td>6</td>
      <td>8</td>
      <td>acer</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>965</th>
      <td>https://www.flipkart.com/acer-predator-helios-300-core-i7-10th-gen-16-gb-2-tb-ssd-windows-10-home-8-gb-graphics-nvidia-geforce-rtx-2070-max-q-design-240-hz-ph315-53-7739-gaming-laptop/p/itm857ef6bc9c942?pid=COMFWREFSMVE7FJG&amp;lid=LSTCOMFWREFSMVE7FJGS1VLEH&amp;marketplace=FLIPKART&amp;store=6bo%2Fb5g&amp;srno=b_41_966&amp;otracker=browse&amp;otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_8_L1_view-all&amp;iid=745caa42-78fd-4014-b4d6-ac842283d01f.COMFWREFSMVE7FJG.SEARCH&amp;ssid=evrirpvyugjmaiv41653224220411</td>
      <td>acer predator helios 300 core i7 10th gen - (16 gb/2 tb ssd/windows 10 home/8 gb graphics/nvidia geforce rtx 2070 with max-q design/240 hz) ph315-53-7739 gaming laptop  (15.6 inch, abyssal black, 2.5 kg)</td>
      <td>4.8</td>
      <td>150490</td>
      <td>gaming laptop</td>
      <td>8.0</td>
      <td>1</td>
      <td>...</td>
      <td>nvidia geforce rtx 2070 max-q</td>
      <td>78.40</td>
      <td>4</td>
      <td>56</td>
      <td>acer</td>
      <td>intel</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>60 rows × 29 columns</p>
      
          <p>__output__ (ndarray):</p>
          <pre><code>[' aspire 5' ' nitro 5' ' aspire 3' ' predator helios 300' ' extensa 15'
 ' swift x' ' ' ' aspire vero(green pc )' ' aspire' ' travelmate'
 ' swift 3' ' nitro' ' aspire 7' ' predator triton 300' ' swift 5']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> laptop-ranked-dataset/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What are the product lines offered by Asus? Return a list of names disregarding version and year.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def disregard_version(x):
    if not x:
        return None
    x = x.strip().split(' ')
    t = []
    for i in x:
        if not i.isalpha():
            break
        t.append(i)
    if not t:
        return None
    return ' '.join(t)

df_comp.get_group('asus').apply(infer_product_model, axis=1).model_name.apply(disregard_version).dropna().unique()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def disregard_version(x):
    if not x:
        return None
    x = x.strip().split(' ')
    t = []
    for i in x:
        if not i.isalpha():
            break
        t.append(i)
    if not t:
        return None
    return ' '.join(t)

df_comp.get_group('asus').apply(infer_product_model, axis=1).model_name.apply(disregard_version).dropna().unique()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def disregard_version(x):
    if not x:
        return None
    x = x.strip().split(' ')
    t = []
    for i in x:
        if not i.isalpha():
            break
        t.append(i)
    if not t:
        return None
    return ' '.join(t)


__output__ = df_comp.get_group('asus').apply(infer_product_model, axis=1
    ).model_name.apply(disregard_version).dropna().unique()
</code></pre>
        <p><span onclick="$('#var_output_4ca45dcc').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4ca45dcc" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>['rog strix scar' 'tuf gaming' 'rog flow' 'vivobook' 'zenbook'
 'vivobook ultra' 'vivobook flip' 'expertbook' 'commercial series'
 'rog strix' 'eeebook' 'zenbook duo' 'vivobook pro' 'vivo book'
 'chromebook' 'tuf dash' 'rog zephyrus' 'zephyrus' 'strix'
 'vivobook gaming' 'chromebook flip' 'tuf dash series' 'zenbook flip']</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (ndarray):</p>
          <pre><code>['rog strix scar' 'tuf gaming' 'rog flow' 'vivobook' 'zenbook'
 'vivobook ultra' 'vivobook flip' 'expertbook' 'commercial series'
 'rog strix' 'eeebook' 'zenbook duo' 'vivobook pro' 'vivo book'
 'chromebook' 'tuf dash' 'rog zephyrus' 'zephyrus' 'strix'
 'vivobook gaming' 'chromebook flip' 'tuf dash series' 'zenbook flip']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> laptop-ranked-dataset/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many gaming product lines does each company offer? Sort in descending order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_g = df[df.Type.str.contains('gaming')].apply(infer_product_model, axis=1)[['Company_Name', 'model_name']]
df_g['product_line'] = df_g.model_name.apply(disregard_version)
df_g.dropna()[['Company_Name', 'product_line']].groupby('Company_Name').count().sort_values('product_line',
                                                                                            ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_g = df[df.Type.str.contains('gaming')].apply(infer_product_model, axis=1)[['Company_Name', 'model_name']]
df_g['product_line'] = df_g.model_name.apply(disregard_version)
df_g.dropna()[['Company_Name', 'product_line']].groupby('Company_Name').count().sort_values('product_line',
                                                                                            ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_g = df[df.Type.str.contains('gaming')].apply(infer_product_model, axis=1)[[
    'Company_Name', 'model_name']]
df_g['product_line'] = df_g.model_name.apply(disregard_version)
__output__ = df_g.dropna()[['Company_Name', 'product_line']].groupby(
    'Company_Name').count().sort_values('product_line', ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_0cf58eba').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0cf58eba" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product_line</th>
    </tr>
    <tr>
      <th>Company_Name</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>asus</th>
      <td>81</td>
    </tr>
    <tr>
      <th>lenovo</th>
      <td>28</td>
    </tr>
    <tr>
      <th>hp</th>
      <td>24</td>
    </tr>
    <tr>
      <th>acer</th>
      <td>21</td>
    </tr>
    <tr>
      <th>msi</th>
      <td>15</td>
    </tr>
    <tr>
      <th>dell</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_g, __output__ </p>
    
          <p>df_g (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Company_Name</th>
      <th>model_name</th>
      <th>product_line</th>
    </tr>
    <tr>
      <th>index</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>asus</td>
      <td>rog strix scar 17</td>
      <td>rog strix scar</td>
    </tr>
    <tr>
      <th>1</th>
      <td>asus</td>
      <td>rog strix scar 15</td>
      <td>rog strix scar</td>
    </tr>
    <tr>
      <th>2</th>
      <td>hp</td>
      <td>victus</td>
      <td>victus</td>
    </tr>
    <tr>
      <th>3</th>
      <td>lenovo</td>
      <td>ideapad gaming 3i</td>
      <td>ideapad gaming</td>
    </tr>
    <tr>
      <th>8</th>
      <td>asus</td>
      <td>tuf gaming f15</td>
      <td>tuf gaming</td>
    </tr>
    <tr>
      <th>13</th>
      <td>asus</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>15</th>
      <td>asus</td>
      <td>rog flow x13 (2021)</td>
      <td>rog flow</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>936</th>
      <td>lenovo</td>
      <td>ideapad gaming 3</td>
      <td>ideapad gaming</td>
    </tr>
    <tr>
      <th>941</th>
      <td>acer</td>
      <td>predator triton 300</td>
      <td>predator triton</td>
    </tr>
    <tr>
      <th>942</th>
      <td>lenovo</td>
      <td>ideapad gaming 3</td>
      <td>ideapad gaming</td>
    </tr>
    <tr>
      <th>959</th>
      <td>acer</td>
      <td>aspire 7</td>
      <td>aspire</td>
    </tr>
    <tr>
      <th>960</th>
      <td>acer</td>
      <td>aspire 7</td>
      <td>aspire</td>
    </tr>
    <tr>
      <th>965</th>
      <td>acer</td>
      <td>predator helios 300</td>
      <td>predator helios</td>
    </tr>
    <tr>
      <th>966</th>
      <td>lenovo</td>
      <td>None</td>
      <td>None</td>
    </tr>
  </tbody>
</table>
<p>232 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product_line</th>
    </tr>
    <tr>
      <th>Company_Name</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>asus</th>
      <td>81</td>
    </tr>
    <tr>
      <th>lenovo</th>
      <td>28</td>
    </tr>
    <tr>
      <th>hp</th>
      <td>24</td>
    </tr>
    <tr>
      <th>acer</th>
      <td>21</td>
    </tr>
    <tr>
      <th>msi</th>
      <td>15</td>
    </tr>
    <tr>
      <th>dell</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> laptop-ranked-dataset/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Count the number of laptops powered by Intel's core i series processors for each generation.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def get_generation(x):
    gen = re.findall('\d+(?=th)', x.Processor_name)[0]
    gen = f'{gen}th'
    x['generation'] = gen
    return x

df[df.Processor_name.str.contains('core i')][['Processor_name']].apply(get_generation, 1).groupby('generation').count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def get_generation(x):
    gen = re.findall('\d+(?=th)', x.Processor_name)[0]
    gen = f'{gen}th'
    x['generation'] = gen
    return x

df[df.Processor_name.str.contains('core i')][['Processor_name']].apply(get_generation, 1).groupby('generation').count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def get_generation(x):
    gen = re.findall('\\d+(?=th)', x.Processor_name)[0]
    gen = f'{gen}th'
    x['generation'] = gen
    return x


__output__ = df[df.Processor_name.str.contains('core i')][['Processor_name']
    ].apply(get_generation, 1).groupby('generation').count()
</code></pre>
        <p><span onclick="$('#var_output_2e9f74be').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_2e9f74be" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Processor_name</th>
    </tr>
    <tr>
      <th>generation</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10th</th>
      <td>164</td>
    </tr>
    <tr>
      <th>11th</th>
      <td>444</td>
    </tr>
    <tr>
      <th>12th</th>
      <td>27</td>
    </tr>
    <tr>
      <th>7th</th>
      <td>2</td>
    </tr>
    <tr>
      <th>8th</th>
      <td>6</td>
    </tr>
    <tr>
      <th>9th</th>
      <td>5</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Processor_name</th>
    </tr>
    <tr>
      <th>generation</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10th</th>
      <td>164</td>
    </tr>
    <tr>
      <th>11th</th>
      <td>444</td>
    </tr>
    <tr>
      <th>12th</th>
      <td>27</td>
    </tr>
    <tr>
      <th>7th</th>
      <td>2</td>
    </tr>
    <tr>
      <th>8th</th>
      <td>6</td>
    </tr>
    <tr>
      <th>9th</th>
      <td>5</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> laptop-ranked-dataset/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show the percent change in price per inch increment of laptop screen size rounded up to the nearest inch.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_screen = df[['Screen_Size_in_inch', 'Price_in_Indian_Rupees']]
df_screen['Screen_Size_in_inch'] = df.Screen_Size_in_inch.round()
(df_screen.groupby('Screen_Size_in_inch').mean().pct_change() * 100)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_screen = df[['Screen_Size_in_inch', 'Price_in_Indian_Rupees']]
df_screen['Screen_Size_in_inch'] = df.Screen_Size_in_inch.round()
(df_screen.groupby('Screen_Size_in_inch').mean().pct_change() * 100)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_screen = df[['Screen_Size_in_inch', 'Price_in_Indian_Rupees']]
df_screen['Screen_Size_in_inch'] = df.Screen_Size_in_inch.round()
__output__ = df_screen.groupby('Screen_Size_in_inch').mean().pct_change() * 100
</code></pre>
        <p><span onclick="$('#var_output_fbcff459').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_fbcff459" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Price_in_Indian_Rupees</th>
    </tr>
    <tr>
      <th>Screen_Size_in_inch</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12.0</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>13.0</th>
      <td>215.733181</td>
    </tr>
    <tr>
      <th>14.0</th>
      <td>-36.220189</td>
    </tr>
    <tr>
      <th>15.0</th>
      <td>-27.304960</td>
    </tr>
    <tr>
      <th>16.0</th>
      <td>50.307942</td>
    </tr>
    <tr>
      <th>17.0</th>
      <td>48.575688</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_screen, __output__ </p>
    
          <p>df_screen (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Screen_Size_in_inch</th>
      <th>Price_in_Indian_Rupees</th>
    </tr>
    <tr>
      <th>index</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17.0</td>
      <td>234990</td>
    </tr>
    <tr>
      <th>1</th>
      <td>16.0</td>
      <td>229990</td>
    </tr>
    <tr>
      <th>2</th>
      <td>16.0</td>
      <td>104091</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16.0</td>
      <td>87717</td>
    </tr>
    <tr>
      <th>4</th>
      <td>14.0</td>
      <td>75990</td>
    </tr>
    <tr>
      <th>5</th>
      <td>14.0</td>
      <td>78395</td>
    </tr>
    <tr>
      <th>6</th>
      <td>16.0</td>
      <td>29290</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>977</th>
      <td>14.0</td>
      <td>142990</td>
    </tr>
    <tr>
      <th>978</th>
      <td>14.0</td>
      <td>214760</td>
    </tr>
    <tr>
      <th>979</th>
      <td>14.0</td>
      <td>53990</td>
    </tr>
    <tr>
      <th>980</th>
      <td>13.0</td>
      <td>239759</td>
    </tr>
    <tr>
      <th>981</th>
      <td>13.0</td>
      <td>85555</td>
    </tr>
    <tr>
      <th>982</th>
      <td>14.0</td>
      <td>26990</td>
    </tr>
    <tr>
      <th>983</th>
      <td>14.0</td>
      <td>44590</td>
    </tr>
  </tbody>
</table>
<p>984 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Price_in_Indian_Rupees</th>
    </tr>
    <tr>
      <th>Screen_Size_in_inch</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12.0</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>13.0</th>
      <td>215.733181</td>
    </tr>
    <tr>
      <th>14.0</th>
      <td>-36.220189</td>
    </tr>
    <tr>
      <th>15.0</th>
      <td>-27.304960</td>
    </tr>
    <tr>
      <th>16.0</th>
      <td>50.307942</td>
    </tr>
    <tr>
      <th>17.0</th>
      <td>48.575688</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which user has purchased the widest variety of items?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>highest_user = df[['User Name', 'item_id']].groupby('User Name').nunique().sort_values('item_id', ascending=False)\
    .idxmax().values[0]
highest_user</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>highest_user = df[['User Name', 'item_id']].groupby('User Name').nunique().sort_values('item_id', ascending=False)\
    .idxmax().values[0]
highest_user</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>highest_user = df[['User Name', 'item_id']].groupby('User Name').nunique(
    ).sort_values('item_id', ascending=False).idxmax().values[0]
__output__ = highest_user
</code></pre>
        <p><span onclick="$('#var_output_d52826c6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d52826c6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>jugonzalez</code></pre>
      
        <p><strong>Hyp output variables:</strong> highest_user, __output__ </p>
    
          <p>highest_user (str):</p>
          <pre><code>jugonzalez</code></pre>
      
          <p>__output__ (str):</p>
          <pre><code>jugonzalez</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How long had that user been a customer when he made his latest purchase?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_t = df[df['User Name'] == highest_user][['Customer Since', 'order_date']]
(df_t.order_date.max() - df_t['Customer Since'].iloc[0]).days</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_t = df[df['User Name'] == highest_user][['Customer Since', 'order_date']]
(df_t.order_date.max() - df_t['Customer Since'].iloc[0]).days</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_t = df[df['User Name'] == highest_user][['Customer Since', 'order_date']]
__output__ = (df_t.order_date.max() - df_t['Customer Since'].iloc[0]).days
</code></pre>
        <p><span onclick="$('#var_output_ba3358c1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ba3358c1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>5782</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_t, __output__ </p>
    
          <p>df_t (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Customer Since</th>
      <th>order_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>30710</th>
      <td>2005-11-30</td>
      <td>2021-02-24</td>
    </tr>
    <tr>
      <th>30711</th>
      <td>2005-11-30</td>
      <td>2021-02-26</td>
    </tr>
    <tr>
      <th>30712</th>
      <td>2005-11-30</td>
      <td>2021-02-26</td>
    </tr>
    <tr>
      <th>30713</th>
      <td>2005-11-30</td>
      <td>2021-02-27</td>
    </tr>
    <tr>
      <th>30714</th>
      <td>2005-11-30</td>
      <td>2021-02-27</td>
    </tr>
    <tr>
      <th>30715</th>
      <td>2005-11-30</td>
      <td>2021-02-28</td>
    </tr>
    <tr>
      <th>30716</th>
      <td>2005-11-30</td>
      <td>2021-03-03</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>31189</th>
      <td>2005-11-30</td>
      <td>2021-09-15</td>
    </tr>
    <tr>
      <th>31190</th>
      <td>2005-11-30</td>
      <td>2021-09-17</td>
    </tr>
    <tr>
      <th>31191</th>
      <td>2005-11-30</td>
      <td>2021-09-18</td>
    </tr>
    <tr>
      <th>31192</th>
      <td>2005-11-30</td>
      <td>2021-09-18</td>
    </tr>
    <tr>
      <th>31193</th>
      <td>2005-11-30</td>
      <td>2021-09-27</td>
    </tr>
    <tr>
      <th>31194</th>
      <td>2005-11-30</td>
      <td>2021-09-29</td>
    </tr>
    <tr>
      <th>31195</th>
      <td>2005-11-30</td>
      <td>2021-09-29</td>
    </tr>
  </tbody>
</table>
<p>486 rows × 2 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>5782</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Count the number of refunds for discounted orders by category.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df.status == 'order_refunded') & (df.discount_amount > 0)]['category'].value_counts()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df.status == 'order_refunded') & (df.discount_amount > 0)]['category'].value_counts()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df.status == 'order_refunded') & (df.discount_amount > 0)][
    'category'].value_counts()
</code></pre>
        <p><span onclick="$('#var_output_703a2dc2').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_703a2dc2" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Mobiles & Tablets     125
Appliances            101
Men's Fashion          71
Women's Fashion        59
Entertainment          55
Beauty & Grooming      26
Computing              22
Home & Living          21
Kids & Baby            13
Superstore              9
Health & Sports         5
Soghaat                 5
Others                  3
Books                   3
School & Education      1
Name: category, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>Mobiles & Tablets     125
Appliances            101
Men's Fashion          71
Women's Fashion        59
Entertainment          55
Beauty & Grooming      26
Computing              22
Home & Living          21
Kids & Baby            13
Superstore              9
Health & Sports         5
Soghaat                 5
Others                  3
Books                   3
School & Education      1
Name: category, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Group unique users according to age quartiles and calculate the male composition in each quartile.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_users = df.groupby('User Name').first()
df_gender_age = df_users.loc[:,['Gender', 'age']]
df_gender_age['age'] = pd.cut(df_gender_age.age, 4)
df_gender_age['Gender'] = df_gender_age.Gender == 'M'
100*df_gender_age.groupby(['age']).sum()/df_gender_age.groupby(['age']).count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_users = df.groupby('User Name').first()
df_gender_age = df_users.loc[:,['Gender', 'age']]
df_gender_age['age'] = pd.cut(df_gender_age.age, 4)
df_gender_age['Gender'] = df_gender_age.Gender == 'M'
100*df_gender_age.groupby(['age']).sum()/df_gender_age.groupby(['age']).count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_users = df.groupby('User Name').first()
df_gender_age = df_users.loc[:, ['Gender', 'age']]
df_gender_age['age'] = pd.cut(df_gender_age.age, 4)
df_gender_age['Gender'] = df_gender_age.Gender == 'M'
__output__ = 100 * df_gender_age.groupby(['age']).sum(
    ) / df_gender_age.groupby(['age']).count()
</code></pre>
        <p><span onclick="$('#var_output_62fc1ed4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_62fc1ed4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
    </tr>
    <tr>
      <th>age</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(17.943, 32.25]</th>
      <td>49.433558</td>
    </tr>
    <tr>
      <th>(32.25, 46.5]</th>
      <td>50.349878</td>
    </tr>
    <tr>
      <th>(46.5, 60.75]</th>
      <td>50.163345</td>
    </tr>
    <tr>
      <th>(60.75, 75.0]</th>
      <td>50.690545</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_users, df_gender_age, __output__ </p>
    
          <p>df_users (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_id</th>
      <th>order_date</th>
      <th>status</th>
      <th>item_id</th>
      <th>sku</th>
      <th>qty_ordered</th>
      <th>price</th>
      <th>...</th>
      <th>Place Name</th>
      <th>County</th>
      <th>City</th>
      <th>State</th>
      <th>Zip</th>
      <th>Region</th>
      <th>Discount_Percent</th>
    </tr>
    <tr>
      <th>User Name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>aaagin</th>
      <td>100420072</td>
      <td>2020-12-27</td>
      <td>order_refunded</td>
      <td>685314.0</td>
      <td>MATINF59C9002EA6AF0</td>
      <td>2.0</td>
      <td>1278.9</td>
      <td>...</td>
      <td>Hogeland</td>
      <td>Blaine</td>
      <td>Hogeland</td>
      <td>MT</td>
      <td>59529</td>
      <td>West</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>aaashlock</th>
      <td>100415251</td>
      <td>2020-12-27</td>
      <td>canceled</td>
      <td>677051.0</td>
      <td>MATSAM59DB757FB47A2</td>
      <td>2.0</td>
      <td>6979.2</td>
      <td>...</td>
      <td>Calvary</td>
      <td>Grady</td>
      <td>Calvary</td>
      <td>GA</td>
      <td>31729</td>
      <td>South</td>
      <td>12.179046</td>
    </tr>
    <tr>
      <th>aaaucoin</th>
      <td>100363065</td>
      <td>2020-11-07</td>
      <td>order_refunded</td>
      <td>588684.0</td>
      <td>HASTHE59AC416806427</td>
      <td>2.0</td>
      <td>150.0</td>
      <td>...</td>
      <td>Sycamore</td>
      <td>Wyandot</td>
      <td>Sycamore</td>
      <td>OH</td>
      <td>44882</td>
      <td>Midwest</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>aabass</th>
      <td>100472142</td>
      <td>2021-04-07</td>
      <td>complete</td>
      <td>773256.0</td>
      <td>ENTORI5A8D3C794E5AC</td>
      <td>2.0</td>
      <td>2020.8</td>
      <td>...</td>
      <td>Huron</td>
      <td>Fresno</td>
      <td>Huron</td>
      <td>CA</td>
      <td>93234</td>
      <td>West</td>
      <td>10.886778</td>
    </tr>
    <tr>
      <th>aabergen</th>
      <td>100411929</td>
      <td>2020-12-26</td>
      <td>complete</td>
      <td>672856.0</td>
      <td>HALSHO59F82EDD5A1AA</td>
      <td>2.0</td>
      <td>29.4</td>
      <td>...</td>
      <td>Marshville</td>
      <td>Union</td>
      <td>Marshville</td>
      <td>NC</td>
      <td>28103</td>
      <td>South</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>aabevilacqua</th>
      <td>100360977</td>
      <td>2020-11-01</td>
      <td>order_refunded</td>
      <td>585634.0</td>
      <td>APPROY59BD023B7689B</td>
      <td>3.0</td>
      <td>411.8</td>
      <td>...</td>
      <td>Dodge Center</td>
      <td>Dodge</td>
      <td>Dodge Center</td>
      <td>MN</td>
      <td>55927</td>
      <td>Midwest</td>
      <td>20.000000</td>
    </tr>
    <tr>
      <th>aabowles</th>
      <td>100480904</td>
      <td>2021-04-17</td>
      <td>received</td>
      <td>785373.0</td>
      <td>OTHPCB5A7D8A12DF5B2</td>
      <td>5.0</td>
      <td>1200.0</td>
      <td>...</td>
      <td>Longmire</td>
      <td>Pierce</td>
      <td>Longmire</td>
      <td>WA</td>
      <td>98397</td>
      <td>West</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>zylindner</th>
      <td>100403919</td>
      <td>2020-12-24</td>
      <td>complete</td>
      <td>658427.0</td>
      <td>MEFAYB59F776CBA9EDC-L</td>
      <td>3.0</td>
      <td>29.8</td>
      <td>...</td>
      <td>Burbank</td>
      <td>Los Angeles</td>
      <td>Burbank</td>
      <td>CA</td>
      <td>91507</td>
      <td>West</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>zyrumsey</th>
      <td>100446728</td>
      <td>2021-02-22</td>
      <td>complete</td>
      <td>733016.0</td>
      <td>HALDAR5A549F244891D</td>
      <td>2.0</td>
      <td>276.3</td>
      <td>...</td>
      <td>Shreveport</td>
      <td>Caddo</td>
      <td>Shreveport</td>
      <td>LA</td>
      <td>71149</td>
      <td>South</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>zzbromberg</th>
      <td>100500606</td>
      <td>2021-04-30</td>
      <td>canceled</td>
      <td>809093.0</td>
      <td>OTHPCB5AB351EC0A239</td>
      <td>4.0</td>
      <td>100.0</td>
      <td>...</td>
      <td>Clear Lake</td>
      <td>Sherburne</td>
      <td>Clear Lake</td>
      <td>MN</td>
      <td>55319</td>
      <td>Midwest</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>zzchambless</th>
      <td>100470034</td>
      <td>2021-04-04</td>
      <td>complete</td>
      <td>770222.0</td>
      <td>MEFBIS5A79917B5298D</td>
      <td>2.0</td>
      <td>99.9</td>
      <td>...</td>
      <td>Solgohachia</td>
      <td>Conway</td>
      <td>Solgohachia</td>
      <td>AR</td>
      <td>72156</td>
      <td>South</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>zzmetzinger</th>
      <td>100397129</td>
      <td>2020-12-22</td>
      <td>canceled</td>
      <td>646250.0</td>
      <td>APPNAS5A0BDFDF7EB1A</td>
      <td>2.0</td>
      <td>155.9</td>
      <td>...</td>
      <td>La Villa</td>
      <td>Hidalgo</td>
      <td>La Villa</td>
      <td>TX</td>
      <td>78562</td>
      <td>South</td>
      <td>18.207184</td>
    </tr>
    <tr>
      <th>zzrascoe</th>
      <td>100462550</td>
      <td>2021-03-27</td>
      <td>canceled</td>
      <td>758962.0</td>
      <td>ENTNOB5A7E865F33FF7</td>
      <td>1.0</td>
      <td>2656.3</td>
      <td>...</td>
      <td>Las Vegas</td>
      <td>Clark</td>
      <td>Las Vegas</td>
      <td>NV</td>
      <td>89135</td>
      <td>West</td>
      <td>7.152807</td>
    </tr>
    <tr>
      <th>zzstansfield</th>
      <td>100512064</td>
      <td>2021-05-16</td>
      <td>complete</td>
      <td>823857.0</td>
      <td>MEFPAK5ABE23D8007FE-L</td>
      <td>2.0</td>
      <td>109.9</td>
      <td>...</td>
      <td>Newland</td>
      <td>Avery</td>
      <td>Newland</td>
      <td>NC</td>
      <td>28657</td>
      <td>South</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>25388 rows × 35 columns</p>
      
          <p>df_gender_age (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>age</th>
    </tr>
    <tr>
      <th>User Name</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>aaagin</th>
      <td>True</td>
      <td>(17.943, 32.25]</td>
    </tr>
    <tr>
      <th>aaashlock</th>
      <td>True</td>
      <td>(60.75, 75.0]</td>
    </tr>
    <tr>
      <th>aaaucoin</th>
      <td>True</td>
      <td>(32.25, 46.5]</td>
    </tr>
    <tr>
      <th>aabass</th>
      <td>True</td>
      <td>(32.25, 46.5]</td>
    </tr>
    <tr>
      <th>aabergen</th>
      <td>True</td>
      <td>(60.75, 75.0]</td>
    </tr>
    <tr>
      <th>aabevilacqua</th>
      <td>True</td>
      <td>(60.75, 75.0]</td>
    </tr>
    <tr>
      <th>aabowles</th>
      <td>False</td>
      <td>(46.5, 60.75]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>zylindner</th>
      <td>False</td>
      <td>(17.943, 32.25]</td>
    </tr>
    <tr>
      <th>zyrumsey</th>
      <td>False</td>
      <td>(60.75, 75.0]</td>
    </tr>
    <tr>
      <th>zzbromberg</th>
      <td>True</td>
      <td>(46.5, 60.75]</td>
    </tr>
    <tr>
      <th>zzchambless</th>
      <td>True</td>
      <td>(46.5, 60.75]</td>
    </tr>
    <tr>
      <th>zzmetzinger</th>
      <td>True</td>
      <td>(46.5, 60.75]</td>
    </tr>
    <tr>
      <th>zzrascoe</th>
      <td>False</td>
      <td>(17.943, 32.25]</td>
    </tr>
    <tr>
      <th>zzstansfield</th>
      <td>False</td>
      <td>(17.943, 32.25]</td>
    </tr>
  </tbody>
</table>
<p>25388 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
    </tr>
    <tr>
      <th>age</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(17.943, 32.25]</th>
      <td>49.433558</td>
    </tr>
    <tr>
      <th>(32.25, 46.5]</th>
      <td>50.349878</td>
    </tr>
    <tr>
      <th>(46.5, 60.75]</th>
      <td>50.163345</td>
    </tr>
    <tr>
      <th>(60.75, 75.0]</th>
      <td>50.690545</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which category has the largest female userbase?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_gender_cat = df_users[['Gender', 'category']]
df_gender_cat['Gender'] = df_gender_cat.Gender == 'F'
df_gender_cat = 100*df_gender_cat.groupby(['category']).sum()
df_gender_cat.sort_values('Gender').idxmax().values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_gender_cat = df_users[['Gender', 'category']]
df_gender_cat['Gender'] = df_gender_cat.Gender == 'F'
df_gender_cat = 100*df_gender_cat.groupby(['category']).sum()
df_gender_cat.sort_values('Gender').idxmax().values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_gender_cat = df_users[['Gender', 'category']]
df_gender_cat['Gender'] = df_gender_cat.Gender == 'F'
df_gender_cat = 100 * df_gender_cat.groupby(['category']).sum()
__output__ = df_gender_cat.sort_values('Gender').idxmax().values[0]
</code></pre>
        <p><span onclick="$('#var_output_96f921af').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_96f921af" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Mobiles & Tablets</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_gender_cat, __output__ </p>
    
          <p>df_gender_cat (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
    </tr>
    <tr>
      <th>category</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Appliances</th>
      <td>144200</td>
    </tr>
    <tr>
      <th>Beauty &amp; Grooming</th>
      <td>67500</td>
    </tr>
    <tr>
      <th>Books</th>
      <td>3900</td>
    </tr>
    <tr>
      <th>Computing</th>
      <td>41500</td>
    </tr>
    <tr>
      <th>Entertainment</th>
      <td>81000</td>
    </tr>
    <tr>
      <th>Health &amp; Sports</th>
      <td>27400</td>
    </tr>
    <tr>
      <th>Home &amp; Living</th>
      <td>53500</td>
    </tr>
    <tr>
      <th>Kids &amp; Baby</th>
      <td>25600</td>
    </tr>
    <tr>
      <th>Men's Fashion</th>
      <td>204400</td>
    </tr>
    <tr>
      <th>Mobiles &amp; Tablets</th>
      <td>280200</td>
    </tr>
    <tr>
      <th>Others</th>
      <td>160300</td>
    </tr>
    <tr>
      <th>School &amp; Education</th>
      <td>4100</td>
    </tr>
    <tr>
      <th>Soghaat</th>
      <td>16400</td>
    </tr>
    <tr>
      <th>Superstore</th>
      <td>34800</td>
    </tr>
    <tr>
      <th>Women's Fashion</th>
      <td>120600</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 1 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>Mobiles & Tablets</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average completed order amount for each type of payment method? Sort in descending order.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.status == 'complete'][['total', 'payment_method']]\
    .groupby('payment_method').mean()\
    .sort_values('total', ascending=False)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.status == 'complete'][['total', 'payment_method']]\
    .groupby('payment_method').mean()\
    .sort_values('total', ascending=False)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.status == 'complete'][['total', 'payment_method']].groupby(
    'payment_method').mean().sort_values('total', ascending=False)
</code></pre>
        <p><span onclick="$('#var_output_99b63fed').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_99b63fed" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total</th>
    </tr>
    <tr>
      <th>payment_method</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>easypay_voucher</th>
      <td>1587.522400</td>
    </tr>
    <tr>
      <th>jazzvoucher</th>
      <td>1345.305956</td>
    </tr>
    <tr>
      <th>Payaxis</th>
      <td>1174.543806</td>
    </tr>
    <tr>
      <th>bankalfalah</th>
      <td>1110.435381</td>
    </tr>
    <tr>
      <th>mcblite</th>
      <td>955.127778</td>
    </tr>
    <tr>
      <th>Easypay</th>
      <td>731.188516</td>
    </tr>
    <tr>
      <th>Easypay_MA</th>
      <td>540.604313</td>
    </tr>
    <tr>
      <th>customercredit</th>
      <td>528.612643</td>
    </tr>
    <tr>
      <th>apg</th>
      <td>309.900000</td>
    </tr>
    <tr>
      <th>cod</th>
      <td>266.154980</td>
    </tr>
    <tr>
      <th>cashatdoorstep</th>
      <td>266.000000</td>
    </tr>
    <tr>
      <th>jazzwallet</th>
      <td>181.627122</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total</th>
    </tr>
    <tr>
      <th>payment_method</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>easypay_voucher</th>
      <td>1587.522400</td>
    </tr>
    <tr>
      <th>jazzvoucher</th>
      <td>1345.305956</td>
    </tr>
    <tr>
      <th>Payaxis</th>
      <td>1174.543806</td>
    </tr>
    <tr>
      <th>bankalfalah</th>
      <td>1110.435381</td>
    </tr>
    <tr>
      <th>mcblite</th>
      <td>955.127778</td>
    </tr>
    <tr>
      <th>Easypay</th>
      <td>731.188516</td>
    </tr>
    <tr>
      <th>Easypay_MA</th>
      <td>540.604313</td>
    </tr>
    <tr>
      <th>customercredit</th>
      <td>528.612643</td>
    </tr>
    <tr>
      <th>apg</th>
      <td>309.900000</td>
    </tr>
    <tr>
      <th>cod</th>
      <td>266.154980</td>
    </tr>
    <tr>
      <th>cashatdoorstep</th>
      <td>266.000000</td>
    </tr>
    <tr>
      <th>jazzwallet</th>
      <td>181.627122</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the total revenue for each month in the last quarter of 2020?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(datetime.fromisoformat('2020-10-01') < df.order_date) & (df.order_date < datetime.fromisoformat('2020-12-31')) &
   (df.status == 'complete')][['total', 'month']].groupby('month').sum()/1e6</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(datetime.fromisoformat('2020-10-01') < df.order_date) & (df.order_date < datetime.fromisoformat('2020-12-31')) &
   (df.status == 'complete')][['total', 'month']].groupby('month').sum()/1e6</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(datetime.fromisoformat('2020-10-01') < df.order_date) & (
    df.order_date < datetime.fromisoformat('2020-12-31')) & (df.status ==
    'complete')][['total', 'month']].groupby('month').sum() / 1000000.0
</code></pre>
        <p><span onclick="$('#var_output_682b9e3c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_682b9e3c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Dec-2020</th>
      <td>4.986357</td>
    </tr>
    <tr>
      <th>Nov-2020</th>
      <td>0.489191</td>
    </tr>
    <tr>
      <th>Oct-2020</th>
      <td>0.117115</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Dec-2020</th>
      <td>4.986357</td>
    </tr>
    <tr>
      <th>Nov-2020</th>
      <td>0.489191</td>
    </tr>
    <tr>
      <th>Oct-2020</th>
      <td>0.117115</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which are the top three email services customers use for signing up? Display the providers with the number of users.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_users['E Mail'].apply(lambda x: re.findall('\@([^)]+)\.', x)[0]).value_counts().head(3)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_users['E Mail'].apply(lambda x: re.findall('\@([^)]+)\.', x)[0]).value_counts().head(3)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_users['E Mail'].apply(lambda x: re.findall('\\@([^)]+)\\.',
    x)[0]).value_counts().head(3)
</code></pre>
        <p><span onclick="$('#var_output_ac00831a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ac00831a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>gmail    7805
yahoo    3136
aol      2711
Name: E Mail, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>gmail    7805
yahoo    3136
aol      2711
Name: E Mail, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What category has the highest number of discounted products?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_disc = df[['category', 'discount_amount', 'item_id']]
df_disc = df_disc.groupby(['category', 'item_id']).first().reset_index()
df_disc['is_discounted'] = df_disc.discount_amount > 0
df_disc[['category', 'is_discounted']].groupby('category').sum().idxmax().values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_disc = df[['category', 'discount_amount', 'item_id']]
df_disc = df_disc.groupby(['category', 'item_id']).first().reset_index()
df_disc['is_discounted'] = df_disc.discount_amount > 0
df_disc[['category', 'is_discounted']].groupby('category').sum().idxmax().values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_disc = df[['category', 'discount_amount', 'item_id']]
df_disc = df_disc.groupby(['category', 'item_id']).first().reset_index()
df_disc['is_discounted'] = df_disc.discount_amount > 0
__output__ = df_disc[['category', 'is_discounted']].groupby('category').sum(
    ).idxmax().values[0]
</code></pre>
        <p><span onclick="$('#var_output_c1b5bd00').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c1b5bd00" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>Mobiles & Tablets</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_disc, __output__ </p>
    
          <p>df_disc (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>category</th>
      <th>item_id</th>
      <th>discount_amount</th>
      <th>is_discounted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Appliances</td>
      <td>574771.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Appliances</td>
      <td>574775.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Appliances</td>
      <td>574781.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Appliances</td>
      <td>574835.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Appliances</td>
      <td>574847.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Appliances</td>
      <td>574937.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Appliances</td>
      <td>575443.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>50003</th>
      <td>Women's Fashion</td>
      <td>904756.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>50004</th>
      <td>Women's Fashion</td>
      <td>904797.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>50005</th>
      <td>Women's Fashion</td>
      <td>904798.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>50006</th>
      <td>Women's Fashion</td>
      <td>904805.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>50007</th>
      <td>Women's Fashion</td>
      <td>904950.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>50008</th>
      <td>Women's Fashion</td>
      <td>905158.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>50009</th>
      <td>Women's Fashion</td>
      <td>905162.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>50010 rows × 4 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>Mobiles & Tablets</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Show how many new users signed up for every year since 2000.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_users[df_users['Customer Since']>datetime.fromisoformat('2000-01-01')]['Customer Since'].apply(lambda x: x.year)\
    .value_counts().sort_index()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_users[df_users['Customer Since']>datetime.fromisoformat('2000-01-01')]['Customer Since'].apply(lambda x: x.year)\
    .value_counts().sort_index()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_users[df_users['Customer Since'] > datetime.fromisoformat(
    '2000-01-01')]['Customer Since'].apply(lambda x: x.year).value_counts(
    ).sort_index()
</code></pre>
        <p><span onclick="$('#var_output_05bdaa8c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_05bdaa8c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>2000     517
2001     569
2002     588
2003     642
2004     670
        ... 
2013    1432
2014    1571
2015    1966
2016    2363
2017    1884
Name: Customer Since, Length: 18, dtype: int64</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>2000     517
2001     569
2002     588
2003     642
2004     670
        ... 
2013    1432
2014    1571
2015    1966
2016    2363
2017    1884
Name: Customer Since, Length: 18, dtype: int64</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Count how many items in each category have a discount.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[(df.status == 'complete') & (df.discount_amount>0)][['category', 'item_id']].groupby('category').count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[(df.status == 'complete') & (df.discount_amount>0)][['category', 'item_id']].groupby('category').count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[(df.status == 'complete') & (df.discount_amount > 0)][[
    'category', 'item_id']].groupby('category').count()
</code></pre>
        <p><span onclick="$('#var_output_fb190ab4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_fb190ab4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>item_id</th>
    </tr>
    <tr>
      <th>category</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Appliances</th>
      <td>1280</td>
    </tr>
    <tr>
      <th>Beauty &amp; Grooming</th>
      <td>281</td>
    </tr>
    <tr>
      <th>Computing</th>
      <td>250</td>
    </tr>
    <tr>
      <th>Entertainment</th>
      <td>856</td>
    </tr>
    <tr>
      <th>Health &amp; Sports</th>
      <td>63</td>
    </tr>
    <tr>
      <th>Home &amp; Living</th>
      <td>179</td>
    </tr>
    <tr>
      <th>Kids &amp; Baby</th>
      <td>58</td>
    </tr>
    <tr>
      <th>Men's Fashion</th>
      <td>400</td>
    </tr>
    <tr>
      <th>Mobiles &amp; Tablets</th>
      <td>2380</td>
    </tr>
    <tr>
      <th>Others</th>
      <td>13</td>
    </tr>
    <tr>
      <th>School &amp; Education</th>
      <td>2</td>
    </tr>
    <tr>
      <th>Soghaat</th>
      <td>71</td>
    </tr>
    <tr>
      <th>Superstore</th>
      <td>265</td>
    </tr>
    <tr>
      <th>Women's Fashion</th>
      <td>322</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>item_id</th>
    </tr>
    <tr>
      <th>category</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Appliances</th>
      <td>1280</td>
    </tr>
    <tr>
      <th>Beauty &amp; Grooming</th>
      <td>281</td>
    </tr>
    <tr>
      <th>Computing</th>
      <td>250</td>
    </tr>
    <tr>
      <th>Entertainment</th>
      <td>856</td>
    </tr>
    <tr>
      <th>Health &amp; Sports</th>
      <td>63</td>
    </tr>
    <tr>
      <th>Home &amp; Living</th>
      <td>179</td>
    </tr>
    <tr>
      <th>Kids &amp; Baby</th>
      <td>58</td>
    </tr>
    <tr>
      <th>Men's Fashion</th>
      <td>400</td>
    </tr>
    <tr>
      <th>Mobiles &amp; Tablets</th>
      <td>2380</td>
    </tr>
    <tr>
      <th>Others</th>
      <td>13</td>
    </tr>
    <tr>
      <th>School &amp; Education</th>
      <td>2</td>
    </tr>
    <tr>
      <th>Soghaat</th>
      <td>71</td>
    </tr>
    <tr>
      <th>Superstore</th>
      <td>265</td>
    </tr>
    <tr>
      <th>Women's Fashion</th>
      <td>322</td>
    </tr>
  </tbody>
</table>
<p>14 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> online-sales-in-usa/notebook_1.ipynb|||turn_11 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which user has requested the most refunds?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df.status == 'order_refunded'][['User Name', 'order_id']].groupby('User Name').count().idxmax().values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df.status == 'order_refunded'][['User Name', 'order_id']].groupby('User Name').count().idxmax().values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df.status == 'order_refunded'][['User Name', 'order_id']
    ].groupby('User Name').count().idxmax().values[0]
</code></pre>
        <p><span onclick="$('#var_output_934fb02c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_934fb02c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>jugonzalez</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>jugonzalez</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> spacex-falcon9-launch-data/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Add two new columns showing the nature of the landing site and the boolean flight outcome.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['did_land_success'] = df.Outcome.str.split(' ').apply(lambda x: x[0]).apply(lambda x: None if x == 'None' else x
                                                                                                                  ==
                                                                                                                  'True')
df['landing_site_type'] = df.Outcome.str.split(' ').apply(lambda x: x[1]).apply(lambda x: None if x == 'None' else x)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['did_land_success'] = df.Outcome.str.split(' ').apply(lambda x: x[0]).apply(lambda x: None if x == 'None' else x
                                                                                                                  ==
                                                                                                                  'True')
df['landing_site_type'] = df.Outcome.str.split(' ').apply(lambda x: x[1]).apply(lambda x: None if x == 'None' else x)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['did_land_success'] = df.Outcome.str.split(' ').apply(lambda x: x[0]).apply(
    lambda x: None if x == 'None' else x == 'True')
__output__ = df['landing_site_type'] = df.Outcome.str.split(' ').apply(lambda
    x: x[1]).apply(lambda x: None if x == 'None' else x)
</code></pre>
        <p><span onclick="$('#var_output_c727f09e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c727f09e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0      None
1      None
2      None
3     Ocean
4      None
      ...  
85     ASDS
86     ASDS
87     ASDS
88     ASDS
89     ASDS
Name: Outcome, Length: 90, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FlightNumber</th>
      <th>Date</th>
      <th>BoosterVersion</th>
      <th>PayloadMass</th>
      <th>Orbit</th>
      <th>LaunchSite</th>
      <th>Outcome</th>
      <th>...</th>
      <th>Block</th>
      <th>ReusedCount</th>
      <th>Serial</th>
      <th>Longitude</th>
      <th>Latitude</th>
      <th>did_land_success</th>
      <th>landing_site_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2010-06-04</td>
      <td>Falcon 9</td>
      <td>NaN</td>
      <td>LEO</td>
      <td>CCSFS SLC 40</td>
      <td>None None</td>
      <td>...</td>
      <td>1.0</td>
      <td>0</td>
      <td>B0003</td>
      <td>-80.577366</td>
      <td>28.561857</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>2012-05-22</td>
      <td>Falcon 9</td>
      <td>525.0</td>
      <td>LEO</td>
      <td>CCSFS SLC 40</td>
      <td>None None</td>
      <td>...</td>
      <td>1.0</td>
      <td>0</td>
      <td>B0005</td>
      <td>-80.577366</td>
      <td>28.561857</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>2013-03-01</td>
      <td>Falcon 9</td>
      <td>677.0</td>
      <td>ISS</td>
      <td>CCSFS SLC 40</td>
      <td>None None</td>
      <td>...</td>
      <td>1.0</td>
      <td>0</td>
      <td>B0007</td>
      <td>-80.577366</td>
      <td>28.561857</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>2013-09-29</td>
      <td>Falcon 9</td>
      <td>500.0</td>
      <td>PO</td>
      <td>VAFB SLC 4E</td>
      <td>False Ocean</td>
      <td>...</td>
      <td>1.0</td>
      <td>0</td>
      <td>B1003</td>
      <td>-120.610829</td>
      <td>34.632093</td>
      <td>False</td>
      <td>Ocean</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>2013-12-03</td>
      <td>Falcon 9</td>
      <td>3170.0</td>
      <td>GTO</td>
      <td>CCSFS SLC 40</td>
      <td>None None</td>
      <td>...</td>
      <td>1.0</td>
      <td>0</td>
      <td>B1004</td>
      <td>-80.577366</td>
      <td>28.561857</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>2014-01-06</td>
      <td>Falcon 9</td>
      <td>3325.0</td>
      <td>GTO</td>
      <td>CCSFS SLC 40</td>
      <td>None None</td>
      <td>...</td>
      <td>1.0</td>
      <td>0</td>
      <td>B1005</td>
      <td>-80.577366</td>
      <td>28.561857</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>2014-04-18</td>
      <td>Falcon 9</td>
      <td>2296.0</td>
      <td>ISS</td>
      <td>CCSFS SLC 40</td>
      <td>True Ocean</td>
      <td>...</td>
      <td>1.0</td>
      <td>0</td>
      <td>B1006</td>
      <td>-80.577366</td>
      <td>28.561857</td>
      <td>True</td>
      <td>Ocean</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>83</th>
      <td>84</td>
      <td>2020-08-18</td>
      <td>Falcon 9</td>
      <td>15600.0</td>
      <td>VLEO</td>
      <td>CCSFS SLC 40</td>
      <td>True ASDS</td>
      <td>...</td>
      <td>5.0</td>
      <td>9</td>
      <td>B1049</td>
      <td>-80.577366</td>
      <td>28.561857</td>
      <td>True</td>
      <td>ASDS</td>
    </tr>
    <tr>
      <th>84</th>
      <td>85</td>
      <td>2020-08-30</td>
      <td>Falcon 9</td>
      <td>1600.0</td>
      <td>SSO</td>
      <td>CCSFS SLC 40</td>
      <td>True RTLS</td>
      <td>...</td>
      <td>5.0</td>
      <td>5</td>
      <td>B1059</td>
      <td>-80.577366</td>
      <td>28.561857</td>
      <td>True</td>
      <td>RTLS</td>
    </tr>
    <tr>
      <th>85</th>
      <td>86</td>
      <td>2020-09-03</td>
      <td>Falcon 9</td>
      <td>15600.0</td>
      <td>VLEO</td>
      <td>KSC LC 39A</td>
      <td>True ASDS</td>
      <td>...</td>
      <td>5.0</td>
      <td>12</td>
      <td>B1060</td>
      <td>-80.603956</td>
      <td>28.608058</td>
      <td>True</td>
      <td>ASDS</td>
    </tr>
    <tr>
      <th>86</th>
      <td>87</td>
      <td>2020-10-06</td>
      <td>Falcon 9</td>
      <td>15600.0</td>
      <td>VLEO</td>
      <td>KSC LC 39A</td>
      <td>True ASDS</td>
      <td>...</td>
      <td>5.0</td>
      <td>12</td>
      <td>B1058</td>
      <td>-80.603956</td>
      <td>28.608058</td>
      <td>True</td>
      <td>ASDS</td>
    </tr>
    <tr>
      <th>87</th>
      <td>88</td>
      <td>2020-10-18</td>
      <td>Falcon 9</td>
      <td>15600.0</td>
      <td>VLEO</td>
      <td>KSC LC 39A</td>
      <td>True ASDS</td>
      <td>...</td>
      <td>5.0</td>
      <td>12</td>
      <td>B1051</td>
      <td>-80.603956</td>
      <td>28.608058</td>
      <td>True</td>
      <td>ASDS</td>
    </tr>
    <tr>
      <th>88</th>
      <td>89</td>
      <td>2020-10-24</td>
      <td>Falcon 9</td>
      <td>15600.0</td>
      <td>VLEO</td>
      <td>CCSFS SLC 40</td>
      <td>True ASDS</td>
      <td>...</td>
      <td>5.0</td>
      <td>12</td>
      <td>B1060</td>
      <td>-80.577366</td>
      <td>28.561857</td>
      <td>True</td>
      <td>ASDS</td>
    </tr>
    <tr>
      <th>89</th>
      <td>90</td>
      <td>2020-11-05</td>
      <td>Falcon 9</td>
      <td>3681.0</td>
      <td>MEO</td>
      <td>CCSFS SLC 40</td>
      <td>True ASDS</td>
      <td>...</td>
      <td>5.0</td>
      <td>6</td>
      <td>B1062</td>
      <td>-80.577366</td>
      <td>28.561857</td>
      <td>True</td>
      <td>ASDS</td>
    </tr>
  </tbody>
</table>
<p>90 rows × 19 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0      None
1      None
2      None
3     Ocean
4      None
      ...  
85     ASDS
86     ASDS
87     ASDS
88     ASDS
89     ASDS
Name: Outcome, Length: 90, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> spacex-falcon9-launch-data/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What sort of landing site type has seen the fewest failed landings?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>(df[['did_land_success', 'landing_site_type']].dropna().groupby('landing_site_type').sum() / df[['did_land_success',
                                                                                                 'landing_site_type']].dropna().groupby(
    'landing_site_type').count()).sort_values('did_land_success').tail(1).index[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>(df[['did_land_success', 'landing_site_type']].dropna().groupby('landing_site_type').sum() / df[['did_land_success',
                                                                                                 'landing_site_type']].dropna().groupby(
    'landing_site_type').count()).sort_values('did_land_success').tail(1).index[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = (df[['did_land_success', 'landing_site_type']].dropna().
    groupby('landing_site_type').sum() / df[['did_land_success',
    'landing_site_type']].dropna().groupby('landing_site_type').count()
    ).sort_values('did_land_success').tail(1).index[0]
</code></pre>
        <p><span onclick="$('#var_output_69da3190').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_69da3190" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>RTLS</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>RTLS</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> spacex-falcon9-launch-data/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which orbit has SpaceX sent the most payload to?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['Orbit', 'PayloadMass']].dropna().groupby('Orbit').sum().idxmax()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['Orbit', 'PayloadMass']].dropna().groupby('Orbit').sum().idxmax()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['Orbit', 'PayloadMass']].dropna().groupby('Orbit').sum(
    ).idxmax()
</code></pre>
        <p><span onclick="$('#var_output_38953bab').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_38953bab" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>PayloadMass    VLEO
dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>PayloadMass    VLEO
dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> spacex-falcon9-launch-data/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What year was grid fins introduced?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['GridFins']].Date.apply(dateutil.parser.parse).min().year</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['GridFins']].Date.apply(dateutil.parser.parse).min().year</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['GridFins']].Date.apply(dateutil.parser.parse).min().year
</code></pre>
        <p><span onclick="$('#var_output_e7ff2bca').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e7ff2bca" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>2015</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>2015</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> spacex-falcon9-launch-data/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Display the success rate of flights by year.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_t = df.loc[:,['did_land_success', 'Date']]
df_t['did_land_success'] = (df_t.did_land_success == True)
df_t['Date'] = df_t.Date.apply(dateutil.parser.parse).apply(lambda x: x.year, 1)
dfty = df_t.groupby('Date')
dfty.sum() / dfty.count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_t = df.loc[:,['did_land_success', 'Date']]
df_t['did_land_success'] = (df_t.did_land_success == True)
df_t['Date'] = df_t.Date.apply(dateutil.parser.parse).apply(lambda x: x.year, 1)
dfty = df_t.groupby('Date')
dfty.sum() / dfty.count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_t = df.loc[:, ['did_land_success', 'Date']]
df_t['did_land_success'] = df_t.did_land_success == True
df_t['Date'] = df_t.Date.apply(dateutil.parser.parse).apply(lambda x: x.year, 1
    )
dfty = df_t.groupby('Date')
__output__ = dfty.sum() / dfty.count()
</code></pre>
        <p><span onclick="$('#var_output_bbdbb018').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bbdbb018" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>did_land_success</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0.625000</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0.833333</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0.611111</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>0.900000</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>0.842105</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_t, __output__ </p>
    
          <p>df_t (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>did_land_success</th>
      <th>Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>False</td>
      <td>2010</td>
    </tr>
    <tr>
      <th>1</th>
      <td>False</td>
      <td>2012</td>
    </tr>
    <tr>
      <th>2</th>
      <td>False</td>
      <td>2013</td>
    </tr>
    <tr>
      <th>3</th>
      <td>False</td>
      <td>2013</td>
    </tr>
    <tr>
      <th>4</th>
      <td>False</td>
      <td>2013</td>
    </tr>
    <tr>
      <th>5</th>
      <td>False</td>
      <td>2014</td>
    </tr>
    <tr>
      <th>6</th>
      <td>True</td>
      <td>2014</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>83</th>
      <td>True</td>
      <td>2020</td>
    </tr>
    <tr>
      <th>84</th>
      <td>True</td>
      <td>2020</td>
    </tr>
    <tr>
      <th>85</th>
      <td>True</td>
      <td>2020</td>
    </tr>
    <tr>
      <th>86</th>
      <td>True</td>
      <td>2020</td>
    </tr>
    <tr>
      <th>87</th>
      <td>True</td>
      <td>2020</td>
    </tr>
    <tr>
      <th>88</th>
      <td>True</td>
      <td>2020</td>
    </tr>
    <tr>
      <th>89</th>
      <td>True</td>
      <td>2020</td>
    </tr>
  </tbody>
</table>
<p>90 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>did_land_success</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0.625000</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0.833333</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0.611111</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>0.900000</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>0.842105</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> spacex-falcon9-launch-data/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common landing pad for each launch site?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['LaunchSite', 'LandingPad']].dropna().groupby(['LaunchSite']).apply(
    lambda x: x.groupby('LandingPad').count().idxmax()).rename(columns={'LaunchSite': 'LandingPad'})</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['LaunchSite', 'LandingPad']].dropna().groupby(['LaunchSite']).apply(
    lambda x: x.groupby('LandingPad').count().idxmax()).rename(columns={'LaunchSite': 'LandingPad'})</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['LaunchSite', 'LandingPad']].dropna().groupby(['LaunchSite']
    ).apply(lambda x: x.groupby('LandingPad').count().idxmax()).rename(columns
    ={'LaunchSite': 'LandingPad'})
</code></pre>
        <p><span onclick="$('#var_output_622adf3e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_622adf3e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LandingPad</th>
    </tr>
    <tr>
      <th>LaunchSite</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CCSFS SLC 40</th>
      <td>5e9e3032383ecb6bb234e7ca</td>
    </tr>
    <tr>
      <th>KSC LC 39A</th>
      <td>5e9e3032383ecb6bb234e7ca</td>
    </tr>
    <tr>
      <th>VAFB SLC 4E</th>
      <td>5e9e3033383ecbb9e534e7cc</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LandingPad</th>
    </tr>
    <tr>
      <th>LaunchSite</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CCSFS SLC 40</th>
      <td>5e9e3032383ecb6bb234e7ca</td>
    </tr>
    <tr>
      <th>KSC LC 39A</th>
      <td>5e9e3032383ecb6bb234e7ca</td>
    </tr>
    <tr>
      <th>VAFB SLC 4E</th>
      <td>5e9e3033383ecbb9e534e7cc</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> spacex-falcon9-launch-data/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How much payload has SpaceX lost each year?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_t = df.loc[:,['did_land_success', 'Date', 'PayloadMass']]
df_t['did_land_success'] = (df_t.did_land_success == False)
df_t['Date'] = df_t.Date.apply(dateutil.parser.parse).apply(lambda x: x.year, 1)
dfty = df_t[df_t.did_land_success][['PayloadMass', 'Date']].groupby('Date')
dfty.sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_t = df.loc[:,['did_land_success', 'Date', 'PayloadMass']]
df_t['did_land_success'] = (df_t.did_land_success == False)
df_t['Date'] = df_t.Date.apply(dateutil.parser.parse).apply(lambda x: x.year, 1)
dfty = df_t[df_t.did_land_success][['PayloadMass', 'Date']].groupby('Date')
dfty.sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_t = df.loc[:, ['did_land_success', 'Date', 'PayloadMass']]
df_t['did_land_success'] = df_t.did_land_success == False
df_t['Date'] = df_t.Date.apply(dateutil.parser.parse).apply(lambda x: x.year, 1
    )
dfty = df_t[df_t.did_land_success][['PayloadMass', 'Date']].groupby('Date')
__output__ = dfty.sum()
</code></pre>
        <p><span onclick="$('#var_output_434d639c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_434d639c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PayloadMass</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2013</th>
      <td>500.0</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>2216.0</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>4293.0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>5824.0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>2573.0</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>31200.0</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_t, __output__ </p>
    
          <p>df_t (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>did_land_success</th>
      <th>Date</th>
      <th>PayloadMass</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>False</td>
      <td>2010</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>False</td>
      <td>2012</td>
      <td>525.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>False</td>
      <td>2013</td>
      <td>677.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>True</td>
      <td>2013</td>
      <td>500.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>False</td>
      <td>2013</td>
      <td>3170.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>False</td>
      <td>2014</td>
      <td>3325.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>False</td>
      <td>2014</td>
      <td>2296.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>83</th>
      <td>False</td>
      <td>2020</td>
      <td>15600.0</td>
    </tr>
    <tr>
      <th>84</th>
      <td>False</td>
      <td>2020</td>
      <td>1600.0</td>
    </tr>
    <tr>
      <th>85</th>
      <td>False</td>
      <td>2020</td>
      <td>15600.0</td>
    </tr>
    <tr>
      <th>86</th>
      <td>False</td>
      <td>2020</td>
      <td>15600.0</td>
    </tr>
    <tr>
      <th>87</th>
      <td>False</td>
      <td>2020</td>
      <td>15600.0</td>
    </tr>
    <tr>
      <th>88</th>
      <td>False</td>
      <td>2020</td>
      <td>15600.0</td>
    </tr>
    <tr>
      <th>89</th>
      <td>False</td>
      <td>2020</td>
      <td>3681.0</td>
    </tr>
  </tbody>
</table>
<p>90 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PayloadMass</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2013</th>
      <td>500.0</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>2216.0</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>4293.0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>5824.0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>2573.0</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>31200.0</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> baton-rouge-louisiana-traffic-incidents-legacy/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the binary columns to boolean.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def convert_to_bool(x):
    if set(x.unique()) == {np.NaN, 'X'}:
        return x.replace({'X': True}).fillna(False)
    return x
df = df.apply(convert_to_bool)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def convert_to_bool(x):
    if set(x.unique()) == {np.NaN, 'X'}:
        return x.replace({'X': True}).fillna(False)
    return x
df = df.apply(convert_to_bool)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def convert_to_bool(x):
    if set(x.unique()) == {np.NaN, 'X'}:
        return x.replace({'X': True}).fillna(False)
    return x


__output__ = df = df.apply(convert_to_bool)
</code></pre>
        <p><span onclick="$('#var_output_d98f98dd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d98f98dd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FILE#</th>
      <th>CRASH DATE</th>
      <th>CRASH TIME</th>
      <th>TOT VEH</th>
      <th>DISTRICT</th>
      <th>ZONE</th>
      <th>SUBZONE</th>
      <th>...</th>
      <th>SECOND FACTOR</th>
      <th>WEATHER</th>
      <th>LOCATION KIND</th>
      <th>RELATION ROADWAY</th>
      <th>ACCESS CONTROL</th>
      <th>LIGHTING</th>
      <th>GEOLOCATION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17-00010877</td>
      <td>08/04/2017</td>
      <td>07:36 AM</td>
      <td>2</td>
      <td>1</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>500 I110\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>1</th>
      <td>17-00011507</td>
      <td>08/16/2017</td>
      <td>04:59 PM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>800 W I10 HW\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17-00005091</td>
      <td>03/31/2017</td>
      <td>10:51 AM</td>
      <td>1</td>
      <td>2</td>
      <td>B</td>
      <td>5</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>OTHER</td>
      <td>OTHER</td>
      <td>DAYLIGHT</td>
      <td>PERKINS\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17-00014277</td>
      <td>10/07/2017</td>
      <td>11:50 AM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>3</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLOUDY</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>900 E I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17-00016468</td>
      <td>11/15/2017</td>
      <td>11:02 AM</td>
      <td>2</td>
      <td>2</td>
      <td>D</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>600 E I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>5</th>
      <td>17-00017831</td>
      <td>12/14/2017</td>
      <td>07:32 AM</td>
      <td>2</td>
      <td>3</td>
      <td>F</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>800 W I12\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>6</th>
      <td>17-00018160</td>
      <td>12/20/2017</td>
      <td>01:00 PM</td>
      <td>2</td>
      <td>1</td>
      <td>E</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>UNKNOWN</td>
      <td>OTHER</td>
      <td>UNKNOWN</td>
      <td>UNKNOWN</td>
      <td>UNKNOWN</td>
      <td>CHOCTAW DR\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10003</th>
      <td>13-00012162</td>
      <td>10/08/2013</td>
      <td>06:10 PM</td>
      <td>3</td>
      <td>2</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>100 W I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>10004</th>
      <td>17-00005480</td>
      <td>04/12/2017</td>
      <td>03:30 PM</td>
      <td>2</td>
      <td>3</td>
      <td>B</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>8600 FLORLINE DR\nBATON ROUGE, LA\n(30.457423, -91.099039)</td>
    </tr>
    <tr>
      <th>10005</th>
      <td>10-00005546</td>
      <td>08/02/2010</td>
      <td>06:21 PM</td>
      <td>2</td>
      <td>3</td>
      <td>D</td>
      <td>2</td>
      <td>...</td>
      <td>MOVEMENT PRIOR TO CRASH</td>
      <td>CLOUDY</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>11301 FLORIDA BL\nBATON ROUGE, LA\n(30.459057, -91.058129)</td>
    </tr>
    <tr>
      <th>10006</th>
      <td>15-00009988</td>
      <td>07/23/2015</td>
      <td>10:00 PM</td>
      <td>2</td>
      <td>3</td>
      <td>G</td>
      <td>3</td>
      <td>...</td>
      <td>VIOLATIONS</td>
      <td>CLEAR</td>
      <td>BUSINESS, MIXED RESIDENTIAL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - CONTINUOUS STREET</td>
      <td>8900 JEFFERSON HW\nBATON ROUGE, LA\n(30.417181, -91.089906)</td>
    </tr>
    <tr>
      <th>10007</th>
      <td>17-00002493</td>
      <td>02/18/2017</td>
      <td>11:10 PM</td>
      <td>2</td>
      <td>1</td>
      <td>C</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - STREET LIGHT AT INTERSECTION ONLY</td>
      <td>3400 CHOCTAW\nBATON ROUGE, LA\n(30.4702, -91.154877)</td>
    </tr>
    <tr>
      <th>10008</th>
      <td>18-00012996</td>
      <td>09/29/2018</td>
      <td>08:13 PM</td>
      <td>1</td>
      <td>4</td>
      <td>B</td>
      <td>1</td>
      <td>...</td>
      <td>MOVEMENT PRIOR TO CRASH</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - NO STREET</td>
      <td>1400 I110\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>10009</th>
      <td>17-00011734</td>
      <td>08/20/2017</td>
      <td>07:07 PM</td>
      <td>2</td>
      <td>2</td>
      <td>D</td>
      <td>3</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS, MIXED RESIDENTIAL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>5000 HIGHLAND RD\nBATON ROUGE, LA\n(30.397487, -91.164437)</td>
    </tr>
  </tbody>
</table>
<p>10010 rows × 34 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FILE#</th>
      <th>CRASH DATE</th>
      <th>CRASH TIME</th>
      <th>TOT VEH</th>
      <th>DISTRICT</th>
      <th>ZONE</th>
      <th>SUBZONE</th>
      <th>...</th>
      <th>SECOND FACTOR</th>
      <th>WEATHER</th>
      <th>LOCATION KIND</th>
      <th>RELATION ROADWAY</th>
      <th>ACCESS CONTROL</th>
      <th>LIGHTING</th>
      <th>GEOLOCATION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17-00010877</td>
      <td>08/04/2017</td>
      <td>07:36 AM</td>
      <td>2</td>
      <td>1</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>500 I110\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>1</th>
      <td>17-00011507</td>
      <td>08/16/2017</td>
      <td>04:59 PM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>800 W I10 HW\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17-00005091</td>
      <td>03/31/2017</td>
      <td>10:51 AM</td>
      <td>1</td>
      <td>2</td>
      <td>B</td>
      <td>5</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>OTHER</td>
      <td>OTHER</td>
      <td>DAYLIGHT</td>
      <td>PERKINS\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17-00014277</td>
      <td>10/07/2017</td>
      <td>11:50 AM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>3</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLOUDY</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>900 E I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17-00016468</td>
      <td>11/15/2017</td>
      <td>11:02 AM</td>
      <td>2</td>
      <td>2</td>
      <td>D</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>600 E I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>5</th>
      <td>17-00017831</td>
      <td>12/14/2017</td>
      <td>07:32 AM</td>
      <td>2</td>
      <td>3</td>
      <td>F</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>800 W I12\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>6</th>
      <td>17-00018160</td>
      <td>12/20/2017</td>
      <td>01:00 PM</td>
      <td>2</td>
      <td>1</td>
      <td>E</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>UNKNOWN</td>
      <td>OTHER</td>
      <td>UNKNOWN</td>
      <td>UNKNOWN</td>
      <td>UNKNOWN</td>
      <td>CHOCTAW DR\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10003</th>
      <td>13-00012162</td>
      <td>10/08/2013</td>
      <td>06:10 PM</td>
      <td>3</td>
      <td>2</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>100 W I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>10004</th>
      <td>17-00005480</td>
      <td>04/12/2017</td>
      <td>03:30 PM</td>
      <td>2</td>
      <td>3</td>
      <td>B</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>8600 FLORLINE DR\nBATON ROUGE, LA\n(30.457423, -91.099039)</td>
    </tr>
    <tr>
      <th>10005</th>
      <td>10-00005546</td>
      <td>08/02/2010</td>
      <td>06:21 PM</td>
      <td>2</td>
      <td>3</td>
      <td>D</td>
      <td>2</td>
      <td>...</td>
      <td>MOVEMENT PRIOR TO CRASH</td>
      <td>CLOUDY</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>11301 FLORIDA BL\nBATON ROUGE, LA\n(30.459057, -91.058129)</td>
    </tr>
    <tr>
      <th>10006</th>
      <td>15-00009988</td>
      <td>07/23/2015</td>
      <td>10:00 PM</td>
      <td>2</td>
      <td>3</td>
      <td>G</td>
      <td>3</td>
      <td>...</td>
      <td>VIOLATIONS</td>
      <td>CLEAR</td>
      <td>BUSINESS, MIXED RESIDENTIAL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - CONTINUOUS STREET</td>
      <td>8900 JEFFERSON HW\nBATON ROUGE, LA\n(30.417181, -91.089906)</td>
    </tr>
    <tr>
      <th>10007</th>
      <td>17-00002493</td>
      <td>02/18/2017</td>
      <td>11:10 PM</td>
      <td>2</td>
      <td>1</td>
      <td>C</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - STREET LIGHT AT INTERSECTION ONLY</td>
      <td>3400 CHOCTAW\nBATON ROUGE, LA\n(30.4702, -91.154877)</td>
    </tr>
    <tr>
      <th>10008</th>
      <td>18-00012996</td>
      <td>09/29/2018</td>
      <td>08:13 PM</td>
      <td>1</td>
      <td>4</td>
      <td>B</td>
      <td>1</td>
      <td>...</td>
      <td>MOVEMENT PRIOR TO CRASH</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - NO STREET</td>
      <td>1400 I110\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>10009</th>
      <td>17-00011734</td>
      <td>08/20/2017</td>
      <td>07:07 PM</td>
      <td>2</td>
      <td>2</td>
      <td>D</td>
      <td>3</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS, MIXED RESIDENTIAL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>5000 HIGHLAND RD\nBATON ROUGE, LA\n(30.397487, -91.164437)</td>
    </tr>
  </tbody>
</table>
<p>10010 rows × 34 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FILE#</th>
      <th>CRASH DATE</th>
      <th>CRASH TIME</th>
      <th>TOT VEH</th>
      <th>DISTRICT</th>
      <th>ZONE</th>
      <th>SUBZONE</th>
      <th>...</th>
      <th>SECOND FACTOR</th>
      <th>WEATHER</th>
      <th>LOCATION KIND</th>
      <th>RELATION ROADWAY</th>
      <th>ACCESS CONTROL</th>
      <th>LIGHTING</th>
      <th>GEOLOCATION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17-00010877</td>
      <td>08/04/2017</td>
      <td>07:36 AM</td>
      <td>2</td>
      <td>1</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>500 I110\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>1</th>
      <td>17-00011507</td>
      <td>08/16/2017</td>
      <td>04:59 PM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>800 W I10 HW\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17-00005091</td>
      <td>03/31/2017</td>
      <td>10:51 AM</td>
      <td>1</td>
      <td>2</td>
      <td>B</td>
      <td>5</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>OTHER</td>
      <td>OTHER</td>
      <td>DAYLIGHT</td>
      <td>PERKINS\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17-00014277</td>
      <td>10/07/2017</td>
      <td>11:50 AM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>3</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLOUDY</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>900 E I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17-00016468</td>
      <td>11/15/2017</td>
      <td>11:02 AM</td>
      <td>2</td>
      <td>2</td>
      <td>D</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>600 E I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>5</th>
      <td>17-00017831</td>
      <td>12/14/2017</td>
      <td>07:32 AM</td>
      <td>2</td>
      <td>3</td>
      <td>F</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>800 W I12\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>6</th>
      <td>17-00018160</td>
      <td>12/20/2017</td>
      <td>01:00 PM</td>
      <td>2</td>
      <td>1</td>
      <td>E</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>UNKNOWN</td>
      <td>OTHER</td>
      <td>UNKNOWN</td>
      <td>UNKNOWN</td>
      <td>UNKNOWN</td>
      <td>CHOCTAW DR\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10003</th>
      <td>13-00012162</td>
      <td>10/08/2013</td>
      <td>06:10 PM</td>
      <td>3</td>
      <td>2</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>100 W I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>10004</th>
      <td>17-00005480</td>
      <td>04/12/2017</td>
      <td>03:30 PM</td>
      <td>2</td>
      <td>3</td>
      <td>B</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>8600 FLORLINE DR\nBATON ROUGE, LA\n(30.457423, -91.099039)</td>
    </tr>
    <tr>
      <th>10005</th>
      <td>10-00005546</td>
      <td>08/02/2010</td>
      <td>06:21 PM</td>
      <td>2</td>
      <td>3</td>
      <td>D</td>
      <td>2</td>
      <td>...</td>
      <td>MOVEMENT PRIOR TO CRASH</td>
      <td>CLOUDY</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>11301 FLORIDA BL\nBATON ROUGE, LA\n(30.459057, -91.058129)</td>
    </tr>
    <tr>
      <th>10006</th>
      <td>15-00009988</td>
      <td>07/23/2015</td>
      <td>10:00 PM</td>
      <td>2</td>
      <td>3</td>
      <td>G</td>
      <td>3</td>
      <td>...</td>
      <td>VIOLATIONS</td>
      <td>CLEAR</td>
      <td>BUSINESS, MIXED RESIDENTIAL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - CONTINUOUS STREET</td>
      <td>8900 JEFFERSON HW\nBATON ROUGE, LA\n(30.417181, -91.089906)</td>
    </tr>
    <tr>
      <th>10007</th>
      <td>17-00002493</td>
      <td>02/18/2017</td>
      <td>11:10 PM</td>
      <td>2</td>
      <td>1</td>
      <td>C</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - STREET LIGHT AT INTERSECTION ONLY</td>
      <td>3400 CHOCTAW\nBATON ROUGE, LA\n(30.4702, -91.154877)</td>
    </tr>
    <tr>
      <th>10008</th>
      <td>18-00012996</td>
      <td>09/29/2018</td>
      <td>08:13 PM</td>
      <td>1</td>
      <td>4</td>
      <td>B</td>
      <td>1</td>
      <td>...</td>
      <td>MOVEMENT PRIOR TO CRASH</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - NO STREET</td>
      <td>1400 I110\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>10009</th>
      <td>17-00011734</td>
      <td>08/20/2017</td>
      <td>07:07 PM</td>
      <td>2</td>
      <td>2</td>
      <td>D</td>
      <td>3</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS, MIXED RESIDENTIAL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>5000 HIGHLAND RD\nBATON ROUGE, LA\n(30.397487, -91.164437)</td>
    </tr>
  </tbody>
</table>
<p>10010 rows × 34 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> baton-rouge-louisiana-traffic-incidents-legacy/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert crash dates to datetime and show the total number of vehicles involved in crashes each year.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def get_year(x):
    x['year'] = x['CRASH DATE'].year
    return x
df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])
df.apply(get_year, 1)[['year', 'TOT VEH']].groupby('year').sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def get_year(x):
    x['year'] = x['CRASH DATE'].year
    return x
df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])
df.apply(get_year, 1)[['year', 'TOT VEH']].groupby('year').sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def get_year(x):
    x['year'] = x['CRASH DATE'].year
    return x


df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])
__output__ = df.apply(get_year, 1)[['year', 'TOT VEH']].groupby('year').sum()
</code></pre>
        <p><span onclick="$('#var_output_0c39643d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_0c39643d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TOT VEH</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>1255</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>1718</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>1634</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>1768</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>1934</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>2012</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>2134</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>2087</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>2104</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>1950</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>1615</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FILE#</th>
      <th>CRASH DATE</th>
      <th>CRASH TIME</th>
      <th>TOT VEH</th>
      <th>DISTRICT</th>
      <th>ZONE</th>
      <th>SUBZONE</th>
      <th>...</th>
      <th>SECOND FACTOR</th>
      <th>WEATHER</th>
      <th>LOCATION KIND</th>
      <th>RELATION ROADWAY</th>
      <th>ACCESS CONTROL</th>
      <th>LIGHTING</th>
      <th>GEOLOCATION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17-00010877</td>
      <td>2017-08-04</td>
      <td>07:36 AM</td>
      <td>2</td>
      <td>1</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>500 I110\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>1</th>
      <td>17-00011507</td>
      <td>2017-08-16</td>
      <td>04:59 PM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>800 W I10 HW\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17-00005091</td>
      <td>2017-03-31</td>
      <td>10:51 AM</td>
      <td>1</td>
      <td>2</td>
      <td>B</td>
      <td>5</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>OTHER</td>
      <td>OTHER</td>
      <td>DAYLIGHT</td>
      <td>PERKINS\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17-00014277</td>
      <td>2017-10-07</td>
      <td>11:50 AM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>3</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLOUDY</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>900 E I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17-00016468</td>
      <td>2017-11-15</td>
      <td>11:02 AM</td>
      <td>2</td>
      <td>2</td>
      <td>D</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>600 E I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>5</th>
      <td>17-00017831</td>
      <td>2017-12-14</td>
      <td>07:32 AM</td>
      <td>2</td>
      <td>3</td>
      <td>F</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>800 W I12\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>6</th>
      <td>17-00018160</td>
      <td>2017-12-20</td>
      <td>01:00 PM</td>
      <td>2</td>
      <td>1</td>
      <td>E</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>UNKNOWN</td>
      <td>OTHER</td>
      <td>UNKNOWN</td>
      <td>UNKNOWN</td>
      <td>UNKNOWN</td>
      <td>CHOCTAW DR\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10003</th>
      <td>13-00012162</td>
      <td>2013-10-08</td>
      <td>06:10 PM</td>
      <td>3</td>
      <td>2</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>100 W I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>10004</th>
      <td>17-00005480</td>
      <td>2017-04-12</td>
      <td>03:30 PM</td>
      <td>2</td>
      <td>3</td>
      <td>B</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>8600 FLORLINE DR\nBATON ROUGE, LA\n(30.457423, -91.099039)</td>
    </tr>
    <tr>
      <th>10005</th>
      <td>10-00005546</td>
      <td>2010-08-02</td>
      <td>06:21 PM</td>
      <td>2</td>
      <td>3</td>
      <td>D</td>
      <td>2</td>
      <td>...</td>
      <td>MOVEMENT PRIOR TO CRASH</td>
      <td>CLOUDY</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>11301 FLORIDA BL\nBATON ROUGE, LA\n(30.459057, -91.058129)</td>
    </tr>
    <tr>
      <th>10006</th>
      <td>15-00009988</td>
      <td>2015-07-23</td>
      <td>10:00 PM</td>
      <td>2</td>
      <td>3</td>
      <td>G</td>
      <td>3</td>
      <td>...</td>
      <td>VIOLATIONS</td>
      <td>CLEAR</td>
      <td>BUSINESS, MIXED RESIDENTIAL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - CONTINUOUS STREET</td>
      <td>8900 JEFFERSON HW\nBATON ROUGE, LA\n(30.417181, -91.089906)</td>
    </tr>
    <tr>
      <th>10007</th>
      <td>17-00002493</td>
      <td>2017-02-18</td>
      <td>11:10 PM</td>
      <td>2</td>
      <td>1</td>
      <td>C</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - STREET LIGHT AT INTERSECTION ONLY</td>
      <td>3400 CHOCTAW\nBATON ROUGE, LA\n(30.4702, -91.154877)</td>
    </tr>
    <tr>
      <th>10008</th>
      <td>18-00012996</td>
      <td>2018-09-29</td>
      <td>08:13 PM</td>
      <td>1</td>
      <td>4</td>
      <td>B</td>
      <td>1</td>
      <td>...</td>
      <td>MOVEMENT PRIOR TO CRASH</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DARK - NO STREET</td>
      <td>1400 I110\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>10009</th>
      <td>17-00011734</td>
      <td>2017-08-20</td>
      <td>07:07 PM</td>
      <td>2</td>
      <td>2</td>
      <td>D</td>
      <td>3</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS, MIXED RESIDENTIAL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>5000 HIGHLAND RD\nBATON ROUGE, LA\n(30.397487, -91.164437)</td>
    </tr>
  </tbody>
</table>
<p>10010 rows × 34 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TOT VEH</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>1255</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>1718</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>1634</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>1768</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>1934</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>2012</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>2134</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>2087</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>2104</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>1950</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>1615</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> baton-rouge-louisiana-traffic-incidents-legacy/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many of those crashes each year resulted in fatalities? Show the total number of fatalities with year as index.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['CRASH DATE', 'FATALITY']].apply(get_year, 1)[['year', 'FATALITY']].groupby('year').sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['CRASH DATE', 'FATALITY']].apply(get_year, 1)[['year', 'FATALITY']].groupby('year').sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['CRASH DATE', 'FATALITY']].apply(get_year, 1)[['year',
    'FATALITY']].groupby('year').sum()
</code></pre>
        <p><span onclick="$('#var_output_c7fe74d1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c7fe74d1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FATALITY</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>3</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>4</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FATALITY</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>3</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>4</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> baton-rouge-louisiana-traffic-incidents-legacy/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many of those crashes each year were hit-and-run cases?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[['CRASH DATE', 'FATALITY']].apply(get_year, 1)[['year', 'FATALITY']].groupby('year').sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[['CRASH DATE', 'FATALITY']].apply(get_year, 1)[['year', 'FATALITY']].groupby('year').sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[['CRASH DATE', 'FATALITY']].apply(get_year, 1)[['year',
    'FATALITY']].groupby('year').sum()
</code></pre>
        <p><span onclick="$('#var_output_492eb926').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_492eb926" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FATALITY</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>3</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>4</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FATALITY</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>0</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>3</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>4</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>12 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> baton-rouge-louisiana-traffic-incidents-legacy/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What kind of collision causes the most number of injuries or fatalities in total?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_fni = df.loc[:, ['MANNER OF COLLISION', 'FATALITY', 'INJURY']]
df_fni['TOTAL'] = df_fni.FATALITY + df_fni.INJURY
df_fni[['MANNER OF COLLISION', 'TOTAL']].groupby('MANNER OF COLLISION')\
    .sum().sort_values('TOTAL', ascending=False).head(1).index.values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_fni = df.loc[:, ['MANNER OF COLLISION', 'FATALITY', 'INJURY']]
df_fni['TOTAL'] = df_fni.FATALITY + df_fni.INJURY
df_fni[['MANNER OF COLLISION', 'TOTAL']].groupby('MANNER OF COLLISION')\
    .sum().sort_values('TOTAL', ascending=False).head(1).index.values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_fni = df.loc[:, ['MANNER OF COLLISION', 'FATALITY', 'INJURY']]
df_fni['TOTAL'] = df_fni.FATALITY + df_fni.INJURY
__output__ = df_fni[['MANNER OF COLLISION', 'TOTAL']].groupby(
    'MANNER OF COLLISION').sum().sort_values('TOTAL', ascending=False).head(1
    ).index.values[0]
</code></pre>
        <p><span onclick="$('#var_output_a0fdfa9b').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a0fdfa9b" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>REAR END</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_fni, __output__ </p>
    
          <p>df_fni (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MANNER OF COLLISION</th>
      <th>FATALITY</th>
      <th>INJURY</th>
      <th>TOTAL</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SIDESWIPE SAME</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>REAR END</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>OTHER</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>REAR END</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>REAR END</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>REAR END</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>REAR END</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10003</th>
      <td>REAR END</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10004</th>
      <td>REAR END</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10005</th>
      <td>RIGHT ANGLE</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10006</th>
      <td>REAR END</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10007</th>
      <td>RIGHT ANGLE</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10008</th>
      <td>REAR END</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10009</th>
      <td>REAR END</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>10010 rows × 4 columns</p>
      
          <p>__output__ (str):</p>
          <pre><code>REAR END</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> baton-rouge-louisiana-traffic-incidents-legacy/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common primary reason behind accidents causing bodily harm?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_fni = df.loc[:, ['PRIMARY FACTOR', 'FATALITY', 'INJURY']]
df_fni['TOTAL'] = df_fni.FATALITY + df_fni.INJURY
factor = df_fni[['PRIMARY FACTOR', 'TOTAL']].groupby('PRIMARY FACTOR')\
    .sum().sort_values('TOTAL', ascending=False).head(1).index.values[0]
factor</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_fni = df.loc[:, ['PRIMARY FACTOR', 'FATALITY', 'INJURY']]
df_fni['TOTAL'] = df_fni.FATALITY + df_fni.INJURY
factor = df_fni[['PRIMARY FACTOR', 'TOTAL']].groupby('PRIMARY FACTOR')\
    .sum().sort_values('TOTAL', ascending=False).head(1).index.values[0]
factor</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_fni = df.loc[:, ['PRIMARY FACTOR', 'FATALITY', 'INJURY']]
df_fni['TOTAL'] = df_fni.FATALITY + df_fni.INJURY
factor = df_fni[['PRIMARY FACTOR', 'TOTAL']].groupby('PRIMARY FACTOR').sum(
    ).sort_values('TOTAL', ascending=False).head(1).index.values[0]
__output__ = factor
</code></pre>
        <p><span onclick="$('#var_output_e8c447fc').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_e8c447fc" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>VIOLATIONS</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_fni, factor, __output__ </p>
    
          <p>df_fni (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PRIMARY FACTOR</th>
      <th>FATALITY</th>
      <th>INJURY</th>
      <th>TOTAL</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>CONDITION OF DRIVER</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>VIOLATIONS</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>VIOLATIONS</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>VIOLATIONS</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>VIOLATIONS</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>VIOLATIONS</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>VIOLATIONS</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10003</th>
      <td>VIOLATIONS</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10004</th>
      <td>VIOLATIONS</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10005</th>
      <td>VIOLATIONS</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10006</th>
      <td>MOVEMENT PRIOR TO CRASH</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10007</th>
      <td>VIOLATIONS</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10008</th>
      <td>VIOLATIONS</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10009</th>
      <td>VEHICLE CONDITIONS</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>10010 rows × 4 columns</p>
      
          <p>factor (str):</p>
          <pre><code>VIOLATIONS</code></pre>
      
          <p>__output__ (str):</p>
          <pre><code>VIOLATIONS</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> baton-rouge-louisiana-traffic-incidents-legacy/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For accidents caused by that reason, what is the secondary factor that has involved the most number of vehicles in total?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[df['PRIMARY FACTOR'] == factor].loc[:, ['SECOND FACTOR', 'TOT VEH']].groupby('SECOND FACTOR').sum().sort_values\
    ('TOT VEH', ascending=False).head().index.values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[df['PRIMARY FACTOR'] == factor].loc[:, ['SECOND FACTOR', 'TOT VEH']].groupby('SECOND FACTOR').sum().sort_values\
    ('TOT VEH', ascending=False).head().index.values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[df['PRIMARY FACTOR'] == factor].loc[:, ['SECOND FACTOR',
    'TOT VEH']].groupby('SECOND FACTOR').sum().sort_values('TOT VEH',
    ascending=False).head().index.values[0]
</code></pre>
        <p><span onclick="$('#var_output_a78c2acf').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a78c2acf" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>MOVEMENT PRIOR TO CRASH</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>MOVEMENT PRIOR TO CRASH</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> baton-rouge-louisiana-traffic-incidents-legacy/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common kind of accident that occurs in daylight on dry one-way roads with no abnormalities?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_cond = df[(df['LIGHTING'] == 'DAYLIGHT') \
   & (df['SURFACE CONDITION'] == 'DRY') \
   & (df['ROAD CONDITION'] == 'NO ABNORMALITIES') \
   & (df['ROAD TYPE'] =='ONE-WAY ROAD')]
acc_type = df_cond['MANNER OF COLLISION'].value_counts().index.values[0]
acc_type</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_cond = df[(df['LIGHTING'] == 'DAYLIGHT') \
   & (df['SURFACE CONDITION'] == 'DRY') \
   & (df['ROAD CONDITION'] == 'NO ABNORMALITIES') \
   & (df['ROAD TYPE'] =='ONE-WAY ROAD')]
acc_type = df_cond['MANNER OF COLLISION'].value_counts().index.values[0]
acc_type</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_cond = df[(df['LIGHTING'] == 'DAYLIGHT') & (df['SURFACE CONDITION'] ==
    'DRY') & (df['ROAD CONDITION'] == 'NO ABNORMALITIES') & (df['ROAD TYPE'
    ] == 'ONE-WAY ROAD')]
acc_type = df_cond['MANNER OF COLLISION'].value_counts().index.values[0]
__output__ = acc_type
</code></pre>
        <p><span onclick="$('#var_output_9ccfb5de').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9ccfb5de" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>REAR END</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_cond, acc_type, __output__ </p>
    
          <p>df_cond (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FILE#</th>
      <th>CRASH DATE</th>
      <th>CRASH TIME</th>
      <th>TOT VEH</th>
      <th>DISTRICT</th>
      <th>ZONE</th>
      <th>SUBZONE</th>
      <th>...</th>
      <th>SECOND FACTOR</th>
      <th>WEATHER</th>
      <th>LOCATION KIND</th>
      <th>RELATION ROADWAY</th>
      <th>ACCESS CONTROL</th>
      <th>LIGHTING</th>
      <th>GEOLOCATION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17-00010877</td>
      <td>2017-08-04</td>
      <td>07:36 AM</td>
      <td>2</td>
      <td>1</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>500 I110\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17-00016468</td>
      <td>2017-11-15</td>
      <td>11:02 AM</td>
      <td>2</td>
      <td>2</td>
      <td>D</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>600 E I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>5</th>
      <td>17-00017831</td>
      <td>2017-12-14</td>
      <td>07:32 AM</td>
      <td>2</td>
      <td>3</td>
      <td>F</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>800 W I12\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>9</th>
      <td>18-00003604</td>
      <td>2018-03-19</td>
      <td>02:04 PM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>2</td>
      <td>...</td>
      <td>VIOLATIONS</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>OTHER</td>
      <td>DAYLIGHT</td>
      <td>800 E I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>11</th>
      <td>19-00010127</td>
      <td>2019-08-09</td>
      <td>08:43 AM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>5</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>200 W I12\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>12</th>
      <td>19-00015619</td>
      <td>2019-12-04</td>
      <td>02:53 PM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>15770 E I10\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>13</th>
      <td>18-00011082</td>
      <td>2018-08-23</td>
      <td>01:29 PM</td>
      <td>2</td>
      <td>1</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>500 N I110 HW\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9914</th>
      <td>14-00008464</td>
      <td>2014-07-14</td>
      <td>06:24 PM</td>
      <td>2</td>
      <td>1</td>
      <td>D</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>MANUFACTURING OF INDUSTRAIL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>2000 N LOBDELL BL\nBATON ROUGE, LA\n(30.465286, -91.118264)</td>
    </tr>
    <tr>
      <th>9939</th>
      <td>12-00001035</td>
      <td>2012-01-30</td>
      <td>07:38 AM</td>
      <td>2</td>
      <td>2</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>OTHER</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>100 N I110\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>9952</th>
      <td>20-00011211</td>
      <td>2020-10-14</td>
      <td>04:21 PM</td>
      <td>2</td>
      <td>2</td>
      <td>C</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS, MIXED RESIDENTIAL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>2800 ALASKA ST\nBATON ROUGE, LA\n(30.422197, -91.184281)</td>
    </tr>
    <tr>
      <th>9958</th>
      <td>16-00013721</td>
      <td>2016-09-26</td>
      <td>11:47 AM</td>
      <td>2</td>
      <td>2</td>
      <td>B</td>
      <td>5</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>MANUFACTURING OF INDUSTRAIL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>100 E I12\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>9967</th>
      <td>16-00013660</td>
      <td>2016-09-25</td>
      <td>11:33 AM</td>
      <td>2</td>
      <td>2</td>
      <td>A</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>MANUFACTURING OF INDUSTRAIL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>300 N I110\nBATON ROUGE, LA</td>
    </tr>
    <tr>
      <th>9999</th>
      <td>17-00009847</td>
      <td>2017-07-12</td>
      <td>11:38 AM</td>
      <td>2</td>
      <td>1</td>
      <td>B</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>MANUFACTURING OF INDUSTRAIL</td>
      <td>ON ROADWAY</td>
      <td>NO CONTROL (UNLIMITED ACCESS TO ROADWAY)</td>
      <td>DAYLIGHT</td>
      <td>3301 FLORIDA ST\nBATON ROUGE, LA\n(30.450294, -91.155884)</td>
    </tr>
    <tr>
      <th>10003</th>
      <td>13-00012162</td>
      <td>2013-10-08</td>
      <td>06:10 PM</td>
      <td>3</td>
      <td>2</td>
      <td>A</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>CLEAR</td>
      <td>BUSINESS CONTINUOUS</td>
      <td>ON ROADWAY</td>
      <td>FULL CONTROL (ONLY RAMP ENTRANCE and EXIT)</td>
      <td>DAYLIGHT</td>
      <td>100 W I10\nBATON ROUGE, LA</td>
    </tr>
  </tbody>
</table>
<p>659 rows × 34 columns</p>
      
          <p>acc_type (str):</p>
          <pre><code>REAR END</code></pre>
      
          <p>__output__ (str):</p>
          <pre><code>REAR END</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> baton-rouge-louisiana-traffic-incidents-legacy/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common cause of that type of accident under those conditions?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_cond[df_cond['MANNER OF COLLISION'] == acc_type]['PRIMARY FACTOR'].value_counts().index.values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_cond[df_cond['MANNER OF COLLISION'] == acc_type]['PRIMARY FACTOR'].value_counts().index.values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_cond[df_cond['MANNER OF COLLISION'] == acc_type][
    'PRIMARY FACTOR'].value_counts().index.values[0]
</code></pre>
        <p><span onclick="$('#var_output_bc3a52d0').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_bc3a52d0" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>VIOLATIONS</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>VIOLATIONS</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> baton-rouge-louisiana-traffic-incidents-legacy/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most common cause of accidents for that accident type under all other conditions?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df[~df.index.isin(df_cond.index) & (df['MANNER OF COLLISION'] == acc_type)]['PRIMARY FACTOR'].value_counts().index.values[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df[~df.index.isin(df_cond.index) & (df['MANNER OF COLLISION'] == acc_type)]['PRIMARY FACTOR'].value_counts().index.values[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df[~df.index.isin(df_cond.index) & (df['MANNER OF COLLISION'] ==
    acc_type)]['PRIMARY FACTOR'].value_counts().index.values[0]
</code></pre>
        <p><span onclick="$('#var_output_4a326f35').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4a326f35" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>VIOLATIONS</code></pre>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (str):</p>
          <pre><code>VIOLATIONS</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> euroleague-basketball-20212022/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many fouls were committed in the 1st game between AS Monaco and Panathinaikos OPAP Athens at Salle Gaston Medecin?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_monaco_vs_athens = df[(df.game == 1) & (df.location == 'Salle Gaston Medecin') & (df.team == 'AS Monaco') & (
        df.visitor_team == 'Panathinaikos OPAP Athens')]
len(df_monaco_vs_athens[(df_monaco_vs_athens.FC == 1) & (df_monaco_vs_athens.stat.str.contains('Drawn') == False)])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_monaco_vs_athens = df[(df.game == 1) & (df.location == 'Salle Gaston Medecin') & (df.team == 'AS Monaco') & (
        df.visitor_team == 'Panathinaikos OPAP Athens')]
len(df_monaco_vs_athens[(df_monaco_vs_athens.FC == 1) & (df_monaco_vs_athens.stat.str.contains('Drawn') == False)])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_monaco_vs_athens = df[(df.game == 1) & (df.location ==
    'Salle Gaston Medecin') & (df.team == 'AS Monaco') & (df.visitor_team ==
    'Panathinaikos OPAP Athens')]
__output__ = len(df_monaco_vs_athens[(df_monaco_vs_athens.FC == 1) & (
    df_monaco_vs_athens.stat.str.contains('Drawn') == False)])
</code></pre>
        <p><span onclick="$('#var_output_d31c1724').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d31c1724" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>15</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_monaco_vs_athens, __output__ </p>
    
          <p>df_monaco_vs_athens (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>round</th>
      <th>game</th>
      <th>date</th>
      <th>location</th>
      <th>hour</th>
      <th>local_team</th>
      <th>visitor_team</th>
      <th>...</th>
      <th>AS</th>
      <th>TO</th>
      <th>ST</th>
      <th>BLKF</th>
      <th>BLKA</th>
      <th>FC</th>
      <th>FD</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>460</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>462</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>464</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>465</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>467</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>468</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>472</th>
      <td>1</td>
      <td>1</td>
      <td>30 Sep 2021</td>
      <td>Salle Gaston Medecin</td>
      <td>19:00</td>
      <td>AS Monaco</td>
      <td>Panathinaikos OPAP Athens</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>245 rows × 29 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>15</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> euroleague-basketball-20212022/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # In that game how many fouls were drawn by each player?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_monaco_vs_athens[(df_monaco_vs_athens.FC == 1) & (df_monaco_vs_athens.stat.str.contains('Drawn') == True)][['player', 'FC']].groupby('player').sum()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_monaco_vs_athens[(df_monaco_vs_athens.FC == 1) & (df_monaco_vs_athens.stat.str.contains('Drawn') == True)][['player', 'FC']].groupby('player').sum()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_monaco_vs_athens[(df_monaco_vs_athens.FC == 1) & (
    df_monaco_vs_athens.stat.str.contains('Drawn') == True)][['player', 'FC']
    ].groupby('player').sum()
</code></pre>
        <p><span onclick="$('#var_output_6d9235c4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6d9235c4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FC</th>
    </tr>
    <tr>
      <th>player</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ANDJUSIC, DANILO</th>
      <td>4</td>
    </tr>
    <tr>
      <th>DIALLO, ALPHA</th>
      <td>1</td>
    </tr>
    <tr>
      <th>HALL, DONTA</th>
      <td>1</td>
    </tr>
    <tr>
      <th>JAMES, MIKE</th>
      <td>5</td>
    </tr>
    <tr>
      <th>LEE, PARIS</th>
      <td>3</td>
    </tr>
    <tr>
      <th>THOMAS, WILL</th>
      <td>1</td>
    </tr>
    <tr>
      <th>WESTERMANN, LEO</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FC</th>
    </tr>
    <tr>
      <th>player</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ANDJUSIC, DANILO</th>
      <td>4</td>
    </tr>
    <tr>
      <th>DIALLO, ALPHA</th>
      <td>1</td>
    </tr>
    <tr>
      <th>HALL, DONTA</th>
      <td>1</td>
    </tr>
    <tr>
      <th>JAMES, MIKE</th>
      <td>5</td>
    </tr>
    <tr>
      <th>LEE, PARIS</th>
      <td>3</td>
    </tr>
    <tr>
      <th>THOMAS, WILL</th>
      <td>1</td>
    </tr>
    <tr>
      <th>WESTERMANN, LEO</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> euroleague-basketball-20212022/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which team was leading at the end of each period in that game? Show the team name and the score and if scores are tied show 'tied' instead of team name.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def get_leading_team(x):
    scores = [int(i) for i in x['score'].split('-')]
    x['leading_team'] = x['visitor_team']
    if scores[0] > scores[1]:
        x['leading_team'] = x['local_team']
    elif scores[0] == scores[1]:
        x['leading_team'] = 'tied'
    return x

df_monaco_vs_athens.dropna().apply(get_leading_team, 1)[['period', 'leading_team', 'score']].groupby('period').last()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def get_leading_team(x):
    scores = [int(i) for i in x['score'].split('-')]
    x['leading_team'] = x['visitor_team']
    if scores[0] > scores[1]:
        x['leading_team'] = x['local_team']
    elif scores[0] == scores[1]:
        x['leading_team'] = 'tied'
    return x

df_monaco_vs_athens.dropna().apply(get_leading_team, 1)[['period', 'leading_team', 'score']].groupby('period').last()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def get_leading_team(x):
    scores = [int(i) for i in x['score'].split('-')]
    x['leading_team'] = x['visitor_team']
    if scores[0] > scores[1]:
        x['leading_team'] = x['local_team']
    elif scores[0] == scores[1]:
        x['leading_team'] = 'tied'
    return x


__output__ = df_monaco_vs_athens.dropna().apply(get_leading_team, 1)[[
    'period', 'leading_team', 'score']].groupby('period').last()
</code></pre>
        <p><span onclick="$('#var_output_44f599d4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_44f599d4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>leading_team</th>
      <th>score</th>
    </tr>
    <tr>
      <th>period</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>AS Monaco</td>
      <td>2-0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AS Monaco</td>
      <td>25-15</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AS Monaco</td>
      <td>40-28</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AS Monaco</td>
      <td>59-45</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>leading_team</th>
      <th>score</th>
    </tr>
    <tr>
      <th>period</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>AS Monaco</td>
      <td>2-0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AS Monaco</td>
      <td>25-15</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AS Monaco</td>
      <td>40-28</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AS Monaco</td>
      <td>59-45</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> euroleague-basketball-20212022/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the win percentage of FC Barcelona at home compared to away? Show a dataframe with home and away as columns.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>barcelona_games_home = df[df.local_team == 'FC Barcelona']
barcelona_games_away = df[df.visitor_team == 'FC Barcelona']
barcelona_games_home = barcelona_games_home.dropna().apply(get_leading_team, 1)
barcelona_games_home=barcelona_games_home[barcelona_games_home.period == 4][['game', 'leading_team', 'period']].groupby(['game', 'period']).last()

barcelona_games_away = barcelona_games_away.dropna().apply(get_leading_team, 1)
barcelona_games_away=barcelona_games_away[barcelona_games_away.period == 4][['game', 'leading_team', 'period']].groupby(['game', 'period']).last()

homewins = 100 * len(barcelona_games_home[barcelona_games_home.leading_team == 'FC Barcelona']) / len(
    barcelona_games_home)
awaywins = 100 * len(barcelona_games_away[barcelona_games_away.leading_team == 'FC Barcelona']) / len(
    barcelona_games_away)

pd.DataFrame({'home': {'Win(%)': homewins}, 'away': {'Win(%)': awaywins}})</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>barcelona_games_home = df[df.local_team == 'FC Barcelona']
barcelona_games_away = df[df.visitor_team == 'FC Barcelona']
barcelona_games_home = barcelona_games_home.dropna().apply(get_leading_team, 1)
barcelona_games_home=barcelona_games_home[barcelona_games_home.period == 4][['game', 'leading_team', 'period']].groupby(['game', 'period']).last()

barcelona_games_away = barcelona_games_away.dropna().apply(get_leading_team, 1)
barcelona_games_away=barcelona_games_away[barcelona_games_away.period == 4][['game', 'leading_team', 'period']].groupby(['game', 'period']).last()

homewins = 100 * len(barcelona_games_home[barcelona_games_home.leading_team == 'FC Barcelona']) / len(
    barcelona_games_home)
awaywins = 100 * len(barcelona_games_away[barcelona_games_away.leading_team == 'FC Barcelona']) / len(
    barcelona_games_away)

pd.DataFrame({'home': {'Win(%)': homewins}, 'away': {'Win(%)': awaywins}})</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>barcelona_games_home = df[df.local_team == 'FC Barcelona']
barcelona_games_away = df[df.visitor_team == 'FC Barcelona']
barcelona_games_home = barcelona_games_home.dropna().apply(get_leading_team, 1)
barcelona_games_home = barcelona_games_home[barcelona_games_home.period == 4][[
    'game', 'leading_team', 'period']].groupby(['game', 'period']).last()
barcelona_games_away = barcelona_games_away.dropna().apply(get_leading_team, 1)
barcelona_games_away = barcelona_games_away[barcelona_games_away.period == 4][[
    'game', 'leading_team', 'period']].groupby(['game', 'period']).last()
homewins = 100 * len(barcelona_games_home[barcelona_games_home.leading_team ==
    'FC Barcelona']) / len(barcelona_games_home)
awaywins = 100 * len(barcelona_games_away[barcelona_games_away.leading_team ==
    'FC Barcelona']) / len(barcelona_games_away)
__output__ = pd.DataFrame({'home': {'Win(%)': homewins}, 'away': {'Win(%)':
    awaywins}})
</code></pre>
        <p><span onclick="$('#var_output_f5a855b6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f5a855b6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>home</th>
      <th>away</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Win(%)</th>
      <td>100.0</td>
      <td>57.142857</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> barcelona_games_home, barcelona_games_away, homewins, awaywins, __output__ </p>
    
          <p>barcelona_games_home (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>leading_team</th>
    </tr>
    <tr>
      <th>game</th>
      <th>period</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <th>4</th>
      <td>FC Barcelona</td>
    </tr>
    <tr>
      <th>3</th>
      <th>4</th>
      <td>FC Barcelona</td>
    </tr>
    <tr>
      <th>4</th>
      <th>4</th>
      <td>FC Barcelona</td>
    </tr>
    <tr>
      <th>5</th>
      <th>4</th>
      <td>FC Barcelona</td>
    </tr>
    <tr>
      <th>6</th>
      <th>4</th>
      <td>FC Barcelona</td>
    </tr>
    <tr>
      <th>9</th>
      <th>4</th>
      <td>FC Barcelona</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
          <p>barcelona_games_away (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>leading_team</th>
    </tr>
    <tr>
      <th>game</th>
      <th>period</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <th>4</th>
      <td>UNICS Kazan</td>
    </tr>
    <tr>
      <th>2</th>
      <th>4</th>
      <td>FC Barcelona</td>
    </tr>
    <tr>
      <th>3</th>
      <th>4</th>
      <td>FC Barcelona</td>
    </tr>
    <tr>
      <th>4</th>
      <th>4</th>
      <td>AX Armani Exchange Milan</td>
    </tr>
    <tr>
      <th>5</th>
      <th>4</th>
      <td>FC Barcelona</td>
    </tr>
    <tr>
      <th>6</th>
      <th>4</th>
      <td>tied</td>
    </tr>
    <tr>
      <th>8</th>
      <th>4</th>
      <td>FC Barcelona</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 1 columns</p>
      
          <p>homewins (float):</p>
          <pre><code>100.0</code></pre>
      
          <p>awaywins (float):</p>
          <pre><code>57.142857142857146</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>home</th>
      <th>away</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Win(%)</th>
      <td>100.0</td>
      <td>57.142857</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.2, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> euroleague-basketball-20212022/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # In the 3rd game between AX Armani Exchange Milan and ALBA Berlin at the Mediolanum Forum, how many free throws were 'in'?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_armani_vs_berlin = df[
    (df.game == 3) & (df.location == 'Mediolanum Forum') & (df.local_team == 'AX Armani Exchange Milan') & (
            df.visitor_team == 'ALBA Berlin')]
df_armani_vs_berlin_nona = df_armani_vs_berlin.dropna()
df_armani_vs_berlin_nona[df_armani_vs_berlin_nona.stat.str.contains('Free Throw In')].shape[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_armani_vs_berlin = df[
    (df.game == 3) & (df.location == 'Mediolanum Forum') & (df.local_team == 'AX Armani Exchange Milan') & (
            df.visitor_team == 'ALBA Berlin')]
df_armani_vs_berlin_nona = df_armani_vs_berlin.dropna()
df_armani_vs_berlin_nona[df_armani_vs_berlin_nona.stat.str.contains('Free Throw In')].shape[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_armani_vs_berlin = df[(df.game == 3) & (df.location ==
    'Mediolanum Forum') & (df.local_team == 'AX Armani Exchange Milan') & (
    df.visitor_team == 'ALBA Berlin')]
df_armani_vs_berlin_nona = df_armani_vs_berlin.dropna()
__output__ = df_armani_vs_berlin_nona[df_armani_vs_berlin_nona.stat.str.
    contains('Free Throw In')].shape[0]
</code></pre>
        <p><span onclick="$('#var_output_c2d7eea9').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c2d7eea9" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>28</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_armani_vs_berlin, df_armani_vs_berlin_nona, __output__ </p>
    
          <p>df_armani_vs_berlin (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>round</th>
      <th>game</th>
      <th>date</th>
      <th>location</th>
      <th>hour</th>
      <th>local_team</th>
      <th>visitor_team</th>
      <th>...</th>
      <th>AS</th>
      <th>TO</th>
      <th>ST</th>
      <th>BLKF</th>
      <th>BLKA</th>
      <th>FC</th>
      <th>FD</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>77598</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77599</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77600</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77601</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77602</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77603</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77604</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>78087</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78088</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78089</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78090</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78091</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78092</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78093</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>496 rows × 29 columns</p>
      
          <p>df_armani_vs_berlin_nona (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>round</th>
      <th>game</th>
      <th>date</th>
      <th>location</th>
      <th>hour</th>
      <th>local_team</th>
      <th>visitor_team</th>
      <th>...</th>
      <th>AS</th>
      <th>TO</th>
      <th>ST</th>
      <th>BLKF</th>
      <th>BLKA</th>
      <th>FC</th>
      <th>FD</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>77598</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77603</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77606</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77608</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77611</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77616</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77619</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>78055</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78058</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78060</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78076</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78077</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78079</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78083</th>
      <td>18</td>
      <td>3</td>
      <td>18 Jan 2022</td>
      <td>Mediolanum Forum</td>
      <td>20:30</td>
      <td>AX Armani Exchange Milan</td>
      <td>ALBA Berlin</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>85 rows × 29 columns</p>
      
          <p>__output__ (int):</p>
          <pre><code>28</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> euroleague-basketball-20212022/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # In that game, how many times did each player score? Show only the players who scored.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_armani_vs_berlin_st = df_armani_vs_berlin[['stat', 'player']].dropna()
df_armani_vs_berlin_st[df_armani_vs_berlin_st.stat.str.contains('In')][['player', 'stat']].groupby('player').count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_armani_vs_berlin_st = df_armani_vs_berlin[['stat', 'player']].dropna()
df_armani_vs_berlin_st[df_armani_vs_berlin_st.stat.str.contains('In')][['player', 'stat']].groupby('player').count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_armani_vs_berlin_st = df_armani_vs_berlin[['stat', 'player']].dropna()
__output__ = df_armani_vs_berlin_st[df_armani_vs_berlin_st.stat.str.
    contains('In')][['player', 'stat']].groupby('player').count()
</code></pre>
        <p><span onclick="$('#var_output_d9bb8026').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d9bb8026" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stat</th>
    </tr>
    <tr>
      <th>player</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>BENTIL, BEN</th>
      <td>2</td>
    </tr>
    <tr>
      <th>BLATT, TAMIR</th>
      <td>3</td>
    </tr>
    <tr>
      <th>DA SILVA, OSCAR</th>
      <td>6</td>
    </tr>
    <tr>
      <th>DANIELS, TROY</th>
      <td>1</td>
    </tr>
    <tr>
      <th>DATOME, LUIGI</th>
      <td>4</td>
    </tr>
    <tr>
      <th>DELANEY, MALCOLM</th>
      <td>2</td>
    </tr>
    <tr>
      <th>ERIKSSON, MARCUS</th>
      <td>6</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>RICCI, GIAMPAOLO</th>
      <td>4</td>
    </tr>
    <tr>
      <th>RODRIGUEZ, SERGIO</th>
      <td>6</td>
    </tr>
    <tr>
      <th>SCHNEIDER, TIM</th>
      <td>2</td>
    </tr>
    <tr>
      <th>SIKMA, LUKE</th>
      <td>3</td>
    </tr>
    <tr>
      <th>SMITH, JALEEN</th>
      <td>4</td>
    </tr>
    <tr>
      <th>TARCZEWSKI, KALEB</th>
      <td>4</td>
    </tr>
    <tr>
      <th>ZOOSMAN, YOVEL</th>
      <td>5</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_armani_vs_berlin_st, __output__ </p>
    
          <p>df_armani_vs_berlin_st (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stat</th>
      <th>player</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>77598</th>
      <td>Free Throw In (1/2 -  8 pt)</td>
      <td>LO, MAODO</td>
    </tr>
    <tr>
      <th>77599</th>
      <td>Missed Free Throw (0/1 -  7 pt)</td>
      <td>LO, MAODO</td>
    </tr>
    <tr>
      <th>77600</th>
      <td>Foul (1)</td>
      <td>RODRIGUEZ, SERGIO</td>
    </tr>
    <tr>
      <th>77601</th>
      <td>Foul Drawn (1)</td>
      <td>LO, MAODO</td>
    </tr>
    <tr>
      <th>77602</th>
      <td>Assist (2)</td>
      <td>RODRIGUEZ, SERGIO</td>
    </tr>
    <tr>
      <th>77603</th>
      <td>Two Pointer (1/1 -  2 pt)</td>
      <td>BENTIL, BEN</td>
    </tr>
    <tr>
      <th>77604</th>
      <td>Steal (1)</td>
      <td>RODRIGUEZ, SERGIO</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>78087</th>
      <td>Missed Two Pointer (1/2 -  9 pt)</td>
      <td>RODRIGUEZ, SERGIO</td>
    </tr>
    <tr>
      <th>78088</th>
      <td>In</td>
      <td>SIKMA, LUKE</td>
    </tr>
    <tr>
      <th>78089</th>
      <td>Out</td>
      <td>KOUMADJE, CHRIST</td>
    </tr>
    <tr>
      <th>78090</th>
      <td>Out</td>
      <td>SCHNEIDER, TIM</td>
    </tr>
    <tr>
      <th>78091</th>
      <td>In</td>
      <td>DA SILVA, OSCAR</td>
    </tr>
    <tr>
      <th>78092</th>
      <td>In</td>
      <td>RODRIGUEZ, SERGIO</td>
    </tr>
    <tr>
      <th>78093</th>
      <td>Out</td>
      <td>GRANT, JERIAN</td>
    </tr>
  </tbody>
</table>
<p>481 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stat</th>
    </tr>
    <tr>
      <th>player</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>BENTIL, BEN</th>
      <td>2</td>
    </tr>
    <tr>
      <th>BLATT, TAMIR</th>
      <td>3</td>
    </tr>
    <tr>
      <th>DA SILVA, OSCAR</th>
      <td>6</td>
    </tr>
    <tr>
      <th>DANIELS, TROY</th>
      <td>1</td>
    </tr>
    <tr>
      <th>DATOME, LUIGI</th>
      <td>4</td>
    </tr>
    <tr>
      <th>DELANEY, MALCOLM</th>
      <td>2</td>
    </tr>
    <tr>
      <th>ERIKSSON, MARCUS</th>
      <td>6</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>RICCI, GIAMPAOLO</th>
      <td>4</td>
    </tr>
    <tr>
      <th>RODRIGUEZ, SERGIO</th>
      <td>6</td>
    </tr>
    <tr>
      <th>SCHNEIDER, TIM</th>
      <td>2</td>
    </tr>
    <tr>
      <th>SIKMA, LUKE</th>
      <td>3</td>
    </tr>
    <tr>
      <th>SMITH, JALEEN</th>
      <td>4</td>
    </tr>
    <tr>
      <th>TARCZEWSKI, KALEB</th>
      <td>4</td>
    </tr>
    <tr>
      <th>ZOOSMAN, YOVEL</th>
      <td>5</td>
    </tr>
  </tbody>
</table>
<p>22 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> euroleague-basketball-20212022/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many fouls did each team draw in that game?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_armani_vs_berlin_st = df_armani_vs_berlin[['stat', 'team']].dropna()
df_armani_vs_berlin_st[df_armani_vs_berlin_st.stat.str.contains('Foul Drawn')][['team', 'stat']].groupby('team').count()</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_armani_vs_berlin_st = df_armani_vs_berlin[['stat', 'team']].dropna()
df_armani_vs_berlin_st[df_armani_vs_berlin_st.stat.str.contains('Foul Drawn')][['team', 'stat']].groupby('team').count()</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_armani_vs_berlin_st = df_armani_vs_berlin[['stat', 'team']].dropna()
__output__ = df_armani_vs_berlin_st[df_armani_vs_berlin_st.stat.str.
    contains('Foul Drawn')][['team', 'stat']].groupby('team').count()
</code></pre>
        <p><span onclick="$('#var_output_19de82fe').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_19de82fe" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stat</th>
    </tr>
    <tr>
      <th>team</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ALBA Berlin</th>
      <td>20</td>
    </tr>
    <tr>
      <th>AX Armani Exchange Milan</th>
      <td>15</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_armani_vs_berlin_st, __output__ </p>
    
          <p>df_armani_vs_berlin_st (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stat</th>
      <th>team</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>77598</th>
      <td>Free Throw In (1/2 -  8 pt)</td>
      <td>ALBA Berlin</td>
    </tr>
    <tr>
      <th>77599</th>
      <td>Missed Free Throw (0/1 -  7 pt)</td>
      <td>ALBA Berlin</td>
    </tr>
    <tr>
      <th>77600</th>
      <td>Foul (1)</td>
      <td>AX Armani Exchange Milan</td>
    </tr>
    <tr>
      <th>77601</th>
      <td>Foul Drawn (1)</td>
      <td>ALBA Berlin</td>
    </tr>
    <tr>
      <th>77602</th>
      <td>Assist (2)</td>
      <td>AX Armani Exchange Milan</td>
    </tr>
    <tr>
      <th>77603</th>
      <td>Two Pointer (1/1 -  2 pt)</td>
      <td>AX Armani Exchange Milan</td>
    </tr>
    <tr>
      <th>77604</th>
      <td>Steal (1)</td>
      <td>AX Armani Exchange Milan</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>78087</th>
      <td>Missed Two Pointer (1/2 -  9 pt)</td>
      <td>AX Armani Exchange Milan</td>
    </tr>
    <tr>
      <th>78088</th>
      <td>In</td>
      <td>ALBA Berlin</td>
    </tr>
    <tr>
      <th>78089</th>
      <td>Out</td>
      <td>ALBA Berlin</td>
    </tr>
    <tr>
      <th>78090</th>
      <td>Out</td>
      <td>ALBA Berlin</td>
    </tr>
    <tr>
      <th>78091</th>
      <td>In</td>
      <td>ALBA Berlin</td>
    </tr>
    <tr>
      <th>78092</th>
      <td>In</td>
      <td>AX Armani Exchange Milan</td>
    </tr>
    <tr>
      <th>78093</th>
      <td>Out</td>
      <td>AX Armani Exchange Milan</td>
    </tr>
  </tbody>
</table>
<p>493 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stat</th>
    </tr>
    <tr>
      <th>team</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ALBA Berlin</th>
      <td>20</td>
    </tr>
    <tr>
      <th>AX Armani Exchange Milan</th>
      <td>15</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> euroleague-basketball-20212022/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What were the top 3 lowest scoring games? Sort in ascending order and show location, local and visitor team name</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def sum_score(x):
    x['total_score'] = sum([int(i) for i in x['score'].split('-')])
    return x

df_scores = df.dropna()
df_scores = df_scores[df_scores.period == 4].apply(sum_score, 1)[['game', 'location', 'local_team', 'visitor_team',
                                                                  'total_score', 'score']]
df_scores = df_scores.groupby(['game', 'location', 'local_team', 'visitor_team']).last().sort_values('total_score')
df_scores.head(3).reset_index()[['location', 'local_team', 'visitor_team']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def sum_score(x):
    x['total_score'] = sum([int(i) for i in x['score'].split('-')])
    return x

df_scores = df.dropna()
df_scores = df_scores[df_scores.period == 4].apply(sum_score, 1)[['game', 'location', 'local_team', 'visitor_team',
                                                                  'total_score', 'score']]
df_scores = df_scores.groupby(['game', 'location', 'local_team', 'visitor_team']).last().sort_values('total_score')
df_scores.head(3).reset_index()[['location', 'local_team', 'visitor_team']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def sum_score(x):
    x['total_score'] = sum([int(i) for i in x['score'].split('-')])
    return x


df_scores = df.dropna()
df_scores = df_scores[df_scores.period == 4].apply(sum_score, 1)[['game',
    'location', 'local_team', 'visitor_team', 'total_score', 'score']]
df_scores = df_scores.groupby(['game', 'location', 'local_team',
    'visitor_team']).last().sort_values('total_score')
__output__ = df_scores.head(3).reset_index()[['location', 'local_team',
    'visitor_team']]
</code></pre>
        <p><span onclick="$('#var_output_70923bc4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_70923bc4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>location</th>
      <th>local_team</th>
      <th>visitor_team</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Ulker Sports And Event Hall</td>
      <td>Fenerbahce Beko Istanbul</td>
      <td>Real Madrid</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Peace And Friendship Stadium</td>
      <td>Olympiacos Piraeus</td>
      <td>AX Armani Exchange Milan</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Ulker Sports And Event Hall</td>
      <td>Fenerbahce Beko Istanbul</td>
      <td>Crvena Zvezda mts Belgrade</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_scores, __output__ </p>
    
          <p>df_scores (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th>total_score</th>
      <th>score</th>
    </tr>
    <tr>
      <th>game</th>
      <th>location</th>
      <th>local_team</th>
      <th>visitor_team</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <th>Ulker Sports And Event Hall</th>
      <th>Fenerbahce Beko Istanbul</th>
      <th>Real Madrid</th>
      <td>80</td>
      <td>48-32</td>
    </tr>
    <tr>
      <th>3</th>
      <th>Peace And Friendship Stadium</th>
      <th>Olympiacos Piraeus</th>
      <th>AX Armani Exchange Milan</th>
      <td>84</td>
      <td>41-43</td>
    </tr>
    <tr>
      <th>6</th>
      <th>Ulker Sports And Event Hall</th>
      <th>Fenerbahce Beko Istanbul</th>
      <th>Crvena Zvezda mts Belgrade</th>
      <td>84</td>
      <td>45-39</td>
    </tr>
    <tr>
      <th>5</th>
      <th>Basket Hall Kazan</th>
      <th>UNICS Kazan</th>
      <th>Zalgiris Kaunas</th>
      <td>87</td>
      <td>45-42</td>
    </tr>
    <tr>
      <th>2</th>
      <th>Aleksandar Nikolic Hall</th>
      <th>Crvena Zvezda mts Belgrade</th>
      <th>Real Madrid</th>
      <td>87</td>
      <td>45-42</td>
    </tr>
    <tr>
      <th>8</th>
      <th>Audi Dome</th>
      <th>FC Bayern Munich</th>
      <th>ALBA Berlin</th>
      <td>87</td>
      <td>43-44</td>
    </tr>
    <tr>
      <th>6</th>
      <th>Palau Blaugrana</th>
      <th>FC Barcelona</th>
      <th>FC Bayern Munich</th>
      <td>88</td>
      <td>47-41</td>
    </tr>
    <tr>
      <th>...</th>
      <th>...</th>
      <th>...</th>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>7</th>
      <th>Oaka Altion</th>
      <th>Panathinaikos OPAP Athens</th>
      <th>Zalgiris Kaunas</th>
      <td>139</td>
      <td>61-78</td>
    </tr>
    <tr>
      <th>8</th>
      <th>Wizink Center</th>
      <th>Real Madrid</th>
      <th>AS Monaco</th>
      <td>139</td>
      <td>74-65</td>
    </tr>
    <tr>
      <th>6</th>
      <th>Audi Dome</th>
      <th>FC Bayern Munich</th>
      <th>Olympiacos Piraeus</th>
      <td>144</td>
      <td>71-73</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">9</th>
      <th>Mercedes-benz Arena</th>
      <th>ALBA Berlin</th>
      <th>CSKA Moscow</th>
      <td>145</td>
      <td>73-72</td>
    </tr>
    <tr>
      <th>Wizink Center</th>
      <th>Real Madrid</th>
      <th>Zalgiris Kaunas</th>
      <td>147</td>
      <td>75-72</td>
    </tr>
    <tr>
      <th>2</th>
      <th>Menora Mivtachim Arena</th>
      <th>Maccabi Playtika Tel Aviv</th>
      <th>Bitci Baskonia Vitoria-Gasteiz</th>
      <td>149</td>
      <td>71-78</td>
    </tr>
    <tr>
      <th>6</th>
      <th>Sinan Erdem Sports Hall.</th>
      <th>Anadolu Efes Istanbul</th>
      <th>CSKA Moscow</th>
      <td>149</td>
      <td>70-79</td>
    </tr>
  </tbody>
</table>
<p>244 rows × 2 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>location</th>
      <th>local_team</th>
      <th>visitor_team</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Ulker Sports And Event Hall</td>
      <td>Fenerbahce Beko Istanbul</td>
      <td>Real Madrid</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Peace And Friendship Stadium</td>
      <td>Olympiacos Piraeus</td>
      <td>AX Armani Exchange Milan</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Ulker Sports And Event Hall</td>
      <td>Fenerbahce Beko Istanbul</td>
      <td>Crvena Zvezda mts Belgrade</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> euroleague-basketball-20212022/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Which teams won those games? Show the venue and the winning teams.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_scores.head(3).reset_index().apply(get_leading_team, 1)[['location', 'leading_team']]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_scores.head(3).reset_index().apply(get_leading_team, 1)[['location', 'leading_team']]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_scores.head(3).reset_index().apply(get_leading_team, 1)[[
    'location', 'leading_team']]
</code></pre>
        <p><span onclick="$('#var_output_a2848bd6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_a2848bd6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>location</th>
      <th>leading_team</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Ulker Sports And Event Hall</td>
      <td>Fenerbahce Beko Istanbul</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Peace And Friendship Stadium</td>
      <td>AX Armani Exchange Milan</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Ulker Sports And Event Hall</td>
      <td>Fenerbahce Beko Istanbul</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>location</th>
      <th>leading_team</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Ulker Sports And Event Hall</td>
      <td>Fenerbahce Beko Istanbul</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Peace And Friendship Stadium</td>
      <td>AX Armani Exchange Milan</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Ulker Sports And Event Hall</td>
      <td>Fenerbahce Beko Istanbul</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 2 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> euroleague-basketball-20212022/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many games did each team win?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_scores.reset_index().apply(get_leading_team, 1)[['game', 'leading_team']].groupby('leading_team').count()\
    .drop('tied')</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_scores.reset_index().apply(get_leading_team, 1)[['game', 'leading_team']].groupby('leading_team').count()\
    .drop('tied')</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>__output__ = df_scores.reset_index().apply(get_leading_team, 1)[['game',
    'leading_team']].groupby('leading_team').count().drop('tied')
</code></pre>
        <p><span onclick="$('#var_output_db67af9e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_db67af9e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>game</th>
    </tr>
    <tr>
      <th>leading_team</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ALBA Berlin</th>
      <td>13</td>
    </tr>
    <tr>
      <th>AS Monaco</th>
      <td>17</td>
    </tr>
    <tr>
      <th>AX Armani Exchange Milan</th>
      <td>18</td>
    </tr>
    <tr>
      <th>Anadolu Efes Istanbul</th>
      <td>14</td>
    </tr>
    <tr>
      <th>Bitci Baskonia Vitoria-Gasteiz</th>
      <td>11</td>
    </tr>
    <tr>
      <th>CSKA Moscow</th>
      <td>13</td>
    </tr>
    <tr>
      <th>Crvena Zvezda mts Belgrade</th>
      <td>15</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Maccabi Playtika Tel Aviv</th>
      <td>12</td>
    </tr>
    <tr>
      <th>Olympiacos Piraeus</th>
      <td>14</td>
    </tr>
    <tr>
      <th>Panathinaikos OPAP Athens</th>
      <td>6</td>
    </tr>
    <tr>
      <th>Real Madrid</th>
      <td>19</td>
    </tr>
    <tr>
      <th>UNICS Kazan</th>
      <td>12</td>
    </tr>
    <tr>
      <th>Zalgiris Kaunas</th>
      <td>8</td>
    </tr>
    <tr>
      <th>Zenit St Petersburg</th>
      <td>10</td>
    </tr>
  </tbody>
</table>
<p>18 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>game</th>
    </tr>
    <tr>
      <th>leading_team</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ALBA Berlin</th>
      <td>13</td>
    </tr>
    <tr>
      <th>AS Monaco</th>
      <td>17</td>
    </tr>
    <tr>
      <th>AX Armani Exchange Milan</th>
      <td>18</td>
    </tr>
    <tr>
      <th>Anadolu Efes Istanbul</th>
      <td>14</td>
    </tr>
    <tr>
      <th>Bitci Baskonia Vitoria-Gasteiz</th>
      <td>11</td>
    </tr>
    <tr>
      <th>CSKA Moscow</th>
      <td>13</td>
    </tr>
    <tr>
      <th>Crvena Zvezda mts Belgrade</th>
      <td>15</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Maccabi Playtika Tel Aviv</th>
      <td>12</td>
    </tr>
    <tr>
      <th>Olympiacos Piraeus</th>
      <td>14</td>
    </tr>
    <tr>
      <th>Panathinaikos OPAP Athens</th>
      <td>6</td>
    </tr>
    <tr>
      <th>Real Madrid</th>
      <td>19</td>
    </tr>
    <tr>
      <th>UNICS Kazan</th>
      <td>12</td>
    </tr>
    <tr>
      <th>Zalgiris Kaunas</th>
      <td>8</td>
    </tr>
    <tr>
      <th>Zenit St Petersburg</th>
      <td>10</td>
    </tr>
  </tbody>
</table>
<p>18 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 1.0, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> iit-nit-data/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Drop duplicates from the data and create a new dataframe considering only general students (all india or out of state) with no quota, pool or other advantages.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df = df.drop_duplicates()
df_general = df[(df.pool=='Gender-Neutral')
             & (df.quota.str.contains('AI|OS'))
             & (df.category=='GEN')]
df_general</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df = df.drop_duplicates()
df_general = df[(df.pool=='Gender-Neutral')
             & (df.quota.str.contains('AI|OS'))
             & (df.category=='GEN')]
df_general</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df = df.drop_duplicates()
df_general = df[(df.pool == 'Gender-Neutral') & df.quota.str.contains(
    'AI|OS') & (df.category == 'GEN')]
__output__ = df_general
</code></pre>
        <p><span onclick="$('#var_output_534d24bd').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_534d24bd" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>institute_type</th>
      <th>round_no</th>
      <th>quota</th>
      <th>pool</th>
      <th>institute_short</th>
      <th>program_name</th>
      <th>program_duration</th>
      <th>degree_short</th>
      <th>category</th>
      <th>opening_rank</th>
      <th>closing_rank</th>
      <th>is_preparatory</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>838</td>
      <td>1841</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>422</td>
      <td>1479</td>
      <td>0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemistry</td>
      <td>4 Years</td>
      <td>BSc</td>
      <td>GEN</td>
      <td>3323</td>
      <td>4880</td>
      <td>0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>897</td>
      <td>2251</td>
      <td>0</td>
    </tr>
    <tr>
      <th>25</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>1</td>
      <td>60</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Electrical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>22</td>
      <td>227</td>
      <td>0</td>
    </tr>
    <tr>
      <th>37</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Electrical Engineering with M.Tech. in Communications and Signal Processing</td>
      <td>5 Years</td>
      <td>B.Tech + M.Tech (IDD)</td>
      <td>GEN</td>
      <td>249</td>
      <td>583</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>30977</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Silchar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>12225</td>
      <td>16141</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31001</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Silchar</td>
      <td>Electronics and Instrumentation Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>14487</td>
      <td>22175</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31023</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Silchar</td>
      <td>Mechanical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>17040</td>
      <td>27768</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31046</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>34849</td>
      <td>41530</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31069</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>35472</td>
      <td>43558</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31093</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>8851</td>
      <td>19669</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31116</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Electrical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>27275</td>
      <td>35311</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>2273 rows × 13 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, df_general, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>institute_type</th>
      <th>round_no</th>
      <th>quota</th>
      <th>pool</th>
      <th>institute_short</th>
      <th>program_name</th>
      <th>program_duration</th>
      <th>degree_short</th>
      <th>category</th>
      <th>opening_rank</th>
      <th>closing_rank</th>
      <th>is_preparatory</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>838</td>
      <td>1841</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>OBC-NCL</td>
      <td>408</td>
      <td>1098</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>SC</td>
      <td>297</td>
      <td>468</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>ST</td>
      <td>79</td>
      <td>145</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN-PWD</td>
      <td>94</td>
      <td>94</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>OBC-NCL-PWD</td>
      <td>45</td>
      <td>45</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>422</td>
      <td>1479</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>31134</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>JK</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>OBC-NCL</td>
      <td>73818</td>
      <td>113212</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31135</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>JK</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>SC</td>
      <td>5992</td>
      <td>14469</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31136</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>JK</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>SC</td>
      <td>14185</td>
      <td>24048</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31137</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>JK</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>ST</td>
      <td>2736</td>
      <td>4171</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31138</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>JK</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>ST</td>
      <td>10870</td>
      <td>10870</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31139</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>LA</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>166453</td>
      <td>265454</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31140</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>LA</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>215054</td>
      <td>215054</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>25458 rows × 13 columns</p>
      
          <p>df_general (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>institute_type</th>
      <th>round_no</th>
      <th>quota</th>
      <th>pool</th>
      <th>institute_short</th>
      <th>program_name</th>
      <th>program_duration</th>
      <th>degree_short</th>
      <th>category</th>
      <th>opening_rank</th>
      <th>closing_rank</th>
      <th>is_preparatory</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>838</td>
      <td>1841</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>422</td>
      <td>1479</td>
      <td>0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemistry</td>
      <td>4 Years</td>
      <td>BSc</td>
      <td>GEN</td>
      <td>3323</td>
      <td>4880</td>
      <td>0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>897</td>
      <td>2251</td>
      <td>0</td>
    </tr>
    <tr>
      <th>25</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>1</td>
      <td>60</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Electrical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>22</td>
      <td>227</td>
      <td>0</td>
    </tr>
    <tr>
      <th>37</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Electrical Engineering with M.Tech. in Communications and Signal Processing</td>
      <td>5 Years</td>
      <td>B.Tech + M.Tech (IDD)</td>
      <td>GEN</td>
      <td>249</td>
      <td>583</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>30977</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Silchar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>12225</td>
      <td>16141</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31001</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Silchar</td>
      <td>Electronics and Instrumentation Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>14487</td>
      <td>22175</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31023</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Silchar</td>
      <td>Mechanical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>17040</td>
      <td>27768</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31046</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>34849</td>
      <td>41530</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31069</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>35472</td>
      <td>43558</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31093</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>8851</td>
      <td>19669</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31116</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Electrical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>27275</td>
      <td>35311</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>2273 rows × 13 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>institute_type</th>
      <th>round_no</th>
      <th>quota</th>
      <th>pool</th>
      <th>institute_short</th>
      <th>program_name</th>
      <th>program_duration</th>
      <th>degree_short</th>
      <th>category</th>
      <th>opening_rank</th>
      <th>closing_rank</th>
      <th>is_preparatory</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>838</td>
      <td>1841</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>422</td>
      <td>1479</td>
      <td>0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemistry</td>
      <td>4 Years</td>
      <td>BSc</td>
      <td>GEN</td>
      <td>3323</td>
      <td>4880</td>
      <td>0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>897</td>
      <td>2251</td>
      <td>0</td>
    </tr>
    <tr>
      <th>25</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>1</td>
      <td>60</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Electrical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>22</td>
      <td>227</td>
      <td>0</td>
    </tr>
    <tr>
      <th>37</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Electrical Engineering with M.Tech. in Communications and Signal Processing</td>
      <td>5 Years</td>
      <td>B.Tech + M.Tech (IDD)</td>
      <td>GEN</td>
      <td>249</td>
      <td>583</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>30977</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Silchar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>12225</td>
      <td>16141</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31001</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Silchar</td>
      <td>Electronics and Instrumentation Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>14487</td>
      <td>22175</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31023</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Silchar</td>
      <td>Mechanical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>17040</td>
      <td>27768</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31046</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>34849</td>
      <td>41530</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31069</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>35472</td>
      <td>43558</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31093</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>8851</td>
      <td>19669</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31116</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Electrical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>27275</td>
      <td>35311</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>2273 rows × 13 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> iit-nit-data/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What has been the mean closing rank for all subjects at IIT-Delhi over the years compared with NIT-Delhi? Show the years as columns and institutes as index and consider only general students.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_iit_bombay = df_general[(df_general.institute_short == 'IIT-Delhi') | (df_general.institute_short == 'NIT-Delhi')]
df_iit_bombay[['year', 'closing_rank', 'institute_short']].groupby(['year', 'institute_short']).mean().unstack(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_iit_bombay = df_general[(df_general.institute_short == 'IIT-Delhi') | (df_general.institute_short == 'NIT-Delhi')]
df_iit_bombay[['year', 'closing_rank', 'institute_short']].groupby(['year', 'institute_short']).mean().unstack(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_iit_bombay = df_general[(df_general.institute_short == 'IIT-Delhi') | (
    df_general.institute_short == 'NIT-Delhi')]
__output__ = df_iit_bombay[['year', 'closing_rank', 'institute_short']
    ].groupby(['year', 'institute_short']).mean().unstack(0)
</code></pre>
        <p><span onclick="$('#var_output_ebf1414d').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_ebf1414d" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="6" halign="left">closing_rank</th>
    </tr>
    <tr>
      <th>year</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
    <tr>
      <th>institute_short</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>IIT-Delhi</th>
      <td>2000.0</td>
      <td>1942.0</td>
      <td>2071.866667</td>
      <td>1991.769231</td>
      <td>2217.625</td>
      <td>2147.617647</td>
    </tr>
    <tr>
      <th>NIT-Delhi</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9651.000000</td>
      <td>12792.000</td>
      <td>11481.333333</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 6 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_iit_bombay, __output__ </p>
    
          <p>df_iit_bombay (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>institute_type</th>
      <th>round_no</th>
      <th>quota</th>
      <th>pool</th>
      <th>institute_short</th>
      <th>program_name</th>
      <th>program_duration</th>
      <th>degree_short</th>
      <th>category</th>
      <th>opening_rank</th>
      <th>closing_rank</th>
      <th>is_preparatory</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>85</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Biochemical Engineering and Biotechnology</td>
      <td>5 Years</td>
      <td>B.Tech + M.Tech (IDD)</td>
      <td>GEN</td>
      <td>3787</td>
      <td>4714</td>
      <td>0</td>
    </tr>
    <tr>
      <th>89</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Biotechnology and Biochemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>2609</td>
      <td>3718</td>
      <td>0</td>
    </tr>
    <tr>
      <th>94</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>980</td>
      <td>1704</td>
      <td>0</td>
    </tr>
    <tr>
      <th>95</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Chemical Engineering</td>
      <td>5 Years</td>
      <td>B.Tech + M.Tech (IDD)</td>
      <td>GEN</td>
      <td>1729</td>
      <td>2996</td>
      <td>0</td>
    </tr>
    <tr>
      <th>105</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>767</td>
      <td>2618</td>
      <td>0</td>
    </tr>
    <tr>
      <th>111</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>24</td>
      <td>115</td>
      <td>0</td>
    </tr>
    <tr>
      <th>112</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Computer Science and Engineering</td>
      <td>5 Years</td>
      <td>B.Tech + M.Tech (IDD)</td>
      <td>GEN</td>
      <td>124</td>
      <td>186</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>18949</th>
      <td>2019</td>
      <td>NIT</td>
      <td>7</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Delhi</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>9099</td>
      <td>12016</td>
      <td>0</td>
    </tr>
    <tr>
      <th>23556</th>
      <td>2020</td>
      <td>NIT</td>
      <td>6</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Delhi</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>5095</td>
      <td>6983</td>
      <td>0</td>
    </tr>
    <tr>
      <th>23572</th>
      <td>2020</td>
      <td>NIT</td>
      <td>6</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Delhi</td>
      <td>Electrical and Electronics Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>11548</td>
      <td>18291</td>
      <td>0</td>
    </tr>
    <tr>
      <th>23588</th>
      <td>2020</td>
      <td>NIT</td>
      <td>6</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Delhi</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>9854</td>
      <td>13102</td>
      <td>0</td>
    </tr>
    <tr>
      <th>28476</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Delhi</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>623</td>
      <td>5700</td>
      <td>0</td>
    </tr>
    <tr>
      <th>28496</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Delhi</td>
      <td>Electrical and Electronics Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>13278</td>
      <td>15967</td>
      <td>0</td>
    </tr>
    <tr>
      <th>28518</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Delhi</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>6619</td>
      <td>12777</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>116 rows × 13 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="6" halign="left">closing_rank</th>
    </tr>
    <tr>
      <th>year</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
    <tr>
      <th>institute_short</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>IIT-Delhi</th>
      <td>2000.0</td>
      <td>1942.0</td>
      <td>2071.866667</td>
      <td>1991.769231</td>
      <td>2217.625</td>
      <td>2147.617647</td>
    </tr>
    <tr>
      <th>NIT-Delhi</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9651.000000</td>
      <td>12792.000</td>
      <td>11481.333333</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 6 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> iit-nit-data/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the mean opening rank across all IIT institutes for each program over the years? Show the mean opening rank for each year in columns with program as index and consider only general students.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_iit = df_general[df_general.institute_type == 'IIT']
df_iit[['year', 'opening_rank', 'program_name']].groupby(['year', 'program_name']).mean().unstack(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_iit = df_general[df_general.institute_type == 'IIT']
df_iit[['year', 'opening_rank', 'program_name']].groupby(['year', 'program_name']).mean().unstack(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_iit = df_general[df_general.institute_type == 'IIT']
__output__ = df_iit[['year', 'opening_rank', 'program_name']].groupby([
    'year', 'program_name']).mean().unstack(0)
</code></pre>
        <p><span onclick="$('#var_output_6e7cc886').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6e7cc886" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="6" halign="left">opening_rank</th>
    </tr>
    <tr>
      <th>year</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
    <tr>
      <th>program_name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Aerospace Engineering</th>
      <td>2072.833333</td>
      <td>1806.0</td>
      <td>2157.666667</td>
      <td>2278.833333</td>
      <td>2477.166667</td>
      <td>1977.083333</td>
    </tr>
    <tr>
      <th>Agricultural and Food Engineering</th>
      <td>4321.000000</td>
      <td>5183.0</td>
      <td>4614.000000</td>
      <td>5247.000000</td>
      <td>7039.000000</td>
      <td>6491.000000</td>
    </tr>
    <tr>
      <th>Agricultural and Food Engineering with M.Tech. in any of the listed specializations</th>
      <td>6306.000000</td>
      <td>6939.0</td>
      <td>6949.000000</td>
      <td>NaN</td>
      <td>7291.000000</td>
      <td>7769.000000</td>
    </tr>
    <tr>
      <th>Agricultural and Food Engineering with M.Tech. in any of the listedspecializations</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>8114.000000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Applied Geology</th>
      <td>6596.000000</td>
      <td>7875.0</td>
      <td>8550.000000</td>
      <td>9935.000000</td>
      <td>10901.000000</td>
      <td>9836.666667</td>
    </tr>
    <tr>
      <th>Applied Geophysics</th>
      <td>6760.000000</td>
      <td>9211.0</td>
      <td>8572.000000</td>
      <td>10064.000000</td>
      <td>10533.000000</td>
      <td>10820.000000</td>
    </tr>
    <tr>
      <th>Applied Mathematics</th>
      <td>1938.000000</td>
      <td>1876.0</td>
      <td>1544.000000</td>
      <td>1551.000000</td>
      <td>1937.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Pharmaceutics</th>
      <td>8064.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Physics</th>
      <td>1919.666667</td>
      <td>2989.5</td>
      <td>2403.500000</td>
      <td>3155.500000</td>
      <td>2441.500000</td>
      <td>2978.375000</td>
    </tr>
    <tr>
      <th>Polymer Science and Engineering</th>
      <td>5943.000000</td>
      <td>6088.0</td>
      <td>6632.000000</td>
      <td>6962.000000</td>
      <td>7165.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Production and Industrial Engineering</th>
      <td>2269.000000</td>
      <td>2780.0</td>
      <td>2857.500000</td>
      <td>2912.500000</td>
      <td>2932.000000</td>
      <td>3219.750000</td>
    </tr>
    <tr>
      <th>Quality Engineering Design and Manufacturing</th>
      <td>4496.000000</td>
      <td>3990.0</td>
      <td>4093.000000</td>
      <td>3720.000000</td>
      <td>5568.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Statistics and Data Science</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>492.000000</td>
    </tr>
    <tr>
      <th>Textile Technology</th>
      <td>2826.000000</td>
      <td>3481.0</td>
      <td>3624.000000</td>
      <td>3937.000000</td>
      <td>4470.000000</td>
      <td>4012.000000</td>
    </tr>
  </tbody>
</table>
<p>115 rows × 6 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_iit, __output__ </p>
    
          <p>df_iit (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>institute_type</th>
      <th>round_no</th>
      <th>quota</th>
      <th>pool</th>
      <th>institute_short</th>
      <th>program_name</th>
      <th>program_duration</th>
      <th>degree_short</th>
      <th>category</th>
      <th>opening_rank</th>
      <th>closing_rank</th>
      <th>is_preparatory</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>838</td>
      <td>1841</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>422</td>
      <td>1479</td>
      <td>0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemistry</td>
      <td>4 Years</td>
      <td>BSc</td>
      <td>GEN</td>
      <td>3323</td>
      <td>4880</td>
      <td>0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>897</td>
      <td>2251</td>
      <td>0</td>
    </tr>
    <tr>
      <th>25</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>1</td>
      <td>60</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Electrical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>22</td>
      <td>227</td>
      <td>0</td>
    </tr>
    <tr>
      <th>37</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Electrical Engineering with M.Tech. in Communications and Signal Processing</td>
      <td>5 Years</td>
      <td>B.Tech + M.Tech (IDD)</td>
      <td>GEN</td>
      <td>249</td>
      <td>583</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>13092</th>
      <td>2021</td>
      <td>IIT</td>
      <td>2</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Roorkee</td>
      <td>Geological Technology</td>
      <td>5 Years</td>
      <td>Int M.Tech</td>
      <td>GEN</td>
      <td>8390</td>
      <td>9430</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13102</th>
      <td>2021</td>
      <td>IIT</td>
      <td>2</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Roorkee</td>
      <td>Geophysical Technology</td>
      <td>5 Years</td>
      <td>Int M.Tech</td>
      <td>GEN</td>
      <td>7481</td>
      <td>8919</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13112</th>
      <td>2021</td>
      <td>IIT</td>
      <td>2</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Roorkee</td>
      <td>Mathematics &amp; Computing</td>
      <td>5 Years</td>
      <td>BS + MS (IDD)</td>
      <td>GEN</td>
      <td>1336</td>
      <td>1585</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13122</th>
      <td>2021</td>
      <td>IIT</td>
      <td>2</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Roorkee</td>
      <td>Mechanical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>2246</td>
      <td>3473</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13133</th>
      <td>2021</td>
      <td>IIT</td>
      <td>2</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Roorkee</td>
      <td>Metallurgical and Materials Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>5745</td>
      <td>6471</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13143</th>
      <td>2021</td>
      <td>IIT</td>
      <td>2</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Roorkee</td>
      <td>Physics</td>
      <td>5 Years</td>
      <td>BS + MS (IDD)</td>
      <td>GEN</td>
      <td>5972</td>
      <td>7227</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13152</th>
      <td>2021</td>
      <td>IIT</td>
      <td>2</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Roorkee</td>
      <td>Production and Industrial Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>4200</td>
      <td>5194</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>1605 rows × 13 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="6" halign="left">opening_rank</th>
    </tr>
    <tr>
      <th>year</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
    <tr>
      <th>program_name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Aerospace Engineering</th>
      <td>2072.833333</td>
      <td>1806.0</td>
      <td>2157.666667</td>
      <td>2278.833333</td>
      <td>2477.166667</td>
      <td>1977.083333</td>
    </tr>
    <tr>
      <th>Agricultural and Food Engineering</th>
      <td>4321.000000</td>
      <td>5183.0</td>
      <td>4614.000000</td>
      <td>5247.000000</td>
      <td>7039.000000</td>
      <td>6491.000000</td>
    </tr>
    <tr>
      <th>Agricultural and Food Engineering with M.Tech. in any of the listed specializations</th>
      <td>6306.000000</td>
      <td>6939.0</td>
      <td>6949.000000</td>
      <td>NaN</td>
      <td>7291.000000</td>
      <td>7769.000000</td>
    </tr>
    <tr>
      <th>Agricultural and Food Engineering with M.Tech. in any of the listedspecializations</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>8114.000000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Applied Geology</th>
      <td>6596.000000</td>
      <td>7875.0</td>
      <td>8550.000000</td>
      <td>9935.000000</td>
      <td>10901.000000</td>
      <td>9836.666667</td>
    </tr>
    <tr>
      <th>Applied Geophysics</th>
      <td>6760.000000</td>
      <td>9211.0</td>
      <td>8572.000000</td>
      <td>10064.000000</td>
      <td>10533.000000</td>
      <td>10820.000000</td>
    </tr>
    <tr>
      <th>Applied Mathematics</th>
      <td>1938.000000</td>
      <td>1876.0</td>
      <td>1544.000000</td>
      <td>1551.000000</td>
      <td>1937.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Pharmaceutics</th>
      <td>8064.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Physics</th>
      <td>1919.666667</td>
      <td>2989.5</td>
      <td>2403.500000</td>
      <td>3155.500000</td>
      <td>2441.500000</td>
      <td>2978.375000</td>
    </tr>
    <tr>
      <th>Polymer Science and Engineering</th>
      <td>5943.000000</td>
      <td>6088.0</td>
      <td>6632.000000</td>
      <td>6962.000000</td>
      <td>7165.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Production and Industrial Engineering</th>
      <td>2269.000000</td>
      <td>2780.0</td>
      <td>2857.500000</td>
      <td>2912.500000</td>
      <td>2932.000000</td>
      <td>3219.750000</td>
    </tr>
    <tr>
      <th>Quality Engineering Design and Manufacturing</th>
      <td>4496.000000</td>
      <td>3990.0</td>
      <td>4093.000000</td>
      <td>3720.000000</td>
      <td>5568.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Statistics and Data Science</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>492.000000</td>
    </tr>
    <tr>
      <th>Textile Technology</th>
      <td>2826.000000</td>
      <td>3481.0</td>
      <td>3624.000000</td>
      <td>3937.000000</td>
      <td>4470.000000</td>
      <td>4012.000000</td>
    </tr>
  </tbody>
</table>
<p>115 rows × 6 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> iit-nit-data/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new column showing the city each institute is in and show the list of cities that have both an IIT and an NIT institute.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df['city'] = df.institute_short.str.split('-').apply(lambda x: x[-1])
df_cities = df[['city', 'institute_type']].groupby('city').nunique()
cities = df_cities[df_cities['institute_type'] > 1].index.tolist()
cities</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df['city'] = df.institute_short.str.split('-').apply(lambda x: x[-1])
df_cities = df[['city', 'institute_type']].groupby('city').nunique()
cities = df_cities[df_cities['institute_type'] > 1].index.tolist()
cities</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df['city'] = df.institute_short.str.split('-').apply(lambda x: x[-1])
df_cities = df[['city', 'institute_type']].groupby('city').nunique()
cities = df_cities[df_cities['institute_type'] > 1].index.tolist()
__output__ = cities
</code></pre>
        <p><span onclick="$('#var_output_b67388fe').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_b67388fe" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (list):</p>
          <pre><code>['Delhi', 'Goa', 'Patna']</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, df_cities, cities, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>institute_type</th>
      <th>round_no</th>
      <th>quota</th>
      <th>pool</th>
      <th>institute_short</th>
      <th>program_name</th>
      <th>program_duration</th>
      <th>degree_short</th>
      <th>category</th>
      <th>opening_rank</th>
      <th>closing_rank</th>
      <th>is_preparatory</th>
      <th>city</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>838</td>
      <td>1841</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>OBC-NCL</td>
      <td>408</td>
      <td>1098</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>SC</td>
      <td>297</td>
      <td>468</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>ST</td>
      <td>79</td>
      <td>145</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN-PWD</td>
      <td>94</td>
      <td>94</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>OBC-NCL-PWD</td>
      <td>45</td>
      <td>45</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>422</td>
      <td>1479</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>31134</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>JK</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>OBC-NCL</td>
      <td>73818</td>
      <td>113212</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31135</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>JK</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>SC</td>
      <td>5992</td>
      <td>14469</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31136</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>JK</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>SC</td>
      <td>14185</td>
      <td>24048</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31137</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>JK</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>ST</td>
      <td>2736</td>
      <td>4171</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31138</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>JK</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>ST</td>
      <td>10870</td>
      <td>10870</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31139</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>LA</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>166453</td>
      <td>265454</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31140</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>LA</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>215054</td>
      <td>215054</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
  </tbody>
</table>
<p>25458 rows × 14 columns</p>
      
          <p>df_cities (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>institute_type</th>
    </tr>
    <tr>
      <th>city</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(BHU) Varanasi</th>
      <td>1</td>
    </tr>
    <tr>
      <th>(ISM) Dhanbad</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Agartala</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Allahabad</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Bhilai</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Bhopal</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Bhubaneswar</th>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>Srinagar</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Surat</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Surathkal</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Tiruchirappalli</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Tirupati</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Uttarakhand</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Warangal</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>50 rows × 1 columns</p>
      
          <p>cities (list):</p>
          <pre><code>['Delhi', 'Goa', 'Patna']</code></pre>
      
          <p>__output__ (list):</p>
          <pre><code>['Delhi', 'Goa', 'Patna']</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.25, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> iit-nit-data/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the average closing ranks of those IIT and NIT institutes for each year? Show each year in columns with mean closing rank of each city and institute as values considering only general students.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_iit_nit = df[df.city.apply(lambda x: x in cities) & df.index.isin(df_general.index)]
df_iit_nit[['year', 'closing_rank', 'institute_type', 'city']].groupby(
    ['year', 'city', 'institute_type']).mean().unstack(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_iit_nit = df[df.city.apply(lambda x: x in cities) & df.index.isin(df_general.index)]
df_iit_nit[['year', 'closing_rank', 'institute_type', 'city']].groupby(
    ['year', 'city', 'institute_type']).mean().unstack(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_iit_nit = df[df.city.apply(lambda x: x in cities) & df.index.isin(
    df_general.index)]
__output__ = df_iit_nit[['year', 'closing_rank', 'institute_type', 'city']
    ].groupby(['year', 'city', 'institute_type']).mean().unstack(0)
</code></pre>
        <p><span onclick="$('#var_output_d0d392c8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d0d392c8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th colspan="6" halign="left">closing_rank</th>
    </tr>
    <tr>
      <th></th>
      <th>year</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
    <tr>
      <th>city</th>
      <th>institute_type</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">Delhi</th>
      <th>IIT</th>
      <td>2000.000000</td>
      <td>1942.000000</td>
      <td>2071.866667</td>
      <td>1991.769231</td>
      <td>2217.625000</td>
      <td>2147.617647</td>
    </tr>
    <tr>
      <th>NIT</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9651.000000</td>
      <td>12792.000000</td>
      <td>11481.333333</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Goa</th>
      <th>IIT</th>
      <td>6568.666667</td>
      <td>6854.333333</td>
      <td>6375.000000</td>
      <td>6363.250000</td>
      <td>7197.000000</td>
      <td>6669.500000</td>
    </tr>
    <tr>
      <th>NIT</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>19563.400000</td>
      <td>21988.800000</td>
      <td>18851.200000</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Patna</th>
      <th>IIT</th>
      <td>5931.000000</td>
      <td>6764.000000</td>
      <td>6609.000000</td>
      <td>8659.400000</td>
      <td>9523.166667</td>
      <td>7526.888889</td>
    </tr>
    <tr>
      <th>NIT</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>28632.250000</td>
      <td>22969.833333</td>
      <td>19541.666667</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 6 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_iit_nit, __output__ </p>
    
          <p>df_iit_nit (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>institute_type</th>
      <th>round_no</th>
      <th>quota</th>
      <th>pool</th>
      <th>institute_short</th>
      <th>program_name</th>
      <th>program_duration</th>
      <th>degree_short</th>
      <th>category</th>
      <th>opening_rank</th>
      <th>closing_rank</th>
      <th>is_preparatory</th>
      <th>city</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>85</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Biochemical Engineering and Biotechnology</td>
      <td>5 Years</td>
      <td>B.Tech + M.Tech (IDD)</td>
      <td>GEN</td>
      <td>3787</td>
      <td>4714</td>
      <td>0</td>
      <td>Delhi</td>
    </tr>
    <tr>
      <th>89</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Biotechnology and Biochemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>2609</td>
      <td>3718</td>
      <td>0</td>
      <td>Delhi</td>
    </tr>
    <tr>
      <th>94</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>980</td>
      <td>1704</td>
      <td>0</td>
      <td>Delhi</td>
    </tr>
    <tr>
      <th>95</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Chemical Engineering</td>
      <td>5 Years</td>
      <td>B.Tech + M.Tech (IDD)</td>
      <td>GEN</td>
      <td>1729</td>
      <td>2996</td>
      <td>0</td>
      <td>Delhi</td>
    </tr>
    <tr>
      <th>105</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>767</td>
      <td>2618</td>
      <td>0</td>
      <td>Delhi</td>
    </tr>
    <tr>
      <th>111</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>24</td>
      <td>115</td>
      <td>0</td>
      <td>Delhi</td>
    </tr>
    <tr>
      <th>112</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Delhi</td>
      <td>Computer Science and Engineering</td>
      <td>5 Years</td>
      <td>B.Tech + M.Tech (IDD)</td>
      <td>GEN</td>
      <td>124</td>
      <td>186</td>
      <td>0</td>
      <td>Delhi</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>28831</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Goa</td>
      <td>Mechanical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>17740</td>
      <td>22606</td>
      <td>0</td>
      <td>Goa</td>
    </tr>
    <tr>
      <th>29443</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Patna</td>
      <td>Architecture</td>
      <td>5 Years</td>
      <td>B.Arch</td>
      <td>GEN</td>
      <td>763</td>
      <td>1012</td>
      <td>0</td>
      <td>Patna</td>
    </tr>
    <tr>
      <th>29467</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Patna</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>20460</td>
      <td>34680</td>
      <td>0</td>
      <td>Patna</td>
    </tr>
    <tr>
      <th>29494</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Patna</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>10234</td>
      <td>12661</td>
      <td>0</td>
      <td>Patna</td>
    </tr>
    <tr>
      <th>29519</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Patna</td>
      <td>Electrical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>10295</td>
      <td>22989</td>
      <td>0</td>
      <td>Patna</td>
    </tr>
    <tr>
      <th>29544</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Patna</td>
      <td>Electronics and Communication Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>12935</td>
      <td>17871</td>
      <td>0</td>
      <td>Patna</td>
    </tr>
    <tr>
      <th>29570</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Patna</td>
      <td>Mechanical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>19814</td>
      <td>28037</td>
      <td>0</td>
      <td>Patna</td>
    </tr>
  </tbody>
</table>
<p>207 rows × 14 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th colspan="6" halign="left">closing_rank</th>
    </tr>
    <tr>
      <th></th>
      <th>year</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
    <tr>
      <th>city</th>
      <th>institute_type</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">Delhi</th>
      <th>IIT</th>
      <td>2000.000000</td>
      <td>1942.000000</td>
      <td>2071.866667</td>
      <td>1991.769231</td>
      <td>2217.625000</td>
      <td>2147.617647</td>
    </tr>
    <tr>
      <th>NIT</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9651.000000</td>
      <td>12792.000000</td>
      <td>11481.333333</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Goa</th>
      <th>IIT</th>
      <td>6568.666667</td>
      <td>6854.333333</td>
      <td>6375.000000</td>
      <td>6363.250000</td>
      <td>7197.000000</td>
      <td>6669.500000</td>
    </tr>
    <tr>
      <th>NIT</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>19563.400000</td>
      <td>21988.800000</td>
      <td>18851.200000</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Patna</th>
      <th>IIT</th>
      <td>5931.000000</td>
      <td>6764.000000</td>
      <td>6609.000000</td>
      <td>8659.400000</td>
      <td>9523.166667</td>
      <td>7526.888889</td>
    </tr>
    <tr>
      <th>NIT</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>28632.250000</td>
      <td>22969.833333</td>
      <td>19541.666667</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 6 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> iit-nit-data/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What were the most competitive programs in each year in terms of median opening rank? Show years as index considering only general students.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_prg = df_general[['year', 'opening_rank', 'program_name']]\
    .groupby(['year', 'program_name']).median().reset_index().sort_values('opening_rank')\
    .groupby('year').first()[['program_name']]
df_prg</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_prg = df_general[['year', 'opening_rank', 'program_name']]\
    .groupby(['year', 'program_name']).median().reset_index().sort_values('opening_rank')\
    .groupby('year').first()[['program_name']]
df_prg</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_prg = df_general[['year', 'opening_rank', 'program_name']].groupby([
    'year', 'program_name']).median().reset_index().sort_values('opening_rank'
    ).groupby('year').first()[['program_name']]
__output__ = df_prg
</code></pre>
        <p><span onclick="$('#var_output_4b88fef1').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_4b88fef1" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>program_name</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016</th>
      <td>Electrical Engineering with M.Tech. in Microelectronics</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>Mechanical Engineering and M.Tech. in Computer Integrated Manufacturing</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>Electrical Engineering with M.Tech. in Communications and Signal Processing</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>Mathematics and Scientific Computing</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>BS in Mathematics</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>Planning</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_prg, __output__ </p>
    
          <p>df_prg (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>program_name</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016</th>
      <td>Electrical Engineering with M.Tech. in Microelectronics</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>Mechanical Engineering and M.Tech. in Computer Integrated Manufacturing</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>Electrical Engineering with M.Tech. in Communications and Signal Processing</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>Mathematics and Scientific Computing</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>BS in Mathematics</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>Planning</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>program_name</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016</th>
      <td>Electrical Engineering with M.Tech. in Microelectronics</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>Mechanical Engineering and M.Tech. in Computer Integrated Manufacturing</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>Electrical Engineering with M.Tech. in Communications and Signal Processing</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>Mathematics and Scientific Computing</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>BS in Mathematics</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>Planning</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> iit-nit-data/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What program was most competitive in terms of median opening rank for each degree type in 2021? Show degree as index.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_deg = df_general[df_general.year == 2021][['degree_short', 'opening_rank', 'program_name']]\
    .groupby(['degree_short', 'program_name']).median().reset_index().sort_values('opening_rank')\
    .groupby('degree_short').first()[['program_name']]
df_deg</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_deg = df_general[df_general.year == 2021][['degree_short', 'opening_rank', 'program_name']]\
    .groupby(['degree_short', 'program_name']).median().reset_index().sort_values('opening_rank')\
    .groupby('degree_short').first()[['program_name']]
df_deg</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_deg = df_general[df_general.year == 2021][['degree_short',
    'opening_rank', 'program_name']].groupby(['degree_short', 'program_name']
    ).median().reset_index().sort_values('opening_rank').groupby('degree_short'
    ).first()[['program_name']]
__output__ = df_deg
</code></pre>
        <p><span onclick="$('#var_output_1a543d79').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_1a543d79" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>program_name</th>
    </tr>
    <tr>
      <th>degree_short</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>B.Arch</th>
      <td>Architecture</td>
    </tr>
    <tr>
      <th>B.Plan</th>
      <td>Planning</td>
    </tr>
    <tr>
      <th>B.Tech</th>
      <td>Electronics and Electrical Communication Engineering</td>
    </tr>
    <tr>
      <th>B.Tech + M.Tech (IDD)</th>
      <td>Mathematics and Computing</td>
    </tr>
    <tr>
      <th>BS + MS (IDD)</th>
      <td>Mathematics &amp; Computing</td>
    </tr>
    <tr>
      <th>BSc</th>
      <td>BS in Mathematics</td>
    </tr>
    <tr>
      <th>BSc + MSc (IDD)</th>
      <td>Mathematics &amp; Computing</td>
    </tr>
    <tr>
      <th>Btech + M.Tech (IDD)</th>
      <td>Mathematics and Data Science</td>
    </tr>
    <tr>
      <th>Int M.Tech</th>
      <td>Mathematics and Computing</td>
    </tr>
    <tr>
      <th>Int Msc.</th>
      <td>Physics</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_deg, __output__ </p>
    
          <p>df_deg (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>program_name</th>
    </tr>
    <tr>
      <th>degree_short</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>B.Arch</th>
      <td>Architecture</td>
    </tr>
    <tr>
      <th>B.Plan</th>
      <td>Planning</td>
    </tr>
    <tr>
      <th>B.Tech</th>
      <td>Electronics and Electrical Communication Engineering</td>
    </tr>
    <tr>
      <th>B.Tech + M.Tech (IDD)</th>
      <td>Mathematics and Computing</td>
    </tr>
    <tr>
      <th>BS + MS (IDD)</th>
      <td>Mathematics &amp; Computing</td>
    </tr>
    <tr>
      <th>BSc</th>
      <td>BS in Mathematics</td>
    </tr>
    <tr>
      <th>BSc + MSc (IDD)</th>
      <td>Mathematics &amp; Computing</td>
    </tr>
    <tr>
      <th>Btech + M.Tech (IDD)</th>
      <td>Mathematics and Data Science</td>
    </tr>
    <tr>
      <th>Int M.Tech</th>
      <td>Mathematics and Computing</td>
    </tr>
    <tr>
      <th>Int Msc.</th>
      <td>Physics</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>program_name</th>
    </tr>
    <tr>
      <th>degree_short</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>B.Arch</th>
      <td>Architecture</td>
    </tr>
    <tr>
      <th>B.Plan</th>
      <td>Planning</td>
    </tr>
    <tr>
      <th>B.Tech</th>
      <td>Electronics and Electrical Communication Engineering</td>
    </tr>
    <tr>
      <th>B.Tech + M.Tech (IDD)</th>
      <td>Mathematics and Computing</td>
    </tr>
    <tr>
      <th>BS + MS (IDD)</th>
      <td>Mathematics &amp; Computing</td>
    </tr>
    <tr>
      <th>BSc</th>
      <td>BS in Mathematics</td>
    </tr>
    <tr>
      <th>BSc + MSc (IDD)</th>
      <td>Mathematics &amp; Computing</td>
    </tr>
    <tr>
      <th>Btech + M.Tech (IDD)</th>
      <td>Mathematics and Data Science</td>
    </tr>
    <tr>
      <th>Int M.Tech</th>
      <td>Mathematics and Computing</td>
    </tr>
    <tr>
      <th>Int Msc.</th>
      <td>Physics</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> iit-nit-data/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For each quota type in 2019, which degree was most sought after in terms of median closing rank? Show quota type as index.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_quota = df[df.year == 2019][['degree_short', 'closing_rank', 'quota']]\
    .groupby(['degree_short', 'quota']).median().reset_index().sort_values('closing_rank')\
    .groupby('quota').first()[['degree_short']]
df_quota</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_quota = df[df.year == 2019][['degree_short', 'closing_rank', 'quota']]\
    .groupby(['degree_short', 'quota']).median().reset_index().sort_values('closing_rank')\
    .groupby('quota').first()[['degree_short']]
df_quota</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_quota = df[df.year == 2019][['degree_short', 'closing_rank', 'quota']
    ].groupby(['degree_short', 'quota']).median().reset_index().sort_values(
    'closing_rank').groupby('quota').first()[['degree_short']]
__output__ = df_quota
</code></pre>
        <p><span onclick="$('#var_output_6adf17d8').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_6adf17d8" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>degree_short</th>
    </tr>
    <tr>
      <th>quota</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>AI</th>
      <td>B.Tech</td>
    </tr>
    <tr>
      <th>AP</th>
      <td>B.Tech</td>
    </tr>
    <tr>
      <th>GO</th>
      <td>B.Tech</td>
    </tr>
    <tr>
      <th>HS</th>
      <td>B.Arch</td>
    </tr>
    <tr>
      <th>OS</th>
      <td>B.Arch</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_quota, __output__ </p>
    
          <p>df_quota (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>degree_short</th>
    </tr>
    <tr>
      <th>quota</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>AI</th>
      <td>B.Tech</td>
    </tr>
    <tr>
      <th>AP</th>
      <td>B.Tech</td>
    </tr>
    <tr>
      <th>GO</th>
      <td>B.Tech</td>
    </tr>
    <tr>
      <th>HS</th>
      <td>B.Arch</td>
    </tr>
    <tr>
      <th>OS</th>
      <td>B.Arch</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>degree_short</th>
    </tr>
    <tr>
      <th>quota</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>AI</th>
      <td>B.Tech</td>
    </tr>
    <tr>
      <th>AP</th>
      <td>B.Tech</td>
    </tr>
    <tr>
      <th>GO</th>
      <td>B.Tech</td>
    </tr>
    <tr>
      <th>HS</th>
      <td>B.Arch</td>
    </tr>
    <tr>
      <th>OS</th>
      <td>B.Arch</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> iit-nit-data/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For each year, what institute was the hardest to get into in terms of median closing rank? Show year as index and consider only general applicants.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_inst = df_general[['year', 'closing_rank', 'institute_short']]\
    .groupby(['year', 'institute_short']).median().reset_index().sort_values('closing_rank')\
    .groupby('year').first()[['institute_short']]
df_inst</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_inst = df_general[['year', 'closing_rank', 'institute_short']]\
    .groupby(['year', 'institute_short']).median().reset_index().sort_values('closing_rank')\
    .groupby('year').first()[['institute_short']]
df_inst</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_inst = df_general[['year', 'closing_rank', 'institute_short']].groupby([
    'year', 'institute_short']).median().reset_index().sort_values(
    'closing_rank').groupby('year').first()[['institute_short']]
__output__ = df_inst
</code></pre>
        <p><span onclick="$('#var_output_f1ffaf5c').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_f1ffaf5c" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>institute_short</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016</th>
      <td>IIT-Bombay</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>IIT-Bombay</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>IIT-Delhi</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>IIT-Delhi</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>IIT-Delhi</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>IIT-Bombay</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_inst, __output__ </p>
    
          <p>df_inst (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>institute_short</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016</th>
      <td>IIT-Bombay</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>IIT-Bombay</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>IIT-Delhi</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>IIT-Delhi</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>IIT-Delhi</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>IIT-Bombay</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>institute_short</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016</th>
      <td>IIT-Bombay</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>IIT-Bombay</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>IIT-Delhi</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>IIT-Delhi</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>IIT-Delhi</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>IIT-Bombay</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 1 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> iit-nit-data/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What was the average closing rank of each pool type in each year? Show year in columns and consider only general category with no quotas (AI or OS).</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_p = df[(df.quota.str.contains('AI|OS'))
             & (df.category=='GEN')]
df_p[['year', 'closing_rank', 'pool']].groupby(['year', 'pool']).mean().unstack(0)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_p = df[(df.quota.str.contains('AI|OS'))
             & (df.category=='GEN')]
df_p[['year', 'closing_rank', 'pool']].groupby(['year', 'pool']).mean().unstack(0)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_p = df[df.quota.str.contains('AI|OS') & (df.category == 'GEN')]
__output__ = df_p[['year', 'closing_rank', 'pool']].groupby(['year', 'pool']
    ).mean().unstack(0)
</code></pre>
        <p><span onclick="$('#var_output_c5521ea4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_c5521ea4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="6" halign="left">closing_rank</th>
    </tr>
    <tr>
      <th>year</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
    <tr>
      <th>pool</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Female-Only</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>7858.10</td>
      <td>19135.209459</td>
      <td>20803.792411</td>
      <td>16601.902998</td>
    </tr>
    <tr>
      <th>Gender-Neutral</th>
      <td>6642.014388</td>
      <td>5003.155102</td>
      <td>5182.78</td>
      <td>14352.074890</td>
      <td>15604.406048</td>
      <td>11527.516295</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 6 columns</p>
      
        <p><strong>Hyp output variables:</strong> df_p, __output__ </p>
    
          <p>df_p (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>institute_type</th>
      <th>round_no</th>
      <th>quota</th>
      <th>pool</th>
      <th>institute_short</th>
      <th>program_name</th>
      <th>program_duration</th>
      <th>degree_short</th>
      <th>category</th>
      <th>opening_rank</th>
      <th>closing_rank</th>
      <th>is_preparatory</th>
      <th>city</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Aerospace Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>838</td>
      <td>1841</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>422</td>
      <td>1479</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>14</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Chemistry</td>
      <td>4 Years</td>
      <td>BSc</td>
      <td>GEN</td>
      <td>3323</td>
      <td>4880</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>19</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>897</td>
      <td>2251</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>25</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>1</td>
      <td>60</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>31</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Electrical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>22</td>
      <td>227</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>37</th>
      <td>2016</td>
      <td>IIT</td>
      <td>6</td>
      <td>AI</td>
      <td>Gender-Neutral</td>
      <td>IIT-Bombay</td>
      <td>Electrical Engineering with M.Tech. in Communications and Signal Processing</td>
      <td>5 Years</td>
      <td>B.Tech + M.Tech (IDD)</td>
      <td>GEN</td>
      <td>249</td>
      <td>583</td>
      <td>0</td>
      <td>Bombay</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>31047</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Chemical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>41021</td>
      <td>45475</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31069</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>35472</td>
      <td>43558</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31070</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Civil Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>46239</td>
      <td>49641</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31093</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>8851</td>
      <td>19669</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31094</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Computer Science and Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>20553</td>
      <td>25231</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31116</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Gender-Neutral</td>
      <td>NIT-Srinagar</td>
      <td>Electrical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>27275</td>
      <td>35311</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
    <tr>
      <th>31117</th>
      <td>2021</td>
      <td>NIT</td>
      <td>1</td>
      <td>OS</td>
      <td>Female-Only</td>
      <td>NIT-Srinagar</td>
      <td>Electrical Engineering</td>
      <td>4 Years</td>
      <td>B.Tech</td>
      <td>GEN</td>
      <td>39397</td>
      <td>42620</td>
      <td>0</td>
      <td>Srinagar</td>
    </tr>
  </tbody>
</table>
<p>3982 rows × 14 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="6" halign="left">closing_rank</th>
    </tr>
    <tr>
      <th>year</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
    <tr>
      <th>pool</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Female-Only</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>7858.10</td>
      <td>19135.209459</td>
      <td>20803.792411</td>
      <td>16601.902998</td>
    </tr>
    <tr>
      <th>Gender-Neutral</th>
      <td>6642.014388</td>
      <td>5003.155102</td>
      <td>5182.78</td>
      <td>14352.074890</td>
      <td>15604.406048</td>
      <td>11527.516295</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 6 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-ukraine-conflict/notebook_1.ipynb|||turn_0 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Remove columns with no non-null values.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>columns_to_include = [column for column in df.columns if len(df[column].dropna())]
df = df[columns_to_include]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>columns_to_include = [column for column in df.columns if len(df[column].dropna())]
df = df[columns_to_include]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>columns_to_include = [column for column in df.columns if len(df[column].
    dropna())]
__output__ = df = df[columns_to_include]
</code></pre>
        <p><span onclick="$('#var_output_8a29dd7e').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_8a29dd7e" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>conversation_id</th>
      <th>created_at</th>
      <th>date</th>
      <th>time</th>
      <th>timezone</th>
      <th>user_id</th>
      <th>...</th>
      <th>cashtags</th>
      <th>link</th>
      <th>retweet</th>
      <th>quote_url</th>
      <th>video</th>
      <th>thumbnail</th>
      <th>reply_to</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1546893528218976256</td>
      <td>1546893528218976256</td>
      <td>2022-07-12 21:55:31 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:31</td>
      <td>530</td>
      <td>1459600109445033990</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/ejustin46/status/1546893528218976256</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1546893503208251393</td>
      <td>1546893503208251393</td>
      <td>2022-07-12 21:55:25 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:25</td>
      <td>530</td>
      <td>122167302</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Ing_Var/status/1546893503208251393</td>
      <td>False</td>
      <td>https://twitter.com/lilygrutcher/status/1546805702089445376</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1546893476402536454</td>
      <td>1546893476402536454</td>
      <td>2022-07-12 21:55:19 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:19</td>
      <td>530</td>
      <td>581782217</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/cliffordribner/status/1546893476402536454</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1546893470421471240</td>
      <td>1546893470421471240</td>
      <td>2022-07-12 21:55:17 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:17</td>
      <td>530</td>
      <td>626731783</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/kroon125/status/1546893470421471240</td>
      <td>False</td>
      <td>NaN</td>
      <td>1</td>
      <td>https://pbs.twimg.com/media/FXerRyGXwAAN04Q.jpg</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1546893303584546816</td>
      <td>1546893303584546816</td>
      <td>2022-07-12 21:54:38 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:54:38</td>
      <td>530</td>
      <td>122167302</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Ing_Var/status/1546893303584546816</td>
      <td>False</td>
      <td>https://twitter.com/vyshebaba/status/1546472239767371782</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1546893107404455936</td>
      <td>1546893107404455936</td>
      <td>2022-07-12 21:53:51 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:53:51</td>
      <td>530</td>
      <td>821227993741885441</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/LukeRussell1281/status/1546893107404455936</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1546893050345127941</td>
      <td>1541210396463431681</td>
      <td>2022-07-12 21:53:37 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:53:37</td>
      <td>530</td>
      <td>98780424</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Blockdog1/status/1546893050345127941</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'PatrykLesniak7', 'name': 'Lightning', 'id': '1382847873814044674'}, {'screen_name': 'StoneMan489', 'name': 'Matt stone489', 'id': '1428663970408407041'}, {'screen_name': 'brxarx', 'name': 'Brxarx', 'id': '1304301715634548737'}, {'screen_name': 'RajendranTheva1', 'name': 'Wisdom_trade1', 'id': '1253367340768456705'}, {'screen_name': 'QuocVu59239912', 'name': 'Bloody_Slayer', 'id': '1233063275434143744'}, {'screen_name': 'War_Mapper', 'name': 'Ukraine War Map', 'id': '1496850942209183744'}]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>43390</th>
      <td>1543352577890209792</td>
      <td>1543352577890209792</td>
      <td>2022-07-03 03:25:03 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:25:03</td>
      <td>530</td>
      <td>1196304745603817472</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/dissectmarkets/status/1543352577890209792</td>
      <td>False</td>
      <td>https://twitter.com/jseldin/status/1541792996596875267</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43391</th>
      <td>1543352573121396736</td>
      <td>1543352573121396736</td>
      <td>2022-07-03 03:25:02 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:25:02</td>
      <td>530</td>
      <td>422071593</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GFloars/status/1543352573121396736</td>
      <td>False</td>
      <td>https://twitter.com/Aryan_warlord/status/1543289684981211137</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43392</th>
      <td>1543352544776392705</td>
      <td>1543352544776392705</td>
      <td>2022-07-03 03:24:55 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:55</td>
      <td>530</td>
      <td>2255439716</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GuntersChain/status/1543352544776392705</td>
      <td>False</td>
      <td>https://twitter.com/uawarinfo/status/1543350776654974978</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43393</th>
      <td>1543352544684122113</td>
      <td>1543352544684122113</td>
      <td>2022-07-03 03:24:55 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:55</td>
      <td>530</td>
      <td>3104222776</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Rebel44CZ/status/1543352544684122113</td>
      <td>False</td>
      <td>NaN</td>
      <td>1</td>
      <td>https://pbs.twimg.com/media/FWsWONDXgAEOizv.jpg</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43394</th>
      <td>1543352492624338945</td>
      <td>1542993153912881152</td>
      <td>2022-07-03 03:24:43 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:43</td>
      <td>530</td>
      <td>505370909</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/AmyXi11/status/1543352492624338945</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'NogrowthCole', 'name': 'cole', 'id': '1493598763'}, {'screen_name': 'RyanMaue', 'name': 'Ryan Maue', 'id': '16117029'}]</td>
    </tr>
    <tr>
      <th>43395</th>
      <td>1543352478409887745</td>
      <td>1543326437742198784</td>
      <td>2022-07-03 03:24:39 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:39</td>
      <td>530</td>
      <td>1542154254055612416</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Somethngisthere/status/1543352478409887745</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'TimothyDSnyder', 'name': 'Timothy Snyder', 'id': '3129968261'}]</td>
    </tr>
    <tr>
      <th>43396</th>
      <td>1543352455064440832</td>
      <td>1543006934097338368</td>
      <td>2022-07-03 03:24:34 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:34</td>
      <td>530</td>
      <td>1300763166624886784</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GladesYouth/status/1543352455064440832</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'MikeMalloyShow', 'name': 'The Mike Malloy Show', 'id': '27433794'}]</td>
    </tr>
  </tbody>
</table>
<p>43397 rows × 26 columns</p>
      
        <p><strong>Hyp output variables:</strong> df, columns_to_include, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>conversation_id</th>
      <th>created_at</th>
      <th>date</th>
      <th>time</th>
      <th>timezone</th>
      <th>user_id</th>
      <th>...</th>
      <th>cashtags</th>
      <th>link</th>
      <th>retweet</th>
      <th>quote_url</th>
      <th>video</th>
      <th>thumbnail</th>
      <th>reply_to</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1546893528218976256</td>
      <td>1546893528218976256</td>
      <td>2022-07-12 21:55:31 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:31</td>
      <td>530</td>
      <td>1459600109445033990</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/ejustin46/status/1546893528218976256</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1546893503208251393</td>
      <td>1546893503208251393</td>
      <td>2022-07-12 21:55:25 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:25</td>
      <td>530</td>
      <td>122167302</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Ing_Var/status/1546893503208251393</td>
      <td>False</td>
      <td>https://twitter.com/lilygrutcher/status/1546805702089445376</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1546893476402536454</td>
      <td>1546893476402536454</td>
      <td>2022-07-12 21:55:19 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:19</td>
      <td>530</td>
      <td>581782217</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/cliffordribner/status/1546893476402536454</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1546893470421471240</td>
      <td>1546893470421471240</td>
      <td>2022-07-12 21:55:17 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:17</td>
      <td>530</td>
      <td>626731783</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/kroon125/status/1546893470421471240</td>
      <td>False</td>
      <td>NaN</td>
      <td>1</td>
      <td>https://pbs.twimg.com/media/FXerRyGXwAAN04Q.jpg</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1546893303584546816</td>
      <td>1546893303584546816</td>
      <td>2022-07-12 21:54:38 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:54:38</td>
      <td>530</td>
      <td>122167302</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Ing_Var/status/1546893303584546816</td>
      <td>False</td>
      <td>https://twitter.com/vyshebaba/status/1546472239767371782</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1546893107404455936</td>
      <td>1546893107404455936</td>
      <td>2022-07-12 21:53:51 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:53:51</td>
      <td>530</td>
      <td>821227993741885441</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/LukeRussell1281/status/1546893107404455936</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1546893050345127941</td>
      <td>1541210396463431681</td>
      <td>2022-07-12 21:53:37 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:53:37</td>
      <td>530</td>
      <td>98780424</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Blockdog1/status/1546893050345127941</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'PatrykLesniak7', 'name': 'Lightning', 'id': '1382847873814044674'}, {'screen_name': 'StoneMan489', 'name': 'Matt stone489', 'id': '1428663970408407041'}, {'screen_name': 'brxarx', 'name': 'Brxarx', 'id': '1304301715634548737'}, {'screen_name': 'RajendranTheva1', 'name': 'Wisdom_trade1', 'id': '1253367340768456705'}, {'screen_name': 'QuocVu59239912', 'name': 'Bloody_Slayer', 'id': '1233063275434143744'}, {'screen_name': 'War_Mapper', 'name': 'Ukraine War Map', 'id': '1496850942209183744'}]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>43390</th>
      <td>1543352577890209792</td>
      <td>1543352577890209792</td>
      <td>2022-07-03 03:25:03 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:25:03</td>
      <td>530</td>
      <td>1196304745603817472</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/dissectmarkets/status/1543352577890209792</td>
      <td>False</td>
      <td>https://twitter.com/jseldin/status/1541792996596875267</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43391</th>
      <td>1543352573121396736</td>
      <td>1543352573121396736</td>
      <td>2022-07-03 03:25:02 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:25:02</td>
      <td>530</td>
      <td>422071593</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GFloars/status/1543352573121396736</td>
      <td>False</td>
      <td>https://twitter.com/Aryan_warlord/status/1543289684981211137</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43392</th>
      <td>1543352544776392705</td>
      <td>1543352544776392705</td>
      <td>2022-07-03 03:24:55 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:55</td>
      <td>530</td>
      <td>2255439716</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GuntersChain/status/1543352544776392705</td>
      <td>False</td>
      <td>https://twitter.com/uawarinfo/status/1543350776654974978</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43393</th>
      <td>1543352544684122113</td>
      <td>1543352544684122113</td>
      <td>2022-07-03 03:24:55 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:55</td>
      <td>530</td>
      <td>3104222776</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Rebel44CZ/status/1543352544684122113</td>
      <td>False</td>
      <td>NaN</td>
      <td>1</td>
      <td>https://pbs.twimg.com/media/FWsWONDXgAEOizv.jpg</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43394</th>
      <td>1543352492624338945</td>
      <td>1542993153912881152</td>
      <td>2022-07-03 03:24:43 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:43</td>
      <td>530</td>
      <td>505370909</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/AmyXi11/status/1543352492624338945</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'NogrowthCole', 'name': 'cole', 'id': '1493598763'}, {'screen_name': 'RyanMaue', 'name': 'Ryan Maue', 'id': '16117029'}]</td>
    </tr>
    <tr>
      <th>43395</th>
      <td>1543352478409887745</td>
      <td>1543326437742198784</td>
      <td>2022-07-03 03:24:39 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:39</td>
      <td>530</td>
      <td>1542154254055612416</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Somethngisthere/status/1543352478409887745</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'TimothyDSnyder', 'name': 'Timothy Snyder', 'id': '3129968261'}]</td>
    </tr>
    <tr>
      <th>43396</th>
      <td>1543352455064440832</td>
      <td>1543006934097338368</td>
      <td>2022-07-03 03:24:34 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:34</td>
      <td>530</td>
      <td>1300763166624886784</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GladesYouth/status/1543352455064440832</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'MikeMalloyShow', 'name': 'The Mike Malloy Show', 'id': '27433794'}]</td>
    </tr>
  </tbody>
</table>
<p>43397 rows × 26 columns</p>
      
          <p>columns_to_include (list):</p>
          <pre><code>['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone', 'user_id', 'username', 'name', 'place', 'tweet', 'language', 'mentions', 'urls', 'photos', 'replies_count', 'retweets_count', 'likes_count', 'hashtags', 'cashtags', 'link', 'retweet', 'quote_url', 'video', 'thumbnail', 'reply_to']</code></pre>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>conversation_id</th>
      <th>created_at</th>
      <th>date</th>
      <th>time</th>
      <th>timezone</th>
      <th>user_id</th>
      <th>...</th>
      <th>cashtags</th>
      <th>link</th>
      <th>retweet</th>
      <th>quote_url</th>
      <th>video</th>
      <th>thumbnail</th>
      <th>reply_to</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1546893528218976256</td>
      <td>1546893528218976256</td>
      <td>2022-07-12 21:55:31 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:31</td>
      <td>530</td>
      <td>1459600109445033990</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/ejustin46/status/1546893528218976256</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1546893503208251393</td>
      <td>1546893503208251393</td>
      <td>2022-07-12 21:55:25 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:25</td>
      <td>530</td>
      <td>122167302</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Ing_Var/status/1546893503208251393</td>
      <td>False</td>
      <td>https://twitter.com/lilygrutcher/status/1546805702089445376</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1546893476402536454</td>
      <td>1546893476402536454</td>
      <td>2022-07-12 21:55:19 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:19</td>
      <td>530</td>
      <td>581782217</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/cliffordribner/status/1546893476402536454</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1546893470421471240</td>
      <td>1546893470421471240</td>
      <td>2022-07-12 21:55:17 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:17</td>
      <td>530</td>
      <td>626731783</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/kroon125/status/1546893470421471240</td>
      <td>False</td>
      <td>NaN</td>
      <td>1</td>
      <td>https://pbs.twimg.com/media/FXerRyGXwAAN04Q.jpg</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1546893303584546816</td>
      <td>1546893303584546816</td>
      <td>2022-07-12 21:54:38 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:54:38</td>
      <td>530</td>
      <td>122167302</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Ing_Var/status/1546893303584546816</td>
      <td>False</td>
      <td>https://twitter.com/vyshebaba/status/1546472239767371782</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1546893107404455936</td>
      <td>1546893107404455936</td>
      <td>2022-07-12 21:53:51 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:53:51</td>
      <td>530</td>
      <td>821227993741885441</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/LukeRussell1281/status/1546893107404455936</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1546893050345127941</td>
      <td>1541210396463431681</td>
      <td>2022-07-12 21:53:37 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:53:37</td>
      <td>530</td>
      <td>98780424</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Blockdog1/status/1546893050345127941</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'PatrykLesniak7', 'name': 'Lightning', 'id': '1382847873814044674'}, {'screen_name': 'StoneMan489', 'name': 'Matt stone489', 'id': '1428663970408407041'}, {'screen_name': 'brxarx', 'name': 'Brxarx', 'id': '1304301715634548737'}, {'screen_name': 'RajendranTheva1', 'name': 'Wisdom_trade1', 'id': '1253367340768456705'}, {'screen_name': 'QuocVu59239912', 'name': 'Bloody_Slayer', 'id': '1233063275434143744'}, {'screen_name': 'War_Mapper', 'name': 'Ukraine War Map', 'id': '1496850942209183744'}]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>43390</th>
      <td>1543352577890209792</td>
      <td>1543352577890209792</td>
      <td>2022-07-03 03:25:03 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:25:03</td>
      <td>530</td>
      <td>1196304745603817472</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/dissectmarkets/status/1543352577890209792</td>
      <td>False</td>
      <td>https://twitter.com/jseldin/status/1541792996596875267</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43391</th>
      <td>1543352573121396736</td>
      <td>1543352573121396736</td>
      <td>2022-07-03 03:25:02 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:25:02</td>
      <td>530</td>
      <td>422071593</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GFloars/status/1543352573121396736</td>
      <td>False</td>
      <td>https://twitter.com/Aryan_warlord/status/1543289684981211137</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43392</th>
      <td>1543352544776392705</td>
      <td>1543352544776392705</td>
      <td>2022-07-03 03:24:55 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:55</td>
      <td>530</td>
      <td>2255439716</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GuntersChain/status/1543352544776392705</td>
      <td>False</td>
      <td>https://twitter.com/uawarinfo/status/1543350776654974978</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43393</th>
      <td>1543352544684122113</td>
      <td>1543352544684122113</td>
      <td>2022-07-03 03:24:55 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:55</td>
      <td>530</td>
      <td>3104222776</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Rebel44CZ/status/1543352544684122113</td>
      <td>False</td>
      <td>NaN</td>
      <td>1</td>
      <td>https://pbs.twimg.com/media/FWsWONDXgAEOizv.jpg</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43394</th>
      <td>1543352492624338945</td>
      <td>1542993153912881152</td>
      <td>2022-07-03 03:24:43 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:43</td>
      <td>530</td>
      <td>505370909</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/AmyXi11/status/1543352492624338945</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'NogrowthCole', 'name': 'cole', 'id': '1493598763'}, {'screen_name': 'RyanMaue', 'name': 'Ryan Maue', 'id': '16117029'}]</td>
    </tr>
    <tr>
      <th>43395</th>
      <td>1543352478409887745</td>
      <td>1543326437742198784</td>
      <td>2022-07-03 03:24:39 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:39</td>
      <td>530</td>
      <td>1542154254055612416</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Somethngisthere/status/1543352478409887745</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'TimothyDSnyder', 'name': 'Timothy Snyder', 'id': '3129968261'}]</td>
    </tr>
    <tr>
      <th>43396</th>
      <td>1543352455064440832</td>
      <td>1543006934097338368</td>
      <td>2022-07-03 03:24:34 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:34</td>
      <td>530</td>
      <td>1300763166624886784</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GladesYouth/status/1543352455064440832</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'MikeMalloyShow', 'name': 'The Mike Malloy Show', 'id': '27433794'}]</td>
    </tr>
  </tbody>
</table>
<p>43397 rows × 26 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-ukraine-conflict/notebook_1.ipynb|||turn_1 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # In how many tweets are there mentions?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>mentions = df.mentions.apply(eval).apply(lambda x: x if x else None)
len(mentions.dropna())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>mentions = df.mentions.apply(eval).apply(lambda x: x if x else None)
len(mentions.dropna())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>mentions = df.mentions.apply(eval).apply(lambda x: x if x else None)
__output__ = len(mentions.dropna())
</code></pre>
        <p><span onclick="$('#var_output_02a903de').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_02a903de" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>4371</code></pre>
      
        <p><strong>Hyp output variables:</strong> mentions, __output__ </p>
    
          <p>mentions (Series):</p>
          <pre><code>0        None
1        None
2        None
3        None
4        None
         ... 
43392    None
43393    None
43394    None
43395    None
43396    None
Name: mentions, Length: 43397, dtype: object</code></pre>
      
          <p>__output__ (int):</p>
          <pre><code>4371</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-ukraine-conflict/notebook_1.ipynb|||turn_2 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many of those tweets also contain hashtags?</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>hashtags = df.loc[mentions.dropna().index].hashtags.apply(lambda x: x if x else None)
len(hashtags.dropna())</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>hashtags = df.loc[mentions.dropna().index].hashtags.apply(lambda x: x if x else None)
len(hashtags.dropna())</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>hashtags = df.loc[mentions.dropna().index].hashtags.apply(lambda x: x if x else
    None)
__output__ = len(hashtags.dropna())
</code></pre>
        <p><span onclick="$('#var_output_9f2857c6').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_9f2857c6" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (int):</p>
          <pre><code>4371</code></pre>
      
        <p><strong>Hyp output variables:</strong> hashtags, __output__ </p>
    
          <p>hashtags (Series):</p>
          <pre><code>21                                                      []
25                                                      []
27                                                      []
28                                                      []
44                                                      []
                               ...                        
43377                                                   []
43384    ['stopputin', 'ukrainewar', 'stoprussia', 'spo...
43386    ['walterreport', 'ukraine️', 'ukrainewar', 'uk...
43387            ['ukrainewar', 'ukraine', 'kotvytskyymp']
43388                         ['russia', 'ukraine', 'war']
Name: hashtags, Length: 4371, dtype: object</code></pre>
      
          <p>__output__ (int):</p>
          <pre><code>4371</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-ukraine-conflict/notebook_1.ipynb|||turn_3 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most trending hashtag? Consider unique tags made in single tweet amd show the number of tweets along with the tag name.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>hashtag_set = df.hashtags.apply(eval).apply(lambda x: x if x else None).dropna().apply(set)
Counter(hashtag_set.explode()).most_common(1)[0]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>hashtag_set = df.hashtags.apply(eval).apply(lambda x: x if x else None).dropna().apply(set)
Counter(hashtag_set.explode()).most_common(1)[0]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>hashtag_set = df.hashtags.apply(eval).apply(lambda x: x if x else None).dropna(
    ).apply(set)
__output__ = Counter(hashtag_set.explode()).most_common(1)[0]
</code></pre>
        <p><span onclick="$('#var_output_5e4fddbb').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5e4fddbb" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (tuple):</p>
          <pre><code>('ukrainewar', 15925)</code></pre>
      
        <p><strong>Hyp output variables:</strong> hashtag_set, __output__ </p>
    
          <p>hashtag_set (Series):</p>
          <pre><code>1        {ukraine, ukrainewar, russianukrainianwar, rus...
2                     {ukraine, putin, war, biden, russia}
3        {ukraine, stoprussianaggression, ukrainewar, u...
4        {ukraine, ukrainewar, russianukrainianwar, rus...
13       {ukraine, ukrainewar, russianukrainianwar, rus...
                               ...                        
43389                                         {ukrainewar}
43391             {ukraine, ukrainewar, ukrainerussianwar}
43392                      {ukrainewar, ukrainerussianwar}
43393                                         {ukrainewar}
43396                                         {ukrainewar}
Name: hashtags, Length: 20362, dtype: object</code></pre>
      
          <p>__output__ (tuple):</p>
          <pre><code>('ukrainewar', 15925)</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-ukraine-conflict/notebook_1.ipynb|||turn_4 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Convert the elements of the url column to python list. Make empty lists NaN.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def remove_empty_urls(x: list):
    for i in x:
        if i == '':
            x.remove(i)
    return x

df.urls = df.urls.str.replace('\[|\]', '', regex=True).str.split(',').apply(remove_empty_urls).apply(lambda x: x if x else np.NaN)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def remove_empty_urls(x: list):
    for i in x:
        if i == '':
            x.remove(i)
    return x

df.urls = df.urls.str.replace('\[|\]', '', regex=True).str.split(',').apply(remove_empty_urls).apply(lambda x: x if x else np.NaN)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def remove_empty_urls(x: list):
    for i in x:
        if i == '':
            x.remove(i)
    return x


__output__ = df.urls = df.urls.str.replace('\\[|\\]', '', regex=True
    ).str.split(',').apply(remove_empty_urls).apply(lambda x: x if x else
    np.NaN)
</code></pre>
        <p><span onclick="$('#var_output_d2913897').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_d2913897" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0        ['https://www.dw.com/en/ukraine-war-worsens-fo...
1                                                      NaN
2                 ['https://cliffordribner.com/?p=339699']
3                                                      NaN
4                                                      NaN
                               ...                        
43392                                                  NaN
43393    ['https://www.oryxspioenkop.com/2022/02/attack...
43394                                                  NaN
43395                                                  NaN
43396                                                  NaN
Name: urls, Length: 43397, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>conversation_id</th>
      <th>created_at</th>
      <th>date</th>
      <th>time</th>
      <th>timezone</th>
      <th>user_id</th>
      <th>...</th>
      <th>cashtags</th>
      <th>link</th>
      <th>retweet</th>
      <th>quote_url</th>
      <th>video</th>
      <th>thumbnail</th>
      <th>reply_to</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1546893528218976256</td>
      <td>1546893528218976256</td>
      <td>2022-07-12 21:55:31 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:31</td>
      <td>530</td>
      <td>1459600109445033990</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/ejustin46/status/1546893528218976256</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1546893503208251393</td>
      <td>1546893503208251393</td>
      <td>2022-07-12 21:55:25 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:25</td>
      <td>530</td>
      <td>122167302</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Ing_Var/status/1546893503208251393</td>
      <td>False</td>
      <td>https://twitter.com/lilygrutcher/status/1546805702089445376</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1546893476402536454</td>
      <td>1546893476402536454</td>
      <td>2022-07-12 21:55:19 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:19</td>
      <td>530</td>
      <td>581782217</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/cliffordribner/status/1546893476402536454</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1546893470421471240</td>
      <td>1546893470421471240</td>
      <td>2022-07-12 21:55:17 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:17</td>
      <td>530</td>
      <td>626731783</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/kroon125/status/1546893470421471240</td>
      <td>False</td>
      <td>NaN</td>
      <td>1</td>
      <td>https://pbs.twimg.com/media/FXerRyGXwAAN04Q.jpg</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1546893303584546816</td>
      <td>1546893303584546816</td>
      <td>2022-07-12 21:54:38 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:54:38</td>
      <td>530</td>
      <td>122167302</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Ing_Var/status/1546893303584546816</td>
      <td>False</td>
      <td>https://twitter.com/vyshebaba/status/1546472239767371782</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1546893107404455936</td>
      <td>1546893107404455936</td>
      <td>2022-07-12 21:53:51 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:53:51</td>
      <td>530</td>
      <td>821227993741885441</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/LukeRussell1281/status/1546893107404455936</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1546893050345127941</td>
      <td>1541210396463431681</td>
      <td>2022-07-12 21:53:37 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:53:37</td>
      <td>530</td>
      <td>98780424</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Blockdog1/status/1546893050345127941</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'PatrykLesniak7', 'name': 'Lightning', 'id': '1382847873814044674'}, {'screen_name': 'StoneMan489', 'name': 'Matt stone489', 'id': '1428663970408407041'}, {'screen_name': 'brxarx', 'name': 'Brxarx', 'id': '1304301715634548737'}, {'screen_name': 'RajendranTheva1', 'name': 'Wisdom_trade1', 'id': '1253367340768456705'}, {'screen_name': 'QuocVu59239912', 'name': 'Bloody_Slayer', 'id': '1233063275434143744'}, {'screen_name': 'War_Mapper', 'name': 'Ukraine War Map', 'id': '1496850942209183744'}]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>43390</th>
      <td>1543352577890209792</td>
      <td>1543352577890209792</td>
      <td>2022-07-03 03:25:03 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:25:03</td>
      <td>530</td>
      <td>1196304745603817472</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/dissectmarkets/status/1543352577890209792</td>
      <td>False</td>
      <td>https://twitter.com/jseldin/status/1541792996596875267</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43391</th>
      <td>1543352573121396736</td>
      <td>1543352573121396736</td>
      <td>2022-07-03 03:25:02 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:25:02</td>
      <td>530</td>
      <td>422071593</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GFloars/status/1543352573121396736</td>
      <td>False</td>
      <td>https://twitter.com/Aryan_warlord/status/1543289684981211137</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43392</th>
      <td>1543352544776392705</td>
      <td>1543352544776392705</td>
      <td>2022-07-03 03:24:55 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:55</td>
      <td>530</td>
      <td>2255439716</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GuntersChain/status/1543352544776392705</td>
      <td>False</td>
      <td>https://twitter.com/uawarinfo/status/1543350776654974978</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43393</th>
      <td>1543352544684122113</td>
      <td>1543352544684122113</td>
      <td>2022-07-03 03:24:55 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:55</td>
      <td>530</td>
      <td>3104222776</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Rebel44CZ/status/1543352544684122113</td>
      <td>False</td>
      <td>NaN</td>
      <td>1</td>
      <td>https://pbs.twimg.com/media/FWsWONDXgAEOizv.jpg</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43394</th>
      <td>1543352492624338945</td>
      <td>1542993153912881152</td>
      <td>2022-07-03 03:24:43 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:43</td>
      <td>530</td>
      <td>505370909</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/AmyXi11/status/1543352492624338945</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'NogrowthCole', 'name': 'cole', 'id': '1493598763'}, {'screen_name': 'RyanMaue', 'name': 'Ryan Maue', 'id': '16117029'}]</td>
    </tr>
    <tr>
      <th>43395</th>
      <td>1543352478409887745</td>
      <td>1543326437742198784</td>
      <td>2022-07-03 03:24:39 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:39</td>
      <td>530</td>
      <td>1542154254055612416</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/Somethngisthere/status/1543352478409887745</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'TimothyDSnyder', 'name': 'Timothy Snyder', 'id': '3129968261'}]</td>
    </tr>
    <tr>
      <th>43396</th>
      <td>1543352455064440832</td>
      <td>1543006934097338368</td>
      <td>2022-07-03 03:24:34 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:34</td>
      <td>530</td>
      <td>1300763166624886784</td>
      <td>...</td>
      <td>[]</td>
      <td>https://twitter.com/GladesYouth/status/1543352455064440832</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'MikeMalloyShow', 'name': 'The Mike Malloy Show', 'id': '27433794'}]</td>
    </tr>
  </tbody>
</table>
<p>43397 rows × 26 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>0        ['https://www.dw.com/en/ukraine-war-worsens-fo...
1                                                      NaN
2                 ['https://cliffordribner.com/?p=339699']
3                                                      NaN
4                                                      NaN
                               ...                        
43392                                                  NaN
43393    ['https://www.oryxspioenkop.com/2022/02/attack...
43394                                                  NaN
43395                                                  NaN
43396                                                  NaN
Name: urls, Length: 43397, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-ukraine-conflict/notebook_1.ipynb|||turn_5 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Create a new column simplified_domains with domain names (excluding subdomains) in the url.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>pattern = '.*\://(?:www.)?([^\/]+)'

def find_slds(x):
    x = [i.replace("'", '') for i in x]
    x = [re.findall(pattern, i) for i in x]
    slds = []
    for i in x:
        if i:
            i = i[0]
            slds.append(i)
    return slds

df['simplified_domains'] = df.urls.dropna().apply(find_slds)</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>pattern = '.*\://(?:www.)?([^\/]+)'

def find_slds(x):
    x = [i.replace("'", '') for i in x]
    x = [re.findall(pattern, i) for i in x]
    slds = []
    for i in x:
        if i:
            i = i[0]
            slds.append(i)
    return slds

df['simplified_domains'] = df.urls.dropna().apply(find_slds)</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>pattern = '.*\\://(?:www.)?([^\\/]+)'


def find_slds(x):
    x = [i.replace("'", '') for i in x]
    x = [re.findall(pattern, i) for i in x]
    slds = []
    for i in x:
        if i:
            i = i[0]
            slds.append(i)
    return slds


__output__ = df['simplified_domains'] = df.urls.dropna().apply(find_slds)
</code></pre>
        <p><span onclick="$('#var_output_09a6450f').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_09a6450f" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>0                          [dw.com]
2              [cliffordribner.com]
5                       [bbc.co.uk]
10             [washingtonpost.com]
17             [foreignaffairs.com]
                    ...            
43382    [news.dearbusinessman.com]
43384            [open.spotify.com]
43386                 [twitter.com]
43388                  [t.me, t.me]
43393           [oryxspioenkop.com]
Name: urls, Length: 19783, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df, pattern, __output__ </p>
    
          <p>df (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>conversation_id</th>
      <th>created_at</th>
      <th>date</th>
      <th>time</th>
      <th>timezone</th>
      <th>user_id</th>
      <th>...</th>
      <th>link</th>
      <th>retweet</th>
      <th>quote_url</th>
      <th>video</th>
      <th>thumbnail</th>
      <th>reply_to</th>
      <th>simplified_domains</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1546893528218976256</td>
      <td>1546893528218976256</td>
      <td>2022-07-12 21:55:31 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:31</td>
      <td>530</td>
      <td>1459600109445033990</td>
      <td>...</td>
      <td>https://twitter.com/ejustin46/status/1546893528218976256</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
      <td>[dw.com]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1546893503208251393</td>
      <td>1546893503208251393</td>
      <td>2022-07-12 21:55:25 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:25</td>
      <td>530</td>
      <td>122167302</td>
      <td>...</td>
      <td>https://twitter.com/Ing_Var/status/1546893503208251393</td>
      <td>False</td>
      <td>https://twitter.com/lilygrutcher/status/1546805702089445376</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1546893476402536454</td>
      <td>1546893476402536454</td>
      <td>2022-07-12 21:55:19 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:19</td>
      <td>530</td>
      <td>581782217</td>
      <td>...</td>
      <td>https://twitter.com/cliffordribner/status/1546893476402536454</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
      <td>[cliffordribner.com]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1546893470421471240</td>
      <td>1546893470421471240</td>
      <td>2022-07-12 21:55:17 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:55:17</td>
      <td>530</td>
      <td>626731783</td>
      <td>...</td>
      <td>https://twitter.com/kroon125/status/1546893470421471240</td>
      <td>False</td>
      <td>NaN</td>
      <td>1</td>
      <td>https://pbs.twimg.com/media/FXerRyGXwAAN04Q.jpg</td>
      <td>[]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1546893303584546816</td>
      <td>1546893303584546816</td>
      <td>2022-07-12 21:54:38 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:54:38</td>
      <td>530</td>
      <td>122167302</td>
      <td>...</td>
      <td>https://twitter.com/Ing_Var/status/1546893303584546816</td>
      <td>False</td>
      <td>https://twitter.com/vyshebaba/status/1546472239767371782</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1546893107404455936</td>
      <td>1546893107404455936</td>
      <td>2022-07-12 21:53:51 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:53:51</td>
      <td>530</td>
      <td>821227993741885441</td>
      <td>...</td>
      <td>https://twitter.com/LukeRussell1281/status/1546893107404455936</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
      <td>[bbc.co.uk]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1546893050345127941</td>
      <td>1541210396463431681</td>
      <td>2022-07-12 21:53:37 India Standard Time</td>
      <td>2022-07-12</td>
      <td>21:53:37</td>
      <td>530</td>
      <td>98780424</td>
      <td>...</td>
      <td>https://twitter.com/Blockdog1/status/1546893050345127941</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'PatrykLesniak7', 'name': 'Lightning', 'id': '1382847873814044674'}, {'screen_name': 'StoneMan489', 'name': 'Matt stone489', 'id': '1428663970408407041'}, {'screen_name': 'brxarx', 'name': 'Brxarx', 'id': '1304301715634548737'}, {'screen_name': 'RajendranTheva1', 'name': 'Wisdom_trade1', 'id': '1253367340768456705'}, {'screen_name': 'QuocVu59239912', 'name': 'Bloody_Slayer', 'id': '1233063275434143744'}, {'screen_name': 'War_Mapper', 'name': 'Ukraine War Map', 'id': '1496850942209183744'}]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>43390</th>
      <td>1543352577890209792</td>
      <td>1543352577890209792</td>
      <td>2022-07-03 03:25:03 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:25:03</td>
      <td>530</td>
      <td>1196304745603817472</td>
      <td>...</td>
      <td>https://twitter.com/dissectmarkets/status/1543352577890209792</td>
      <td>False</td>
      <td>https://twitter.com/jseldin/status/1541792996596875267</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43391</th>
      <td>1543352573121396736</td>
      <td>1543352573121396736</td>
      <td>2022-07-03 03:25:02 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:25:02</td>
      <td>530</td>
      <td>422071593</td>
      <td>...</td>
      <td>https://twitter.com/GFloars/status/1543352573121396736</td>
      <td>False</td>
      <td>https://twitter.com/Aryan_warlord/status/1543289684981211137</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43392</th>
      <td>1543352544776392705</td>
      <td>1543352544776392705</td>
      <td>2022-07-03 03:24:55 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:55</td>
      <td>530</td>
      <td>2255439716</td>
      <td>...</td>
      <td>https://twitter.com/GuntersChain/status/1543352544776392705</td>
      <td>False</td>
      <td>https://twitter.com/uawarinfo/status/1543350776654974978</td>
      <td>0</td>
      <td>NaN</td>
      <td>[]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43393</th>
      <td>1543352544684122113</td>
      <td>1543352544684122113</td>
      <td>2022-07-03 03:24:55 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:55</td>
      <td>530</td>
      <td>3104222776</td>
      <td>...</td>
      <td>https://twitter.com/Rebel44CZ/status/1543352544684122113</td>
      <td>False</td>
      <td>NaN</td>
      <td>1</td>
      <td>https://pbs.twimg.com/media/FWsWONDXgAEOizv.jpg</td>
      <td>[]</td>
      <td>[oryxspioenkop.com]</td>
    </tr>
    <tr>
      <th>43394</th>
      <td>1543352492624338945</td>
      <td>1542993153912881152</td>
      <td>2022-07-03 03:24:43 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:43</td>
      <td>530</td>
      <td>505370909</td>
      <td>...</td>
      <td>https://twitter.com/AmyXi11/status/1543352492624338945</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'NogrowthCole', 'name': 'cole', 'id': '1493598763'}, {'screen_name': 'RyanMaue', 'name': 'Ryan Maue', 'id': '16117029'}]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43395</th>
      <td>1543352478409887745</td>
      <td>1543326437742198784</td>
      <td>2022-07-03 03:24:39 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:39</td>
      <td>530</td>
      <td>1542154254055612416</td>
      <td>...</td>
      <td>https://twitter.com/Somethngisthere/status/1543352478409887745</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'TimothyDSnyder', 'name': 'Timothy Snyder', 'id': '3129968261'}]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43396</th>
      <td>1543352455064440832</td>
      <td>1543006934097338368</td>
      <td>2022-07-03 03:24:34 India Standard Time</td>
      <td>2022-07-03</td>
      <td>03:24:34</td>
      <td>530</td>
      <td>1300763166624886784</td>
      <td>...</td>
      <td>https://twitter.com/GladesYouth/status/1543352455064440832</td>
      <td>False</td>
      <td>NaN</td>
      <td>0</td>
      <td>NaN</td>
      <td>[{'screen_name': 'MikeMalloyShow', 'name': 'The Mike Malloy Show', 'id': '27433794'}]</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>43397 rows × 27 columns</p>
      
          <p>pattern (str):</p>
          <pre><code>.*\://(?:www.)?([^\/]+)</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>0                          [dw.com]
2              [cliffordribner.com]
5                       [bbc.co.uk]
10             [washingtonpost.com]
17             [foreignaffairs.com]
                    ...            
43382    [news.dearbusinessman.com]
43384            [open.spotify.com]
43386                 [twitter.com]
43388                  [t.me, t.me]
43393           [oryxspioenkop.com]
Name: urls, Length: 19783, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-ukraine-conflict/notebook_1.ipynb|||turn_6 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Among these simplified domain names, list the one that is most popular for each language. Show the language codes as index.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_l = df[['language', 'simplified_domains']]
df_l = df_l.dropna().explode(column='simplified_domains').groupby('language').apply(lambda x: x.value_counts().sort_values
(ascending=False).index[0][-1])
df_l</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_l = df[['language', 'simplified_domains']]
df_l = df_l.dropna().explode(column='simplified_domains').groupby('language').apply(lambda x: x.value_counts().sort_values
(ascending=False).index[0][-1])
df_l</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_l = df[['language', 'simplified_domains']]
df_l = df_l.dropna().explode(column='simplified_domains').groupby('language'
    ).apply(lambda x: x.value_counts().sort_values(ascending=False).index[0
    ][-1])
__output__ = df_l
</code></pre>
        <p><span onclick="$('#var_output_51cb8590').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_51cb8590" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>language
am               am.al-ain.com
ar                    youtu.be
bg                      bta.bg
bn              jagonews24.com
ca             thediplomat.com
                ...           
uk                 youtube.com
und                   youtu.be
ur     mozangblog.blogspot.com
vi       thongcongnghet.com.vn
zh                   gettr.com
Length: 52, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_l, __output__ </p>
    
          <p>df_l (Series):</p>
          <pre><code>language
am               am.al-ain.com
ar                    youtu.be
bg                      bta.bg
bn              jagonews24.com
ca             thediplomat.com
                ...           
uk                 youtube.com
und                   youtu.be
ur     mozangblog.blogspot.com
vi       thongcongnghet.com.vn
zh                   gettr.com
Length: 52, dtype: object</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>language
am               am.al-ain.com
ar                    youtu.be
bg                      bta.bg
bn              jagonews24.com
ca             thediplomat.com
                ...           
uk                 youtube.com
und                   youtu.be
ur     mozangblog.blogspot.com
vi       thongcongnghet.com.vn
zh                   gettr.com
Length: 52, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-ukraine-conflict/notebook_1.ipynb|||turn_7 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # How many simplified domains appear on that list more than once? Show the domain names and the language codes as lists.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_d = df_l.reset_index().rename(columns={0: 'simplified_domains'}).groupby('simplified_domains').apply(lambda x: x['language'].unique())
df_d[df_d.apply(len) > 1]</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_d = df_l.reset_index().rename(columns={0: 'simplified_domains'}).groupby('simplified_domains').apply(lambda x: x['language'].unique())
df_d[df_d.apply(len) > 1]</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_d = df_l.reset_index().rename(columns={(0): 'simplified_domains'}).groupby(
    'simplified_domains').apply(lambda x: x['language'].unique())
__output__ = df_d[df_d.apply(len) > 1]
</code></pre>
        <p><span onclick="$('#var_output_5e1d31bb').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_5e1d31bb" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>simplified_domains
bit.ly                          [cy, da, fi]
n-tv.de                             [de, no]
twitter.com                [fr, ht, iw, qme]
youtu.be       [ar, en, et, ja, nl, ro, und]
dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_d, __output__ </p>
    
          <p>df_d (Series):</p>
          <pre><code>simplified_domains
a.msn.com                                                  [sl]
am.al-ain.com                                              [am]
awfulavalanche.wordpress.com                               [lt]
baskenttekarar.com                                         [tr]
bbc.com                                                    [sv]
                                              ...              
tv9gujarati.com                                            [gu]
twitter.com                                   [fr, ht, iw, qme]
ukrainehelp.emergenzehack.info                             [it]
youtu.be                          [ar, en, et, ja, nl, ro, und]
youtube.com                                                [uk]
Length: 40, dtype: object</code></pre>
      
          <p>__output__ (Series):</p>
          <pre><code>simplified_domains
bit.ly                          [cy, da, fi]
n-tv.de                             [de, no]
twitter.com                [fr, ht, iw, qme]
youtu.be       [ar, en, et, ja, nl, ro, und]
dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-ukraine-conflict/notebook_1.ipynb|||turn_8 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # What is the most viral hashtag for each of the processed domains? List the simplified domains as index and the tags as a column</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>df_h = df.loc[:, ['simplified_domains', 'hashtags']]
df_h.dropna().explode('simplified_domains').explode('hashtags').groupby('simplified_domains').apply(lambda x: x.value_counts().sort_values
(ascending=False).index[0][-1])</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>df_h = df.loc[:, ['simplified_domains', 'hashtags']]
df_h.dropna().explode('simplified_domains').explode('hashtags').groupby('simplified_domains').apply(lambda x: x.value_counts().sort_values
(ascending=False).index[0][-1])</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>df_h = df.loc[:, ['simplified_domains', 'hashtags']]
__output__ = df_h.dropna().explode('simplified_domains').explode('hashtags'
    ).groupby('simplified_domains').apply(lambda x: x.value_counts().
    sort_values(ascending=False).index[0][-1])
</code></pre>
        <p><span onclick="$('#var_output_7cf0ecc4').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_7cf0ecc4" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (Series):</p>
          <pre><code>simplified_domains
.cbn.com                                                            []
.folha.uol.com.br    ['putin', 'bolsonaro', 'nuclear', 'submarine',...
.nhk.or.jp              ['ukrainewar', 'ukraine', 'japan', 'refugees']
1.Open                                                              []
10ztalk.com                                             ['ukrainewar']
                                           ...                        
zittrex.com                                                         []
zona.media           ['fuckputin', 'russian', 'ukrainewar', 'ukrain...
zoom.us                                                             []
zpr.io               ['ukrainewar', 'ukraine', 'war', 'army', 'mili...
zrzutka.pl           ['armukrainenow', 'ukrainewar', 'standwithukra...
Length: 2969, dtype: object</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_h, __output__ </p>
    
          <p>df_h (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>simplified_domains</th>
      <th>hashtags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[dw.com]</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>['ukraineunderattaсk', 'ukraineinvasion', 'ukrainewar', 'russianukrainianwar', 'russia', 'kiev', 'ukraine']</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[cliffordribner.com]</td>
      <td>['biden', 'putin', 'russia', 'ukraine', 'war']</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NaN</td>
      <td>['ukraine', 'ukrainecrisis', 'ukrainewar', 'stopputin', 'stoprussianaggression', 'warcrimes', 'crimesofwar', 'putinwarcriminal']</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NaN</td>
      <td>['ukraineunderattaсk', 'ukraineinvasion', 'ukrainewar', 'russianukrainianwar', 'russia', 'kiev', 'ukraine']</td>
    </tr>
    <tr>
      <th>5</th>
      <td>[bbc.co.uk]</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>43390</th>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43391</th>
      <td>NaN</td>
      <td>['ukrainewar', 'ukraine', 'ukrainerussianwar']</td>
    </tr>
    <tr>
      <th>43392</th>
      <td>NaN</td>
      <td>['ukrainerussianwar', 'ukrainewar']</td>
    </tr>
    <tr>
      <th>43393</th>
      <td>[oryxspioenkop.com]</td>
      <td>['ukrainewar']</td>
    </tr>
    <tr>
      <th>43394</th>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43395</th>
      <td>NaN</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43396</th>
      <td>NaN</td>
      <td>['ukrainewar']</td>
    </tr>
  </tbody>
</table>
<p>43397 rows × 2 columns</p>
      
          <p>__output__ (Series):</p>
          <pre><code>simplified_domains
.cbn.com                                                            []
.folha.uol.com.br    ['putin', 'bolsonaro', 'nuclear', 'submarine',...
.nhk.or.jp              ['ukrainewar', 'ukraine', 'japan', 'refugees']
1.Open                                                              []
10ztalk.com                                             ['ukrainewar']
                                           ...                        
zittrex.com                                                         []
zona.media           ['fuckputin', 'russian', 'ukrainewar', 'ukrain...
zoom.us                                                             []
zpr.io               ['ukrainewar', 'ukraine', 'war', 'army', 'mili...
zrzutka.pl           ['armukrainenow', 'ukrainewar', 'standwithukra...
Length: 2969, dtype: object</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.5, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-ukraine-conflict/notebook_1.ipynb|||turn_9 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # Whose tweets were replied to with thumbnails? Show their names, tweet and the picture links.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>def decode_str(x):
    x = list(eval(x))
    return x if x else np.nan

dfr_t = df.loc[:, ['reply_to', 'tweet', 'thumbnail']]
dfr_t['reply_to'] = dfr_t.reply_to.apply(decode_str)
dfr = dfr_t.dropna()
dfr.reply_to.all = dfr.reply_to.apply(lambda x: [i['name'] for i in x])
dfr = dfr.explode('reply_to')
dfr</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>def decode_str(x):
    x = list(eval(x))
    return x if x else np.nan

dfr_t = df.loc[:, ['reply_to', 'tweet', 'thumbnail']]
dfr_t['reply_to'] = dfr_t.reply_to.apply(decode_str)
dfr = dfr_t.dropna()
dfr.reply_to.all = dfr.reply_to.apply(lambda x: [i['name'] for i in x])
dfr = dfr.explode('reply_to')
dfr</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>def decode_str(x):
    x = list(eval(x))
    return x if x else np.nan


dfr_t = df.loc[:, ['reply_to', 'tweet', 'thumbnail']]
dfr_t['reply_to'] = dfr_t.reply_to.apply(decode_str)
dfr = dfr_t.dropna()
dfr.reply_to.all = dfr.reply_to.apply(lambda x: [i['name'] for i in x])
dfr = dfr.explode('reply_to')
__output__ = dfr
</code></pre>
        <p><span onclick="$('#var_output_98c5cc99').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_98c5cc99" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reply_to</th>
      <th>tweet</th>
      <th>thumbnail</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'PatrykLesniak7', 'name': 'Lightning', 'id': '1382847873814044674'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'brxarx', 'name': 'Brxarx', 'id': '1304301715634548737'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'RajendranTheva1', 'name': 'Wisdom_trade1', 'id': '1253367340768456705'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'QuocVu59239912', 'name': 'Bloody_Slayer', 'id': '1233063275434143744'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'War_Mapper', 'name': 'Ukraine War Map', 'id': '1496850942209183744'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>18</th>
      <td>{'screen_name': 'INCIndia', 'name': 'Congress', 'id': '1153045459'}</td>
      <td>@INCIndia check fact andkh congress bhakt--------- na covid tha na hi  russia Ukraine war fir 11% se upar inflation ku tha congress ke time wah re double standards America inflation 8 % pe ja raha hai break record india ne accha manage kiya hai congress hoti to 200 rs petrol pakka tha  https://t.co/4V8rmluSUL</td>
      <td>https://pbs.twimg.com/media/FXepkpyakAAaVj6.jpg</td>
    </tr>
    <tr>
      <th>38</th>
      <td>{'screen_name': 'Abundant_Power', 'name': 'LuckyNuke', 'id': '1469987703685013506'}</td>
      <td>@Abundant_Power Nice example how stats can be manipulated.  Fact is Coal in Germany's electricity mix is going down only in a short term due to the Ukraine war the coal part is going TEMPORARILY going up. Renewables are substituting coal &amp;amp; nuclear.  Take a look at a meaningful stat.  https://t.co/t8ehFHy0JE</td>
      <td>https://pbs.twimg.com/media/FXeoujXXoAMNhaf.jpg</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>43139</th>
      <td>{'screen_name': 'BidensWins', 'name': 'Biden Wins', 'id': '1486069441259397125'}</td>
      <td>@BidensWins Is this true Mr. Biden? Because if it is your doing nothing but looking out for your own interests. #Ukraine️ #UkraineWar  https://t.co/0OOFtZY1UR</td>
      <td>https://pbs.twimg.com/ext_tw_video_thumb/1543380750044733441/pu/img/p42XaQuu_q3YKgmH.jpg</td>
    </tr>
    <tr>
      <th>43256</th>
      <td>{'screen_name': 'EmmanuelMacron', 'name': 'Emmanuel Macron', 'id': '1976143068'}</td>
      <td>@EmmanuelMacron On en est à combien de morts innocents en #UkraineWar POUR RIEN ?! Et sans parler des autres exactions comme les viols ou les tortures...?!  Si en 2022, des Démocraties peuvent tjrs êtres ainsi agressées, c bien que l'Humanité n'a pas progressé, voire régressé ?!#GuerreEnUkraine  https://t.co/hsxzlruzKy</td>
      <td>https://pbs.twimg.com/tweet_video_thumb/FWsi8cfWAAIKuAb.jpg</td>
    </tr>
    <tr>
      <th>43257</th>
      <td>{'screen_name': 'MS2513479406', 'name': 'MS_25', 'id': '1088883005253271553'}</td>
      <td>@MS2513479406 @realTomBohn #Whataboutismus. Der letzte Eroberungskrieg vor dem Überfall des #Ruschismus auf die #Ukraine war 1991 Qayt; in Europa 1941 Barbarossa. Natürlich sind im Putin-#Faschismus immer andere schuld; das ist Teil des #Urfaschismus. "Seit 24. Feber wird jetzt zurückgeschossen!"  https://t.co/vGIvBoOqvp</td>
      <td>https://pbs.twimg.com/media/FWsi1IxX0AMXREx.jpg</td>
    </tr>
    <tr>
      <th>43257</th>
      <td>{'screen_name': 'realTomBohn', 'name': 'Tom Bohn', 'id': '1228725567832363008'}</td>
      <td>@MS2513479406 @realTomBohn #Whataboutismus. Der letzte Eroberungskrieg vor dem Überfall des #Ruschismus auf die #Ukraine war 1991 Qayt; in Europa 1941 Barbarossa. Natürlich sind im Putin-#Faschismus immer andere schuld; das ist Teil des #Urfaschismus. "Seit 24. Feber wird jetzt zurückgeschossen!"  https://t.co/vGIvBoOqvp</td>
      <td>https://pbs.twimg.com/media/FWsi1IxX0AMXREx.jpg</td>
    </tr>
    <tr>
      <th>43282</th>
      <td>{'screen_name': 'VviewSsonicMair', 'name': 'Sarah Jackman', 'id': '778045033828057092'}</td>
      <td>@VviewSsonicMair @TimothyDSnyder  YALE is the LEADING ANTI-Russia institution in America.  This article reflects YALE’s thinking on Ukraine war ⬇️⬇️  https://t.co/4faBQ9nfUP</td>
      <td>https://pbs.twimg.com/media/FWsfu9qUsAEAK8z.jpg</td>
    </tr>
    <tr>
      <th>43298</th>
      <td>{'screen_name': 'PaulaKoo1', 'name': 'Paula Koo', 'id': '716469514'}</td>
      <td>@PaulaKoo1 @Ukraine66251776 This is a Ukrainian worried about Ukraine army setting up military equipment near their homes? Sorry this Ukraine war is not what your led to believe.  https://t.co/RVSjeFSmII</td>
      <td>https://pbs.twimg.com/ext_tw_video_thumb/1543358259104567299/pu/img/Nc2Y8WZbym_APagk.jpg</td>
    </tr>
    <tr>
      <th>43298</th>
      <td>{'screen_name': 'Ukraine66251776', 'name': 'UkraineNews', 'id': '1517696955329228800'}</td>
      <td>@PaulaKoo1 @Ukraine66251776 This is a Ukrainian worried about Ukraine army setting up military equipment near their homes? Sorry this Ukraine war is not what your led to believe.  https://t.co/RVSjeFSmII</td>
      <td>https://pbs.twimg.com/ext_tw_video_thumb/1543358259104567299/pu/img/Nc2Y8WZbym_APagk.jpg</td>
    </tr>
  </tbody>
</table>
<p>1190 rows × 3 columns</p>
      
        <p><strong>Hyp output variables:</strong> dfr_t, dfr, __output__ </p>
    
          <p>dfr_t (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reply_to</th>
      <th>tweet</th>
      <th>thumbnail</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NaN</td>
      <td>Ukraine war worsens food insecurity worldwide: report  https://t.co/qfSEHGM8hH</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>Sweden considers sending Ukraine Archer systems.  #UkraineUnderAttaсk #UkraineInvasion  #UkraineWar #RussianUkrainianWar #Russia #Kiev #Ukraine</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>The Brave Ukrainians Fight Back – And We Do Absolutely Nothing, As Has Been The Case Since Obama Under Every Democrat President #biden #putin #russia #ukraine #war  https://t.co/4lKmFIYqA2</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NaN</td>
      <td>(1) Apple heeft een boete van 2 miljoen roebel opgelegd voor het weigeren om gebruikersgegevens te lokaliseren #Ukraine #UkraineCrisis #UkraineWar #StopPutin #StopRussianAggression #WarCrimes #CrimesOfWar #PutinWarCriminal  https://t.co/5cltJjZ3Ov</td>
      <td>https://pbs.twimg.com/media/FXerRyGXwAAN04Q.jpg</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NaN</td>
      <td>I'm just talking about the fauna of Donetsk region, and Instagram and Facebook block this video  #UkraineUnderAttaсk #UkraineInvasion  #UkraineWar #RussianUkrainianWar #Russia #Kiev #Ukraine</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>NaN</td>
      <td>On one hand this should be taken seriously, on the other being resupplied by Iran is a statement on how hard Russia is having to work to maintain their offensive.  BBC News - Ukraine war: Iran plans to supply Russia with combat drones, US warns  https://t.co/u3tN8L0zeM</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>[{'screen_name': 'PatrykLesniak7', 'name': 'Lightning', 'id': '1382847873814044674'}, {'screen_name': 'StoneMan489', 'name': 'Matt stone489', 'id': '1428663970408407041'}, {'screen_name': 'brxarx', 'name': 'Brxarx', 'id': '1304301715634548737'}, {'screen_name': 'RajendranTheva1', 'name': 'Wisdom_trade1', 'id': '1253367340768456705'}, {'screen_name': 'QuocVu59239912', 'name': 'Bloody_Slayer', 'id': '1233063275434143744'}, {'screen_name': 'War_Mapper', 'name': 'Ukraine War Map', 'id': '1496850942209183744'}]</td>
      <td>@PatrykLesniak7 @StoneMan489 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper War is hell. The civilians need to get out of the way more need to leave the country 6 million is not enough. When a Russian missile is intercepted, the missiles fall and destroy randomly. Ukes need to leave all war zones. Only return with Russian issued passports</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>43390</th>
      <td>NaN</td>
      <td>This fact about the Russian-Ukraine war is why I believe that the defense industry will save the world economy from a major recession.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43391</th>
      <td>NaN</td>
      <td>#UkraineWar #Ukraine #UkraineRussianWar</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43392</th>
      <td>NaN</td>
      <td>Yo America you catching this?#UkraineRussianWar  #UkraineWar</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43393</th>
      <td>NaN</td>
      <td>#UkraineWar: Overview of Russian equipment losses added on 02/07/2022  Full list:  https://t.co/fmhlTM3zHA  https://t.co/wsscYe5TDD</td>
      <td>https://pbs.twimg.com/media/FWsWONDXgAEOizv.jpg</td>
    </tr>
    <tr>
      <th>43394</th>
      <td>[{'screen_name': 'NogrowthCole', 'name': 'cole', 'id': '1493598763'}, {'screen_name': 'RyanMaue', 'name': 'Ryan Maue', 'id': '16117029'}]</td>
      <td>@NogrowthCole @RyanMaue Would you like a planet? We need to be more responsible. Biden admin and Ukraine war are both issues but we don need to start transferring dependence on fossil fuel</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43395</th>
      <td>[{'screen_name': 'TimothyDSnyder', 'name': 'Timothy Snyder', 'id': '3129968261'}]</td>
      <td>@TimothyDSnyder Can you comment on John Mearsheimer's argument of June 16 in "The causes and consequences of the Ukraine war." You seem to ignore this perspective entirely and the evidence he adduced.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>43396</th>
      <td>[{'screen_name': 'MikeMalloyShow', 'name': 'The Mike Malloy Show', 'id': '27433794'}]</td>
      <td>@MikeMalloyShow #UkraineWar</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>43397 rows × 3 columns</p>
      
          <p>dfr (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reply_to</th>
      <th>tweet</th>
      <th>thumbnail</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'PatrykLesniak7', 'name': 'Lightning', 'id': '1382847873814044674'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'brxarx', 'name': 'Brxarx', 'id': '1304301715634548737'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'RajendranTheva1', 'name': 'Wisdom_trade1', 'id': '1253367340768456705'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'QuocVu59239912', 'name': 'Bloody_Slayer', 'id': '1233063275434143744'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'War_Mapper', 'name': 'Ukraine War Map', 'id': '1496850942209183744'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>18</th>
      <td>{'screen_name': 'INCIndia', 'name': 'Congress', 'id': '1153045459'}</td>
      <td>@INCIndia check fact andkh congress bhakt--------- na covid tha na hi  russia Ukraine war fir 11% se upar inflation ku tha congress ke time wah re double standards America inflation 8 % pe ja raha hai break record india ne accha manage kiya hai congress hoti to 200 rs petrol pakka tha  https://t.co/4V8rmluSUL</td>
      <td>https://pbs.twimg.com/media/FXepkpyakAAaVj6.jpg</td>
    </tr>
    <tr>
      <th>38</th>
      <td>{'screen_name': 'Abundant_Power', 'name': 'LuckyNuke', 'id': '1469987703685013506'}</td>
      <td>@Abundant_Power Nice example how stats can be manipulated.  Fact is Coal in Germany's electricity mix is going down only in a short term due to the Ukraine war the coal part is going TEMPORARILY going up. Renewables are substituting coal &amp;amp; nuclear.  Take a look at a meaningful stat.  https://t.co/t8ehFHy0JE</td>
      <td>https://pbs.twimg.com/media/FXeoujXXoAMNhaf.jpg</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>43139</th>
      <td>{'screen_name': 'BidensWins', 'name': 'Biden Wins', 'id': '1486069441259397125'}</td>
      <td>@BidensWins Is this true Mr. Biden? Because if it is your doing nothing but looking out for your own interests. #Ukraine️ #UkraineWar  https://t.co/0OOFtZY1UR</td>
      <td>https://pbs.twimg.com/ext_tw_video_thumb/1543380750044733441/pu/img/p42XaQuu_q3YKgmH.jpg</td>
    </tr>
    <tr>
      <th>43256</th>
      <td>{'screen_name': 'EmmanuelMacron', 'name': 'Emmanuel Macron', 'id': '1976143068'}</td>
      <td>@EmmanuelMacron On en est à combien de morts innocents en #UkraineWar POUR RIEN ?! Et sans parler des autres exactions comme les viols ou les tortures...?!  Si en 2022, des Démocraties peuvent tjrs êtres ainsi agressées, c bien que l'Humanité n'a pas progressé, voire régressé ?!#GuerreEnUkraine  https://t.co/hsxzlruzKy</td>
      <td>https://pbs.twimg.com/tweet_video_thumb/FWsi8cfWAAIKuAb.jpg</td>
    </tr>
    <tr>
      <th>43257</th>
      <td>{'screen_name': 'MS2513479406', 'name': 'MS_25', 'id': '1088883005253271553'}</td>
      <td>@MS2513479406 @realTomBohn #Whataboutismus. Der letzte Eroberungskrieg vor dem Überfall des #Ruschismus auf die #Ukraine war 1991 Qayt; in Europa 1941 Barbarossa. Natürlich sind im Putin-#Faschismus immer andere schuld; das ist Teil des #Urfaschismus. "Seit 24. Feber wird jetzt zurückgeschossen!"  https://t.co/vGIvBoOqvp</td>
      <td>https://pbs.twimg.com/media/FWsi1IxX0AMXREx.jpg</td>
    </tr>
    <tr>
      <th>43257</th>
      <td>{'screen_name': 'realTomBohn', 'name': 'Tom Bohn', 'id': '1228725567832363008'}</td>
      <td>@MS2513479406 @realTomBohn #Whataboutismus. Der letzte Eroberungskrieg vor dem Überfall des #Ruschismus auf die #Ukraine war 1991 Qayt; in Europa 1941 Barbarossa. Natürlich sind im Putin-#Faschismus immer andere schuld; das ist Teil des #Urfaschismus. "Seit 24. Feber wird jetzt zurückgeschossen!"  https://t.co/vGIvBoOqvp</td>
      <td>https://pbs.twimg.com/media/FWsi1IxX0AMXREx.jpg</td>
    </tr>
    <tr>
      <th>43282</th>
      <td>{'screen_name': 'VviewSsonicMair', 'name': 'Sarah Jackman', 'id': '778045033828057092'}</td>
      <td>@VviewSsonicMair @TimothyDSnyder  YALE is the LEADING ANTI-Russia institution in America.  This article reflects YALE’s thinking on Ukraine war ⬇️⬇️  https://t.co/4faBQ9nfUP</td>
      <td>https://pbs.twimg.com/media/FWsfu9qUsAEAK8z.jpg</td>
    </tr>
    <tr>
      <th>43298</th>
      <td>{'screen_name': 'PaulaKoo1', 'name': 'Paula Koo', 'id': '716469514'}</td>
      <td>@PaulaKoo1 @Ukraine66251776 This is a Ukrainian worried about Ukraine army setting up military equipment near their homes? Sorry this Ukraine war is not what your led to believe.  https://t.co/RVSjeFSmII</td>
      <td>https://pbs.twimg.com/ext_tw_video_thumb/1543358259104567299/pu/img/Nc2Y8WZbym_APagk.jpg</td>
    </tr>
    <tr>
      <th>43298</th>
      <td>{'screen_name': 'Ukraine66251776', 'name': 'UkraineNews', 'id': '1517696955329228800'}</td>
      <td>@PaulaKoo1 @Ukraine66251776 This is a Ukrainian worried about Ukraine army setting up military equipment near their homes? Sorry this Ukraine war is not what your led to believe.  https://t.co/RVSjeFSmII</td>
      <td>https://pbs.twimg.com/ext_tw_video_thumb/1543358259104567299/pu/img/Nc2Y8WZbym_APagk.jpg</td>
    </tr>
  </tbody>
</table>
<p>1190 rows × 3 columns</p>
      
          <p>__output__ (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reply_to</th>
      <th>tweet</th>
      <th>thumbnail</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'PatrykLesniak7', 'name': 'Lightning', 'id': '1382847873814044674'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'brxarx', 'name': 'Brxarx', 'id': '1304301715634548737'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'RajendranTheva1', 'name': 'Wisdom_trade1', 'id': '1253367340768456705'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'QuocVu59239912', 'name': 'Bloody_Slayer', 'id': '1233063275434143744'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>14</th>
      <td>{'screen_name': 'War_Mapper', 'name': 'Ukraine War Map', 'id': '1496850942209183744'}</td>
      <td>@PatrykLesniak7 @brxarx @RajendranTheva1 @QuocVu59239912 @War_Mapper Lol losing, you cannot see the facts?  https://t.co/3meJGbufot</td>
      <td>https://pbs.twimg.com/media/FXeqgfcWAAIAdAd.jpg</td>
    </tr>
    <tr>
      <th>18</th>
      <td>{'screen_name': 'INCIndia', 'name': 'Congress', 'id': '1153045459'}</td>
      <td>@INCIndia check fact andkh congress bhakt--------- na covid tha na hi  russia Ukraine war fir 11% se upar inflation ku tha congress ke time wah re double standards America inflation 8 % pe ja raha hai break record india ne accha manage kiya hai congress hoti to 200 rs petrol pakka tha  https://t.co/4V8rmluSUL</td>
      <td>https://pbs.twimg.com/media/FXepkpyakAAaVj6.jpg</td>
    </tr>
    <tr>
      <th>38</th>
      <td>{'screen_name': 'Abundant_Power', 'name': 'LuckyNuke', 'id': '1469987703685013506'}</td>
      <td>@Abundant_Power Nice example how stats can be manipulated.  Fact is Coal in Germany's electricity mix is going down only in a short term due to the Ukraine war the coal part is going TEMPORARILY going up. Renewables are substituting coal &amp;amp; nuclear.  Take a look at a meaningful stat.  https://t.co/t8ehFHy0JE</td>
      <td>https://pbs.twimg.com/media/FXeoujXXoAMNhaf.jpg</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>43139</th>
      <td>{'screen_name': 'BidensWins', 'name': 'Biden Wins', 'id': '1486069441259397125'}</td>
      <td>@BidensWins Is this true Mr. Biden? Because if it is your doing nothing but looking out for your own interests. #Ukraine️ #UkraineWar  https://t.co/0OOFtZY1UR</td>
      <td>https://pbs.twimg.com/ext_tw_video_thumb/1543380750044733441/pu/img/p42XaQuu_q3YKgmH.jpg</td>
    </tr>
    <tr>
      <th>43256</th>
      <td>{'screen_name': 'EmmanuelMacron', 'name': 'Emmanuel Macron', 'id': '1976143068'}</td>
      <td>@EmmanuelMacron On en est à combien de morts innocents en #UkraineWar POUR RIEN ?! Et sans parler des autres exactions comme les viols ou les tortures...?!  Si en 2022, des Démocraties peuvent tjrs êtres ainsi agressées, c bien que l'Humanité n'a pas progressé, voire régressé ?!#GuerreEnUkraine  https://t.co/hsxzlruzKy</td>
      <td>https://pbs.twimg.com/tweet_video_thumb/FWsi8cfWAAIKuAb.jpg</td>
    </tr>
    <tr>
      <th>43257</th>
      <td>{'screen_name': 'MS2513479406', 'name': 'MS_25', 'id': '1088883005253271553'}</td>
      <td>@MS2513479406 @realTomBohn #Whataboutismus. Der letzte Eroberungskrieg vor dem Überfall des #Ruschismus auf die #Ukraine war 1991 Qayt; in Europa 1941 Barbarossa. Natürlich sind im Putin-#Faschismus immer andere schuld; das ist Teil des #Urfaschismus. "Seit 24. Feber wird jetzt zurückgeschossen!"  https://t.co/vGIvBoOqvp</td>
      <td>https://pbs.twimg.com/media/FWsi1IxX0AMXREx.jpg</td>
    </tr>
    <tr>
      <th>43257</th>
      <td>{'screen_name': 'realTomBohn', 'name': 'Tom Bohn', 'id': '1228725567832363008'}</td>
      <td>@MS2513479406 @realTomBohn #Whataboutismus. Der letzte Eroberungskrieg vor dem Überfall des #Ruschismus auf die #Ukraine war 1991 Qayt; in Europa 1941 Barbarossa. Natürlich sind im Putin-#Faschismus immer andere schuld; das ist Teil des #Urfaschismus. "Seit 24. Feber wird jetzt zurückgeschossen!"  https://t.co/vGIvBoOqvp</td>
      <td>https://pbs.twimg.com/media/FWsi1IxX0AMXREx.jpg</td>
    </tr>
    <tr>
      <th>43282</th>
      <td>{'screen_name': 'VviewSsonicMair', 'name': 'Sarah Jackman', 'id': '778045033828057092'}</td>
      <td>@VviewSsonicMair @TimothyDSnyder  YALE is the LEADING ANTI-Russia institution in America.  This article reflects YALE’s thinking on Ukraine war ⬇️⬇️  https://t.co/4faBQ9nfUP</td>
      <td>https://pbs.twimg.com/media/FWsfu9qUsAEAK8z.jpg</td>
    </tr>
    <tr>
      <th>43298</th>
      <td>{'screen_name': 'PaulaKoo1', 'name': 'Paula Koo', 'id': '716469514'}</td>
      <td>@PaulaKoo1 @Ukraine66251776 This is a Ukrainian worried about Ukraine army setting up military equipment near their homes? Sorry this Ukraine war is not what your led to believe.  https://t.co/RVSjeFSmII</td>
      <td>https://pbs.twimg.com/ext_tw_video_thumb/1543358259104567299/pu/img/Nc2Y8WZbym_APagk.jpg</td>
    </tr>
    <tr>
      <th>43298</th>
      <td>{'screen_name': 'Ukraine66251776', 'name': 'UkraineNews', 'id': '1517696955329228800'}</td>
      <td>@PaulaKoo1 @Ukraine66251776 This is a Ukrainian worried about Ukraine army setting up military equipment near their homes? Sorry this Ukraine war is not what your led to believe.  https://t.co/RVSjeFSmII</td>
      <td>https://pbs.twimg.com/ext_tw_video_thumb/1543358259104567299/pu/img/Nc2Y8WZbym_APagk.jpg</td>
    </tr>
  </tbody>
</table>
<p>1190 rows × 3 columns</p>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>

        <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        </head>
    
          <div>
            <h3 style="color:teal">Evaluating Example</h3>
            <p><strong>Notebook:</strong> russia-ukraine-conflict/notebook_1.ipynb|||turn_10 | <strong>Turn: 0</strong></p>
            <p><strong>Intent:</strong> # For the tweet that has been responded to the most, what hashtags were used in its replies? Show only unique hashtags as a set.</p>
            <p><strong>Having Visualization:</strong>False</p>
            <p><strong>Target:</strong></p> <pre><code>flat_map = lambda xs: sum(map(lambda x: x, xs), [])

df_tr = df.loc[:, ['reply_to']]
df_tr.reply_to = df_tr.reply_to.apply(decode_str).apply(lambda x: [i['id'] for i in x] if x is not np.NaN else x)
df_tr['hashtags'] = hashtags
df_tr = df_tr.dropna().explode('reply_to')
ids = df_tr.reply_to.value_counts().sort_values().tail(1).index.values[0]
set(flat_map(df_tr[df_tr.reply_to == ids].hashtags.apply(eval).to_list()))</code></pre>
            <p><strong>Target Output Variable:</strong> <pre><code>[]</code></pre></p>
            <hr>
          </div>
            <div>
              <p><strong>Hyp 0:</strong></p>
              <pre><code>flat_map = lambda xs: sum(map(lambda x: x, xs), [])

df_tr = df.loc[:, ['reply_to']]
df_tr.reply_to = df_tr.reply_to.apply(decode_str).apply(lambda x: [i['id'] for i in x] if x is not np.NaN else x)
df_tr['hashtags'] = hashtags
df_tr = df_tr.dropna().explode('reply_to')
ids = df_tr.reply_to.value_counts().sort_values().tail(1).index.values[0]
set(flat_map(df_tr[df_tr.reply_to == ids].hashtags.apply(eval).to_list()))</code></pre>
            </div>
                <p><strong>Pre-processed Hyp: </strong></p>
                <pre><code>flat_map = lambda xs: sum(map(lambda x: x, xs), [])
df_tr = df.loc[:, ['reply_to']]
df_tr.reply_to = df_tr.reply_to.apply(decode_str).apply(lambda x: [i['id'] for
    i in x] if x is not np.NaN else x)
df_tr['hashtags'] = hashtags
df_tr = df_tr.dropna().explode('reply_to')
ids = df_tr.reply_to.value_counts().sort_values().tail(1).index.values[0]
__output__ = set(flat_map(df_tr[df_tr.reply_to == ids].hashtags.apply(eval)
    .to_list()))
</code></pre>
        <p><span onclick="$('#var_output_02e7354a').toggle();">[Toggle to Show Eval Details]</span></p>
        <div id="var_output_02e7354a" style="display: none;">
          
        <p><strong>Ref output variables:</strong> __output__ </p>
    
          <p>__output__ (set):</p>
          <pre><code>{'bilohorivka'}</code></pre>
      
        <p><strong>Hyp output variables:</strong> df_tr, ids, __output__ </p>
    
          <p>df_tr (DataFrame):</p>
          <table border="1" class="dataframe rendered_dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reply_to</th>
      <th>hashtags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>44</th>
      <td>39344374</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>71</th>
      <td>869825995</td>
      <td>['yondenlhatoo', 'assange']</td>
    </tr>
    <tr>
      <th>165</th>
      <td>1221462414744596483</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>240</th>
      <td>573918122</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>443</th>
      <td>927513257946083329</td>
      <td>['ukrainewar']</td>
    </tr>
    <tr>
      <th>496</th>
      <td>1350150750966603777</td>
      <td>['lavrov', 'ukrainewar', 'stopthewar', 'trysomethingnew']</td>
    </tr>
    <tr>
      <th>496</th>
      <td>9624742</td>
      <td>['lavrov', 'ukrainewar', 'stopthewar', 'trysomethingnew']</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>42974</th>
      <td>948954070777253889</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43002</th>
      <td>551232817</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43002</th>
      <td>1496850942209183744</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43044</th>
      <td>1234260054368342016</td>
      <td>['ukrainewar']</td>
    </tr>
    <tr>
      <th>43044</th>
      <td>1110877798820777986</td>
      <td>['ukrainewar']</td>
    </tr>
    <tr>
      <th>43081</th>
      <td>32703165</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>43348</th>
      <td>1534511397597478912</td>
      <td>['ukrainewar']</td>
    </tr>
  </tbody>
</table>
<p>754 rows × 2 columns</p>
      
          <p>ids (str):</p>
          <pre><code>1496850942209183744</code></pre>
      
          <p>__output__ (set):</p>
          <pre><code>{'bilohorivka'}</code></pre>
      
        <p><strong>Ref -> Hyp match:</strong> [('__output__', '__output__', None)]</p>
    
        </div>
        <p><strong>Metrics:</strong> {'precision': 0.3333333333333333, 'recall': 1.0, 'accuracy': 1.0}</p>
    <hr>